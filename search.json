[{"title":"Java基础","url":"/2021/11/17/java-ji-chu/","content":"JDK版本：jdk11\n静态方法不能通过对象调用，只能通过类名调用。\n静态方法可被子类继承。\n类的int属性如果没有赋初值，则在创建类对象时，会被赋值为0。    JPA可能就是根据对象的id是否为0来判断表中是否存在该对象的记录，从而决定save方法是插入还是修改操作。类的String类型的属性不会再创建对象时被赋默认值，为null。    类的对象类型属性，创建时不会赋予默认值，为null。\n字符串关于字符串，在JVM的底层好像有一个字符串常量池。\npublic class Test &#123;    A a;    static class A&#123;        int id;        String name;        public void setName(String name) &#123;            this.name = name;        &#125;        public String getName() &#123;            return name;        &#125;        public void setId(int id) &#123;            this.id = id;        &#125;        public int getId() &#123;            return id;        &#125;    &#125;    public static void main(String[] args) &#123;         A a = new A();         a.setName(&quot;name&quot;);        System.out.println(a.getName());         Test.alter1(a);        System.out.println(a.getName());        System.out.println();        String s = &quot;hello&quot;;        System.out.println(s);        alter2(s);        System.out.println(s);    &#125;    static void alter1(A a)&#123;        a.name = &quot;alterA&quot;;    &#125;    static void alter2(String str)&#123;        str = &quot;hi&quot;;    &#125;&#125;\n运行结果：\n","categories":["java"]},{"title":"Java实体类","url":"/2022/03/10/java-shi-ti-lei/","content":"实体类的属性名称不能和数据库的保留字相同，否则会导致数据表创建错误。Mysql保留字有：    call\n","categories":["mysql","Java"]},{"title":"SpringBoot-JPA","url":"/2021/12/04/springboot-jpa/","content":"pom依赖配置jpa本身配置&lt;dependency&gt;\t&lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;\t&lt;artifactId&gt;spring-boot-starter-data-jpa&lt;/artifactId&gt;&lt;/dependency&gt;\n引入驱动依赖（mysql数据库操作必配）&lt;dependency&gt;\t&lt;groupId&gt;mysql&lt;/groupId&gt;\t&lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt;&lt;/dependency&gt;\n\nmysql数据库链接#数据库连接spring.datasource.url=jdbc:mysql://127.0.0.1:3306/admin?characterEncoding=UTF-8spring.datasource.username=用户名spring.datasource.password=用户密码#mysql驱动spring.datasource.driver-class-name=com.mysql.cj.jdbc.Driver\n\n使用步骤一、创建实体类实体类标注注解：@Entity、@Table。注意导入的包为：javax.persistence.*\n@Entity@Table(name = &quot;user&quot;)public class User &#123;    @Id    @GeneratedValue(strategy = GenerationType.IDENTITY)    @Column    int id;    @Column    String userName;    @Column    String name;    @Column    String headImg;    //性别    @Column    String gender;    @Column    String phone;    @Column    String email;    String password;    public void setId(int id) &#123;        this.id = id;    &#125;    public int getId() &#123;        return id;    &#125;    public void setUserName(String userName) &#123;        this.userName = userName;    &#125;    public String getUserName() &#123;        return userName;    &#125;    public void setName(String name) &#123;        this.name = name;    &#125;    public String getName() &#123;        return name;    &#125;    public void setHeadImg(String headImg) &#123;        this.headImg = headImg;    &#125;    public String getHeadImg() &#123;        return headImg;    &#125;    public void setGender(String gender) &#123;        this.gender = gender;    &#125;    public String getGender() &#123;        return gender;    &#125;    public void setPhone(String phone) &#123;        this.phone = phone;    &#125;    public String getPhone() &#123;        return phone;    &#125;    public void setEmail(String email) &#123;        this.email = email;    &#125;    public String getEmail() &#123;        return email;    &#125;    public void setPassword(String password) &#123;        this.password = password;    &#125;    public String getPassword() &#123;        return password;    &#125;&#125;\nJPA默认的字段命名规则是驼峰转换，eg：UserName –&gt; user_name。\nJPA配置修改#设置自动更新表结构spring.jpa.properties.hibernate.hbm2ddl.auto=updatespring.jpa.properties.hibernate.dialect=org.hibernate.dialect.MySQL5InnoDBDialect#在控制台显示sql语句spring.jpa.show-sql= true\n\n二、继承JpaRepository接口//User对应要操作的数据表实体类，Integer是int类型的封装类，固定不变public interface UserDAO extends JpaRepository&lt;User, Integer&gt; &#123;&#125;\n\n三、使用接口类进行CRUD操作当UserDAO继承了JpaRepository后，可以在其它类中注入UserDAO，使用UserDAO进行简单的crud操作。在类UserService标注注解@Service的作用是，向容器中添加该类的组件，之后可以在其它地方使用注解@Autowired注入该类对象。\n@Servicepublic class UserService &#123;    @Autowired    UserDAO userDAO;    public void add(User user)&#123;        userDAO.save(user);    &#125; &#125;\nJPA注入：    使用注解@Autowired。    内部使用了@Autowired的类，在外面不能使用new创建该类对象，而是使用@Autowired注入对象，否则会导致JPA注入失败，报空指针异常。    eg：UserController类中使用了new UserService创建对象，导致UserService类中UserDAO注入失败，userDAO为null\n@Controllerpublic class UserController &#123;    @RequestMapping(&quot;/hello&quot;)    @ResponseBody    public void hi()&#123;        new UserService().add(new User());    &#125;&#125;\n\n正确用法是使用@Autowired注入UserService对象，如下所示\n@Controllerpublic class UserController &#123;    @Autowired    UserService userService;    @RequestMapping(&quot;/hello&quot;)    @ResponseBody    public void hi()&#123;        userService.add(new User());    &#125;&#125;","categories":["mysql","SpringBoot"],"tags":["JPA"]},{"title":"SpringBoot-方法参数","url":"/2021/12/02/springboot-fang-fa-can-shu/","content":"方法参数封装","categories":["SpringBoot"]},{"title":"SpringBoot-注解","url":"/2021/11/15/springboot-zhu-jie/","content":"@Configuration注释类，向SpringBoot表示该类为一个配置类。该注解有一个属性proxyBeanMethods，默认为true，表示该类被SpringBoot所代理，可以理解为该被SpringBoot托管。@Configuration配置类本身也是一个组件，组件ID为类名（首字母小写）。\n@Bean用来注释方法，要和 “能将类作为组件添加到容器中” 的注解组合使用，例如@Configuration和@Conpoment。表示向IOC容器中添加一个组件，组件ID默认为方法名，组件实例为方法的返回值。当@Configuration的 proxyBeanMethods=true 时，当使用类对象调用注解了@Bean的方法时，SpringBoot会去容器中寻找该组件，返回该组件的引用，而不是重新构造一个对象实例。多次从获取时，仍然引用的是容器中组件实例，即该方法的返回值保持单实例。当@Configuration的proxyBeanMethods=false时，表示配置类不会由SpringBoot所代理，使用类对象调用注解@Bean方法时，SpringBoot不会去容器中寻找组件，而是直接创建一个实例，每次调用都会创建不同的实例。\n@Configuration(&quot;haha&quot;)public class test &#123;    @Bean    public User user()&#123;        return new User();    &#125;&#125;@SpringBootApplicationpublic class DemoApplication &#123;    public static void main(String[] args) &#123;        ConfigurableApplicationContext app = SpringApplication.run(DemoApplication.class, args);        System.out.println(app.containsBean(&quot;haha&quot;));        System.out.println(app.containsBean(&quot;user&quot;));    &#125;&#125;\n输出结果为：\n组件依赖：小结：注解@Bean和@Configuration表示在SpringBoot启动时，像容器中添加一个组件。但是如果proxyBeanMethods=true，表示该类被SpringBoot代理。注意：如果使用普通方式，通过构造方法创建是实例时，和注解@Configuration、@Bean没有任何关系。\n@Import注释类。表示向容器中添加组件。使用方式：@Import(“class”, “.class”)，组件名为全类名\n@Component标注在类上，表示将该类作为一个组件添加到Spring容器中。\n@ConfigurationProperties@ConfigurationProperties注解可以和@Component搭配（同一类中），也可以和@EnableConfigurationProperties搭配（不同类中）。@ConfigurationProperties将类的属性和配置文件中的属性进行绑定。如果该类只有@ConfigurationProperties注解而没有@Component注解，那么配置绑定功能是无法实现的，因为该类没有被作为组件添加到Spring容器中（不能享受Spring容器带来的强大功能），此时可以在其他类中使用@EnableConfigurationProperties注解，将类添加到容器中，开启配置绑定功能。代码示例：\npackage org.springframework.boot.autoconfigure.web;@ConfigurationProperties(&quot;spring.web&quot;)public class WebProperties &#123;\tpublic static class Resources &#123;        //和配置文件application.properties中的 spring.web.resources.static-locations 进行绑定\t\tprivate String[] staticLocations = CLASSPATH_RESOURCE_LOCATIONS;\t&#125;&#125;\n\n@EnableConfigurationProperties对只有@ConfigurationProperties注解而没有@Component注解的配置类，使用@EnableConfigurationProperties将配置类添加到容器中。代码示例：\npackage org.springframework.boot.autoconfigure.web.servlet;@Configuration(proxyBeanMethods = false)@ConditionalOnWebApplication(type = Type.SERVLET)@ConditionalOnClass(&#123; Servlet.class, DispatcherServlet.class, WebMvcConfigurer.class &#125;)@ConditionalOnMissingBean(WebMvcConfigurationSupport.class)@AutoConfigureOrder(Ordered.HIGHEST_PRECEDENCE + 10)@AutoConfigureAfter(&#123; DispatcherServletAutoConfiguration.class, TaskExecutionAutoConfiguration.class,\t\tValidationAutoConfiguration.class &#125;)public class WebMvcAutoConfiguration &#123;\t@Configuration(proxyBeanMethods = false)\t@Import(EnableWebMvcConfiguration.class)\t@EnableConfigurationProperties(&#123; WebMvcProperties.class,\t\t\torg.springframework.boot.autoconfigure.web.ResourceProperties.class, WebProperties.class &#125;)\t@Order(0)\tpublic static class WebMvcAutoConfigurationAdapter implements WebMvcConfigurer, ServletContextAware &#123;\t\t&#125;&#125;package org.springframework.boot.autoconfigure.web.servlet;@ConfigurationProperties(prefix = &quot;spring.mvc&quot;)public class WebMvcProperties &#123;&#125;\n\n参数自动封装表单的字段会被自动封装到参数对象中。表单name属性的值要和对象的属性名一致，否则会封装失败，造成对象的属性值为null的情况。代码示例：\n@GetMapping(&quot;/form_createManager&quot;)    public String createManager(Manager manager)&#123;        if(managerService.isExitsByManagerName(manager.getName()))&#123;            return &quot;redirect:/createManager.html&quot;;        &#125;else &#123;            managerService.add(manager);            return &quot;redirect:/listManager.html&quot;;        &#125;    &#125;\n&lt;form action=&quot;/form_createManager&quot;&gt;    &lt;input type=&quot;text&quot; placeholder=&quot;姓名&quot; name=&quot;name&quot;&gt;    &lt;input type=&quot;text&quot; placeholder=&quot;手机&quot; name=&quot;phone&quot;&gt;    &lt;input type=&quot;email&quot; placeholder=&quot;邮箱&quot; name=&quot;email&quot;&gt;    &lt;input type=&quot;submit&quot; value=&quot;提交&quot;&gt;&lt;/form&gt;","categories":["SpringBoot"],"tags":["注解"]},{"title":"aplayer","url":"/2021/10/30/aplayer/","content":"使用aplayer播放器\n安装aplayer使用命令fs    npm install aplayer –save\n文章添加音乐在文章头部Front-matter中添加语句，否则不成功    aplayer: true在文章正文中添加以下语句。（具体字段属性请参考官方文档）\n方法2：使用hexo-tag-aplayer插件实现安装插件    npm install –save hexo-tag-aplayer在hexo的配置文件 _config.yml 中添加以下语句。    aplayer:        true在文章正文添加以下语句。（具体字段属性请参考官方文档）使用hexo-tag-aplayer有个小问题，音乐播放列表列表不能折叠。添加”listfolded:true”后音乐页面直接不能显示了。\n\n\t\t\t\n\t\t\t\tconsole.error(\"Error: [hexo-tag-aplayer] Specified asset file not found (caffeine.mp3)\");\n\t\t\t\n\nwocao\n","categories":["blog"],"tags":["aplayer"]},{"title":"my-first-blog","url":"/2021/10/17/my-first-blog/","content":"Hexo + GitHub 搭建个人博客环境准备npm、git\n\n使用命令（均在git bash下执行）安装Hexo博客框架\nnpm install hexo-cli -g\n初始化项目文件夹\nhexo init 文件夹名称（后面不跟文件名称时，需要自己创建文件，并在切换到对应文件路径下执行该命令\n安装npm依赖。执行上条命令时，会提示dependencies 下载失败。按照提示运行命令。\nnpm install有时使用npm下载不成，可以使用cnpm install，多运行几次就好了（亲试）\n本地预览博客是否搭建成功。执行以下两条命令。\nhexo g\t#编译静态文件hexo s\t#本地预览\n访问 http://localhost:4000/ 。出现以下页面表示本地搭建成功。\n\n上线到Github准备工作：获取SSH密钥    查看本地有无SSH密钥    cd ~/.ssh    如果没有则生成密钥。    ssh-keygen -t rsa -C &quot;你的邮箱&quot;\t\t#会提示你设置密钥文件名称，和密码，两者都可以为空，直接回车    再次查看密钥文件，查询结果出现***.ssh文件表示成功，同样会显示密钥路径。Github设置SSH密钥    在setting中选中SSH and GPG keys，点击New SSH key，密钥名称任取，密钥内容使用记事本打开生成的密钥文件，复制过去，就ok了。安装Github部署插件    npm install hexo-deployer-git --saveGithub创建新库 username.github.io。修改项目目录下的配置文件。如下所示。    deploy: \t\ttype: git \t\trepo: git@github.com:up-bear/up-bear.github.io.git\t\t branch: master部署命令    hexo d每次修改博客后，需要使用以下命令重新部署hexo cleanhexo ghexo d访问博客网址username.github.io。\n\n    ","categories":["blog"]},{"title":"html","url":"/2021/10/31/html/","content":"textareatextarea标签：\ncols:字符列数rows:字符行数readonly:值true/false 是否设为只读\n去除首行缩进：将首尾标签放在同一行\n&lt;textarea&gt;hello&lt;/textarea&gt;\n去除下拉斜线：添加属性 resize: none\n&lt;textarea style=&quot;resize: none;&quot;&gt;hello&lt;/textarea&gt;\n去除滚动条：添加属性 overflow: hidden\n&lt;textarea style=&quot;overflow: hidden;&quot;&gt;hello&lt;/textarea&gt;\n去除边框：添加属性border: none\n&lt;textarea style=&quot;border: none;&quot;&gt;hello&lt;/textarea&gt;\n去除点击文本时的边框：添加属性 outline: none\n&lt;textarea style=&quot;outline: none;&quot;&gt;hello&lt;/textarea\n显示高度自适应：\n&lt;textarea  autoHeight=&quot;true&quot; readonly=&quot;readonly&quot; style=&quot;resize: \t\tnone; border: none; overflow: hidden; outline: \tnone;&quot;&gt;qwerrtyuiopasdfghjklzxcnm1234567890qwertyuiopasdfghjklzxcvbnm&lt;/textarea&gt;\n$(function()&#123;        $.fn.autoHeight = function()&#123;                function autoHeight(elem)&#123;                elem.style.height = &#x27;auto&#x27;;                elem.scrollTop = 0; //防抖动                elem.style.height = elem.scrollHeight + &#x27;px&#x27;;            &#125;            this.each(function()&#123;                autoHeight(this);                $(this).on(&#x27;keyup&#x27;, function()&#123;                    autoHeight(this);                &#125;);            &#125;);     &#125;                   $(&#x27;textarea[autoHeight]&#x27;).autoHeight();    &#125;)\ntextarea自适应小问题：实际textarea的宽度比文字行数多了一行\n&lt;!--单个媒体对象 start--&gt;&lt;div class=&quot;media&quot;&gt;&lt;div class=&quot;media-left&quot;&gt;&lt;a href=&quot;#&quot;&gt;&lt;img class=&quot;media-object&quot; src=&quot;../images/72534562.jpg&quot; alt=&quot;头像&quot; width=&quot;64px&quot; height=&quot;64px&quot;&gt;&lt;h5 style=&quot;margin: 0px;text-align: center;&quot;&gt;用户名&lt;/h5&gt;&lt;/a&gt;&lt;/div&gt;&lt;div class=&quot;media-body&quot;&gt;&lt;h4 class=&quot;media-heading&quot;&gt;Media heading&lt;/h4&gt;&lt;textarea cols=&quot;50&quot; rows=&quot;3&quot; style=&quot;resize: none; border: none; overflow: hidden; outline: none;&quot; readonly=&quot;true&quot;&gt;Cras sit amet nibh libero, in gravida nulla. Nulla vel metus scelerisque ante sollicitudin commodo.&lt;/textarea&gt;&lt;/div&gt;&lt;/div&gt;&lt;!--单个媒体对象 end--&gt;","categories":["html"]},{"title":"nginx初试","url":"/2022/04/06/nginx-chu-shi/","content":"Linux安装nginx，安装路径为 /usr/local/nginx 。启动及其他命令须在 sbin 目录下进行。常用命令\n启动nginx\t\t./nginx\t\t停止nginx\t\t./nginx\t-s stop\t重新加载nginx  ./nginx -s reload\n\n反向代理概念：客户端发送的请求经过中间件，然后派发到不同服务器的过程即为反向代理。正向代理代理的是客户端，特点是用户明确知道实际访问的服务器。反向代理代理的是服务器，特点是用户不知道实际要访问的服务器，服务器对用户来说是隐藏的，用户知道的是中间件。\n反向代理单个节点nginx.con配置\nserver &#123;\tlisten\t&quot;访问端口&quot;;\tserver_name:\t&quot;访问ip&quot;;\tlocation / &#123;\t\troot\thtml;\t\tindex\tindex.html index.html;\t\tproxy_name\t&quot;被代理的服务器ip:port&quot;;\t&#125;&#125;\n反向代理两个节点nginx.conf配置\nserver &#123;\tlisten\t&quot;访问端口&quot;;\tserver\t&quot;访问ip&quot;;\t\tlocation ~ /edu/ &#123;\t\tproxy_pass\thttp://op:port;\t&#125;\t\tlocation ~ /vod/ &#123;\t\tproxy_pass\thttp://ip:port;\t&#125;&#125;\n/edu/ 是正则表达式，nginx会根据客户端的访问路径，将请求派发到与正则表达式匹配的服务器。\n负载均衡概念：将请求派发到不同服务器上，减轻服务器的负担，提高系统的可用性和可靠性。\n默认轮询nginx.conf配置\nupstream myServer&#123;\tserver\tip:port;\tserver\tip:port;&#125;server&#123;\tlisten\tport;\tserver_name\t\tip;        location&#123;    \tproxy_pass\thttp://myServer;    \t    \troot\thtml;    \tindex\tindex.html\tindex.html;    &#125;&#125;\n分配权重nginx.conf配置\nupstream myServer&#123;\tserver\tip:port\t\tweight=10;\tserver\tip:port\t\tweight=5;\t&#125;server&#123;\tlisten\tport;\tserver_name\t\tip;        location&#123;    \tproxy_pass\thttp://myServer;    \t    \troot\thtml;    \tindex\tindex.html\tindex.html;    &#125;&#125;\nweight的值越大，请求被派发到该服务器的几率越大。\nip_hashnginx.conf配置\nupstream myServer&#123;\tip_hash;\tserver\tip:port;\tserver\tip:port;&#125;server&#123;\tlisten\tport;\tserver_name\t\tip;        location&#123;    \tproxy_pass\thttp://myServer;    \t    \troot\thtml;    \tindex\tindex.html\tindex.html;    &#125;&#125;\nnginx根据客户端的ip的hash值进行派发请求，此方法可以解决session问题。\nfairnginx.conf配置\nupstream myServer&#123;\tfair;\tserver\tip:port;\tserver\tip:port;&#125;server&#123;\tlisten\tport;\tserver_name\t\tip;        location&#123;    \tproxy_pass\thttp://myServer;    \t    \troot\thtml;    \tindex\tindex.html\tindex.html;    &#125;&#125;\nnginx根据服务器的响应时间来分配请求，响应时间越短越优先分配。\n动静分离看尚硅谷的nginx视频，感觉这部分讲的不是很好，和一般的反向代理差不多，但还是记录一下。本次测试是把静态资源放在nginx所在的主机下，在/myData/img 和 /myData/html 目录下放置静态资源。nginx.conf配置\nserver&#123;\tlisten\tport;\tserver_name\t\tip;        location&#123;    \tproxy_pass\thttp://myServer;    \t    \troot\thtml;    \tindex\tindex.html\tindex.html;    &#125;        #添加规则    location /html/ &#123;        root    /myData/;    &#125;    location /img/ &#123; \t\troot    /myData/; \t\t#访问/img/会把该目录下的资源列出来\t\tautoindex       on;    &#125;&#125;\n","categories":["nginx"]},{"title":"Java实体类和Mysql表结构","url":"/2021/11/26/mysql/","content":"mysql和实体类布尔类型mysql中没有布尔类型的数据，在实体类中的属性尽量使用布尔变量的封装类型Boolean\n@Entity@Table(name = &quot;a&quot;)public class A &#123;    @Id    @GeneratedValue(strategy = GenerationType.IDENTITY)    @Column    int id;    @Column    Boolean flag;        //set、get方法省略&#125;\n表结构中flag字段的类型为：\n字符串mysql中，字符串为空和为null，两者并不相等。字符串为空对应 “” 。要想查询数据表中字符串为空的记录，要传入参数 “” ,而不是 null\n\n\n索引（主键也是一种索引？在执行sql语句 show index from myTest 时，主键也被列了出来）\n\n\n创建索引创建表时创建索引：\ncreate table myTest(id int NOT NULL,name varchar(255) NOT NULL,age int(3) NOT NULL,weight int(3) NOT NULL,PRIMARY KEY (id),key in_myTest_weight(weight));\n创建表后添加索引：方式一\ncreate index in_sqltest_age on sqltest(age);\t//in_sqltest_age 索引名， sqltest 表名， age 字段名\n方式二\nalter table sqltest add index in_sqltest_name(name);\t//sqltest 表名， in_sqltest_name 索引名， name 字段名\n删除索引alter table sqltest drop index in_sqltest_age;\t//sqltest 表名， in_sqltest_age 索引名\n\n普通索引：index； 唯一索引：unique index。唯一索引即被索引的列中数据的值是唯一的，不允许重复。当列中的数据有重复时，创建唯一索引会失败；同样当创建好唯一索引后，插入重复数据的记录也会插入失败。\n唯一约束 UNIQUE创建表时添加 UNIQUE 约束\nCREATE TABLE Persons(Id_P int NOT NULL,LastName varchar(255) NOT NULL,FirstName varchar(255),Address varchar(255),City varchar(255),UNIQUE (Id_P));\n创建表时添加多个 UNIQUE 约束\nCREATE TABLE Persons(Id_P int NOT NULL,LastName varchar(255) NOT NULL,FirstName varchar(255),Address varchar(255),City varchar(255),CONSTRAINT uc_PersonID UNIQUE (Id_P,LastName));\n创建表后添加 UNIQUE 约束\nalter table sqltest add unique (name);\n创建表后添加多个 UNIQUE 约束\nalter table sqltest add unique (name, age);","categories":["mysql"],"tags":["实体类"]},{"title":"thymeleaf","url":"/2021/10/30/thymeleaf/","content":"动态包含页面&lt;script&gt;    $(&quot;#head&quot;).load(&quot;public/head.html&quot;);&lt;/script&gt;\nIDEA创建SpringBoot项目重定向重定向的默认访问路径是Resource/templates,想要访问Resource/static下的静态资源返回字符串要明确添加redirect，例如 return “redirect:html/hello.html”\nbootstrap&amp;thymeleaf二者不兼容：bootstrap静态页面经由thymeleaf动态打开后静态页面样式消失\n动态创建列表代码示例：\n&lt;table&gt;    &lt;thead&gt;    &lt;tr&gt;        &lt;th&gt;管理者名称&lt;/th&gt;        &lt;th&gt;手机&lt;/th&gt;    &lt;/tr&gt;    &lt;/thead&gt;    &lt;tbody&gt;    &lt;tr th:each=&quot;manager : $&#123;manager_list&#125;&quot;&gt;        &lt;td th:text=&quot;$&#123;manager.getName()&#125;&quot;&gt;&lt;/td&gt;        &lt;td th:text=&quot;$&#123;manager.phone&#125;&quot;&gt;&lt;/td&gt;    &lt;/tr&gt;    &lt;/tbody&gt;&lt;/table&gt;\n\n向request中放入一个名manager_list的List类型对象。 向Request、Model、ModelAndView中放入数据，都是一样的效果，因为三者最终都将数据放入了同一个地方（雷神SpringBoot2中有讲）\n使用Thymeleaf取数据，显示在列表中。 ${manager_list}:取出request中key为manager_list的对象 ${manager.getName()}和${manager.phone}两种方法都可以获取对象manager的属性\n\nThymeleaf常见错误\n路径拼写错误。 使用了Thymeleaf模板，默认使用了@Controller类的字符串返回类型会被当作转发请求，且返回的字符串不需要带后缀”.html’，因为Thymeleaf会默认去寻找html文件。如果想使用重定向，需要使用：return “redirect:请求路径”。\nthymeleaf获取request、session中的参数错误。 使用thymeleaf表达式 ${…} 获取数据时，一定要确保在到达该页面前一定已经向对应的request、session中放入了要取的数据，否则也会造成错误。 使用 ${对象.属性} 或 ${对象.方法} 获取数据时，一定确保属性名和方法名和Java类中的保持一致，即使少了一个字母也会报错\n\nbackground-image: url() 拼接设置背景\n&lt;div th:style=&quot;&#x27;background:url(&#x27; + @&#123;/&lt;path-to-image&gt;&#125; + &#x27;);&#x27;&quot;&gt;&lt;/div&gt;\n根据属性值改变背景\n&lt;div class=&quot;media-object resource-card-image&quot;  th:style=&quot;&#x27;background:url(&#x27; + @&#123;($&#123;collect.webLogo&#125;==&#x27;&#x27; ? &#x27;img/favicon.png&#x27; : $&#123;collect.webLogo&#125;)&#125; + &#x27;)&#x27;&quot; &gt;&lt;/div&gt;\n\n行内写法（表达式内联）语法：\n&lt;p&gt;Hello, [[$&#123;session.user.name&#125;]]!&lt;/p&gt;\n禁用内联：\n&lt;p th:inline=&quot;none&quot;&gt;A double array looks like this: [[1, 2, 3], [4, 5]]!&lt;/p&gt;","categories":["SpringBoot","html"],"tags":["bootstrap","thymeleaf"]},{"title":"注解与反射","url":"/2021/11/16/zhu-jie-yu-fan-she/","content":"注解Annotation作用：注释和解释（狂神说的，很喜欢，简洁）。被人用来注释代码，并交给JVM去解释执行。\n定义：\n@Target(&#123;ElementType.TYPE&#125;)@Retention(RetentionPolicy.RUNTIME)@interface MyAnnotation&#123;    public String value();&#125;\n以上就简单自定义了一个注解。在定义注解的时候可以使用其他注解。\n元注解：用来注解注解的注解。四个元注解：\n@Target 确定注解可以使用的地方，如类、接口、方法等@Retention 可以理解为注解的&quot;生命周期&quot;@Documented 此注解会被javadoc工具提取成文档@Inherited 允许子类继承父类中的注解\n\n反射Reflection个人理解：通过Class类去操纵对象的过程就称为反射。代码示例：\n\n","categories":["java"],"tags":["注解","反射"]},{"title":"开发问题汇总","url":"/2022/03/17/kai-fa-wen-ti-hui-zong/","content":"问题1——请路径参数获取问题使用ajax发送请求，在请求路径中拼接了一个参数 calledName ，在后台 controller 方法中使用 request.getAttribute(“calledName”) 获取 calledName ，结果为 null 。换一种方法使用 @RequestParam 注解却能获取到 calledName 的值。原因尚未知，在以后的开发中尽量使用 @RequestParam 注解获取参数值。请求路径中拼接参数的方式，GET 和 POST 都可以使用。\n问题2——ajax回调函数的返回数据data使用 $.ajax() 方式发送 ajax 请求，其中 datatype 的值设为 json，发现最终回调函数不能正常使用，将 datatype 这一参数设置不写，（后台 controller 方法注解是有 @RequestBody 的），回调函数能够正常使用。\n"},{"title":"重载与重写","url":"/2021/11/16/chong-zai-yu-chong-xie/","content":"重载描述：一个类中，同一个方法名，有用多个参数类型或数量不同的方法实现，则称之为方法重载。代码示例：\npublic class A&#123;\tpublic void methodA()&#123;&#125;;\tpublic void methodA(int a)&#123;&#125;;    public void methodA(String str)&#123;&#125;;&#125;\n\n继承定义：\npublic class B extends A&#123;\t&#125;\n类B继承了类A，B拥有A的所有方法（构造方法除外）和属性。类B可以对父类A的方法进行重写，还可以声明父类A没有的属性。构造方法：当父类有多个构造方法时，子类必须声明一个参数列表（可以是无参类型）和父类相同的构造方法，并在方法体的第一行调用父类的其中一个构造方法。注意，当父类只有默认无参构造方法时，子类的默认无参构造方法中默认调用了父类的无参构造方法。当以一个类声明了构造方法，默认的无参构造方法便不存在了。代码示例：\n示例一：public class Father &#123;    public Father()&#123;        System.out.println(&quot;Father&quot;);    &#125;    public Father(String name, String age)&#123;        System.out.println(name + age);    &#125;&#125;class Son extends Father&#123;    public Son(String name) &#123;        super();    &#125;&#125;示例二：public class Father &#123;    public Father()&#123;        System.out.println(&quot;Father&quot;);    &#125;    public Father(String name, String age)&#123;        System.out.println(name + age);    &#125;&#125;class Son extends Father&#123;\t//有默认的无参构造器，而且会默认调用父类的无参构造器\t\tpublic static void main(String[] args)&#123;\t\tnew Son();\t&#125;&#125;输出：Father示例三：public class Father &#123;    public Father(String name)&#123;        System.out.println(name);    &#125;    public Father(String name, String age)&#123;        System.out.println(name + age);    &#125;&#125;class Son extends Father&#123;\tpublic Son(String name)&#123;\t\tsuper(name + &quot;age&quot;);\t&#125;&#125;\n\n重写描述：子类继承父类，并对继承的父类方法进行重新实现的过程，称之为方法重写。\n代码示例\npublic class Father&#123;\tpublic String method1()&#123;\t\treturn &quot;father&quot;;\t&#125;&#125;public class Son extends Father&#123;\tpublic String method1()&#123;\t\treturn &quot;son&quot;\t&#125;&#125;\n\n向上转型与向下转型向上转型描述：把子类的对象实例赋值给父类的引用。代码示例：\npublic class Father&#123;\tpublic void method1()&#123;\t\tSystem.out.println(&quot;father&quot;);\t&#125;&#125;public class B extends Father&#123;\tpublic void method1()&#123;\t\tSystem.out.println(&quot;son&quot;);\t&#125;\t\tpublic static void main(String[] args)&#123;\t\tFather f = new Son();\t//向上转型,将子类实例赋值给父类引用。可以理解为把子类对象向上转换成父类对象。 \t\tf.method1();\t//输出结果为&quot;son&quot;,而不是&quot;father&quot;\t&#125;&#125;\n通过向上转型的获得的对象引用，在调用方法时，只能调用父类中已有的方法，但执行的方法体是子类的方法。\n易混淆情况：\npublic class Father&#123;\tpublic void method1()&#123;\t\tSystem.out.println(&quot;father&quot;);\t&#125;\t\tpublic void method2()&#123;\t\tSystem.out.println(&quot;father.method2&quot;);\t&#125;&#125;public class B extends Father&#123;\tpublic void method1()&#123;\t\tSystem.out.println(&quot;son&quot;);\t&#125;\t\tpublic static void main(String[] args)&#123;\t\tFather f = new Son();\t//向上转型,将子类实例赋值给父类引用。可以理解为把子类对象向上转换成父类对象。 \t\tf.method2();\t//输出结果为&quot;father.method2&quot;,method2()方法没有被子类B重写，是从父类A中继承过来的，也是类B的方法不要理解为method2不是B的方法。\t&#125;&#125;\n\n代码示例：\npublic class Father &#123;    public String method1()&#123;        return &quot;father&quot;;    &#125;&#125;class Son extends Father&#123;    public String method1()&#123;        return &quot;son&quot;;    &#125;    public String method2()&#123;        return &quot;Son.method2&quot;;    &#125;    public static void main(String[] args)&#123;        Father f = new Son();        //System.out.println(f.method2());\t该行会提示报错，因为f此时是Father类型，没有method2()方法        System.out.println(((Son)f).method2());\t//此时再使用向下转型，便不会报错。输出结果为&quot;Son.method2&quot;    &#125;&#125;\n\n向上转型经典例题class A &#123;    public String show(D obj) &#123;        return (&quot;A and D&quot;);    &#125;    public String show(A obj) &#123;        return (&quot;A and A&quot;);    &#125;&#125;class B extends A&#123;    public String show(B obj)&#123;        return (&quot;B and B&quot;);    &#125;    public String show(A obj)&#123;        return (&quot;B and A&quot;);    &#125;&#125;class C extends B&#123;&#125;class D extends B&#123;&#125;public class Demo &#123;    public static void main(String[] args) &#123;        A a1 = new A();        A a2 = new B();        B b = new B();        C c = new C();        D d = new D();        System.out.println(&quot;1--&quot; + a1.show(b));        System.out.println(&quot;2--&quot; + a1.show(c));        System.out.println(&quot;3--&quot; + a1.show(d));        System.out.println(&quot;4--&quot; + a2.show(b));        System.out.println(&quot;5--&quot; + a2.show(c));        System.out.println(&quot;6--&quot; + a2.show(d));        System.out.println(&quot;7--&quot; + b.show(b));        System.out.println(&quot;8--&quot; + b.show(c));        System.out.println(&quot;9--&quot; + b.show(d));    &#125;&#125;//结果：//1--A and A//2--A and A//3--A and D//4--B and A//5--B and A//6--A and D//7--B and B//8--B and B//9--A and D//能看懂这个结果么？先自分析一下。\n这个例子是非常复杂的啦，要想完全理解后面几个输出结果还要知道一条重要知识：\n继承链中对象方法的调用的优先级：this.show(O)、super.show(O)、this.show((super)O)、super.show((super)O)(其实按照我前面的理解，感觉这一条原则不要也行，因为子类没有重写的方法是默认继承自父类的，验证了一下例题也没问题)\n对于输出4，a2.show(b))的输出结果是”B and A”。对象a2是A类型，但是指向B类型实例，为向上转型。a2可执行的方法名为类A中的方法，public String show(D obj)和public String show(A obj)；\n继承链第一步：this.show(O)显然不行，因为对象b是B类型，可执行方法中没有符合要求的。继承链第二步：super.show(O)，显然没有符合要求的。继承链第三步：this.show((super)O)，即shou((A) b)，执行类B中的方法show(A obj)，输出&quot;B and A&quot;\n对于输出5，分析同输出4，略。对于输出6，a2.show(d))的输出结果为”A and D”，也很好理解。\n继承链第一步：this.show(O)显然可以，因为类B继承了类A的public String show(D obj)方法，\n\n\n\n参考博文\n","categories":["java"]},{"title":"SpringBoot源码笔记","url":"/2022/01/19/springboot-yuan-ma-bi-ji/","content":"静态资源默认路径项目资源文件夹resources下：/META-INF/resources/、/resources/、/static/、/public/ 共四个路径。即使是使用了thymeleaf模板的情况下，放在以上路径下的静态资源仍然可以被访问，而且在这些路径下的html页面中使用thymeleaf语法同样有效。（thymeleaf似乎值对拦截再templates路径下的资源访问进行拦截设置）源码探究：\npackage org.springframework.boot.autoconfigure.web;@ConfigurationProperties(&quot;spring.web&quot;)public class WebProperties &#123;\tpublic static class Resources &#123;\t\tprivate static final String[] CLASSPATH_RESOURCE_LOCATIONS = &#123; &quot;classpath:/META-INF/resources/&quot;,&quot;classpath:/resources/&quot;, &quot;classpath:/static/&quot;, &quot;classpath:/public/&quot; &#125;;\t&#125;&#125;\n自定义资源路径注解@ConfigurationProperties(“spring.web”)，WebProperties类下的属性和配置文件进行了绑定，在配置文件application.properties中即可自定义静态资源访问路径。\n##由于CLASSPATH_RESOURCE_LOCATIONS被final修饰，所以不能修改##类属性和配置文件的对应规则：spring.web为注解设置前缀，resource对应内部类Resources的类名，static-locations对应类属性staticLocationsspring.web.resources.static-locations = 自定义资源路径\n源码探究：\npackage org.springframework.boot.autoconfigure.web;@ConfigurationProperties(&quot;spring.web&quot;)public class WebProperties &#123;\tpublic static class Resources &#123;\t\tprivate static final String[] CLASSPATH_RESOURCE_LOCATIONS = &#123; &quot;classpath:/META-INF/resources/&quot;,&quot;classpath:/resources/&quot;, &quot;classpath:/static/&quot;, &quot;classpath:/public/&quot; &#125;;\t\tprivate String[] staticLocations = CLASSPATH_RESOURCE_LOCATIONS;\t&#125;&#125;\n\n资源访问前缀默认访问前缀：/源码探究：\n@ConfigurationProperties(prefix = &quot;spring.mvc&quot;)public class WebMvcProperties &#123;\tpublic static class Servlet &#123;\t\t/**\t\t * Path of the dispatcher servlet. Setting a custom value for this property is not\t\t * compatible with the PathPatternParser matching strategy.\t\t */\t\tprivate String path = &quot;/&quot;;\t&#125;&#125;\n自定义访问前缀：\nspring.web.servlet.path = 自定义前缀（注意要“/”结尾）\n\n\nweb请求处理过程所有web请求都会进入到 org.springframework.web.servlet 包下的 DispatcherServlet 类的 doDispatch(HttpServletRequest request, HttpServletResponse response) 方法中\nprotected void doDispatch(HttpServletRequest request, HttpServletResponse response) throws Exception &#123;\tHttpServletRequest processedRequest = request;\tHandlerExecutionChain mappedHandler = null;\t    boolean multipartRequestParsed = false;\tWebAsyncManager asyncManager = WebAsyncUtils.getAsyncManager(request);\t\ttry &#123;\t\t\tModelAndView mv = null;\t\tException dispatchException = null;\t\ttry &#123;\t\t\tprocessedRequest = checkMultipart(request);\t\t\tmultipartRequestParsed = (processedRequest != request);\t\t\t// Determine handler for the current request.\t\t\t//***获取映射处理器，进入该方法可以看到所有的请求路径映射***\t\t\tmappedHandler = getHandler(processedRequest);\t\t\tif (mappedHandler == null) &#123;\t\t\t\tnoHandlerFound(processedRequest, response);\t\t\t\treturn;\t\t\t&#125;\t\t\t// Determine handler adapter for the current request.\t\t\tHandlerAdapter ha = getHandlerAdapter(mappedHandler.getHandler());\t\t\t// Process last-modified header, if supported by the handler.\t\t\tString method = request.getMethod();\t\t\tboolean isGet = HttpMethod.GET.matches(method);\t\t\tif (isGet || HttpMethod.HEAD.matches(method)) &#123;\t\t\t\tlong lastModified = ha.getLastModified(request, mappedHandler.getHandler());\t\t\t\tif (new ServletWebRequest(request, response).checkNotModified(lastModified) &amp;&amp; isGet) &#123;\t\t\t\t\treturn;\t\t\t\t&#125;\t\t\t&#125;\t\t\tif (!mappedHandler.applyPreHandle(processedRequest, response)) &#123;\t\t\t\treturn;\t\t\t&#125;\t\t\t//***（1）***             //***真正要开始处理请求映射的方法***\t\t\t// Actually invoke the handler.\t\t\tmv = ha.handle(processedRequest, response, mappedHandler.getHandler());\t\t\tif (asyncManager.isConcurrentHandlingStarted()) &#123;\t\t\t\treturn;\t\t\t&#125;\t\t\tapplyDefaultViewName(processedRequest, mv);\t\t\tmappedHandler.applyPostHandle(processedRequest, response, mv);\t\t&#125;\t\tcatch (Exception ex) &#123;\t\t\tdispatchException = ex;\t\t&#125;\t\tcatch (Throwable err) &#123;\t\t\t// As of 4.3, we&#x27;re processing Errors thrown from handler methods as well,\t\t\t// making them available for @ExceptionHandler methods and other scenarios.\t\t\tdispatchException = new NestedServletException(&quot;Handler dispatch failed&quot;, err);\t\t&#125;\t\tprocessDispatchResult(processedRequest, response, mappedHandler, mv, dispatchException);\t&#125;\tcatch (Exception ex) &#123;\t\ttriggerAfterCompletion(processedRequest, response, mappedHandler, ex);\t&#125;\tcatch (Throwable err) &#123;\t\ttriggerAfterCompletion(processedRequest, response, mappedHandler,\t\t\tnew NestedServletException(&quot;Handler processing failed&quot;, err));\t&#125;\tfinally &#123;\t\tif (asyncManager.isConcurrentHandlingStarted()) &#123;\t\t\t// Instead of postHandle and afterCompletion\t\t\tif (mappedHandler != null) &#123;\t\t\t\tmappedHandler.applyAfterConcurrentHandlingStarted(processedRequest, response);\t\t\t&#125;\t\t&#125;\t\telse &#123;\t\t\t// Clean up any resources used by a multipart request.\t\t\tif (multipartRequestParsed) &#123;\t\t\t\tcleanupMultipart(processedRequest);\t\t\t&#125;\t\t&#125;\t&#125;&#125;\n\n执行 mappedHandler = getHandler(processedRequest) ，进入到 getHandler() 方法\nprotected HandlerExecutionChain getHandler(HttpServletRequest request) throws Exception &#123;\tif (this.handlerMappings != null) &#123;\t\t//***mapping中包含了所有的请求路径，和请求路径映射的方法。\t\tfor (HandlerMapping mapping : this.handlerMappings) &#123;\t\t\tHandlerExecutionChain handler = mapping.getHandler(request);\t\t\tif (handler != null) &#123;\t\t\t\treturn handler;\t\t\t&#125;\t\t&#125;\t&#125;\treturn null;&#125;\nthis.handlerMappings:    mapping:    包含了所有请求路径和请求路径的映射方法        \n执行 mv = ha.handle(processedRequest, response, mappedHandler.getHandler()) 时，会进入到 AbstractHandlerMethodAdapter 类的 handle(HttpServletRequest request, HttpServletResponse response, Object handler) 方法中（共有四个HandleMethodAdapter， 分别是…）。\npublic final ModelAndView handle(HttpServletRequest request, HttpServletResponse response, Object handler)\t\t\tthrows Exception &#123;\t\treturn handleInternal(request, response, (HandlerMethod) handler);\t&#125;\n接着进入到 RequestMappingHandlerAdapter 类的 handleInternal(HttpServletRequest request,HttpServletResponse response, HandlerMethod handlerMethod) 方法\nprotected ModelAndView handleInternal(HttpServletRequest request,\t\t\tHttpServletResponse response, HandlerMethod handlerMethod) throws Exception &#123;\tModelAndView mav;\tcheckRequest(request);\t// Execute invokeHandlerMethod in synchronized block if required.\tif (this.synchronizeOnSession) &#123;\t\tHttpSession session = request.getSession(false);\t\tif (session != null) &#123;\t\t\tObject mutex = WebUtils.getSessionMutex(session);\t\t\tsynchronized (mutex) &#123;\t\t\t\tmav = invokeHandlerMethod(request, response, handlerMethod);\t\t\t&#125;\t\t&#125;\t\telse &#123;\t\t\t// No HttpSession available -&gt; no mutex necessary\t\t\tmav = invokeHandlerMethod(request, response, handlerMethod);\t\t&#125;\t&#125;\telse &#123;         //***(2)***         //***开始进入请求方法执行流程***\t\t// No synchronization on session demanded at all...\t\tmav = invokeHandlerMethod(request, response, handlerMethod);\t&#125;\t\tif (!response.containsHeader(HEADER_CACHE_CONTROL)) &#123;\t\tif (getSessionAttributesHandler(handlerMethod).hasSessionAttributes()) &#123;\t\t\tapplyCacheSeconds(response, this.cacheSecondsForSessionAttributeHandlers);\t\t&#125;\t\telse &#123;\t\t\tprepareResponse(response);\t\t&#125;\t&#125;\treturn mav;&#125;\n\n执行 mav = invokeHandlerMethod(request, response, handlerMethod) 进入到同类中的 invokeHandlerMethod(HttpServletRequest request,HttpServletResponse response, HandlerMethod handlerMethod) 方法。\nprotected ModelAndView invokeHandlerMethod(HttpServletRequest request,\t\tHttpServletResponse response, HandlerMethod handlerMethod) throws Exception &#123;\tServletWebRequest webRequest = new ServletWebRequest(request, response);\ttry &#123;\t\tWebDataBinderFactory binderFactory = getDataBinderFactory(handlerMethod);\t\tModelFactory modelFactory = getModelFactory(handlerMethod, binderFactory);\t\tServletInvocableHandlerMethod invocableMethod = createInvocableHandlerMethod(handlerMethod);\t\tif (this.argumentResolvers != null) &#123;\t\t\t\t\t\t  //***设置请求方法的参数解析器***invocableMethod.setHandlerMethodArgumentResolvers(this.argumentResolvers);\t\t&#125;\t\tif (this.returnValueHandlers != null) &#123;//***设置请求方法的返回值处理器***invocableMethod.setHandlerMethodReturnValueHandlers(this.returnValueHandlers);\t\t&#125;\t\tinvocableMethod.setDataBinderFactory(binderFactory);\t\tinvocableMethod.setParameterNameDiscoverer(this.parameterNameDiscoverer);\t\tModelAndViewContainer mavContainer = new ModelAndViewContainer();\t\tmavContainer.addAllAttributes(RequestContextUtils.getInputFlashMap(request));\t\tmodelFactory.initModel(webRequest, mavContainer, invocableMethod);\t\tmavContainer.setIgnoreDefaultModelOnRedirect(this.ignoreDefaultModelOnRedirect);\t\tAsyncWebRequest asyncWebRequest = WebAsyncUtils.createAsyncWebRequest(request, response);\t\tasyncWebRequest.setTimeout(this.asyncRequestTimeout);\t\tWebAsyncManager asyncManager = WebAsyncUtils.getAsyncManager(request);\t\tasyncManager.setTaskExecutor(this.taskExecutor);\t\tasyncManager.setAsyncWebRequest(asyncWebRequest);\t\tasyncManager.registerCallableInterceptors(this.callableInterceptors);\t\tasyncManager.registerDeferredResultInterceptors(this.deferredResultInterceptors);\t\tif (asyncManager.hasConcurrentResult()) &#123;\t\t\tObject result = asyncManager.getConcurrentResult();\t\t\tmavContainer = (ModelAndViewContainer) asyncManager.getConcurrentResultContext()[0];\t\t\tasyncManager.clearConcurrentResult();\t\t\tLogFormatUtils.traceDebug(logger, traceOn -&gt; &#123;\t\t\t\tString formatted = LogFormatUtils.formatValue(result, !traceOn);\t\t\t\treturn &quot;Resume with async result [&quot; + formatted + &quot;]&quot;;\t\t\t&#125;);\t\t\tinvocableMethod = invocableMethod.wrapConcurrentResult(result);\t\t&#125;        //***(3)***        //***开始处理请求方法的参数、试图等\t\tinvocableMethod.invokeAndHandle(webRequest, mavContainer);\t\tif (asyncManager.isConcurrentHandlingStarted()) &#123;\t\t\treturn null;\t\t&#125;\t\treturn getModelAndView(mavContainer, modelFactory, webRequest);\t&#125;\tfinally &#123;\t\twebRequest.requestCompleted();&#125;\n请求方法参数解析器 ：请求方法返回值处理器：\n执行 invocableMethod.invokeAndHandle(webRequest, mavContainer)，进入到 ServletInvocableHandlerMethod 类下的 invokeAndHandle(ServletWebRequest webRequest, ModelAndViewContainer mavContainer,Object… providedArgs) 方法。\npublic void invokeAndHandle(ServletWebRequest webRequest, ModelAndViewContainer mavContainer,\t\tObject... providedArgs) throws Exception &#123;    //***(4)***    //***对请求方法选择支持的参数类型解析器（可能不准确）***\tObject returnValue = invokeForRequest(webRequest, mavContainer, providedArgs);\tsetResponseStatus(webRequest);\tif (returnValue == null) &#123;\t\tif (isRequestNotModified(webRequest) || getResponseStatus() != null || mavContainer.isRequestHandled()) &#123;\t\t\tdisableContentCachingIfNecessary(webRequest);\t\t\tmavContainer.setRequestHandled(true);\t\t\treturn;\t\t&#125;\t&#125;\telse if (StringUtils.hasText(getResponseStatusReason())) &#123;\t\tmavContainer.setRequestHandled(true);\t\treturn;\t&#125;\tmavContainer.setRequestHandled(false);\tAssert.state(this.returnValueHandlers != null, &quot;No return value handlers&quot;);\ttry &#123;\t\tthis.returnValueHandlers.handleReturnValue(\t\t\t\treturnValue, getReturnValueType(returnValue), mavContainer, webRequest);\t&#125;\tcatch (Exception ex) &#123;\t\tif (logger.isTraceEnabled()) &#123;\t\t\tlogger.trace(formatErrorForReturnValue(returnValue), ex);\t\t&#125;\t\tthrow ex;\t&#125;&#125;\n\n执行 Object returnValue = invokeForRequest(webRequest, mavContainer, providedArgs) ，进入 InvocableHandlerMethod 类下的 invokeForRequest(NativeWebRequest request, @Nullable ModelAndViewContainer mavContainer,Object… providedArgs) 方法。\npublic Object invokeForRequest(NativeWebRequest request, @Nullable ModelAndViewContainer mavContainer,\t\tObject... providedArgs) throws Exception &#123;\t//***(5)***\tObject[] args = getMethodArgumentValues(request, mavContainer, providedArgs);\tif (logger.isTraceEnabled()) &#123;\t\tlogger.trace(&quot;Arguments: &quot; + Arrays.toString(args));\t&#125;\treturn doInvoke(args);&#125;\n\n执行 Object[] args = getMethodArgumentValues(request, mavContainer, providedArgs) ，进入到同类下的 getMethodArgumentValues(NativeWebRequest request, @Nullable ModelAndViewContainer mavContainer,Object… providedArgs) 方法。\nprotected Object[] getMethodArgumentValues(NativeWebRequest request, @Nullable ModelAndViewContainer mavContainer,\t\tObject... providedArgs) throws Exception &#123;\tMethodParameter[] parameters = getMethodParameters();\tif (ObjectUtils.isEmpty(parameters)) &#123;\t\treturn EMPTY_ARGS;\t&#125;\t\t//***(6)***\t//***开始遍历请求方法的参数列表,按照参数列表的数量创建一个对象数组args，args中的的每个元素后来都会转化为对应的参数列表中的对象类型***\tObject[] args = new Object[parameters.length];\tfor (int i = 0; i &lt; parameters.length; i++) &#123;\t\tMethodParameter parameter = parameters[i];\t\tparameter.initParameterNameDiscovery(this.parameterNameDiscoverer);\t\targs[i] = findProvidedArgument(parameter, providedArgs);\t\tif (args[i] != null) &#123;\t\t\tcontinue;\t\t&#125;\t\t//***(7)***\t\t//判断resolvers中是否有支持当前参数的resolver\t\tif (!this.resolvers.supportsParameter(parameter)) &#123;\t\t\tthrow new IllegalStateException(formatArgumentError(parameter, &quot;No suitable resolver&quot;));\t\t&#125;\t\ttry &#123;\t\t\t//***(8)***\t\t\t//***获取参数类型的对象数组***\t\t\targs[i] = this.resolvers.resolveArgument(parameter, mavContainer, request, this.dataBinderFactory);\t\t&#125;\t\tcatch (Exception ex) &#123;\t\t\t// Leave stack trace for later, exception may actually be resolved and handled...\t\t\tif (logger.isDebugEnabled()) &#123;\t\t\t\tString exMsg = ex.getMessage();\t\t\t\tif (exMsg != null &amp;&amp; !exMsg.contains(parameter.getExecutable().toGenericString())) &#123;\t\t\t\t\tlogger.debug(formatArgumentError(parameter, exMsg));\t\t\t\t&#125;\t\t\t&#125;\t\t\tthrow ex;\t\t&#125;\t&#125;\treturn args;&#125;\n\n执行 args[i] = this.resolvers.resolveArgument(parameter, mavContainer, request, this.dataBinderFactory) \npublic Object resolveArgument(MethodParameter parameter, @Nullable ModelAndViewContainer mavContainer,\t\tNativeWebRequest webRequest, @Nullable WebDataBinderFactory binderFactory) throws Exception &#123;\t//***(9)***\t//***获取参数解析器***\tHandlerMethodArgumentResolver resolver = getArgumentResolver(parameter);\tif (resolver == null) &#123;\t\tthrow new IllegalArgumentException(&quot;Unsupported parameter type [&quot; +\t\t\t\tparameter.getParameterType().getName() + &quot;]. supportsParameter should be called first.&quot;);\t&#125;\t\t//***这一部像是递归，还没搞懂该行的作用***\treturn resolver.resolveArgument(parameter, mavContainer, webRequest, binderFactory);&#125;\n\n执行 HandlerMethodArgumentResolver resolver = getArgumentResolver(parameter) \nprivate HandlerMethodArgumentResolver getArgumentResolver(MethodParameter parameter) &#123;\tHandlerMethodArgumentResolver result = this.argumentResolverCache.get(parameter);\tif (result == null) &#123;\t\t//***(10)***\t\t//***遍历所有的参数类型解析器，找到支持该参数的解析器***\t\tfor (HandlerMethodArgumentResolver resolver : this.argumentResolvers) &#123;\t\t\tif (resolver.supportsParameter(parameter)) &#123;\t\t\t\tresult = resolver;\t\t\t\tthis.argumentResolverCache.put(parameter, result);\t\t\t\tbreak;\t\t\t&#125;\t\t&#125;\t&#125;\treturn result;&#125;\n\n\n内容协商机制内容协商：协商浏览器能接受的数据类型和服务端能生产的数据类型（数据类型值的是数据的格式，例如XML和JSON等）在SpringBoot中，内容协商流程发生在返回值处理器中。请求的响应过程中，会得到支持请求路径映射的方法返回值的返回值处理器HandlerMethodReturnValueHandler ，接着进入到 HandlerMethodReturnValueHandler 具体实现类中，执行 handleReturnValue() 方法。以 RequestResponseBodyMethodProcessor 为例。\npublic void handleReturnValue(@Nullable Object returnValue, MethodParameter returnType,\t\t\tModelAndViewContainer mavContainer, NativeWebRequest webRequest)\t\t\tthrows IOException, HttpMediaTypeNotAcceptableException, HttpMessageNotWritableException &#123;\t\tmavContainer.setRequestHandled(true);\t\tServletServerHttpRequest inputMessage = createInputMessage(webRequest);\t\tServletServerHttpResponse outputMessage = createOutputMessage(webRequest);\t\t// Try even with null return value. ResponseBodyAdvice could get involved.\t\twriteWithMessageConverters(returnValue, returnType, inputMessage, outputMessage);\t&#125;\n进入 writeWithMessageConverters(returnValue, returnType, inputMessage, outputMessage) \nprotected &lt;T&gt; void writeWithMessageConverters(@Nullable T value, MethodParameter returnType,\t\t\tServletServerHttpRequest inputMessage, ServletServerHttpResponse outputMessage)\t\t\tthrows IOException, HttpMediaTypeNotAcceptableException, HttpMessageNotWritableException &#123;\t\tObject body;\t\tClass&lt;?&gt; valueType;\t\tType targetType;\t\tif (value instanceof CharSequence) &#123;\t\t\tbody = value.toString();\t\t\tvalueType = String.class;\t\t\ttargetType = String.class;\t\t&#125;\t\telse &#123;\t\t\tbody = value;\t\t\tvalueType = getReturnValueType(body, returnType);\t\t\ttargetType = GenericTypeResolver.resolveType(getGenericType(returnType), returnType.getContainingClass());\t\t&#125;\t\tif (isResourceType(value, returnType)) &#123;\t\t\toutputMessage.getHeaders().set(HttpHeaders.ACCEPT_RANGES, &quot;bytes&quot;);\t\t\tif (value != null &amp;&amp; inputMessage.getHeaders().getFirst(HttpHeaders.RANGE) != null &amp;&amp;\t\t\t\t\toutputMessage.getServletResponse().getStatus() == 200) &#123;\t\t\t\tResource resource = (Resource) value;\t\t\t\ttry &#123;\t\t\t\t\tList&lt;HttpRange&gt; httpRanges = inputMessage.getHeaders().getRange();\t\t\t\t\toutputMessage.getServletResponse().setStatus(HttpStatus.PARTIAL_CONTENT.value());\t\t\t\t\tbody = HttpRange.toResourceRegions(httpRanges, resource);\t\t\t\t\tvalueType = body.getClass();\t\t\t\t\ttargetType = RESOURCE_REGION_LIST_TYPE;\t\t\t\t&#125;\t\t\t\tcatch (IllegalArgumentException ex) &#123;\t\t\t\t\toutputMessage.getHeaders().set(HttpHeaders.CONTENT_RANGE, &quot;bytes */&quot; + resource.contentLength());\t\t\t\t\toutputMessage.getServletResponse().setStatus(HttpStatus.REQUESTED_RANGE_NOT_SATISFIABLE.value());\t\t\t\t&#125;\t\t\t&#125;\t\t&#125;\t\tMediaType selectedMediaType = null;\t\tMediaType contentType = outputMessage.getHeaders().getContentType();\t\tboolean isContentTypePreset = contentType != null &amp;&amp; contentType.isConcrete();\t\tif (isContentTypePreset) &#123;\t\t\tif (logger.isDebugEnabled()) &#123;\t\t\t\tlogger.debug(&quot;Found &#x27;Content-Type:&quot; + contentType + &quot;&#x27; in response&quot;);\t\t\t&#125;\t\t\tselectedMediaType = contentType;\t\t&#125;\t\telse &#123;\t\t\tHttpServletRequest request = inputMessage.getServletRequest();\t\t\tList&lt;MediaType&gt; acceptableTypes;\t\t\ttry &#123;\t\t\t\t//***得到浏览器可接受的媒体类型***\t\t\t\t//***进入getAcceptableMediaTypes方法，可获取使用哪种内容协商策略ContentNegotiationStrategy***\t\t\t\tacceptableTypes = getAcceptableMediaTypes(request);\t\t\t&#125;\t\t\tcatch (HttpMediaTypeNotAcceptableException ex) &#123;\t\t\t\tint series = outputMessage.getServletResponse().getStatus() / 100;\t\t\t\tif (body == null || series == 4 || series == 5) &#123;\t\t\t\t\tif (logger.isDebugEnabled()) &#123;\t\t\t\t\t\tlogger.debug(&quot;Ignoring error response content (if any). &quot; + ex);\t\t\t\t\t&#125;\t\t\t\t\treturn;\t\t\t\t&#125;\t\t\t\tthrow ex;\t\t\t&#125;\t\t\t\t\t\t//***得到服务端可生产的媒体类型***\t\t\tList&lt;MediaType&gt; producibleTypes = getProducibleMediaTypes(request, valueType, targetType);\t\t\tif (body != null &amp;&amp; producibleTypes.isEmpty()) &#123;\t\t\t\tthrow new HttpMessageNotWritableException(\t\t\t\t\t\t&quot;No converter found for return value of type: &quot; + valueType);\t\t\t&#125;\t\t\t\t\t\t//***遍历两种媒体类型，得到双方可以匹配的媒体类型***\t\t\tList&lt;MediaType&gt; mediaTypesToUse = new ArrayList&lt;&gt;();\t\t\tfor (MediaType requestedType : acceptableTypes) &#123;\t\t\t\tfor (MediaType producibleType : producibleTypes) &#123;\t\t\t\t\tif (requestedType.isCompatibleWith(producibleType)) &#123;\t\t\t\t\t\tmediaTypesToUse.add(getMostSpecificMediaType(requestedType, producibleType));\t\t\t\t\t&#125;\t\t\t\t&#125;\t\t\t&#125;\t\t\tif (mediaTypesToUse.isEmpty()) &#123;\t\t\t\tif (body != null) &#123;\t\t\t\t\tthrow new HttpMediaTypeNotAcceptableException(producibleTypes);\t\t\t\t&#125;\t\t\t\tif (logger.isDebugEnabled()) &#123;\t\t\t\t\tlogger.debug(&quot;No match for &quot; + acceptableTypes + &quot;, supported: &quot; + producibleTypes);\t\t\t\t&#125;\t\t\t\treturn;\t\t\t&#125;\t\t\t\t\t\t//***按照权重等规则进行排序***\t\t\tMediaType.sortBySpecificityAndQuality(mediaTypesToUse);\t\t\t//***确定最佳匹配的媒体类型***\t\t\tfor (MediaType mediaType : mediaTypesToUse) &#123;\t\t\t\tif (mediaType.isConcrete()) &#123;\t\t\t\t\tselectedMediaType = mediaType;\t\t\t\t\tbreak;\t\t\t\t&#125;\t\t\t\telse if (mediaType.isPresentIn(ALL_APPLICATION_MEDIA_TYPES)) &#123;\t\t\t\t\tselectedMediaType = MediaType.APPLICATION_OCTET_STREAM;\t\t\t\t\tbreak;\t\t\t\t&#125;\t\t\t&#125;\t\t\tif (logger.isDebugEnabled()) &#123;\t\t\t\tlogger.debug(&quot;Using &#x27;&quot; + selectedMediaType + &quot;&#x27;, given &quot; +\t\t\t\t\t\tacceptableTypes + &quot; and supported &quot; + producibleTypes);\t\t\t&#125;\t\t&#125;\t\tif (selectedMediaType != null) &#123;\t\t\tselectedMediaType = selectedMediaType.removeQualityValue();\t\t\t//***根据最终匹配的媒体类型，遍历寻找支持的消息转换器Converter\t\t\tfor (HttpMessageConverter&lt;?&gt; converter : this.messageConverters) &#123;\t\t\t\tGenericHttpMessageConverter genericConverter = (converter instanceof GenericHttpMessageConverter ?\t\t\t\t\t\t(GenericHttpMessageConverter&lt;?&gt;) converter : null);\t\t\t\tif (genericConverter != null ?\t\t\t\t\t\t((GenericHttpMessageConverter) converter).canWrite(targetType, valueType, selectedMediaType) :\t\t\t\t\t\tconverter.canWrite(valueType, selectedMediaType)) &#123;\t\t\t\t\tbody = getAdvice().beforeBodyWrite(body, returnType, selectedMediaType,\t\t\t\t\t\t\t(Class&lt;? extends HttpMessageConverter&lt;?&gt;&gt;) converter.getClass(),\t\t\t\t\t\t\tinputMessage, outputMessage);\t\t\t\t\tif (body != null) &#123;\t\t\t\t\t\tObject theBody = body;\t\t\t\t\t\tLogFormatUtils.traceDebug(logger, traceOn -&gt;\t\t\t\t\t\t\t\t&quot;Writing [&quot; + LogFormatUtils.formatValue(theBody, !traceOn) + &quot;]&quot;);\t\t\t\t\t\taddContentDispositionHeader(inputMessage, outputMessage);\t\t\t\t\t\tif (genericConverter != null) &#123;\t\t\t\t\t\t//***执行消息转换器的 write 方法***\t\t\t\t\t\t\tgenericConverter.write(body, targetType, selectedMediaType, outputMessage);\t\t\t\t\t\t&#125;\t\t\t\t\t\telse &#123;\t\t\t\t\t\t//***执行消息转换器的 write 方法***\t\t\t\t\t\t\t((HttpMessageConverter) converter).write(body, selectedMediaType, outputMessage);\t\t\t\t\t\t&#125;\t\t\t\t\t&#125;\t\t\t\t\telse &#123;\t\t\t\t\t\tif (logger.isDebugEnabled()) &#123;\t\t\t\t\t\t\tlogger.debug(&quot;Nothing to write: null body&quot;);\t\t\t\t\t\t&#125;\t\t\t\t\t&#125;\t\t\t\t\treturn;\t\t\t\t&#125;\t\t\t&#125;\t\t&#125;\t\tif (body != null) &#123;\t\t\tSet&lt;MediaType&gt; producibleMediaTypes =\t\t\t\t\t(Set&lt;MediaType&gt;) inputMessage.getServletRequest()\t\t\t\t\t\t\t.getAttribute(HandlerMapping.PRODUCIBLE_MEDIA_TYPES_ATTRIBUTE);\t\t\tif (isContentTypePreset || !CollectionUtils.isEmpty(producibleMediaTypes)) &#123;\t\t\t\tthrow new HttpMessageNotWritableException(\t\t\t\t\t\t&quot;No converter for [&quot; + valueType + &quot;] with preset Content-Type &#x27;&quot; + contentType + &quot;&#x27;&quot;);\t\t\t&#125;\t\t\tthrow new HttpMediaTypeNotAcceptableException(getSupportedMediaTypes(body.getClass()));\t\t&#125;\t&#125;\nacceptableTypes = getAcceptableMediaTypes(request) ，确定内容协商策略，进而根据策略获取浏览器可接受的媒体类型\nprivate List&lt;MediaType&gt; getAcceptableMediaTypes(HttpServletRequest request)\t\t\tthrows HttpMediaTypeNotAcceptableException &#123;\t\treturn this.contentNegotiationManager.resolveMediaTypes(new ServletWebRequest(request));\t&#125;\npublic List&lt;MediaType&gt; resolveMediaTypes(NativeWebRequest request) throws HttpMediaTypeNotAcceptableException &#123;\t\tfor (ContentNegotiationStrategy strategy : this.strategies) &#123;\t\t\tList&lt;MediaType&gt; mediaTypes = strategy.resolveMediaTypes(request);\t\t\tif (mediaTypes.equals(MEDIA_TYPE_ALL_LIST)) &#123;\t\t\t\tcontinue;\t\t\t&#125;\t\t\treturn mediaTypes;\t\t&#125;\t\treturn MEDIA_TYPE_ALL_LIST;\t&#125;\n此时只有一种默认的协商策略，基于request请求头的协商策略：HeaderContentNegotiationStrategy。也可以添加其他的内容协商策略，如在配置文件中开启基于请求参数的协商策略，也可以自定义协商策略。\n\n\n消息转换器Converter：\n开启支持XML格式数据：导入依赖\n&lt;dependency&gt;            &lt;groupId&gt;com.fasterxml.jackson.dataformat&lt;/groupId&gt;            &lt;artifactId&gt;jackson-dataformat-xml&lt;/artifactId&gt;&lt;/dependency&gt;\n\n开启基于请求参数的内容协商策略，配置文件中配置相应属性值。此时发送的请求中要附带一个 format 的字段，例如 http://localhost:8080/test/person?format=json 和http://localhost:8080/test/person?format=xml\nspring.contentnegotiation.favor-parameter=true\n\n自定义内容协商策略\n"},{"title":"SpringCloud学习笔记","url":"/2022/07/15/springcloud-xue-xi-bi-ji/","content":"EureKaEureKa注册中心\nmaven依赖&lt;dependency&gt;\t&lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;\t&lt;artifactId&gt;spring-cloud-starter-netflix-eureka-server&lt;/artifactId&gt;&lt;/dependency&gt;\n使用注解@EnableEureKa编写Application启动类\n添加配置信息server:\tport: 10086spring:\tapplication:\t\tname: eurekaservereureka:\tclient:\t\tservice-url:\t\t\tdefaultZone: http://127.0.0.1:10086/eureka/\nEureKa服务者注册\nmaven依赖&lt;dependency&gt;\t&lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;\t&lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt;&lt;/dependency&gt;\n添加配置信息server:\tport: 10086spring:\tapplication:\t\tname: client1eureka:\tclient:\t\tservice-url:\t\t\tdefaultZone: http://127.0.0.1:10086/client1/\nEureKa消费者注册步骤同服务者注册。但需添加http请求模块，以便于向其他微服务模块发送请求。@Bean@LoadBalanced\t//一个微服务模块有多个实例时，开启负载均衡public RestTemplate restTemplate()&#123;\treturn new RestTemplate();&#125;\n发送请求时，使用注册时的服务名代替 ip 和端口，egString url = &quot;http://servicename/user/&quot; + order.getUserId();\nRibbonEureKa的负载均衡组件。选择负载均衡策略方式一：手动添加负载均衡组件 IRule。这种配置方式是全局的，无论调用哪一个微服务都会采用该策略。//选择随机策略的组件@Beanpublic IRule randomRule()&#123;\treturn new RandomRule();&#125;\n方式二：配置文件方式。该方式只对被配置的微服务生效。userservice:\tribbon:\t\tNFLoadBalancerRuleClassName: com.netflix.loadbalancer.RandomRule\n加载方式Ribbon默认采用懒加载方式，即接受到第一次请求后才开始加载。开启饥饿加载，即启动时加载。ribbon:\teager-load:\t\tenabled: true #开启饥饿加载\t\tclients: userservice #指定劝userservice这个服务饥饿加载\nNacos\n下载Nacos\n项目父工程引入依赖&lt;dependency&gt;    &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt;    &lt;artifactId&gt;spring-cloud-alibaba-dependencies&lt;/artifactId&gt;    &lt;version&gt;2.2.5.RELEASE&lt;/version&gt;    &lt;type&gt;pom&lt;/type&gt;    &lt;scope&gt;import&lt;/scope&gt;&lt;/dependency&gt;\n微服务引入Nacos依赖&lt;dependency&gt;    &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt;    &lt;artifactId&gt;spring-cloud-starter-alibaba-nacos-discovery&lt;/artifactId&gt;&lt;/dependency&gt;\n微服务配置Nacosspring:\tcloud:\t\tnacos:\t\t\tserver-addr: localhost:8848\nPS：微服务需要有资源启动后在控制台才能看到注册的微服务，资源是可以被访问的方法等，踩大坑！\n\nNacos集群Nacos默认优先访问同一集群下的微服务，多个微服务实例间是随机访问。当本地微服务不可用时会发生跨集群访问。集群配置\nspring:\tcloud:\t\tnacos:\t\t\tserver-addr: localhost:8848\t\t\tdiscovery:\t\t\t\tcluster-name: HZ #集群名称\n设置负载均衡方式\nuserservice:\tribbon:\t\tNFLoadBalancerRuleClassName: com.alibaba.cloud.nacos.ribbon.NacosRule\nNacos环境隔离在Nacos控制台进行环境管理，不同环境下的微服务之间是相互隔离的，无法访问。配置临时实例为true，开启注册中心主动询问微服务实例状态，频率较高，对服务器的开销比较大。临时实例为false，微服务实例主动向注册中心发送心跳信息，频率较低，开销较小。与EureKa不同，如果Nacos注册中心发现有一个微服务实例不可用，则会主动向消费者推送信息，更新微服务实例列表。\nNacos配置管理远程环境配置\n在Nacos控制台创建配置文件 eg：userservice-dev.yml\n在微服务实例中添加bootstrap.yml文件，将需要从 application.yml 剥离的配置信息改到 bootstrap.yml ，例如Nacos地址，微服务名称等（SpringCloud负责加载 bootstrap.yml，会先于SpringBoot加载application.yml）\n配置热更新方式一：使用 @Value 和 @RefreshScope 刷新方式二：使用 @ConfigurationProperties 实现远程共享配置多个实例间共享设置，eg：userservice.yml配置生效优先级：远程环境配置 &gt; 远程共享配置 &gt; 本地配置\n集群搭建\n搭建MySQL集群并初始化数据库表\n下载解压nacos\n修改集群配置（节点信息）、数据库配置\n分别启动多个nacos节点\nnginx反向代理Feign较RestTemplate更为强大的http客户端。使用步骤：\n引入 maven 依赖&lt;dependency&gt;\t&lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;\t&lt;artifactId&gt;spring-cloud-starter-openfeign&lt;/artifactId&gt; &lt;/dependency&gt;\n启动类添加 @EnableFeignClients 注解\n编写 FeignClient 接口@FeignClient(&quot;userservice&quot;)public interface UserClient &#123;\t@GetMapping(&quot;/user/&#123;id&#125;&quot;) \tUser findById(@PathVariable(&quot;id&quot;) Long id);&#125;\n使用 FeginClientFeign日志级别方式一：配置文件方式\n全局生效feign:\tclient:\t\tconfig:\t\t\tdefault: #对所有微服务生效\t\t\t\tloggerLevel: FULL #  日志级别 \n局部生效feign:\tclient:\t\tconfig:\t\t\tuserservice: #只对userservice生效\t\t\t\tloggerLevel: FULL #  日志级别 \n方式二：代码方式public class FeignClientConfiguration &#123;\t@Bean\tpublic Logger.Level feignLogLevel()&#123;\t\treturn Logger.Level.BASIC;\t&#125;&#125;\n全局配置，则把它放到@EnableFeignClients这个注解中：@EnableFeignClients(defaultConfiguration = FeignClientConfiguration.class)\n局部配置，则把它放到@FeignClient这个注解中：@FeignClient(value = &quot;userservice&quot;, configuration = FeignClientConfiguration.class) \n设置Feign底层Http客户端Feign底层的客户端实现： URLConnection：默认实现，不支持连接池 Apache HttpClient ：支持连接池 OKHttp：支持连接池配置HttpClient\n引入maven依赖&lt;!--httpClient的依赖 --&gt;&lt;dependency&gt;\t&lt;groupId&gt;io.github.openfeign&lt;/groupId&gt;\t&lt;artifactId&gt;feign-httpclient&lt;/artifactId&gt;&lt;/dependency&gt;\n配置连接池feign:\tclient:\t\tconfig:\t\t\tdefault: # default全局的配置\t\t\tloggerLevel: BASIC # 日志级别，BASIC就是基本的请求和响应信息\thttpclient:\t\tenabled: true # 开启feign对HttpClient的支持\t\tmax-connections: 200 # 最大的连接数\t\tmax-connections-per-route: 50 # 每个路径的最大连接数\n抽取FeignClient模块ps：也可以选择继承父接口的方式。\n首先创建一个module，命名为feign-api，然后引入feign的starter依赖\n将order-service中编写的UserClient、User等要抽取的内容都复制到feign-api项目中\n在order-service（需要使用feign-api）中引入feign-api的依赖\n修改order-service，改成导入feign-api中的包\n指定加载FeignClient类//方式一@EnableFeignClients(basePackages = &quot;cn.itcast.feign.clients&quot;)\t//扫描FeignClient所在整个模块//方式二@EnableFeignClients(clients = &#123;UserClient.class&#125;)\t//直接指定加载FeignClient\n重启测试网关Gateway使用步骤：\n创建项目，引入依赖&lt;!--网关依赖--&gt;&lt;dependency&gt;\t&lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;\t&lt;artifactId&gt;spring-cloud-starter-gateway&lt;/artifactId&gt;&lt;/dependency&gt;&lt;!--nacos服务发现依赖--&gt;&lt;dependency&gt;\t&lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt;\t&lt;artifactId&gt;spring-cloud-starter-alibaba-nacos-discovery&lt;/artifactId&gt; &lt;/dependency&gt;\n编写路由配置及nacos地址server:  port: 10010 # 网关端口spring:  application:    name: gateway # 服务名称  cloud:    nacos:      server-addr: localhost:8848 # nacos地址    gateway:      routes: # 网关路由配置        - id: user-service # 路由id，自定义，只要唯一即可          # uri: http://127.0.0.1:8081 # 路由的目标地址 http就是固定地址          uri: lb://userservice # 路由的目标地址 lb就是负载均衡，后面跟服务名称          predicates: # 路由断言，也就是判断请求是否符合路由规则的条件            - Path=/user/** # 这个是按照路径匹配，只要以/user/开头就符合要求\nGateway路由断言工厂Gateway提供多种断言工厂——Route Predicate Factory，对进入的请求进行判断。\n路由过滤器GatewayFilter对进入网关的请求和微服务返回的响应做处理。\neg: 给所有进入userservice的请求添加一个请求头：Truth=itcast is freaking awesome!spring:\tcloud:\t\tgateway:\t\t\troutes: # 网关路由配置                - id: user-service                  uri: lb://userservice                  predicates:                    - Path=/user/**                  filters: # 过滤器                    - AddRequestHeader=Truth, Itcast is freaking awesome! # 添加请求头\n默认过滤器：对所有的路由都生效，将过滤器工厂写到default下。spring:\tapplication:\t\tname: gateway # 服务名称\tcloud:\t\tnacos:\t\t\tserver-addr: localhost:8848 # nacos地址\t\t\tgateway:\t\t\t\troutes: # 网关路由配置                    - id: user-service                       uri: lb://userservice                      predicates:                        - Path=/user/**                    - id: order-service                      uri: lb://orderservice                      predicates:                        - Path=/order/**\t\t\t\tdefault-filters: # 默认过滤器，会对所有的路由请求都生效\t\t\t\t\t\t\t- AddRequestHeader=Truth, Itcast is freaking awesome! # 添加请求头\n自定义全局过滤器GlobalFilter处理一切进入网关的请求和微服务响应，与GatewayFilter的作用一样。自定义过滤器的代码处理逻辑，需要实现GlobalFilter接口。public interface GlobalFilter &#123;\t/**\t*  处理当前请求，有必要的话通过&#123;@link GatewayFilterChain&#125;将请求交给下一个过滤器处理    *    * @param exchange 请求上下文，里面可以获取Request、Response等信息    * @param chain 用来把请求委托给下一个过滤器     * @return &#123;@code Mono&lt;Void&gt;&#125; 返回标示当前过滤器业务结束    */    Mono&lt;Void&gt; filter(ServerWebExchange exchange, GatewayFilterChain chain);&#125;/*** 定义全局过滤器，拦截请求，判断请求的参数是否满足下面条件* 参数中是否有authorization* authorization参数值是否为admin,如果同时满足则放行，否则拦截*/@Order(-1)\t//让类实现Ordered接口，实现接口方法与使用注解效果是一样的@Componentpublic class AuthorizeFilter implements GlobalFilter &#123;\t@Override\tpublic Mono&lt;Void&gt; filter(ServerWebExchange exchange, GatewayFilterChain chain) &#123;        // 1.获取请求参数        MultiValueMap&lt;String, String&gt; params = exchange.getRequest().getQueryParams();        // 2.获取authorization参数        String auth = params.getFirst(&quot;authorization&quot;);        // 3.校验        if (&quot;admin&quot;.equals(auth)) &#123;        // 放行        return chain.filter(exchange);        &#125;        // 4.拦截        // 4.1.禁止访问 exchange.getResponse().setStatusCode(HttpStatus.FORBIDDEN);        // 4.2.结束处理        return exchange.getResponse().setComplete();\t&#125;&#125;\n过滤器执行顺序\norder值越小，优先级越高\n当order值一样时，顺序是defaultFilter最先，然后是局部的路由过滤器，最后是全局过滤器跨域问题浏览器禁止请求的发起者与服务端发生跨域ajax请求，请求被浏览器拦截的问题。解决方案：CORSspring:\tcloud:\t\tgateway:\t\t\tglobalcors: # 全局的跨域处理\t\t\t\tadd-to-simple-url-handler-mapping: true # 解决options请求被拦截问题\t\t\t\tcorsConfigurations:\t\t\t\t\t&#x27;[/**]&#x27;:\t\t\t\t\t\tallowedOrigins: # 允许哪些网站的跨域请求\t\t\t\t\t\t\t- &quot;http://localhost:8090&quot;\t\t\t\t\t\t\t- &quot;http://www.leyou.com&quot;\t\t\t\t\t\tallowedMethods: # 允许的跨域ajax的请求方式                        \t- &quot;GET&quot;                                   \t- &quot;POST&quot;                        \t- &quot;DELETE&quot;                        \t- &quot;PUT&quot;                        \t- &quot;OPTIONS&quot;\t\t\t\t\t\tallowedHeaders: &quot;*&quot; # 允许在请求中携带的头信息\t\t\t\t\t\tallowCredentials: true # 是否允许携带cookie     \t\t\t\t\t\t\tmaxAge: 360000 # 这次跨域检测的有效期\nDocker基本操作\n拉取镜像docker pull nginx\t//不写版本号默认拉取最新版\n查看镜像docker images\n删除镜像docker rmi nginx:latest\n保存、导入镜像docker save -o [保存的目标文件名称] [镜像名称]eg: docker save -o nginx.tar nginx:latest\n加载镜像docker load -i nginx.tar\n容器操作\n\n\n运行：进程正常运行\n暂停：进程暂停，CPU不再运行，并不释放内存\n停止：进程终止，回收进程占用的内存、CPU等资源\n\n\n创建容器docker run --name containerName -p 80:80 -d nginxps:containName 为容器所取名称-p 映射端口，左侧为主机端口，右侧为容器端口-d 后台运行容器nginx 要运行的镜像名称\n\n暂停容器docker pause containerName\n容器取消暂停状态，恢复运行docker unpause containerName\n停止容器docker stop containerName\n容器取消停止，再次运行docker start containerName\n删除容器docker rm containerName\n进入容器docker exec -it mn bashps:-it 给当前进入的容器创建一个标准输入、输出终端，允许我们与容器交互mn 进入的容器的名称bash 进入容器后执行的命令，bash是一个linux终端交互命令\n查看容器日志docker logsps:-f 持续查看日志\n查看容器状态docker psps:-a 查看所有容器（包括已停止）\n数据卷\n\n数据卷（volume）是一个虚拟目录，指向宿主机文件系统中的某个目录。\n\n一旦完成数据卷挂载，对容器的一切操作都会作用在数据卷对应的宿主机目录了。我们操作宿主机的/var/lib/docker/volumes/html目录，就等于操作容器内的/usr/share/nginx/html目录了\n\n创建数据卷docker volume create html\n查看所有数据卷docker volume ls\n查看数据卷详细信息docker volume inspect html\n删除数据卷删除未使用的数据卷docker volume prune \n删除指定数据卷docker volume rm html\n挂载数据卷docker run \\  --name mn \\  -v html:/root/html \\  -p 8080:80 \\  nginx \\ps:-v html:/root/htm 把html数据卷挂载到容器内的/root/html这个目录中\n容器直接挂载主机目录docker run \\  --name mn \\  -v [宿主机目录]:[容器内目录] \\  -p 8080:80 \\  nginx \\\n\nDockerfile\n\nDockerfile就是一个文本文件，其中包含一个个的**指令(Instruction)**，用指令来说明要执行什么操作来构建镜像。每一个指令都会形成一层Layer。\n\nDockerfile文件告诉Docker，我们的镜像的组成，需要哪些BaseImage、需要拷贝什么文件、需要安装什么依赖、启动脚本是什么，将来Docker会帮助我们构建镜像。\n\n构建镜像新建文件夹及准备好相关文件。\n\nDockerfile内容如下\n# 指定基础镜像  FROM ubuntu:16.04  # 配置环境变量，JDK的安装目录  ENV JAVA_DIR=/usr/local    # 拷贝jdk和java项目的包  COPY ./jdk8.tar.gz $JAVA_DIR/  COPY ./docker-demo.jar /tmp/app.jar    # 安装JDK  RUN cd $JAVA_DIR \\   &amp;&amp; tar -xf ./jdk8.tar.gz \\   &amp;&amp; mv ./jdk1.8.0_144 ./java8    # 配置环境变量  ENV JAVA_HOME=$JAVA_DIR/java8  ENV PATH=$PATH:$JAVA_HOME/bin    # 暴露端口  EXPOSE 8090  # 入口，java项目的启动命令  ENTRYPOINT java -jar /tmp/app.jar\n基于镜像构建镜像由于Docker的分层结构，因此我们可以在别人镜像的基础上制作自己的镜像。基于java:8-alpine镜像，将一个Java项目构建为镜像。\n\n新建一个空的目录，然后在目录中新建一个文件，命名为Dockerfile\n拷贝课前资料提供的docker-demo.jar到这个目录中\n编写Dockerfile文件：\n基于java:8-alpine作为基础镜像\n将app.jar拷贝到镜像中\n暴露端口\n编写入口ENTRYPOINTFROM java:8-alpineCOPY ./app.jar /tmp/app.jarEXPOSE 8090ENTRYPOINT java -jar /tmp/app.jar\nDockerComposeDocker Compose可以基于Compose文件帮我们快速的部署分布式应用，而无需手动一个个创建和运行容器！DockerCompose下载安装详细见官网https://docs.docker.com/compose/部署集群案例eg：将之前学习的cloud-demo微服务集群利用DockerCompose部署\n\n\n查看课前资料提供的cloud-demo文件夹，里面已经编写好了docker-compose文件\n修改自己的cloud-demo项目，将数据库、nacos地址都命名为docker-compose中的服务名\n使用maven打包工具，将项目中的每个微服务都打包为app.jar\n将打包好的app.jar拷贝到cloud-demo中的每一个对应的子目录中\n将cloud-demo上传至虚拟机，利用 docker-compose up -d 来部署1. compose文件查看课前资料提供的cloud-demo文件夹，里面已经编写好了docker-compose文件，而且每个微服务都准备了一个独立的目录：\nversion: &quot;3.2&quot;services:  nacos:    image: nacos/nacos-server    environment:      MODE: standalone    ports:      - &quot;8848:8848&quot;  mysql:    image: mysql:5.7.25    environment:      MYSQL_ROOT_PASSWORD: 123    volumes:      - &quot;$PWD/mysql/data:/var/lib/mysql&quot;      - &quot;$PWD/mysql/conf:/etc/mysql/conf.d/&quot;  userservice:    build: ./user-service  orderservice:    build: ./order-service  gateway:    build: ./gateway    ports:      - &quot;10010:10010&quot;\n共有5个service服务：\nnacos：作为注册中心和配置中心\nimage: nacos/nacos-server： 基于nacos/nacos-server镜像构建\nenvironment：环境变量\nMODE: standalone：单点模式启动\n\n\nports：端口映射，这里暴露了8848端口\n\n\nmysql：数据库\nimage: mysql:5.7.25：镜像版本是mysql:5.7.25\nenvironment：环境变量\nMYSQL_ROOT_PASSWORD: 123：设置数据库root账户的密码为123\n\n\nvolumes：数据卷挂载，这里挂载了mysql的data、conf目录，其中有我提前准备好的数据\n\n\nuserservice、orderservice、gateway：都是基于Dockerfile临时构建的mysql目录中可已经准备好了cloud_order、cloud_user表。查看微服务目录，可以看到都包含Dockerfile文件：FROM java:8-alpineCOPY ./app.jar /tmp/app.jarENTRYPOINT java -jar /tmp/app.jar\n2. 修改微服务配置因为微服务将来要部署为docker容器，而容器之间互联不是通过IP地址，而是通过容器名。这里我们将order-service、user-service、gateway服务的mysql、nacos地址都修改为基于容器名的访问。spring:  datasource:    url: jdbc:mysql://mysql:3306/cloud_order?useSSL=false    username: root    password: 123    driver-class-name: com.mysql.jdbc.Driver  application:    name: orderservice  cloud:    nacos:      server-addr: nacos:8848 # nacos服务地址\n3. 打包接下来需要将我们的每个微服务都打包。因为之前查看到Dockerfile中的jar包名称都是app.jar，因此我们的每个微服务都需要用这个名称。可以通过修改pom.xml中的打包名称来实现，每个微服务都需要修改：&lt;build&gt;  &lt;!-- 服务打包的最终名称 --&gt;  &lt;finalName&gt;app&lt;/finalName&gt;  &lt;plugins&gt;    &lt;plugin&gt;      &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;      &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt;    &lt;/plugin&gt;  &lt;/plugins&gt;&lt;/build&gt;\n\n4. 拷贝jar包到部署目录编译打包好的app.jar文件，需要放到Dockerfile的同级目录中。注意：每个微服务的app.jar放到与服务名称对应的目录，不要搞错。eg：order-service\n5. 部署最后将文件整个cloud-demo文件夹上传到虚拟机中，由DockerCompose部署。可上传到任意目录。部署：进入cloud-demo目录，然后运行下面的命令：docker-compose up -d\nDocker镜像仓库简化版镜像仓库docker run -d \\    --restart=always \\    --name registry\t\\    -p 5000:5000 \\    -v registry-data:/var/lib/registry \\    registry\n命令中挂载了一个数据卷registry-data到容器内的/var/lib/registry 目录，这是私有镜像库存放数据的目录。访问http://YourIp:5000/v2/_catalog 可以查看当前私有镜像服务中包含的镜像。\n\n图形界面镜像仓库使用DockerCompose部署带有图象界面的DockerRegistry，命令如下：\nversion: &#x27;3.0&#x27;services:  registry:    image: registry    volumes:      - ./registry-data:/var/lib/registry  ui:    image: joxit/docker-registry-ui:static    ports:      - 8080:80    environment:      - REGISTRY_TITLE=传智教育私有仓库      - REGISTRY_URL=http://registry:5000    depends_on:      - registry\n配置Docker信任地址我们的私服采用的是http协议，默认不被Docker信任，所以需要做一个配置：\n# 打开要修改的文件vi /etc/docker/daemon.json# 添加内容：&quot;insecure-registries&quot;:[&quot;http://192.168.150.101:8080&quot;]# 重加载systemctl daemon-reload# 重启dockersystemctl restart docker\nRabbitMQ安装部署详情请参考官方网站https://www.rabbitmq.com/\n单机部署方式一：镜像安装\ndocker pull rabbitmq:3-management\n方式二：本地文件下载文件后上传到虚拟机，使用以下命令加载镜像\ndocker load -i mq.tar\n运行MQ容器安装成功后，可使用以下命令来运行容器\ndocker run \\ -e RABBITMQ_DEFAULT_USER=itcast \\ -e RABBITMQ_DEFAULT_PASS=123321 \\ --name mq \\ --hostname mq1 \\ -p 15672:15672 \\ -p 5672:5672 \\ -d \\ rabbitmq:3-management\n集群安装在RabbitMQ的官方文档中，讲述了两种集群的配置方式：\n\n普通模式：普通模式集群不进行数据同步，每个MQ都有自己的队列、数据信息（其它元数据信息如交换机等会同步）。例如我们有2个MQ：mq1，和mq2，如果你的消息在mq1，而你连接到了mq2，那么mq2会去mq1拉取消息，然后返回给你。如果mq1宕机，消息就会丢失。\n镜像模式：与普通模式不同，队列会在各个mq的镜像节点之间同步，因此你连接到任何一个镜像节点，均可获取到消息。而且如果一个节点宕机，并不会导致数据丢失。不过，这种方式增加了数据同步的带宽消耗。详细信息请参考参考官方网站https://www.rabbitmq.com/基本介绍RabbitMQ角色：\n\n\npublisher：生产者\nconsumer：消费者\nexchange个：交换机，负责消息路由\nqueue：队列，存储消息\nvirtualHost：虚拟主机，隔离不同租户的exchange、queue、消息的隔离RabbitMQ基本模型：\n消息队列基本使用消息发送publisher\n\n\n建立connection\n创建channel\n利用channel声明队列\n利用channel向队列发送消息eg：package cn.itcast.mq.helloworld;import com.rabbitmq.client.Channel;import com.rabbitmq.client.Connection;import com.rabbitmq.client.ConnectionFactory;import org.junit.Test;import java.io.IOException;import java.util.concurrent.TimeoutException;public class PublisherTest &#123;    @Test    public void testSendMessage() throws IOException, TimeoutException &#123;        // 1.建立连接        ConnectionFactory factory = new ConnectionFactory();        // 1.1.设置连接参数，分别是：主机名、端口号、vhost、用户名、密码        factory.setHost(&quot;192.168.150.101&quot;);        factory.setPort(5672);        factory.setVirtualHost(&quot;/&quot;);        factory.setUsername(&quot;itcast&quot;);        factory.setPassword(&quot;123321&quot;);        // 1.2.建立连接        Connection connection = factory.newConnection();        // 2.创建通道Channel        Channel channel = connection.createChannel();        // 3.创建队列        String queueName = &quot;simple.queue&quot;;        channel.queueDeclare(queueName, false, false, false, null);        // 4.发送消息        String message = &quot;hello, rabbitmq!&quot;;        channel.basicPublish(&quot;&quot;, queueName, null, message.getBytes());        System.out.println(&quot;发送消息成功：【&quot; + message + &quot;】&quot;);        // 5.关闭通道和连接        channel.close();        connection.close();    &#125;&#125;\n消息接收consumer\n建立connection\n创建channel\n利用channel声明队列\n定义consumer的消费行为handleDelivery()\n利用channel将消费者与队列绑定eg：package cn.itcast.mq.helloworld;import com.rabbitmq.client.*;import java.io.IOException;import java.util.concurrent.TimeoutException;public class ConsumerTest &#123;    public static void main(String[] args) throws IOException, TimeoutException &#123;        // 1.建立连接        ConnectionFactory factory = new ConnectionFactory();        // 1.1.设置连接参数，分别是：主机名、端口号、vhost、用户名、密码        factory.setHost(&quot;192.168.150.101&quot;);        factory.setPort(5672);        factory.setVirtualHost(&quot;/&quot;);        factory.setUsername(&quot;itcast&quot;);        factory.setPassword(&quot;123321&quot;);        // 1.2.建立连接        Connection connection = factory.newConnection();        // 2.创建通道Channel        Channel channel = connection.createChannel();        // 3.创建队列        String queueName = &quot;simple.queue&quot;;        channel.queueDeclare(queueName, false, false, false, null);        // 4.订阅消息        channel.basicConsume(queueName, true, new DefaultConsumer(channel)&#123;            @Override            public void handleDelivery(String consumerTag, Envelope envelope,                                       AMQP.BasicProperties properties, byte[] body) throws IOException &#123;                // 5.处理消息                String message = new String(body);                System.out.println(&quot;接收到消息：【&quot; + message + &quot;】&quot;);            &#125;        &#125;);        System.out.println(&quot;等待接收消息。。。。&quot;);    &#125;&#125;\nSpringAMQPSpringAMQP是基于RabbitMQ封装的模板，利用SpringBoot对其实现了自动装配。SpringAMQP提供了三个功能：\n\n\n自动声明队列、交换机及其绑定关系\n基于注解的监听器模式，异步接收消息\n封装了RabbitTemplate工具，用于发送消息 基本使用流程\n\n\n在父工程中引入spring-amqp的依赖&lt;!--AMQP依赖，包含RabbitMQ--&gt;&lt;dependency&gt;    &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;    &lt;artifactId&gt;spring-boot-starter-amqp&lt;/artifactId&gt;&lt;/dependency&gt;\n消息发送配置MQ信息spring:  rabbitmq:    host: 192.168.150.101 # 主机名    port: 5672 # 端口    virtual-host: / # 虚拟主机    username: itcast # 用户名    password: 123321 # 密码\n使用RestTemplate实现消息发送package cn.itcast.mq.spring;import org.junit.Test;import org.junit.runner.RunWith;import org.springframework.amqp.rabbit.core.RabbitTemplate;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.boot.test.context.SpringBootTest;import org.springframework.test.context.junit4.SpringRunner;@RunWith(SpringRunner.class)@SpringBootTestpublic class SpringAmqpTest &#123;    @Autowired    private RabbitTemplate rabbitTemplate;    @Test    public void testSimpleQueue() &#123;        // 队列名称        String queueName = &quot;simple.queue&quot;;        // 消息        String message = &quot;hello, spring amqp!&quot;;        // 发送消息        rabbitTemplate.convertAndSend(queueName, message);    &#125;&#125;\n使用RabbitTemplate消息接收配置MQ：spring:  rabbitmq:    host: 192.168.150.101 # 主机名    port: 5672 # 端口    virtual-host: / # 虚拟主机    username: itcast # 用户名    password: 123321 # 密码\n消息接收：package cn.itcast.mq.listener;import org.springframework.amqp.rabbit.annotation.RabbitListener;import org.springframework.stereotype.Component;@Componentpublic class SpringRabbitListener &#123;    @RabbitListener(queues = &quot;simple.queue&quot;)    public void listenSimpleQueueMessage(String msg) throws InterruptedException &#123;        System.out.println(&quot;spring 消费者接收到消息：【&quot; + msg + &quot;】&quot;);    &#125;&#125;\nWorkQueue也被称为（Task queues），让多个消费者绑定到一个消息队列，共同消费队列中的消息，能够大大提高消息处理的速度。消息发送@Testpublic void testWorkQueue() throws InterruptedException &#123;    // 队列名称    String queueName = &quot;simple.queue&quot;;    // 消息    String message = &quot;hello, message_&quot;;    for (int i = 0; i &lt; 50; i++) &#123;        // 发送消息        rabbitTemplate.convertAndSend(queueName, message + i);        Thread.sleep(20);    &#125;&#125;\n多消费者接收消息@RabbitListener(queues = &quot;simple.queue&quot;)public void listenWorkQueue1(String msg) throws InterruptedException &#123;    System.out.println(&quot;消费者1接收到消息：【&quot; + msg + &quot;】&quot; + LocalTime.now());    Thread.sleep(20);&#125;@RabbitListener(queues = &quot;simple.queue&quot;)public void listenWorkQueue2(String msg) throws InterruptedException &#123;    System.err.println(&quot;消费者2........接收到消息：【&quot; + msg + &quot;】&quot; + LocalTime.now());    Thread.sleep(200);&#125;\n多个消费者间消息分配策略多个消费者之间的分配的消息默认是平均分配，与消费者处理消息的能力无关。eg：上文中的两个消费者，消费者1每20ms处理一个消息，而消费者2则每200ms处理一个消息，但是消息队列中的消息会平均分配给两个消费者，原因是RabbieMQ会预先将消息队列中的消息分配给每一个消费者，可以通过设置prefetch来控制消费者预取的消息数量。spring:  rabbitmq:    listener:      simple:        prefetch: 1 # 每次只能获取一条消息，处理完成才能获取下一个消息\n发布订阅模式发布订阅模型：\n\n\nPublisher：生产者发送的消息不再发送到队列中，而是发给交换机\nExchange：交换机。一方面，接收生产者发送的消息。另一方面，知道如何处理消息，例如递交给某个特别队列、递交给所有队列、或是将消息丢弃。到底如何操作，取决于Exchange的类型。Exchange有以下3种类型：\nFanout：广播，将消息交给所有绑定到交换机的队列\nDirect：定向，把消息交给符合指定routing key 的队列\nTopic：通配符，把消息交给符合routing pattern（路由模式） 的队列\n\n\nConsumer：消费者，与以前一样，订阅队列，没有变化\nQueue：消息队列也与以前一样，接收消息、缓存消息\n\nps：Exchange（交换机）只负责转发消息，不具备存储消息的能力，因此如果没有任何队列与Exchange绑定，或者没有符合路由规则的队列，那么消息会丢失！\nFanout生产者将消息发送给交换机，交换机会将消息发送给与之绑定的所有队列，最后订阅队列的消费者拿到消息。要点如下：\n\n队列绑定交换机\n消费者订阅队列ps：该模式下，生产者的消息只能发送给交换机。声明队列和交换机package cn.itcast.mq.config;import org.springframework.amqp.core.Binding;import org.springframework.amqp.core.BindingBuilder;import org.springframework.amqp.core.FanoutExchange;import org.springframework.amqp.core.Queue;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;@Configurationpublic class FanoutConfig &#123;    /**     * 声明交换机     * @return Fanout类型交换机     */    @Bean    public FanoutExchange fanoutExchange()&#123;        return new FanoutExchange(&quot;itcast.fanout&quot;);    &#125;    /**     * 第1个队列     */    @Bean    public Queue fanoutQueue1()&#123;        return new Queue(&quot;fanout.queue1&quot;);    &#125;    /**     * 绑定队列和交换机     */    @Bean    public Binding bindingQueue1(Queue fanoutQueue1, FanoutExchange fanoutExchange)&#123;        return BindingBuilder.bind(fanoutQueue1).to(fanoutExchange);    &#125;    /**     * 第2个队列     */    @Bean    public Queue fanoutQueue2()&#123;        return new Queue(&quot;fanout.queue2&quot;);    &#125;    /**     * 绑定队列和交换机     */    @Bean    public Binding bindingQueue2(Queue fanoutQueue2, FanoutExchange fanoutExchange)&#123;        return BindingBuilder.bind(fanoutQueue2).to(fanoutExchange);    &#125;&#125;\n消息发送@Testpublic void testFanoutExchange() &#123;    // 队列名称    String exchangeName = &quot;itcast.fanout&quot;;    // 消息    String message = &quot;hello, everyone!&quot;;    rabbitTemplate.convertAndSend(exchangeName, &quot;&quot;, message);&#125;\n消息接收@RabbitListener(queues = &quot;fanout.queue1&quot;)public void listenFanoutQueue1(String msg) &#123;    System.out.println(&quot;消费者1接收到Fanout消息：【&quot; + msg + &quot;】&quot;);&#125;@RabbitListener(queues = &quot;fanout.queue2&quot;)public void listenFanoutQueue2(String msg) &#123;    System.out.println(&quot;消费者2接收到Fanout消息：【&quot; + msg + &quot;】&quot;);&#125;\nDirect在Fanout模式中，一条消息，会被所有订阅的队列都消费。但是，在某些场景下，我们希望不同的消息被不同的队列消费。这时就要用到Direct类型的Exchange。每个队列会绑定不同的关键词——bingkey，交换机发送消息时，会根据消息的key将消息发送到绑定该key的队列。\n声明队列和交换机（基于注解）@RabbitListener(bindings = @QueueBinding(    value = @Queue(name = &quot;direct.queue1&quot;),    exchange = @Exchange(name = &quot;itcast.direct&quot;, type = ExchangeTypes.DIRECT),    key = &#123;&quot;red&quot;, &quot;blue&quot;&#125;))public void listenDirectQueue1(String msg)&#123;    System.out.println(&quot;消费者接收到direct.queue1的消息：【&quot; + msg + &quot;】&quot;);&#125;@RabbitListener(bindings = @QueueBinding(    value = @Queue(name = &quot;direct.queue2&quot;),    exchange = @Exchange(name = &quot;itcast.direct&quot;, type = ExchangeTypes.DIRECT),    key = &#123;&quot;red&quot;, &quot;yellow&quot;&#125;))public void listenDirectQueue2(String msg)&#123;    System.out.println(&quot;消费者接收到direct.queue2的消息：【&quot; + msg + &quot;】&quot;);&#125;\n发送消息@Testpublic void testSendDirectExchange() &#123;    // 交换机名称    String exchangeName = &quot;itcast.direct&quot;;    // 消息    String message = &quot;红色警报！日本乱排核废水，导致海洋生物变异，惊现哥斯拉！&quot;;    // 发送消息    rabbitTemplate.convertAndSend(exchangeName, &quot;red&quot;, message);&#125;\nTopicTopic类型的Exchange与Direct相比，都是可以根据RoutingKey把消息路由到不同的队列。但是Topic类型Exchange可以让队列在绑定Routing key 的时候使用通配符！RoutingKey通配符规则：多个词之间以.分割。\n\n\n#匹配一个或多个词\n*匹配一个词\nQueue1：绑定的是china.# ，因此凡是以 china.开头的routing key 都会被匹配到。包括china.news和china.weather\nQueue2：绑定的是#.news ，因此凡是以 .news结尾的 routing key 都会被匹配。包括china.news和japan.news消息发送/**     * topicExchange     */@Testpublic void testSendTopicExchange() &#123;    // 交换机名称    String exchangeName = &quot;itcast.topic&quot;;    // 消息    String message = &quot;喜报！孙悟空大战哥斯拉，胜!&quot;;    // 发送消息    rabbitTemplate.convertAndSend(exchangeName, &quot;china.news&quot;, message);&#125;\n消息接收@RabbitListener(bindings = @QueueBinding(    value = @Queue(name = &quot;topic.queue1&quot;),    exchange = @Exchange(name = &quot;itcast.topic&quot;, type = ExchangeTypes.TOPIC),    key = &quot;china.#&quot;))public void listenTopicQueue1(String msg)&#123;    System.out.println(&quot;消费者接收到topic.queue1的消息：【&quot; + msg + &quot;】&quot;);&#125;@RabbitListener(bindings = @QueueBinding(    value = @Queue(name = &quot;topic.queue2&quot;),    exchange = @Exchange(name = &quot;itcast.topic&quot;, type = ExchangeTypes.TOPIC),    key = &quot;#.news&quot;))public void listenTopicQueue2(String msg)&#123;    System.out.println(&quot;消费者接收到topic.queue2的消息：【&quot; + msg + &quot;】&quot;);&#125;\n消息转换器Spring会把你发送的消息序列化为字节发送给MQ，接收消息的时候，还会把字节反序列化为Java对象。\n默认情况下Spring采用的序列化方式是JDK序列化，但是JDK序列化存在下列问题：\n数据体积过大\n有安全漏洞\n可读性差\n\n配置Json转换器\n微服务引入依赖&lt;dependency&gt;    &lt;groupId&gt;com.fasterxml.jackson.dataformat&lt;/groupId&gt;    &lt;artifactId&gt;jackson-dataformat-xml&lt;/artifactId&gt;    &lt;version&gt;2.9.10&lt;/version&gt;&lt;/dependency&gt;\n添加组件Bean//会替换Spring默认的转换器@Beanpublic MessageConverter jsonMessageConverter()&#123;    return new Jackson2JsonMessageConverter();&#125;\n\n消息可靠性消息从发送，到消费者接收，会经理多个过程，其中的每一步都可能导致消息丢失，常见的丢失原因包括：\n\n发送时丢失：\n生产者发送的消息未送达exchange\n消息到达exchange后未到达queue\n\n\nMQ宕机，queue将消息丢失\nconsumer接收到消息后未消费就宕机\n\n针对这些问题，RabbitMQ分别给出了解决方案：\n\n生产者确认机制\nmq持久化\n消费者确认机制\n失败重试机制\n\n生产者消息确认RabbitMQ提供了publisher confirm机制来避免消息发送到MQ过程中丢失。这种机制必须给每个消息指定一个唯一ID。消息发送到MQ以后，会返回一个结果给发送者，表示消息是否处理成功。返回结果有两种方式：\n\npublisher-confirm，发送者确认\n消息成功投递到交换机，返回ack\n消息未投递到交换机，返回nack\n\n\npublisher-return，发送者回执\n消息投递到交换机了，但是没有路由到队列。返回ACK，及路由失败原因。\n\n\n\nPS：确认机制发送消息时，需要给每个消息设置一个全局唯一id，以区分不同消息，避免ack冲突\n\n修改配置\n\n修改publisher服务中的application.yml文件，添加下面的内容：\nspring:  rabbitmq:    publisher-confirm-type: correlated    publisher-returns: true    template:      mandatory: true\n\npublish-confirm-type：开启publisher-confirm，这里支持两种类型：\nsimple：同步等待confirm结果，直到超时\ncorrelated：异步回调，定义ConfirmCallback，MQ返回结果时会回调这个ConfirmCallback\n\n\npublish-returns：开启publish-return功能，同样是基于callback机制，不过是定义ReturnCallback\ntemplate.mandatory：定义消息路由失败时的策略。true，则调用ReturnCallback；false：则直接丢弃消息\n\n\n定义Return回调\n\n每个RabbitTemplate只能配置一个ReturnCallback，因此需要在项目加载时配置。修改publisher服务，添加：\npackage cn.itcast.mq.config;import lombok.extern.slf4j.Slf4j;import org.springframework.amqp.rabbit.core.RabbitTemplate;import org.springframework.beans.BeansException;import org.springframework.context.ApplicationContext;import org.springframework.context.ApplicationContextAware;import org.springframework.context.annotation.Configuration;@Slf4j@Configurationpublic class CommonConfig implements ApplicationContextAware &#123;    @Override    public void setApplicationContext(ApplicationContext applicationContext) throws BeansException &#123;        // 获取RabbitTemplate        RabbitTemplate rabbitTemplate = applicationContext.getBean(RabbitTemplate.class);        // 设置ReturnCallback        rabbitTemplate.setReturnCallback((message, replyCode, replyText, exchange, routingKey) -&gt; &#123;            // 投递失败，记录日志            log.info(&quot;消息发送失败，应答码&#123;&#125;，原因&#123;&#125;，交换机&#123;&#125;，路由键&#123;&#125;,消息&#123;&#125;&quot;,                     replyCode, replyText, exchange, routingKey, message.toString());            // 如果有业务需要，可以重发消息        &#125;);    &#125;&#125;\nPS：Spring容器加载成功之后会通知实现ApplicationContextAware接口的类，接着调用 setApplicationContext方法。\n定义ConfirmCallbackConfirmCallback可以在发送消息时指定，因为每个业务处理confirm成功或失败的逻辑不一定相同。在publisher服务的cn.itcast.mq.spring.SpringAmqpTest类中，定义一个单元测试方法：\npublic void testSendMessage2SimpleQueue() throws InterruptedException &#123;    // 1.消息体    String message = &quot;hello, spring amqp!&quot;;    // 2.全局唯一的消息ID，需要封装到CorrelationData中    CorrelationData correlationData = new CorrelationData(UUID.randomUUID().toString());    // 3.添加callback    correlationData.getFuture().addCallback(        result -&gt; &#123;            if(result.isAck())&#123;                // 3.1.ack，消息成功                log.debug(&quot;消息发送成功, ID:&#123;&#125;&quot;, correlationData.getId());            &#125;else&#123;                // 3.2.nack，消息失败                log.error(&quot;消息发送失败, ID:&#123;&#125;, 原因&#123;&#125;&quot;,correlationData.getId(), result.getReason());            &#125;        &#125;,        ex -&gt; log.error(&quot;消息发送异常, ID:&#123;&#125;, 原因&#123;&#125;&quot;,correlationData.getId(),ex.getMessage())    );    // 4.发送消息    rabbitTemplate.convertAndSend(&quot;task.direct&quot;, &quot;task&quot;, message, correlationData);    // 休眠一会儿，等待ack回执    Thread.sleep(2000);&#125;\n\n消息持久化生产者确认可以确保消息投递到RabbitMQ的队列中，但是消息发送到RabbitMQ以后，如果突然宕机，也可能导致消息丢失。要想确保消息在RabbitMQ中安全保存，必须开启消息持久化机制。\n\n交换机持久化\n队列持久化\n消息持久化\n\n交换价持久化RabbitMQ中交换机默认是非持久化的，mq重启后就丢失。SpringAMQP中可以通过代码指定交换机持久化：\n@Beanpublic DirectExchange simpleExchange()&#123;    // 三个参数：交换机名称、是否持久化、当没有queue与其绑定时是否自动删除    return new DirectExchange(&quot;simple.direct&quot;, true, false);&#125;\n事实上，默认情况下，由SpringAMQP声明的交换机都是持久化的。\nPS：持久化的交换机在RabbitMQ控制台上会显示D标示\n队列持久化RabbitMQ中队列默认是非持久化的，mq重启后就丢失。SpringAMQP中可以通过代码指定交换机持久化：\n@Beanpublic Queue simpleQueue()&#123;    // 使用QueueBuilder构建队列，durable就是持久化的    return QueueBuilder.durable(&quot;simple.queue&quot;).build();&#125;\n默认情况下，由SpringAMQP声明的队列都是持久化的。\nPS：持久化的队列在RabbitMQ控制台会显示D标示\n消息持久化利用SpringAMQP发送消息时，可以设置消息的属性（MessageProperties），指定delivery-mode：\n\n非持久化\n持久化\n\nMessage message = MessageBuilder.withBody(&quot;hello,ttl queue&quot;\t.getBytes(StandardCharsets.UTF_8))\t.setDeliveryMode (MessageDeliveryMode.PERSISTENT)\t.build();\n默认情况下，SpringAMQP发出的任何消息都是持久化的，不用特意指定。\n消费者消息确认RabbitMQ是阅后即焚机制，RabbitMQ确认消息被消费者消费后会立刻删除。\nabbitMQ是通过消费者回执来确认消费者是否成功处理消息的：消费者获取消息后，应该向RabbitMQ发送ACK回执，表明自己已经处理消息。\neg：设想这样的场景：\n\n1）RabbitMQ投递消息给消费者\n2）消费者获取消息后，返回ACK给RabbitMQ\n3）RabbitMQ删除消息\n4）消费者宕机，消息尚未处理\n\n这样，消息就丢失了。因此消费者返回ACK的时机非常重要。\nSpringAMQP则允许配置三种确认模式：\n\nmanual：手动ack，需要在业务代码结束后，调用api发送ack。\nauto：自动ack，由spring监测listener代码是否出现异常，没有异常则返回ack；抛出异常则返回nack\nnone：关闭ack，MQ假定消费者获取消息后会成功处理，因此消息投递后立即被删除\n\nnone模式spring:  rabbitmq:    listener:      simple:        acknowledge-mode: none # 关闭ack\nPS：即使消息处理中出现异常，消息任然会被删除\nauto模式spring:  rabbitmq:    listener:      simple:        acknowledge-mode: auto # 关闭ack\nPS：消息处理中出现异常后，消息会被恢复为Ready状态，不会删除\n消息失败重试当消费者出现异常后，消息会不断requeue（重入队）到队列，再重新发送给消费者，然后再次异常，再次requeue，无限循环，导致mq的消息处理飙升，带来不必要的压力。解决方案：\n\n本地重试\n\n利用Spring的retry机制，在消费者出现异常时利用本地重试，而不是无限制的requeue到mq队列。修改consumer服务的application.yml文件，添加内容：\nspring:  rabbitmq:    listener:      simple:        retry:          enabled: true # 开启消费者失败重试          initial-interval: 1000 # 初识的失败等待时长为1秒          multiplier: 1 # 失败的等待时长倍数，下次等待时长 = multiplier * last-interval          max-attempts: 3 # 最大重试次数          stateless: true # true无状态；false有状态。如果业务中包含事务，这里改为false\n重启consumer服务，进行测试：\n\n在重试3次后，SpringAMQP会抛出异常AmqpRejectAndDontRequeueException，说明本地重试触发了\n查看RabbitMQ控制台，发现消息被删除了，说明最后SpringAMQP返回的是ack，mq删除消息了\n\n说明：\n\n开启本地重试时，消息处理过程中抛出异常，不会requeue到队列，而是在消费者本地重试\n重试达到最大次数后，Spring会返回ack，消息会被丢弃\n\n\n失败策略\n\n在本地重试中，达到最大重试次数后，消息会被丢弃，这是由Spring内部机制决定的。在开启重试模式后，重试次数耗尽，如果消息依然失败，则需要有MessageRecovery接口来处理，它包含三种不同的实现：\n\nRejectAndDontRequeueRecoverer：重试耗尽后，直接reject，丢弃消息。默认就是这种方式\nImmediateRequeueMessageRecoverer：重试耗尽后，返回nack，消息重新入队\nRepublishMessageRecoverer：重试耗尽后，将失败消息投递到指定的交换机\n\nRepublishMessageRecoverer：失败后将消息投递到一个指定的，专门存放异常消息的队列，后续由人工集中处理\n\n在consumer服务中定义处理失败消息的交换机和队列\n\n@Beanpublic DirectExchange errorMessageExchange()&#123;    return new DirectExchange(&quot;error.direct&quot;);&#125;@Beanpublic Queue errorQueue()&#123;    return new Queue(&quot;error.queue&quot;, true);&#125;@Beanpublic Binding errorBinding(Queue errorQueue, DirectExchange errorMessageExchange)&#123;    return BindingBuilder.bind(errorQueue).to(errorMessageExchange).with(&quot;error&quot;);&#125;\n\n\n定义一个RepublishMessageRecoverer，关联队列和交换机\n\n@Beanpublic MessageRecoverer republishMessageRecoverer(RabbitTemplate rabbitTemplate)&#123;    return new RepublishMessageRecoverer(rabbitTemplate, &quot;error.direct&quot;, &quot;error&quot;);&#125;\n\n死信交换机当一个队列中的消息满足下列情况之一时，可以成为死信（dead letter）：\n\n消费者使用basic.reject或 basic.nack声明消费失败，并且消息的requeue参数设置为false\n消息是一个过期消息，超时无人消费\n要投递的队列消息满了，无法投递\n\n如果这个包含死信的队列配置了dead-letter-exchange属性，指定了一个交换机，那么队列中的死信就会投递到这个交换机中，而这个交换机称为死信交换机（Dead Letter Exchange，检查DLX）。如果死信交换机也绑定了队列，则消息最终会进入这个存放死信的队列。\n队列将死信投递给死信交换机时，必须知道两个信息：\n\n死信交换机名称\n死信交换机与死信队列绑定的RoutingKey\n\n在失败重试策略中，默认的RejectAndDontRequeueRecoverer会在本地重试次数耗尽后，发送reject给RabbitMQ，消息变成死信，被丢弃。我们可以给simple.queue添加一个死信交换机，给死信交换机绑定一个队列。这样消息变成死信后也不会丢弃，而是最终投递到死信交换机，路由到与死信交换机绑定的队列。\nconsumer服务中，定义一组死信交换机、死信队列：\n// 声明普通的 simple.queue队列，并且为其指定死信交换机：dl.direct@Beanpublic Queue simpleQueue2()&#123;    return QueueBuilder.durable(&quot;simple.queue&quot;) // 指定队列名称，并持久化        .deadLetterExchange(&quot;dl.direct&quot;) // 指定死信交换机        .build();&#125;// 声明死信交换机 dl.direct@Beanpublic DirectExchange dlExchange()&#123;    return new DirectExchange(&quot;dl.direct&quot;, true, false);&#125;// 声明存储死信的队列 dl.queue@Beanpublic Queue dlQueue()&#123;    return new Queue(&quot;dl.queue&quot;, true);&#125;// 将死信队列 与 死信交换机绑定@Beanpublic Binding dlBinding()&#123;    return BindingBuilder.bind(dlQueue()).to(dlExchange()).with(&quot;simple&quot;);&#125;\n\nTTL一个队列中的消息如果超时未消费，则会变为死信，超时分为两种情况：\n\n消息所在的队列设置了超时时间\n消息本身设置了超时时间\n\n\n接收超时死信的死信交换机\n\n@RabbitListener(bindings = @QueueBinding(    value = @Queue(name = &quot;dl.ttl.queue&quot;, durable = &quot;true&quot;),    exchange = @Exchange(name = &quot;dl.ttl.direct&quot;),    key = &quot;ttl&quot;))public void listenDlQueue(String msg)&#123;    log.info(&quot;接收到 dl.ttl.queue的延迟消息：&#123;&#125;&quot;, msg);&#125;\n\n\n声明一个队列，并且指定TTL \n\n队列设置超时时间，需要在声明队列时配置x-message-ttl属性：\n@Beanpublic Queue ttlQueue()&#123;    return QueueBuilder.durable(&quot;ttl.queue&quot;) // 指定队列名称，并持久化        .ttl(10000) // 设置队列的超时时间，10秒        .deadLetterExchange(&quot;dl.ttl.direct&quot;) // 指定死信交换机        .build();&#125;\n队列设定了死信交换机为dl.ttl.direct\n声明交换机，将ttl与交换机绑定：\n@Beanpublic DirectExchange ttlExchange()&#123;    return new DirectExchange(&quot;ttl.direct&quot;);&#125;@Beanpublic Binding ttlBinding()&#123;    return BindingBuilder.bind(ttlQueue()).to(ttlExchange()).with(&quot;ttl&quot;);&#125;\n\n\n发送消息时，设定TTL：@Testpublic void testTTLMsg() &#123;    // 创建消息    Message message = MessageBuilder        .withBody(&quot;hello, ttl message&quot;.getBytes(StandardCharsets.UTF_8))        .setExpiration(&quot;5000&quot;)        .build();    // 消息ID，需要封装到CorrelationData中    CorrelationData correlationData = new CorrelationData(UUID.randomUUID().toString());    // 发送消息    rabbitTemplate.convertAndSend(&quot;ttl.direct&quot;, &quot;ttl&quot;, message, correlationData);    log.debug(&quot;发送消息成功&quot;);&#125;\nPS：当队列、消息都设置了TTL时，任意一个到期就会成为死信\n\n延迟队列利用TTL结合死信交换机，我们实现了消息发出后，消费者延迟收到消息的效果。这种消息模式就称为延迟队列（Delay Queue）模式。\nRabbitMQ官方推出了DelayExchange插件，原生支持延迟队列效果，参考RabbitMQ的插件列表页面：https://www.rabbitmq.com/community-plugins.html\n安装DelayExchange略\nDelayExchange原理DelayExchange需要将一个交换机声明为delayed类型。当我们发送消息到delayExchange时，流程如下：\n\n接收消息\n判断消息是否具备x-delay属性\n如果有x-delay属性，说明是延迟消息，持久化到硬盘，读取x-delay值，作为延迟时间\n返回routing not found结果给消息发送者\nx-delay时间到期后，重新投递消息到指定队列\n\nDelayExchange使用\n声明DelayExchange交换机\n\n\n注解方式\n\n代码注册@Bean\n\n\n\n发送消息，设置x-delay\n\n发送消息时，一定要携带x-delay属性，指定延迟的时间：\n\n\n惰性队列Lazy Queues（惰性队列）：\n\n接收到消息后直接存入磁盘而非内存\n消费者要消费消息时才会从磁盘中读取并加载到内存\n支持数百万条的消息存储\n\n\n基于命令行设置lazy-queue\n\n置一个队列为惰性队列，只需要在声明队列时，指定x-queue-mode属性为lazy即可。可以通过命令行将一个运行中的队列修改为惰性队列：\nrabbitmqctl set_policy Lazy &quot;^lazy-queue$&quot; &#x27;&#123;&quot;queue-mode&quot;:&quot;lazy&quot;&#125;&#x27; --apply-to queues  \n\nrabbitmqctl ：RabbitMQ的命令行工具\nset_policy ：添加一个策略\nLazy ：策略名称，可以自定义\n&quot;^lazy-queue$&quot; ：用正则表达式匹配队列的名字\n&#39;&#123;&quot;queue-mode&quot;:&quot;lazy&quot;&#125;&#39; ：设置队列模式为lazy模式\n--apply-to queues  ：策略的作用对象，是所有的队列\n\n\n基于@Bean声明lazy-queue\n\n\n\n\n基于@RabbitListener声明LazyQueue\n\n\n\n小结：消息堆积问题的解决方案？\n\n队列上绑定多个消费者，提高消费速度\n使用惰性队列，可以再mq中保存更多消息\n\n惰性队列的优点有哪些？\n\n基于磁盘存储，消息上限高\n没有间歇性的page-out，性能比较稳定\n\n惰性队列的缺点有哪些？\n\n基于磁盘存储，消息时效性会降低\n性能受限于磁盘的IO\n\nMQ集群在RabbitMQ的官方文档中，讲述了两种集群的配置方式：\n\n普通模式：普通模式集群不进行数据同步，每个MQ都有自己的队列、数据信息（其它元数据信息如交换机等会同步）。例如我们有2个MQ：mq1，和mq2，如果你的消息在mq1，而你连接到了mq2，那么mq2会去mq1拉取消息，然后返回给你。如果mq1宕机，消息就会丢失。\n镜像模式：与普通模式不同，队列会在各个mq的镜像节点之间同步，因此你连接到任何一个镜像节点，均可获取到消息。而且如果一个节点宕机，并不会导致数据丢失。不过，这种方式增加了数据同步的带宽消耗。\n仲裁队列：仲裁队列是3.8版本以后才有的新功能，用来替代镜像队列，具备下列特征：、\n与镜像队列一样，都是主从模式，支持主从数据同步\n使用非常简单，没有复杂的配置\n主从同步基于Raft协议，强一致\n\n\n\n普通模式部署三节点MQ集群| 主机名 | 控制台端口      | amqp通信端口    || —— | ————— | ————— || mq1    | 8081 —&gt; 15672 | 8071 —&gt; 5672  || mq2    | 8082 —&gt; 15672 | 8072 —&gt; 5672  || mq3    | 8083 —&gt; 15672 | 8073  —&gt; 5672 |\n集群中的节点标示默认都是：rabbit@[hostname]，因此以上三个节点的名称分别为：\n\nrabbit@mq1\nrabbit@mq2\nrabbit@mq3\n\n\n获取cookie\n\n集群模式中的每个RabbitMQ 节点使用 cookie 来确定它们是否被允许相互通信。要使两个节点能够通信，它们必须具有相同的共享秘密，称为Erlang cookie。cookie 只是一串最多 255 个字符的字母数字字符。\n每个集群节点必须具有相同的 cookie。实例之间也需要它来相互通信。从mq容器中获取一个cookie值，作为集群的cookie。执行下面的命令便可以获取到Cookie：\ndocker exec -it mq cat /var/lib/rabbitmq/.erlang.cookie\n\n\n配置文件\n\n新建rabbitmq.conf，内容：\nloopback_users.guest = falselisteners.tcp.default = 5672cluster_formation.peer_discovery_backend = rabbit_peer_discovery_classic_configcluster_formation.classic_config.nodes.1 = rabbit@mq1cluster_formation.classic_config.nodes.2 = rabbit@mq2cluster_formation.classic_config.nodes.3 = rabbit@mq3\n\n另新建文件，记录cookie\ncd /tmp# 创建cookie文件touch .erlang.cookie# 写入cookieecho &quot;FXZMCVGLBIXZCDEMMVZQ&quot; &gt; .erlang.cookie# 修改cookie文件的权限chmod 600 .erlang.cookie\n\n\n准备MQ节点目录\n\n准备三个目录，mq1、mq2、mq3\ncd /tmp# 创建目录mkdir mq1 mq2 mq3\n\n拷贝rabbitmq.conf、cookie文件到mq1、mq2、mq3：\n# 进入/tmpcd /tmp# 拷贝cp rabbitmq.conf mq1cp rabbitmq.conf mq2cp rabbitmq.conf mq3cp .erlang.cookie mq1cp .erlang.cookie mq2cp .erlang.cookie mq3\n\n\n启动集群\n\n创建网络\ndocker network create mq-net\n\n运行三个节点MQ容器：\ndocker run -d --net mq-net \\-v $&#123;PWD&#125;/mq1/rabbitmq.conf:/etc/rabbitmq/rabbitmq.conf \\-v $&#123;PWD&#125;/.erlang.cookie:/var/lib/rabbitmq/.erlang.cookie \\-e RABBITMQ_DEFAULT_USER=itcast \\-e RABBITMQ_DEFAULT_PASS=123321 \\--name mq1 \\--hostname mq1 \\-p 8071:5672 \\-p 8081:15672 \\rabbitmq:3.8-management\ndocker run -d --net mq-net \\-v $&#123;PWD&#125;/mq2/rabbitmq.conf:/etc/rabbitmq/rabbitmq.conf \\-v $&#123;PWD&#125;/.erlang.cookie:/var/lib/rabbitmq/.erlang.cookie \\-e RABBITMQ_DEFAULT_USER=itcast \\-e RABBITMQ_DEFAULT_PASS=123321 \\--name mq2 \\--hostname mq2 \\-p 8072:5672 \\-p 8082:15672 \\rabbitmq:3.8-management\ndocker run -d --net mq-net \\-v $&#123;PWD&#125;/mq3/rabbitmq.conf:/etc/rabbitmq/rabbitmq.conf \\-v $&#123;PWD&#125;/.erlang.cookie:/var/lib/rabbitmq/.erlang.cookie \\-e RABBITMQ_DEFAULT_USER=itcast \\-e RABBITMQ_DEFAULT_PASS=123321 \\--name mq3 \\--hostname mq3 \\-p 8073:5672 \\-p 8083:15672 \\rabbitmq:3.8-management\n\n镜像模式部署镜像模式下，创建队列的节点被称为该队列的主节点，队列还会拷贝到集群中的其它节点，为该队列的镜像节点。\n不同队列可以在集群中的任意节点上创建，因此不同队列的主节点可以不同。甚至，一个队列的主节点可能是另一个队列的镜像节点。\n用户发送给队列的一切请求，例如发送消息、消息回执默认都会在主节点完成，如果是从节点接收到请求，也会路由到主节点去完成。镜像节点仅仅起到备份数据作用。\n当主节点接收到消费者的ACK时，所有镜像都会删除节点中的数据。\n小结：\n\n镜像队列结构是一主多从（从就是镜像）\n所有操作都是主节点完成，然后同步给镜像节点\n主宕机后，镜像节点会替代成新的主（如果在主从同步完成前，主就已经宕机，可能出现数据丢失）\n不具备负载均衡功能，因为所有操作都会有主节点完成（但是不同队列，其主节点可以不同，可以利用这个提高吞吐量）\n\n镜像模式的配置有3种模式：| ha-mode         | ha-params         | 效果                                                         || :————– | :—————- | :———————————————————– || 准确模式exactly | 队列的副本量count | 集群中队列副本（主服务器和镜像服务器之和）的数量。count如果为1意味着单个副本：即队列主节点。count值为2表示2个副本：1个队列主和1个队列镜像。换句话说：count = 镜像数量 + 1。如果群集中的节点数少于count，则该队列将镜像到所有节点。如果有集群总数大于count+1，并且包含镜像的节点出现故障，则将在另一个节点上创建一个新的镜像。 || all             | (none)            | 队列在群集中的所有节点之间进行镜像。队列将镜像到任何新加入的节点。镜像到所有节点将对所有群集节点施加额外的压力，包括网络I / O，磁盘I / O和磁盘空间使用情况。推荐使用exactly，设置副本数为（N / 2 +1）。 || nodes           | node names      | 指定队列创建到哪些节点，如果指定的节点全部不存在，则会出现异常。如果指定的节点在集群中存在，但是暂时不可用，会创建节点到当前客户端连接到的节点。 |\n以rabbitmqctl命令作为案例来讲解配置语法：\n\nexactly模式\n\nrabbitmqctl set_policy ha-two &quot;^two\\.&quot; &#x27;&#123;&quot;ha-mode&quot;:&quot;exactly&quot;,&quot;ha-params&quot;:2,&quot;ha-sync-mode&quot;:&quot;automatic&quot;&#125;&#x27;\n\nrabbitmqctl set_policy：固定写法\nha-two：策略名称，自定义\n&quot;^two\\.&quot;：匹配队列的正则表达式，符合命名规则的队列才生效，这里是任何以two.开头的队列名称\n&#39;&#123;&quot;ha-mode&quot;:&quot;exactly&quot;,&quot;ha-params&quot;:2,&quot;ha-sync-mode&quot;:&quot;automatic&quot;&#125;&#39;: 策略内容\n&quot;ha-mode&quot;:&quot;exactly&quot;：策略模式，此处是exactly模式，指定副本数量\n&quot;ha-params&quot;:2：策略参数，这里是2，就是副本数量为2，1主1镜像\n&quot;ha-sync-mode&quot;:&quot;automatic&quot;：同步策略，默认是manual，即新加入的镜像节点不会同步旧的消息。如果设置为automatic，则新加入的镜像节点会把主节点中所有消息都同步，会带来额外的网络开销\n\n\n\n\nall模式\n\nrabbitmqctl set_policy ha-all &quot;^all\\.&quot; &#x27;&#123;&quot;ha-mode&quot;:&quot;all&quot;&#125;&#x27;\n\nha-all：策略名称，自定义\n&quot;^all\\.&quot;：匹配所有以all.开头的队列名\n&#39;&#123;&quot;ha-mode&quot;:&quot;all&quot;&#125;&#39;：策略内容\n&quot;ha-mode&quot;:&quot;all&quot;：策略模式，此处是all模式，即所有节点都会称为镜像节点\n\n\n\n\nnodes模式\n\nrabbitmqctl set_policy ha-nodes &quot;^nodes\\.&quot; &#x27;&#123;&quot;ha-mode&quot;:&quot;nodes&quot;,&quot;ha-params&quot;:[&quot;rabbit@nodeA&quot;, &quot;rabbit@nodeB&quot;]&#125;&#x27;\n\nrabbitmqctl set_policy：固定写法\nha-nodes：策略名称，自定义\n&quot;^nodes\\.&quot;：匹配队列的正则表达式，符合命名规则的队列才生效，这里是任何以nodes.开头的队列名称\n&#39;&#123;&quot;ha-mode&quot;:&quot;nodes&quot;,&quot;ha-params&quot;:[&quot;rabbit@nodeA&quot;, &quot;rabbit@nodeB&quot;]&#125;&#39;: 策略内容\n&quot;ha-mode&quot;:&quot;nodes&quot;：策略模式，此处是nodes模式\n&quot;ha-params&quot;:[&quot;rabbit@mq1&quot;, &quot;rabbit@mq2&quot;]：策略参数，这里指定副本所在节点名称\n\n\n\n仲裁队列部署在任意RabbitMQ控制台添加一个队列，选择队列类型为Quorum类型。仲裁队列默认的镜像数为5。如果你的集群有7个节点，那么镜像数肯定是5；而我们集群只有3个节点，因此镜像数量就是3。\nJava中创建仲裁队列：\n@Beanpublic Queue quorumQueue() &#123;    return QueueBuilder        .durable(&quot;quorum.queue&quot;) // 持久化        .quorum() // 仲裁队列        .build();&#125;\n\nSpringAMQP连接集群spring:  rabbitmq:    addresses: 192.168.150.105:8071, 192.168.150.105:8072, 192.168.150.105:8073    username: itcast    password: 123321    virtual-host: /\n\n集群扩容略。\nElasticSearch一个开源的分布式搜索引擎，可以用来实现搜索、日志统计、分析、系统监控等功能。\n安装部署因为我们还需要部署kibana容器，因此需要让es和kibana容器互联。这里先创建一个网络：\ndocker network create es-net\nES安装方式一：从DockerHub中pull到虚拟机安装方式二：下载好文件上传到虚拟机，然后加载文件\n# 导入数据docker load -i es.tar\n运行ES容器：\ndocker run -d \\\t--name es \\    -e &quot;ES_JAVA_OPTS=-Xms512m -Xmx512m&quot; \\    -e &quot;discovery.type=single-node&quot; \\    -v es-data:/usr/share/elasticsearch/data \\    -v es-plugins:/usr/share/elasticsearch/plugins \\    --privileged \\    --network es-net \\    -p 9200:9200 \\    -p 9300:9300 \\elasticsearch:7.12.1\n命令解释：\n\n-e &quot;cluster.name=es-docker-cluster&quot;：设置集群名称\n-e &quot;http.host=0.0.0.0&quot;：监听的地址，可以外网访问\n-e &quot;ES_JAVA_OPTS=-Xms512m -Xmx512m&quot;：内存大小\n-e &quot;discovery.type=single-node&quot;：非集群模式\n-v es-data:/usr/share/elasticsearch/data：挂载逻辑卷，绑定es的数据目录\n-v es-logs:/usr/share/elasticsearch/logs：挂载逻辑卷，绑定es的日志目录\n-v es-plugins:/usr/share/elasticsearch/plugins：挂载逻辑卷，绑定es的插件目录\n--privileged：授予逻辑卷访问权\n--network es-net ：加入一个名为es-net的网络中\n-p 9200:9200：端口映射配置\n\n在浏览器中输入：http://192.168.150.101:9200 即可看到elasticsearch的响应结果(192.168.150.101为虚拟机ip)：\n\nkibanakibana提供了一个elasticsearch的可视化界面，可以运行DSL语句，而且具有自动补全功能，方便学习ES。kibana安装同ES。运行kibana容器：\ndocker run -d \\--name kibana \\-e ELASTICSEARCH_HOSTS=http://es:9200 \\--network=es-net \\-p 5601:5601  \\kibana:7.12.1\n\n--network es-net ：加入一个名为es-net的网络中，与elasticsearch在同一个网络中\n-e ELASTICSEARCH_HOSTS=http://es:9200&quot;：设置elasticsearch的地址，因为kibana已经与elasticsearch在一个网络，因此可以用容器名直接访问elasticsearch\n-p 5601:5601：端口映射配置\n\n查看kibana日志，出现以下结果则kibana运行成功\ndocker logs -f kibana\n\nES基础倒排索引重要概念：\n\n文档（document）：用来搜索的数据，每一条数据就是一个文档。例如一个网页、一个商品信息\n词条（term）：对文档数据或用户搜索数据，利用某种算法分词，得到的具备含义的词语就是词条。例如：我是中国人，就可以分为：我、是、中国人、中国、国人这样的几个词条\n\n倒排索引是相对正向索引而言的。传统的正向索引在面对模糊查询时，通常需要逐行扫描数据判断是否符合查询条件，效率不高。创建倒排索引流程如下：\n\n将每一个文档的数据利用算法分词，得到一个个词条\n创建表，每行数据包括词条、词条所在文档id、位置等信息\n因为词条唯一性，可以给词条创建索引，例如hash表结构索引\n\n搜索流程如下：\n\n用户输入条件&quot;华为手机&quot;进行搜索\n对用户输入内容分词，得到词条：华为、手机。\n拿着词条在倒排索引中查找，可以得到包含词条的文档id：1、2、3。\n拿着文档id到正向索引中查找具体文档。\n\n文档和字段elasticsearch是面向文档（Document）存储的，可以是数据库中的一条商品数据，一个订单信息。文档数据会被序列化为json格式后存储在elasticsearch中。Json文档中往往包含很多的字段（Field），类似于数据库中的列。\n\n索引和映射索引（Index），就是相同类型的文档的集合。\n\n索引库中有映射（mapping），是索引中文档的字段约束信息，类似表的结构约束。常见mapping属性：\n\ntype：字段数据类型，常见的简单类型有：\n字符串：text（可分词的文本）、keyword（精确值，例如：品牌、国家、ip地址）\n数值：long、integer、short、byte、double、float、\n布尔：boolean\n日期：date\n对象：object\n地址（地理坐标，包含经纬度）：geo_point\n\n\nindex：是否创建索引，默认为true\nanalyzer：使用哪种分词器\nproperties：该字段的子字段\n\neg:\n&#123;    &quot;age&quot;: 21,    &quot;weight&quot;: 52.1,    &quot;isMarried&quot;: false,    &quot;info&quot;: &quot;黑马程序员Java讲师&quot;,    &quot;email&quot;: &quot;zy@itcast.cn&quot;,    &quot;score&quot;: [99.1, 99.5, 98.9],    &quot;name&quot;: &#123;        &quot;firstName&quot;: &quot;云&quot;,        &quot;lastName&quot;: &quot;赵&quot;    &#125;&#125;\n对应的每个字段映射（mapping）：\n\nage：类型为 integer；参与搜索，因此需要index为true；无需分词器\nweight：类型为float；参与搜索，因此需要index为true；无需分词器\nisMarried：类型为boolean；参与搜索，因此需要index为true；无需分词器\ninfo：类型为字符串，需要分词，因此是text；参与搜索，因此需要index为true；分词器可以用ik_smart\nemail：类型为字符串，但是不需要分词，因此是keyword；不参与搜索，因此需要index为false；无需分词器\nscore：虽然是数组，但是我们只看元素的类型，类型为float；参与搜索，因此需要index为true；无需分词器\nname：类型为object，需要定义多个子属性\nname.firstName；类型为字符串，但是不需要分词，因此是keyword；参与搜索，因此需要index为true；无需分词器\nname.lastName；类型为字符串，但是不需要分词，因此是keyword；参与搜索，因此需要index为true；无需分词器\n\n\n\nES与Mysql概念对比\n\n\nES\nMysql\n说明\n\n\n\nTable\nIndex\n索引(index)，就是文档的集合，类似数据库的表(table)\n\n\nRow\nDocument\n文档（Document），就是一条条的数据，类似数据库中的行（Row），文档都是JSON格式\n\n\nColumn\nField\n字段（Field），就是JSON文档中的字段，类似数据库中的列（Column）\n\n\nSchema\nMapping\nMapping（映射）是索引中文档的约束，例如字段类型约束。类似数据库的表结构（Schema）\n\n\nSQL\nDSL\nDSL是elasticsearch提供的JSON风格的请求语句，用来操作elasticsearch，实现CRUD\n\n\nik分词器安装配置ik分词器方式一：在线安装\n# 进入容器内部docker exec -it elasticsearch /bin/bash# 在线下载并安装./bin/elasticsearch-plugin  install https://github.com/medcl/elasticsearch-analysis-ik/releases/download/v7.12.1/elasticsearch-analysis-ik-7.12.1.zip#退出exit#重启容器docker restart elasticsearch\n方式二：离线安装ik插件\n\n查看ES数据卷目录docker volume inspect es-plugins\n结果如下：[    &#123;        &quot;CreatedAt&quot;: &quot;2022-05-06T10:06:34+08:00&quot;,        &quot;Driver&quot;: &quot;local&quot;,        &quot;Labels&quot;: null,        &quot;Mountpoint&quot;: &quot;/var/lib/docker/volumes/es-plugins/_data&quot;,        &quot;Name&quot;: &quot;es-plugins&quot;,        &quot;Options&quot;: null,        &quot;Scope&quot;: &quot;local&quot;    &#125;]\n说明plugins目录被挂载到了：/var/lib/docker/volumes/es-plugins/_data 目录\n将ik分词器文件上传到/var/lib/docker/volumes/es-plugins/_data \n重启ESdocker restart es\n分词模式\n\n\nik_smart：最少切分\nik_max_word：最细切分\n\nGET /_analyze&#123;  &quot;analyzer&quot;: &quot;ik_max_word&quot;,  &quot;text&quot;: &quot;黑马程序员学习java太棒了&quot;&#125;\n结果如下\n&#123;  &quot;tokens&quot; : [    &#123;      &quot;token&quot; : &quot;黑马&quot;,      &quot;start_offset&quot; : 0,      &quot;end_offset&quot; : 2,      &quot;type&quot; : &quot;CN_WORD&quot;,      &quot;position&quot; : 0    &#125;,    &#123;      &quot;token&quot; : &quot;程序员&quot;,      &quot;start_offset&quot; : 2,      &quot;end_offset&quot; : 5,      &quot;type&quot; : &quot;CN_WORD&quot;,      &quot;position&quot; : 1    &#125;,    &#123;      &quot;token&quot; : &quot;程序&quot;,      &quot;start_offset&quot; : 2,      &quot;end_offset&quot; : 4,      &quot;type&quot; : &quot;CN_WORD&quot;,      &quot;position&quot; : 2    &#125;,    &#123;      &quot;token&quot; : &quot;员&quot;,      &quot;start_offset&quot; : 4,      &quot;end_offset&quot; : 5,      &quot;type&quot; : &quot;CN_CHAR&quot;,      &quot;position&quot; : 3    &#125;,    &#123;      &quot;token&quot; : &quot;学习&quot;,      &quot;start_offset&quot; : 5,      &quot;end_offset&quot; : 7,      &quot;type&quot; : &quot;CN_WORD&quot;,      &quot;position&quot; : 4    &#125;,    &#123;      &quot;token&quot; : &quot;java&quot;,      &quot;start_offset&quot; : 7,      &quot;end_offset&quot; : 11,      &quot;type&quot; : &quot;ENGLISH&quot;,      &quot;position&quot; : 5    &#125;,    &#123;      &quot;token&quot; : &quot;太棒了&quot;,      &quot;start_offset&quot; : 11,      &quot;end_offset&quot; : 14,      &quot;type&quot; : &quot;CN_WORD&quot;,      &quot;position&quot; : 6    &#125;,    &#123;      &quot;token&quot; : &quot;太棒&quot;,      &quot;start_offset&quot; : 11,      &quot;end_offset&quot; : 13,      &quot;type&quot; : &quot;CN_WORD&quot;,      &quot;position&quot; : 7    &#125;,    &#123;      &quot;token&quot; : &quot;了&quot;,      &quot;start_offset&quot; : 13,      &quot;end_offset&quot; : 14,      &quot;type&quot; : &quot;CN_CHAR&quot;,      &quot;position&quot; : 8    &#125;  ]&#125;\n拓展词词典\n进入ikbana的config目录，修改IKAnalyzer.cfg.xml文件，添加&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;!DOCTYPE properties SYSTEM &quot;http://java.sun.com/dtd/properties.dtd&quot;&gt;&lt;properties&gt;        &lt;comment&gt;IK Analyzer 扩展配置&lt;/comment&gt;        &lt;!--用户可以在这里配置自己的扩展字典 *** 添加扩展词典--&gt;        &lt;entry key=&quot;ext_dict&quot;&gt;ext.dic&lt;/entry&gt;&lt;/properties&gt;\n在config目录下新建 ext.dic文件拿来吧你永远的神\n重启ESdocker restart es# 查看 日志docker logs -f elasticsearch\n停用词词典\n在IKAnalyzer.cfg.xml文件添加如下内容：&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;!DOCTYPE properties SYSTEM &quot;http://java.sun.com/dtd/properties.dtd&quot;&gt;&lt;properties&gt;        &lt;comment&gt;IK Analyzer 扩展配置&lt;/comment&gt;        &lt;!--用户可以在这里配置自己的扩展字典--&gt;        &lt;entry key=&quot;ext_dict&quot;&gt;ext.dic&lt;/entry&gt;         &lt;!--用户可以在这里配置自己的扩展停止词字典  *** 添加停用词词典--&gt;        &lt;entry key=&quot;ext_stopwords&quot;&gt;stopword.dic&lt;/entry&gt;&lt;/properties&gt;\n在stopword.dic文件中添加停用词黄赌毒\n重启ES# 重启服务docker restart elasticsearchdocker restart kibana# 查看 日志docker logs -f elasticsearch\nDSL索引库操作创建索引库和映射\n\n\n请求方式：PUT\n请求路径：/索引库名，可以自定义\n请求参数：mapping映射\n\n格式：\nPUT /索引库名称&#123;  &quot;mappings&quot;: &#123;    &quot;properties&quot;: &#123;      &quot;字段名&quot;:&#123;        &quot;type&quot;: &quot;text&quot;,        &quot;analyzer&quot;: &quot;ik_smart&quot;      &#125;,      &quot;字段名2&quot;:&#123;        &quot;type&quot;: &quot;keyword&quot;,        &quot;index&quot;: &quot;false&quot;      &#125;,      &quot;字段名3&quot;:&#123;        &quot;properties&quot;: &#123;          &quot;子字段&quot;: &#123;            &quot;type&quot;: &quot;keyword&quot;          &#125;        &#125;      &#125;,      // ...略    &#125;  &#125;&#125;\neg：\nPUT /heima&#123;  &quot;mappings&quot;: &#123;    &quot;properties&quot;: &#123;      &quot;info&quot;:&#123;        &quot;type&quot;: &quot;text&quot;,        &quot;analyzer&quot;: &quot;ik_smart&quot;      &#125;,      &quot;email&quot;:&#123;        &quot;type&quot;: &quot;keyword&quot;,        &quot;index&quot;: &quot;falsae&quot;      &#125;,      &quot;name&quot;:&#123;        &quot;properties&quot;: &#123;          &quot;firstName&quot;: &#123;            &quot;type&quot;: &quot;keyword&quot;          &#125;        &#125;      &#125;,      // ... 略    &#125;  &#125;&#125;\n查询索引库\n请求方式：GET\n请求路径：/索引库名\n请求参数：无\n\n格式：\nGET /索引库名\n修改索引库倒排索引一旦数据结构改变，需要重新创建倒排索引。因此ES索引库一旦创建，无法修改mapping。虽然无法修改，但是ES允许添加新的字段到mapping中，因为不会对倒排索引产生影响。\nPUT /索引库名/_mapping&#123;  &quot;properties&quot;: &#123;    &quot;新字段名&quot;:&#123;      &quot;type&quot;: &quot;integer&quot;    &#125;  &#125;&#125;\n删除索引库\n请求方式：DELETE\n请求路径：/索引库名\n请求参数：无\n\n格式：\nDELETE /索引库名\n文档操作新增文档格式：\nPOST /索引库名/_doc/文档id&#123;    &quot;字段1&quot;: &quot;值1&quot;,    &quot;字段2&quot;: &quot;值2&quot;,    &quot;字段3&quot;: &#123;        &quot;子属性1&quot;: &quot;值3&quot;,        &quot;子属性2&quot;: &quot;值4&quot;    &#125;,    // ...&#125;\neg：\nPOST /heima/_doc/1&#123;    &quot;info&quot;: &quot;黑马程序员Java讲师&quot;,    &quot;email&quot;: &quot;zy@itcast.cn&quot;,    &quot;name&quot;: &#123;        &quot;firstName&quot;: &quot;云&quot;,        &quot;lastName&quot;: &quot;赵&quot;    &#125;&#125;\n查询文档格式：\nGET /&#123;索引库名称&#125;/_doc/&#123;id&#125;\n删除文档格式：\nDELETE /&#123;索引库名&#125;/_doc/id值\n修改文档全量修改：直接覆盖原有文档（如果文档不存在则会新建文档）格式：\nPUT /&#123;索引库名&#125;/_doc/文档id&#123;    &quot;字段1&quot;: &quot;值1&quot;,    &quot;字段2&quot;: &quot;值2&quot;,    // ... 略&#125;\n增量修改：修改文档中的部分字段\nPOST /&#123;索引库名&#125;/_update/文档id&#123;    &quot;doc&quot;: &#123;         &quot;字段名&quot;: &quot;新的值&quot;,    &#125;&#125;\n查询文档ES copy_to参数：将多个字段合并为一个字段进行查询，可以避免由于多字段查询时的效率低问题。在创建映射时可以设置该属性，但是该字段仅在查询时起作用，并不会直接作为数据存在ES中。PS：搜索字段越多，对查询性能影响越大，因此建议采用copy_to，然后单字段查询的方式。\n常见的查询类型包括：\n\n查询所有：查询出所有数据，一般测试用。例如：match_all\n\n全文检索（full text）查询：利用分词器对用户输入内容分词，然后去倒排索引库中匹配。例如：\n\nmatch_query\nmulti_match_query\n\n\n精确查询：根据精确词条值查找数据，一般是查找keyword、数值、日期、boolean等类型字段。例如：\n\nids\nrange\nterm\n\n\n地理（geo）查询：根据经纬度查询。例如：\n\ngeo_distance\ngeo_bounding_box\n\n\n复合（compound）查询：复合查询可以将上述各种查询条件组合起来，合并查询条件。例如：\n\nbool\nfunction_score\n\n\n\n基本语法：\nGET /indexName/_search&#123;  &quot;query&quot;: &#123;    &quot;查询类型&quot;: &#123;      &quot;查询条件&quot;: &quot;条件值&quot;    &#125;  &#125;&#125;\neg：查询所有\n// 查询所有GET /indexName/_search&#123;  &quot;query&quot;: &#123;    &quot;match_all&quot;: &#123;    &#125;  &#125;&#125;\n全文检索查询参与搜索的字段也必须是可分词的text类型的字段\n\nmatch查询：单字段查询\nmulti_match查询：多字段查询，任意一个字段符合条件就算符合查询条件\n\nmatch查询格式：\nGET /indexName/_search&#123;  &quot;query&quot;: &#123;    &quot;match&quot;: &#123;      &quot;FIELD&quot;: &quot;TEXT&quot;    &#125;  &#125;&#125;\nmulit_match查询格式：\nGET /indexName/_search&#123;  &quot;query&quot;: &#123;    &quot;multi_match&quot;: &#123;      &quot;query&quot;: &quot;TEXT&quot;,      &quot;fields&quot;: [&quot;FIELD1&quot;, &quot; FIELD12&quot;]    &#125;  &#125;&#125;\n精准查询一般是查找keyword、数值、日期、boolean等类型字段。所以不会对搜索条件分词。\n\nterm：根据词条精确值查询\nrange：根据值的范围查询\n\nterm查询：\n// term查询GET /indexName/_search&#123;  &quot;query&quot;: &#123;    &quot;term&quot;: &#123;      &quot;FIELD&quot;: &#123;        &quot;value&quot;: &quot;VALUE&quot;      &#125;    &#125;  &#125;&#125;\nrange查询：\n// range查询GET /indexName/_search&#123;  &quot;query&quot;: &#123;    &quot;range&quot;: &#123;      &quot;FIELD&quot;: &#123;        &quot;gte&quot;: 10, // 这里的gte代表大于等于，gt则代表大于        &quot;lte&quot;: 20 // lte代表小于等于，lt则代表小于      &#125;    &#125;  &#125;&#125;\n地理坐标查询\n矩形范围查询// geo_bounding_box查询GET /indexName/_search&#123;  &quot;query&quot;: &#123;    &quot;geo_bounding_box&quot;: &#123;      &quot;FIELD&quot;: &#123;        &quot;top_left&quot;: &#123; // 左上点          &quot;lat&quot;: 31.1,          &quot;lon&quot;: 121.5        &#125;,        &quot;bottom_right&quot;: &#123; // 右下点          &quot;lat&quot;: 30.9,          &quot;lon&quot;: 121.7        &#125;      &#125;    &#125;  &#125;&#125;\n距离查询也称附近查询// geo_distance 查询GET /indexName/_search&#123;  &quot;query&quot;: &#123;    &quot;geo_distance&quot;: &#123;      &quot;distance&quot;: &quot;15km&quot;, // 半径      &quot;FIELD&quot;: &quot;31.21,121.5&quot; // 圆心    &#125;  &#125;&#125;\n复合查询相关性算分当我们利用match查询时，文档结果会根据与搜索词条的关联度打分（_score），返回结果时按照分值降序排列。ES会根据词条和文档的相关度做打分，算法由两种：\n\n\nTF-IDF算法\nBM25算法，elasticsearch5.1版本后采用的算法\n\n\nTF-IDF算法有一各缺陷，就是词条频率越高，文档得分也会越高，单个词条对文档影响较大。而BM25则会让单个词条的算分有一个上限，曲线更加平滑。\n\n算分函数查询通过控制算分函数调整最终的查询相关性得分。function score\n\nfunction score 查询中包含四部分内容：\n\n原始查询条件：query部分，基于这个条件搜索文档，并且基于BM25算法给文档打分，原始算分（query score)\n过滤条件：filter部分，符合该条件的文档才会重新算分\n算分函数：符合filter条件的文档要根据这个函数做运算，得到的函数算分（function score），有四种函数\nweight：函数结果是常量\nfield_value_factor：以文档中的某个字段值作为函数结果\nrandom_score：以随机数作为函数结果\nscript_score：自定义算分函数算法\n\n\n运算模式：算分函数的结果、原始查询的相关性算分，两者之间的运算方式，包括：\nmultiply：相乘\nreplace：用function score替换query score\n其它，例如：sum、avg、max、min\n\n\n\nfunction score的运行流程如下：\n\n根据原始条件查询搜索文档，并且计算相关性算分，称为原始算分（query score）\n根据过滤条件，过滤文档\n符合过滤条件的文档，基于算分函数运算，得到函数算分（function score）\n将原始算分（query score）和函数算分（function score）基于运算模式做运算，得到最终结果，作为相关性算分。\n\neg：使“如家”这个品牌的酒店排名靠前一些\nGET /hotel/_search&#123;  &quot;query&quot;: &#123;    &quot;function_score&quot;: &#123;      &quot;query&quot;: &#123;  .... &#125;, // 原始查询，可以是任意条件      &quot;functions&quot;: [ // 算分函数        &#123;          &quot;filter&quot;: &#123; // 满足的条件，品牌必须是如家            &quot;term&quot;: &#123;              &quot;brand&quot;: &quot;如家&quot;            &#125;          &#125;,          &quot;weight&quot;: 2 // 算分权重为2        &#125;      ],      &quot;boost_mode&quot;: &quot;sum&quot; // 加权模式，求和    &#125;  &#125;&#125;\n布尔查询布尔查询是一个或多个查询子句的组合，每一个子句就是一个子查询。子查询的组合方式有：\n\nmust：必须匹配每个子查询，类似“与”\nshould：选择性匹配子查询，类似“或”\nmust_not：必须不匹配，不参与算分，类似“非”\nfilter：必须匹配，不参与算分\n\nPS：需要注意的是，搜索时，参与打分的字段越多，查询的性能也越差。因此这种多条件查询时，建议：\n\n搜索框的关键字搜索，是全文检索查询，使用must查询，参与算分\n其它过滤条件，采用filter查询。不参与算分\n\neg：\nGET /hotel/_search&#123;  &quot;query&quot;: &#123;    &quot;bool&quot;: &#123;      &quot;must&quot;: [        &#123;&quot;term&quot;: &#123;&quot;city&quot;: &quot;上海&quot; &#125;&#125;      ],      &quot;should&quot;: [        &#123;&quot;term&quot;: &#123;&quot;brand&quot;: &quot;皇冠假日&quot; &#125;&#125;,        &#123;&quot;term&quot;: &#123;&quot;brand&quot;: &quot;华美达&quot; &#125;&#125;      ],      &quot;must_not&quot;: [        &#123; &quot;range&quot;: &#123; &quot;price&quot;: &#123; &quot;lte&quot;: 500 &#125; &#125;&#125;      ],      &quot;filter&quot;: [        &#123; &quot;range&quot;: &#123;&quot;score&quot;: &#123; &quot;gte&quot;: 45 &#125; &#125;&#125;      ]    &#125;  &#125;&#125;\n搜索结果排序ES默认根据相关度算分（_score）排序，但是也支持自定义方式对搜索排序。可以排序字段类型有：keyword类型、数值类型、地理坐标类型、日期类型等。\n\n普通字段排序\n\nkeyword、数值、日期类型排序的语法基本一致。\nGET /indexName/_search&#123;  &quot;query&quot;: &#123;    &quot;match_all&quot;: &#123;&#125;  &#125;,  &quot;sort&quot;: [    &#123;      &quot;FIELD&quot;: &quot;desc&quot;  // 排序字段、排序方式ASC、DESC    &#125;  ]&#125;\nPS：排序条件是一个数组，也就是可以写多个排序条件。按照声明的顺序，当第一个条件相等时，再按照第二个条件排序，以此类推。2. 地理坐标排序\nGET /indexName/_search&#123;  &quot;query&quot;: &#123;    &quot;match_all&quot;: &#123;&#125;  &#125;,  &quot;sort&quot;: [    &#123;      &quot;_geo_distance&quot; : &#123;          &quot;FIELD&quot; : &quot;纬度，经度&quot;, // 文档中geo_point类型的字段名、目标坐标点          &quot;order&quot; : &quot;asc&quot;, // 排序方式          &quot;unit&quot; : &quot;km&quot; // 排序的距离单位      &#125;    &#125;  ]&#125;\n\n指定一个坐标，作为目标点\n计算每一个文档中，指定字段（必须是geo_point类型）的坐标 到目标点的距离是多少\n根据距离排序\n\n分页ES默认情况下只返回top10的数据。查询更多数据可以通过修改from、size参数来控制要返回的分页结果：\n\nfrom：从第几个文档开始\nsize：总共查询几个文档\n\n基本分页GET /hotel/_search&#123;  &quot;query&quot;: &#123;    &quot;match_all&quot;: &#123;&#125;  &#125;,  &quot;from&quot;: 0, // 分页开始的位置，默认为0  &quot;size&quot;: 10, // 期望获取的文档总数  &quot;sort&quot;: [    &#123;&quot;price&quot;: &quot;asc&quot;&#125;  ]&#125;\n深度分页\n单点ES分页过程 例如查询9901000的数据，ES会将查询排序01000条数据，然后截取990~1000的10条数据。\n集群模式分页 集群模式下有N个ES节点，查询9901000的数据，此时要对每个ES节点进行9901000的数据查询过程，最后将所有节点的数据（注意是每个节点的01000数据，而不是每个节点的9901000数据）进行汇总排序，最终得到正确的990~1000的数据。 可见，集群模式下ES的数据查询的消耗是十分巨大的，会对内存和CPU造成巨大压力，因此ES禁止form+size超过10000的查询请求。 针对深度分页问题，ES提供两种解决方案：\nsearch after：分页时需要排序，原理是从上一次的排序值开始，查询下一页数据。官方推荐使用的方式。\n原理将排序后的文档id形成快照，保存在内存。官方已经不推荐使用。\n\n\n\n高亮搜索结果中的高亮显示:\n\n给文档中的所有关键字都添加一个标签，例如&lt;em&gt;标签\n页面给&lt;em&gt;标签编写CSS样式\n\n高亮语法:\nGET /hotel/_search&#123;  &quot;query&quot;: &#123;    &quot;match&quot;: &#123;      &quot;FIELD&quot;: &quot;TEXT&quot; // 查询条件，高亮一定要使用全文检索查询    &#125;  &#125;,  &quot;highlight&quot;: &#123;    &quot;fields&quot;: &#123; // 指定要高亮的字段      &quot;FIELD&quot;: &#123;        &quot;pre_tags&quot;: &quot;&lt;em&gt;&quot;,  // 用来标记高亮字段的前置标签        &quot;post_tags&quot;: &quot;&lt;/em&gt;&quot; // 用来标记高亮字段的后置标签      &#125;    &#125;  &#125;&#125;\nPS:\n\n高亮是对关键字高亮，因此搜索条件必须带有关键字，而不能是范围这样的查询。\n默认情况下，高亮的字段，必须与搜索指定的字段一致，否则无法高亮\n如果要对非搜索字段高亮，则需要添加一个属性：required_field_match=false\n\n数据聚合根据文档的属性值对文档进行分组。三类聚合：\n\n桶（Bucket）聚合：用来对文档做分组\nTermAggregation：按照文档字段值分组，例如按照品牌值分组、按照国家分组\nDate Histogram：按照日期阶梯分组，例如一周为一组，或者一月为一组\n\n\n度量（Metric）聚合：用以计算一些值，比如：最大值、最小值、平均值等\nAvg：求平均值\nMax：求最大值\nMin：求最小值\nStats：同时求max、min、avg、sum等\n\n\n管道（pipeline）聚合：其它聚合的结果为基础做聚合\n\nPS：参加聚合的字段必须是keyword、日期、数值、布尔类型\nBucket聚合GET /hotel/_search&#123;  &quot;size&quot;: 0,  // 设置size为0，结果中不包含文档，只包含聚合结果  &quot;aggs&quot;: &#123; // 定义聚合    &quot;brandAgg&quot;: &#123; //给聚合起个名字      &quot;terms&quot;: &#123; // 聚合的类型，按照品牌值聚合，所以选择term        &quot;field&quot;: &quot;brand&quot;, // 参与聚合的字段        &quot;size&quot;: 20 // 希望获取的聚合结果数量      &#125;    &#125;  &#125;&#125;\n\n聚合结果排序：Bucket聚合会统计Bucket内的文档数量记为_count，并且按照_count降序排序。可以指定order属性，自定义聚合的排序方式：\nGET /hotel/_search&#123;  &quot;size&quot;: 0,   &quot;aggs&quot;: &#123;    &quot;brandAgg&quot;: &#123;      &quot;terms&quot;: &#123;        &quot;field&quot;: &quot;brand&quot;,        &quot;order&quot;: &#123;          &quot;_count&quot;: &quot;asc&quot; // 按照_count升序排列        &#125;,        &quot;size&quot;: 20      &#125;    &#125;  &#125;&#125;\n\n限定聚合范围：限定要聚合的文档范围，只要添加query条件即可。\nGET /hotel/_search&#123;  &quot;query&quot;: &#123;    &quot;range&quot;: &#123;      &quot;price&quot;: &#123;        &quot;lte&quot;: 200 // 只对200元以下的文档聚合      &#125;    &#125;  &#125;,   &quot;size&quot;: 0,   &quot;aggs&quot;: &#123;    &quot;brandAgg&quot;: &#123;      &quot;terms&quot;: &#123;        &quot;field&quot;: &quot;brand&quot;,        &quot;size&quot;: 20      &#125;    &#125;  &#125;&#125;\nMetric聚合语法GET /hotel/_search&#123;  &quot;size&quot;: 0,   &quot;aggs&quot;: &#123;    &quot;brandAgg&quot;: &#123;       &quot;terms&quot;: &#123;         &quot;field&quot;: &quot;brand&quot;,         &quot;size&quot;: 20      &#125;,      &quot;aggs&quot;: &#123; // 是brands聚合的子聚合，也就是分组后对每组分别计算        &quot;score_stats&quot;: &#123; // 聚合名称          &quot;stats&quot;: &#123; // 聚合类型，这里stats可以计算min、max、avg等            &quot;field&quot;: &quot;score&quot; // 聚合字段，这里是score          &#125;        &#125;      &#125;    &#125;  &#125;&#125;\n\n自定义分词器默认的拼音分词器会将每个汉字单独分为拼音，而我们希望的是每个词条形成一组拼音，需要对拼音分词器做个性化定制，形成自定义分词器。elasticsearch中分词器（analyzer）的组成包含三部分：\n\ncharacter filters：在tokenizer之前对文本进行处理。例如删除字符、替换字符\ntokenizer：将文本按照一定的规则切割成词条（term）。例如keyword，就是不分词；还有ik_smart\ntokenizer filter：将tokenizer输出的词条做进一步处理。例如大小写转换、同义词处理、拼音处理等拼音分词器拼音分词插件，地址：https://github.com/medcl/elasticsearch-analysis-pinyin安装同IK分词器安装后测试：POST /_analyze&#123;  &quot;text&quot;: &quot;如家酒店还不错&quot;,  &quot;analyzer&quot;: &quot;pinyin&quot;&#125;\n声明自定义分词器PUT /test&#123;  &quot;settings&quot;: &#123;    &quot;analysis&quot;: &#123;      &quot;analyzer&quot;: &#123; // 自定义分词器        &quot;my_analyzer&quot;: &#123;  // 分词器名称          &quot;tokenizer&quot;: &quot;ik_max_word&quot;,          &quot;filter&quot;: &quot;py&quot;        &#125;      &#125;,      &quot;filter&quot;: &#123; // 自定义tokenizer filter        &quot;py&quot;: &#123; // 过滤器名称          &quot;type&quot;: &quot;pinyin&quot;, // 过滤器类型，这里是pinyin\t\t  &quot;keep_full_pinyin&quot;: false,          &quot;keep_joined_full_pinyin&quot;: true,          &quot;keep_original&quot;: true,          &quot;limit_first_letter_length&quot;: 16,          &quot;remove_duplicated_term&quot;: true,          &quot;none_chinese_pinyin_tokenize&quot;: false        &#125;      &#125;    &#125;  &#125;,  &quot;mappings&quot;: &#123;    &quot;properties&quot;: &#123;      &quot;name&quot;: &#123;        &quot;type&quot;: &quot;text&quot;,        &quot;analyzer&quot;: &quot;my_analyzer&quot;,        &quot;search_analyzer&quot;: &quot;ik_smart&quot;      &#125;    &#125;  &#125;&#125;\n自动补全查询elasticsearch提供了Completion Suggester查询来实现自动补全功能。这个查询会匹配以用户输入内容开头的词条并返回。为了提高补全查询的效率，对于文档中字段的类型有一些约束：\n参与补全查询的字段必须是completion类型。\n字段的内容一般是用来补全的多个词条形成的数组。\n\neg：\n\n创建索引库// 创建索引库PUT test&#123;  &quot;mappings&quot;: &#123;    &quot;properties&quot;: &#123;      &quot;title&quot;:&#123;        &quot;type&quot;: &quot;completion&quot;      &#125;    &#125;  &#125;&#125;\n插入数据// 示例数据POST test/_doc&#123;  &quot;title&quot;: [&quot;Sony&quot;, &quot;WH-1000XM3&quot;]&#125;POST test/_doc&#123;  &quot;title&quot;: [&quot;SK-II&quot;, &quot;PITERA&quot;]&#125;POST test/_doc&#123;  &quot;title&quot;: [&quot;Nintendo&quot;, &quot;switch&quot;]&#125;\n测试自动补全// 自动补全查询GET /test/_search&#123;  &quot;suggest&quot;: &#123;    &quot;title_suggest&quot;: &#123;      &quot;text&quot;: &quot;s&quot;, // 关键字      &quot;completion&quot;: &#123;        &quot;field&quot;: &quot;title&quot;, // 补全查询的字段        &quot;skip_duplicates&quot;: true, // 跳过重复的        &quot;size&quot;: 10 // 获取前10条结果      &#125;    &#125;  &#125;&#125;\n\nRestAPI操作ES的客户端，官方文档：https://www.elastic.co/guide/en/elasticsearch/client/index.html\n准备工作\n引入ES RestHighLevelClient依赖&lt;dependency&gt;    &lt;groupId&gt;org.elasticsearch.client&lt;/groupId&gt;    &lt;artifactId&gt;elasticsearch-rest-high-level-client&lt;/artifactId&gt;&lt;/dependency&gt;\n覆盖SpringBoot的默认版本&lt;properties&gt;    &lt;java.version&gt;1.8&lt;/java.version&gt;    &lt;elasticsearch.version&gt;7.12.1&lt;/elasticsearch.version&gt;&lt;/properties&gt;\n初始化RestHighLevelClientRestHighLevelClient client = new RestHighLevelClient(RestClient.builder(        HttpHost.create(&quot;http://192.168.150.101:9200&quot;)));\n单元测试类package cn.itcast.hotel;import org.apache.http.HttpHost;import org.elasticsearch.client.RestHighLevelClient;import org.junit.jupiter.api.AfterEach;import org.junit.jupiter.api.BeforeEach;import org.junit.jupiter.api.Test;import java.io.IOException;public class HotelIndexTest &#123;    private RestHighLevelClient client;    @BeforeEach    void setUp() &#123;        this.client = new RestHighLevelClient(RestClient.builder(                HttpHost.create(&quot;http://192.168.150.101:9200&quot;)        ));    &#125;    @AfterEach    void tearDown() throws IOException &#123;        this.client.close();    &#125;&#125;\n操作索引库创建索引库使用Java代码操作ES时，操作步骤可以仿照DSL语句来编写代码，逻辑会比较清晰\n准备DSL语句\n\npackage cn.itcast.hotel.constants;public class HotelConstants &#123;    public static final String MAPPING_TEMPLATE = &quot;&#123;\\n&quot; +            &quot;  \\&quot;mappings\\&quot;: &#123;\\n&quot; +            &quot;    \\&quot;properties\\&quot;: &#123;\\n&quot; +            &quot;      \\&quot;id\\&quot;: &#123;\\n&quot; +            &quot;        \\&quot;type\\&quot;: \\&quot;keyword\\&quot;\\n&quot; +            &quot;      &#125;,\\n&quot; +            &quot;      \\&quot;name\\&quot;:&#123;\\n&quot; +            &quot;        \\&quot;type\\&quot;: \\&quot;text\\&quot;,\\n&quot; +            &quot;        \\&quot;analyzer\\&quot;: \\&quot;ik_max_word\\&quot;,\\n&quot; +            &quot;        \\&quot;copy_to\\&quot;: \\&quot;all\\&quot;\\n&quot; +            &quot;      &#125;,\\n&quot; +            &quot;      \\&quot;address\\&quot;:&#123;\\n&quot; +            &quot;        \\&quot;type\\&quot;: \\&quot;keyword\\&quot;,\\n&quot; +            &quot;        \\&quot;index\\&quot;: false\\n&quot; +            &quot;      &#125;,\\n&quot; +            &quot;      \\&quot;price\\&quot;:&#123;\\n&quot; +            &quot;        \\&quot;type\\&quot;: \\&quot;integer\\&quot;\\n&quot; +            &quot;      &#125;,\\n&quot; +            &quot;      \\&quot;score\\&quot;:&#123;\\n&quot; +            &quot;        \\&quot;type\\&quot;: \\&quot;integer\\&quot;\\n&quot; +            &quot;      &#125;,\\n&quot; +            &quot;      \\&quot;brand\\&quot;:&#123;\\n&quot; +            &quot;        \\&quot;type\\&quot;: \\&quot;keyword\\&quot;,\\n&quot; +            &quot;        \\&quot;copy_to\\&quot;: \\&quot;all\\&quot;\\n&quot; +            &quot;      &#125;,\\n&quot; +            &quot;      \\&quot;city\\&quot;:&#123;\\n&quot; +            &quot;        \\&quot;type\\&quot;: \\&quot;keyword\\&quot;,\\n&quot; +            &quot;        \\&quot;copy_to\\&quot;: \\&quot;all\\&quot;\\n&quot; +            &quot;      &#125;,\\n&quot; +            &quot;      \\&quot;starName\\&quot;:&#123;\\n&quot; +            &quot;        \\&quot;type\\&quot;: \\&quot;keyword\\&quot;\\n&quot; +            &quot;      &#125;,\\n&quot; +            &quot;      \\&quot;business\\&quot;:&#123;\\n&quot; +            &quot;        \\&quot;type\\&quot;: \\&quot;keyword\\&quot;\\n&quot; +            &quot;      &#125;,\\n&quot; +            &quot;      \\&quot;location\\&quot;:&#123;\\n&quot; +            &quot;        \\&quot;type\\&quot;: \\&quot;geo_point\\&quot;\\n&quot; +            &quot;      &#125;,\\n&quot; +            &quot;      \\&quot;pic\\&quot;:&#123;\\n&quot; +            &quot;        \\&quot;type\\&quot;: \\&quot;keyword\\&quot;,\\n&quot; +            &quot;        \\&quot;index\\&quot;: false\\n&quot; +            &quot;      &#125;,\\n&quot; +            &quot;      \\&quot;all\\&quot;:&#123;\\n&quot; +            &quot;        \\&quot;type\\&quot;: \\&quot;text\\&quot;,\\n&quot; +            &quot;        \\&quot;analyzer\\&quot;: \\&quot;ik_max_word\\&quot;\\n&quot; +            &quot;      &#125;\\n&quot; +            &quot;    &#125;\\n&quot; +            &quot;  &#125;\\n&quot; +            &quot;&#125;&quot;;&#125;\n向ES发送请求创建索引库\n@Testvoid createHotelIndex() throws IOException &#123;    // 1.创建Request对象    CreateIndexRequest request = new CreateIndexRequest(&quot;hotel&quot;);    // 2.准备请求的参数：DSL语句    request.source(MAPPING_TEMPLATE, XContentType.JSON);    // 3.发送请求    client.indices().create(request, RequestOptions.DEFAULT);&#125;\n\n创建Request对象。因为是创建索引库的操作，因此Request是CreateIndexRequest。\n添加请求参数，其实就是DSL的JSON参数部分。因为json字符串很长，这里是定义了静态字符串常量MAPPING_TEMPLATE，让代码看起来更加优雅。\n发送请求，client.indices()方法的返回值是IndicesClient类型，封装了所有与索引库操作有关的方法。\n\n删除索引库\n创建Request对象。这次是DeleteIndexRequest对象\n准备参数。这里是无参\n发送请求。改用delete方法\n\n@Testvoid testDeleteHotelIndex() throws IOException &#123;    // 1.创建Request对象    DeleteIndexRequest request = new DeleteIndexRequest(&quot;hotel&quot;);    // 2.发送请求    client.indices().delete(request, RequestOptions.DEFAULT);&#125;\n查询索引库是否存在\n创建Request对象。这次是GetIndexRequest对象\n准备参数。这里是无参\n发送请求。改用exists方法\n\n@Testvoid testExistsHotelIndex() throws IOException &#123;    // 1.创建Request对象    GetIndexRequest request = new GetIndexRequest(&quot;hotel&quot;);    // 2.发送请求    boolean exists = client.indices().exists(request, RequestOptions.DEFAULT);    // 3.输出    System.err.println(exists ? &quot;索引库已经存在！&quot; : &quot;索引库不存在！&quot;);&#125;\n总结Java操作索引库的基本步骤：\n\n初始化RestHighLevelClient\n创建XxxIndexRequest。XXX是Create、Get、Delete\n准备DSL（ Create时需要，其它是无参）\n发送请求。调用RestHighLevelClient#indices().xxx()方法，xxx是create、exists、delete\n\n操作文档索引库实体类package cn.itcast.hotel.pojo;import lombok.Data;import lombok.NoArgsConstructor;@Data@NoArgsConstructorpublic class HotelDoc &#123;    private Long id;    private String name;    private String address;    private Integer price;    private Integer score;    private String brand;    private String city;    private String starName;    private String business;    private String location;\t//对应ES中的坐标类型，geo_point    private String pic;    public HotelDoc(Hotel hotel) &#123;        this.id = hotel.getId();        this.name = hotel.getName();        this.address = hotel.getAddress();        this.price = hotel.getPrice();        this.score = hotel.getScore();        this.brand = hotel.getBrand();        this.city = hotel.getCity();        this.starName = hotel.getStarName();        this.business = hotel.getBusiness();        this.location = hotel.getLatitude() + &quot;, &quot; + hotel.getLongitude();        this.pic = hotel.getPic();    &#125;&#125;\n新增文档\n\n创建Request对象\n准备请求参数，也就是DSL中的JSON文档\n发送请求\n\n从数据库中查询数据，再将数据转换成JSON文档存储在ES中\n\n根据id查询酒店数据Hotel\n将Hotel封装为HotelDoc\n将HotelDoc序列化为JSON\n创建IndexRequest，指定索引库名和id\n准备请求参数，也就是JSON文档\n发送请求\n\n@Testvoid testAddDocument() throws IOException &#123;    // 1.根据id查询酒店数据    Hotel hotel = hotelService.getById(61083L);    // 2.转换为文档类型    HotelDoc hotelDoc = new HotelDoc(hotel);    // 3.将HotelDoc转json    String json = JSON.toJSONString(hotelDoc);    // 1.准备Request对象    IndexRequest request = new IndexRequest(&quot;hotel&quot;).id(hotelDoc.getId().toString());    // 2.准备Json文档    request.source(json, XContentType.JSON);    // 3.发送请求    client.index(request, RequestOptions.DEFAULT);&#125;\n查询文档\n准备Request对象。这次是查询，所以是GetRequest\n发送请求，得到结果。因为是查询，这里调用client.get()方法\n解析结果，就是对JSON做反序列化\n\n@Testvoid testGetDocumentById() throws IOException &#123;    // 1.准备Request    GetRequest request = new GetRequest(&quot;hotel&quot;, &quot;61082&quot;);    // 2.发送请求，得到响应    GetResponse response = client.get(request, RequestOptions.DEFAULT);    // 3.解析响应结果    String json = response.getSourceAsString();    HotelDoc hotelDoc = JSON.parseObject(json, HotelDoc.class);    System.out.println(hotelDoc);&#125;\n删除文档\n准备Request对象，因为是删除，这次是DeleteRequest对象。要指定索引库名和id\n准备参数，无参\n发送请求。因为是删除，所以是client.delete()方法\n\n@Testvoid testDeleteDocument() throws IOException &#123;    // 1.准备Request    DeleteRequest request = new DeleteRequest(&quot;hotel&quot;, &quot;61083&quot;);    // 2.发送请求    client.delete(request, RequestOptions.DEFAULT);&#125;\n修改文档在RestClient的API中，全量修改与新增的API完全一致，判断依据是ID：\n\n如果新增时，ID已经存在，则修改\n如果新增时，ID不存在，则新增\n\n以下是增量修改代码\n@Testvoid testUpdateDocument() throws IOException &#123;    // 1.准备Request    UpdateRequest request = new UpdateRequest(&quot;hotel&quot;, &quot;61083&quot;);    // 2.准备请求参数    request.doc(        &quot;price&quot;, &quot;952&quot;,        &quot;starName&quot;, &quot;四钻&quot;    );    // 3.发送请求    client.update(request, RequestOptions.DEFAULT);&#125;\n总结文档操作的基本步骤：\n\n初始化RestHighLevelClient\n创建XxxRequest。XXX是Index、Get、Update、Delete、Bulk\n准备参数（Index、Update、Bulk时需要）\n发送请求。调用RestHighLevelClient#.xxx()方法，xxx是index、get、update、delete、bulk\n解析结果（Get时需要）\n\n查询文档基本步骤:\n\n准备Request对象\n准备请求参数\n发起请求\n解析响应\n\nmatch_all查询@Testvoid testMatchAll() throws IOException &#123;    // 1.准备Request    SearchRequest request = new SearchRequest(&quot;hotel&quot;);    // 2.准备DSL    request.source()        .query(QueryBuilders.matchAllQuery());    // 3.发送请求    SearchResponse response = client.search(request, RequestOptions.DEFAULT);    // 4.解析响应    handleResponse(response);&#125;private void handleResponse(SearchResponse response) &#123;    // 4.解析响应    SearchHits searchHits = response.getHits();    // 4.1.获取总条数    long total = searchHits.getTotalHits().value;    System.out.println(&quot;共搜索到&quot; + total + &quot;条数据&quot;);    // 4.2.文档数组    SearchHit[] hits = searchHits.getHits();    // 4.3.遍历    for (SearchHit hit : hits) &#123;        // 获取文档source        String json = hit.getSourceAsString();        // 反序列化        HotelDoc hotelDoc = JSON.parseObject(json, HotelDoc.class);        System.out.println(&quot;hotelDoc = &quot; + hotelDoc);    &#125;&#125;\n\n创建SearchRequest对象\n准备Request.source()，也就是DSL。\nQueryBuilders来构建查询条件\n传入Request.source() 的 query() 方法\n\n\n发送请求，得到结果\n解析结果（参考JSON结果，从外到内，逐层解析）\n\nAPI:\n\nrequest.soure()，包含了查询、分页、排序高亮等功能\nQueryBuilders，包含match、term、function_score、bool等各种查询\n\n\n解析响应：逐层解析JSON字符串，流程如下：\n\nSearchHits：通过response.getHits()获取，就是JSON中的最外层的hits，代表命中的结果\nSearchHits#getTotalHits().value：获取总条数信息\nSearchHits#getHits()：获取SearchHit数组，也就是文档数组\nSearchHit#getSourceAsString()：获取文档结果中的_source，也就是原始的json文档数据\n\n\n\n\n\nmatch查询@Testvoid testMatch() throws IOException &#123;    // 1.准备Request    SearchRequest request = new SearchRequest(&quot;hotel&quot;);    // 2.准备DSL    request.source()        .query(QueryBuilders.matchQuery(&quot;all&quot;, &quot;如家&quot;));    // 3.发送请求    SearchResponse response = client.search(request, RequestOptions.DEFAULT);    // 4.解析响应    handleResponse(response);&#125;\n精确查询查询流程同上，差异是使用到的API：\n\nQueryBuilders.termQuery()\nQueryBuilders.rangeQuery().gte().lte()\n\n布尔查询@Testvoid testBool() throws IOException &#123;    // 1.准备Request    SearchRequest request = new SearchRequest(&quot;hotel&quot;);    // 2.准备DSL    // 2.1.准备BooleanQuery    BoolQueryBuilder boolQuery = QueryBuilders.boolQuery();    // 2.2.添加term    boolQuery.must(QueryBuilders.termQuery(&quot;city&quot;, &quot;杭州&quot;));    // 2.3.添加range    boolQuery.filter(QueryBuilders.rangeQuery(&quot;price&quot;).lte(250));    request.source().query(boolQuery);    // 3.发送请求    SearchResponse response = client.search(request, RequestOptions.DEFAULT);    // 4.解析响应    handleResponse(response);&#125;\n排序、分页、高亮\n排序分页@Testvoid testPageAndSort() throws IOException &#123;    // 页码，每页大小    int page = 1, size = 5;    // 1.准备Request    SearchRequest request = new SearchRequest(&quot;hotel&quot;);    // 2.准备DSL    // 2.1.query    request.source().query(QueryBuilders.matchAllQuery());    // 2.2.排序 sort    request.source().sort(&quot;price&quot;, SortOrder.ASC);    // 2.3.分页 from、size    request.source().from((page - 1) * size).size(5);    // 3.发送请求    SearchResponse response = client.search(request, RequestOptions.DEFAULT);    // 4.解析响应    handleResponse(response);&#125;\n高亮private void handleResponse(SearchResponse response) &#123;    // 4.解析响应    SearchHits searchHits = response.getHits();    // 4.1.获取总条数    long total = searchHits.getTotalHits().value;    System.out.println(&quot;共搜索到&quot; + total + &quot;条数据&quot;);    // 4.2.文档数组    SearchHit[] hits = searchHits.getHits();    // 4.3.遍历    for (SearchHit hit : hits) &#123;        // 获取文档source        String json = hit.getSourceAsString();        // 反序列化        HotelDoc hotelDoc = JSON.parseObject(json, HotelDoc.class);        // 获取高亮结果        Map&lt;String, HighlightField&gt; highlightFields = hit.getHighlightFields();        if (!CollectionUtils.isEmpty(highlightFields)) &#123;            // 根据字段名获取高亮结果            HighlightField highlightField = highlightFields.get(&quot;name&quot;);            if (highlightField != null) &#123;                // 获取高亮值                String name = highlightField.getFragments()[0].string();                // 覆盖非高亮结果                hotelDoc.setName(name);            &#125;        &#125;        System.out.println(&quot;hotelDoc = &quot; + hotelDoc);    &#125;&#125;\n\n\n第一步：从结果中获取source。hit.getSourceAsString()，这部分是非高亮结果，json字符串。还需要反序列为HotelDoc对象\n第二步：获取高亮结果。hit.getHighlightFields()，返回值是一个Map，key是高亮字段名称，值是HighlightField对象，代表高亮值\n第三步：从map中根据高亮字段名称，获取高亮字段值对象HighlightField\n第四步：从HighlightField中获取Fragments，并且转为字符串。这部分就是真正的高亮字符串了\n第五步：用高亮的结果替换HotelDoc中的非高亮结果\n\n数据聚合请求API：\n\n返回结果解析：\n\n\n数据同步数据库中的数据和ES中的数据保持一致。\n\n同步调用：依次更新数据库和ES，实现简单，但是业务会耗时较长，业务耦合度高。\n异步调用：数据库写入完成后使用异步消息队列来通知ES更新数据，响应时间短，但实现复杂，而且依赖消息队列的可靠性。\n监听binlog：Mysql主从模式下，主服务器会将数据操作记录到binlog中，通过binlog实现主从数据库的数据一致，因此我们可以通过监听binlog的方式来实现Mysql和ES的数据一致。\n\nES集群部署集群使用虚拟机利用docker模拟ES集群，docker-compose文件如下：\nversion: &#x27;2.2&#x27;services:  es01:    image: elasticsearch:7.12.1    container_name: es01    environment:      - node.name=es01      - cluster.name=es-docker-cluster      - discovery.seed_hosts=es02,es03      - cluster.initial_master_nodes=es01,es02,es03      - &quot;ES_JAVA_OPTS=-Xms512m -Xmx512m&quot;    volumes:      - data01:/usr/share/elasticsearch/data    ports:      - 9200:9200    networks:      - elastic  es02:    image: elasticsearch:7.12.1    container_name: es02    environment:      - node.name=es02      - cluster.name=es-docker-cluster      - discovery.seed_hosts=es01,es03      - cluster.initial_master_nodes=es01,es02,es03      - &quot;ES_JAVA_OPTS=-Xms512m -Xmx512m&quot;    volumes:      - data02:/usr/share/elasticsearch/data    ports:      - 9201:9200    networks:      - elastic  es03:    image: elasticsearch:7.12.1    container_name: es03    environment:      - node.name=es03      - cluster.name=es-docker-cluster      - discovery.seed_hosts=es01,es02      - cluster.initial_master_nodes=es01,es02,es03      - &quot;ES_JAVA_OPTS=-Xms512m -Xmx512m&quot;    volumes:      - data03:/usr/share/elasticsearch/data    networks:      - elastic    ports:      - 9202:9200volumes:  data01:    driver: local  data02:    driver: local  data03:    driver: localnetworks:  elastic:    driver: bridge\n\n修改linux系统权限，修改 /etc/sysctl.conf 文件，添加：vm.max_map_count=262144\n执行命令，使配置生效sysctl -p\n重启ES集群docker-compose up -d\n\n集群监控推荐使用cerebro来监控es集群状态，官方网址：https://github.com/lmenezes/cerebro安装成功后，进入bin目录双击 cerebro.bat 文件启动cerebro，访问 http://localhost:9000 进入控制台\n集群脑裂问题集群ES节点的职责划分：\n\n默认情况下，集群中的任何一个节点都同时具备上述四种角色。将集群职责分离有利于提高集群工作效率：\n\nmaster节点：对CPU要求高，但是内存要求第\ndata节点：对CPU和内存要求都高\ncoordinating节点：对网络带宽、CPU要求高\n\n典型集群职责划分：\n\n\n脑裂问题当ES集群中主节点和其他节点失联（主节点并未宕机），导致从节点中选出一个新的主节点，旧主节点恢复连接后，集群便会出现两个主节点，造成集群数据不一致（旧主节点自成集群，新主节点和其他节点构成新集群）。解决方案：要求选票超过 ( eligible节点数量 + 1 ）/ 2 才能当选为主，因此eligible节点数量最好是奇数。对应配置项是discovery.zen.minimum_master_nodes，在es7.0以后，已经成为默认配置，因此一般不会发生脑裂问题。eg：3个节点形成的集群，选票必须超过 （3 + 1） / 2 ，也就是2票。node3得到node2和node3的选票，当选为主。node1只有自己1票，没有当选。集群中依然只有1个主节点，没有出现脑裂。\n集群分布式存储分片Shard和副本ReplicasES提供了把 Index（索引）拆分到多个 Shard（分片）中的能力。在创建索引时，可以定义 Shard的数量。每个 Shard 本身就是一个全功能的和独立的 “Index（索引）”，Shard可以存储在集群中的任何节点上。ES会通过hash算法来计算文档应该存储到哪个分片：\n\n\n_routing默认是文档的id\n算法与分片数量有关，因此索引库一旦创建，分片数量不能修改！\n\n在网络/云环境中可能随时会故障，为了数据的安全性和可靠性，ES 可以让您设置一个或多个索引的 Shard 副本到所谓的副本分片，或者副本中去。\n\n在 shard/node 故障的情况下提供了高可用性。为了达到这个目的，需要注意的是在原始的/主 Shard 被复制时副本的 Shard 不会被分配到相同的节点上。\n它可以让你水平扩展搜索量/吞吐量，因为搜索可以在所有的副本上并行执行。\n\n每个索引可以被拆分成多个分片，一个索引可以设置 0 个（没有副本）或多个副本。开启副本后，每个索引将有主分片（被复制的原始分片）和副本分片（主分片的副本）。分片和副本的数量在索引被创建时都能够被指定。在创建索引后，您也可以在任何时候动态的改变副本的数量，但是不能够改变分片数量。默认情况下，Elasticsearch 中的每个索引分配了 5 个主分片和 1 个副本，这也就意味着如果您的集群至少有两个节点的话，您的索引将会有 5 个主分片和另外 5 个副本分片（1 个完整的副本），每个索引共计 10 个分片。\n新增文档流程\n\n新增一个id=1的文档\n对id做hash运算，假如得到的是2，则应该存储到shard-2\nshard-2的主分片在node3节点，将数据路由到node3\n保存文档\n同步给shard-2的副本replica-2，在node2节点\n返回结果给coordinating-node节点\n\n查询文档流程\n\nscatter phase：分散阶段，coordinating node会把请求分发到每一个分片\ngather phase：聚集阶段，coordinating node汇总data node的搜索结果，并处理为最终结果集返回给用户\n\n集群故障转移集群的master节点会监控集群中的节点状态，如果发现有节点宕机，会立即将宕机节点的分片数据迁移到其它节点，确保数据安全，这个叫做故障转移。\n\node1是主节点，其它两个节点是从节点。\n突然node1发生了故障\n宕机后的第一件事，需要重新选主，例如选中了node2：\nnode2成为主节点后会检测集群监控状态，发现：shard-1、shard-0没有副本节点。因此需要将node1上的数据迁移到node2、node3： \n\n微服务保护Sentinel是阿里巴巴开源的一款微服务流量控制组件。官网地址：https://sentinelguard.io/zh-cn/index.html\n初识sentinel\n下载安装Sentinel\n运行java -jar sentinel-dashboard-1.8.1.jar\n如果要修改Sentinel的默认端口、账户、密码，可以通过下列配置：\n\n\n\n\n配置项\n默认值\n说明\n\n\n\nserver.port\n8080\n服务端口\n\n\nsentinel.dashboard.auth.username\nsentinel\n默认用户名\n\n\nsentinel.dashboard.auth.password\nsentinel\n默认密码\n\n\n例如，修改端口：\njava -Dserver.port=8090 -jar sentinel-dashboard-1.8.1.jar\n\nSentinel控制台，访问http://localhost:8080 ，输入账号和密码，默认都是：sentinel\n\n微服务整合Sentinel\n引入sentinel依赖&lt;!--sentinel--&gt;&lt;dependency&gt;    &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt;     &lt;artifactId&gt;spring-cloud-starter-alibaba-sentinel&lt;/artifactId&gt;&lt;/dependency&gt;\n配置控制台，修改application.yaml文件，添加：server:  port: 8088spring:  cloud:     sentinel:      transport:        dashboard: localhost:8080\n访问order-service的任意端点，触发sentinel的监控。访问sentinel的控制台，查看效果\n\n雪崩问题一个微服务发生故障，导致依赖于该微服务的整个服务链发生故障，甚至发生级联故障造成大范围内的微服务不可用，即微服务的雪崩问题。几种解决方案：\n\n超时处理：设定超时时间，请求超过一定时间没有响应就返回错误信息，不会无休止等待\n仓壁模式：可以限定每个业务能使用的线程数，避免耗尽整个tomcat的资源，因此也叫线程隔离\n断路器：由断路器统计业务执行的异常比例，如果超出阈值则会熔断该业务，拦截访问该业务的一切请求。\n流量控制：限制业务访问的QPS，避免服务因流量的突增而故障。\n\n小结：\n\n限流是对服务的保护，避免因瞬间高并发流量而导致服务故障，进而避免雪崩。是一种预防措施。\n超时处理、线程隔离、降级熔断是在部分服务故障时，将故障控制在一定范围，避免雪崩。是一种补救措施。\n\n流量控制簇点链路当请求进入微服务时，首先会访问DispatcherServlet，然后进入Controller、Service、Mapper，这样的一个调用链就叫做簇点链路。簇点链路中被监控的每一个接口就是一个资源。默认情况下sentinel会监控SpringMVC的每一个端点（Endpoint，也就是controller中的方法），因此SpringMVC的每一个端点（Endpoint）就是调用链路中的一个资源。\n流控模式\n直接：统计当前资源的请求，触发阈值时对当前资源直接限流，也是默认的模式\n关联：统计与当前资源相关的另一个资源，触发阈值时，对当前资源限流\n链路：统计从指定链路访问到本资源的请求，触发阈值时，对指定链路限流\n\n流控效果流控效果是指请求达到流控阈值时应该采取的措施，包括三种：\n\n快速失败：达到阈值后，新的请求会被立即拒绝并抛出FlowException异常。是默认的处理方式。\nwarm up：预热模式，对超出阈值的请求同样是拒绝并抛出异常。但这种模式阈值会动态变化，从一个较小值逐渐增加到最大阈值。\n排队等待：让所有的请求按照先后次序排队执行，两个请求的间隔不能小于指定时长\n\n热点参数限流限流是统计访问某个资源的所有请求，判断是否超过QPS阈值。而热点参数限流是分别统计参数值相同的请求，判断是否超过QPS阈值。PS：热点参数限流对默认的SpringMVC资源无效，需要利用@SentinelResource注解标记资源\n隔离、降级限流是一种预防措施，虽然可以尽量避免因高并发而引起的服务故障，但服务还会因为其它原因而故障。要将这些故障控制在一定范围，避免雪崩，就要靠线程隔离（舱壁模式）和熔断降级不管是线程隔离还是熔断降级，都是对客户端（调用方）的保护。需要在调用方 发起远程调用时做线程隔离、或者服务熔断。我们的微服务远程调用都是基于Feign来完成的，因此我们需要将Feign与Sentinel整合，在Feign里面实现线程隔离和服务熔断。\nFeignClient整合Sentinel\n修改配置，开启sentinel功能修改OrderService的application.yml文件，开启Feign的Sentinel功能：feign:  sentinel:    enabled: true # 开启feign对sentinel的支持\n编写失败降级逻辑业务失败后，不能直接报错，而应该返回用户一个友好提示或者默认结果，这个就是失败降级逻辑。给FeignClient编写失败后的降级逻辑：\n\n\n方式一：FallbackClass，无法对远程调用的异常做处理\n方式二：FallbackFactory，可以对远程调用的异常做处理（推荐使用）\n\neg：降级逻辑实现方式二\n\n自定义类实现FallbackFactorypackage cn.itcast.feign.clients.fallback;import cn.itcast.feign.clients.UserClient;import cn.itcast.feign.pojo.User;import feign.hystrix.FallbackFactory;import lombok.extern.slf4j.Slf4j;@Slf4jpublic class UserClientFallbackFactory implements FallbackFactory&lt;UserClient&gt; &#123;    @Override    public UserClient create(Throwable throwable) &#123;        return new UserClient() &#123;            @Override            public User findById(Long id) &#123;                log.error(&quot;查询用户异常&quot;, throwable);                return new User();            &#125;        &#125;;    &#125;&#125;\n将自定义类UserClientFallbackFactory注册为一个Bean@Beanpublic UserClientFallbackFactory userClientFallbackFactory()&#123;    return new UserClientFallbackFactory();&#125;\n在UserClient接口中使用UserClientFallbackFactoryimport cn.itcast.feign.clients.fallback.UserClientFallbackFactory;import cn.itcast.feign.pojo.User;import org.springframework.cloud.openfeign.FeignClient;import org.springframework.web.bind.annotation.GetMapping;import org.springframework.web.bind.annotation.PathVariable;@FeignClient(value = &quot;userservice&quot;, fallbackFactory = UserClientFallbackFactory.class)public interface UserClient &#123;    @GetMapping(&quot;/user/&#123;id&#125;&quot;)    User findById(@PathVariable(&quot;id&quot;) Long id);&#125;\n\n线程隔离（舱壁模式）线程隔离有两种方式实现：\n\n线程池隔离：给每个服务调用业务分配一个线程池，利用线程池本身实现隔离效果\n信号量隔离（Sentinel默认采用）：不创建线程池，而是计数器模式，记录业务使用的线程数量，达到信号量上限时，禁止新的请求\n\n熔断降级断路器统计服务调用的异常比例、慢请求比例，如果超出阈值则会熔断该服务。即拦截访问该服务的一切请求；而当服务恢复时，断路器会放行访问该服务的请求。断路器控制熔断和放行是通过状态机来完成的：\n\n\n状态机包括三个状态：\n\nclosed：关闭状态，断路器放行所有请求，并开始统计异常比例、慢请求比例。超过阈值则切换到open状态\nopen：打开状态，服务调用被熔断，访问被熔断服务的请求会被拒绝，快速失败，直接走降级逻辑。Open状态5秒后会进入half-open状态\nhalf-open：半开状态，放行一次请求，根据执行结果来判断接下来的操作。\n请求成功：则切换到closed状态\n请求失败：则切换到open状态\n\n\n\n断路器熔断策略有三种：\n\n慢调用：业务的响应时长（RT）大于指定时长的请求认定为慢调用请求。在指定时间内，如果请求数量超过设定的最小数量，慢调用比例大于设定的阈值，则触发熔断\n异常比例：统计指定时间内的调用，如果调用次数超过指定请求数，并且出现异常的比例达到设定的比例阈值，则触发熔断\n异常数：统计指定时间内的调用，如果调用次数超过指定请求数，并且出现异常超过指定异常数达，则触发熔断\n\n授权规则授权规则授权规则可以对调用方的来源做控制，有白名单和黑名单两种方式。\n\n白名单：来源（origin）在白名单内的调用者允许访问\n黑名单：来源（origin）在黑名单内的调用者不允许访问\n\n通过流控应用选项来指定调用方，sentiel通过获取Request请求头中的origin字段来获取调用方的名称。\n获取originSentinel是通过RequestOriginParser这个接口的parseOrigin来获取请求的来源的。默认情况下，sentinel不管请求者从哪里来，返回值永远是default。\npublic interface RequestOriginParser &#123;    /**     * 从请求request对象中获取origin，获取方式自定义     */    String parseOrigin(HttpServletRequest request);&#125;\n因此，我们需要自定义这个接口的实现，让不同的请求，返回不同的origineg：order-service服务中，定义一个RequestOriginParser的实现类\npackage cn.itcast.order.sentinel;import com.alibaba.csp.sentinel.adapter.spring.webmvc.callback.RequestOriginParser;import org.springframework.stereotype.Component;import org.springframework.util.StringUtils;import javax.servlet.http.HttpServletRequest;@Componentpublic class HeaderOriginParser implements RequestOriginParser &#123;    @Override    public String parseOrigin(HttpServletRequest request) &#123;        // 1.获取请求头        String origin = request.getHeader(&quot;origin&quot;);        // 2.非空判断        if (StringUtils.isEmpty(origin)) &#123;            origin = &quot;blank&quot;;        &#125;        return origin;    &#125;&#125;\n请求附带origin请求头获取origin的方式是从reques-header中获取origin值，我们需要让所有从gateway路由到微服务的请求都带上origin头。利用GatewayFilter——AddRequestHeaderGatewayFilter。修改gateway服务中的application.yml，添加一个defaultFilter：\nspring:  cloud:    gateway:      default-filters:        - AddRequestHeader=origin,gateway      routes:       # ...略\n配置授权规则\n跳过网关，访问order-service服务，结果如下：\n:\n通过gateway网关访问，结果如下：\n\n\n自定义异常默认情况下，发生限流、降级、授权拦截时，都会抛出异常到调用方。异常结果都是flow limmiting（限流）。这样不够友好，无法得知是限流还是降级还是授权拦截。\npublic interface BlockExceptionHandler &#123;    /**     * 处理请求被限流、降级、授权拦截时抛出的异常：BlockException     */    void handle(HttpServletRequest request, HttpServletResponse response, BlockException e) throws Exception;&#125;\n\nBlockException e：被sentinel拦截时抛出的异常，子类如下\n\n\n\n\n异常\n说明\n\n\n\nFlowException\n限流异常\n\n\nParamFlowException\n热点参数限流的异常\n\n\nDegradeException\n降级异常\n\n\nAuthorityException\n授权规则异常\n\n\nSystemBlockException\n系统规则异常\n\n\n自定义异常处理类：\npackage cn.itcast.order.sentinel;import com.alibaba.csp.sentinel.adapter.spring.webmvc.callback.BlockExceptionHandler;import com.alibaba.csp.sentinel.slots.block.BlockException;import com.alibaba.csp.sentinel.slots.block.authority.AuthorityException;import com.alibaba.csp.sentinel.slots.block.degrade.DegradeException;import com.alibaba.csp.sentinel.slots.block.flow.FlowException;import com.alibaba.csp.sentinel.slots.block.flow.param.ParamFlowException;import org.springframework.stereotype.Component;import javax.servlet.http.HttpServletRequest;import javax.servlet.http.HttpServletResponse;@Componentpublic class SentinelExceptionHandler implements BlockExceptionHandler &#123;    @Override    public void handle(HttpServletRequest request, HttpServletResponse response, BlockException e) throws Exception &#123;        String msg = &quot;未知异常&quot;;        int status = 429;        if (e instanceof FlowException) &#123;            msg = &quot;请求被限流了&quot;;        &#125; else if (e instanceof ParamFlowException) &#123;            msg = &quot;请求被热点参数限流&quot;;        &#125; else if (e instanceof DegradeException) &#123;            msg = &quot;请求被降级了&quot;;        &#125; else if (e instanceof AuthorityException) &#123;            msg = &quot;没有权限访问&quot;;            status = 401;        &#125;        response.setContentType(&quot;application/json;charset=utf-8&quot;);        response.setStatus(status);        response.getWriter().println(&quot;&#123;\\&quot;msg\\&quot;: &quot; + msg + &quot;, \\&quot;status\\&quot;: &quot; + status + &quot;&#125;&quot;);    &#125;&#125;\n\n规则持久化sentinel的所有规则都是内存存储，重启后所有规则都会丢失。在生产环境下，必须确保这些规则的持久化，避免丢失。规则是否能持久化，取决于规则管理模式，sentinel支持三种规则管理模式：\n\n原始模式：Sentinel的默认模式，将规则保存在内存，重启服务会丢失。\npull模式：控制台将配置的规则推送到Sentinel客户端，而客户端会将配置规则保存在本地文件或数据库中。以后会定时去本地文件或数据库中查询，更新本地规则\npush模式：控制台将配置规则推送到远程配置中心，例如Nacos。Sentinel客户端监听Nacos，获取配置变更的推送消息，完成本地配置更新\n\n配置方法参见官网：https://sentinelguard.io/zh-cn/docs/dynamic-rule-configuration.html\n分布式事务在分布式系统下，一个业务跨越多个服务或数据源，每个服务都是一个分支事务，要保证所有分支事务最终状态一致，这样的事务就是分布式事务。\nCAP定理加州大学的计算机科学家 Eric Brewer 提出，分布式系统有三个指标：\n\nConsistency（一致性）\nAvailability（可用性）\nPartition tolerance （分区容错性）\n\nCAP定理：分布式系统，不可能同时满足三个指标\n\n一致性：用户访问分布式系统中的任意节点，得到的数据必须一致\n可用性：用户访问集群中的任意健康节点，必须能得到响应，而不是超时或拒绝\n分区容错性：\n分区：因为网络故障或其它原因导致分布式系统中的部分节点与其它节点失去连接，形成独立分区。\n容错：在集群出现分区时，整个系统也要持续对外提供服务\n\n\n\n在分布式系统中，系统间的网络不能100%保证健康，一定会有故障的时候，而服务有必须对外保证服务。因此Partition Tolerance（分区容错性）是不可或缺的。\n\n如果此时要保证一致性，就必须等待网络恢复，完成数据同步后，整个集群才对外提供服务，服务处于阻塞状态，不可用\n如果此时要保证可用性，就不能等待网络恢复，那node01、node02与node03之间就会出现数据不一致\n\nBASE理论BASE理论是对CAP的一种解决思路，包含三个思想：\n\nBasically Available （基本可用）：分布式系统在出现故障时，允许损失部分可用性，即保证核心可用。\nSoft State（软状态）：在一定时间内，允许出现中间状态，比如临时的不一致状态。\nEventually Consistent（最终一致性）：虽然无法保证强一致性，但是在软状态结束后，最终达到数据一致。\n\n分布式事务解决思路分布式事务最大的问题是各个子事务的一致性问题，因此可以借鉴CAP定理和BASE理论，有两种解决思路：\n\nAP模式：各子事务分别执行和提交，允许出现结果不一致，然后采用弥补措施恢复数据即可，实现最终一致\nCP模式：各个子事务执行后互相等待，同时提交，同时回滚，达成强一致。但事务等待过程中，处于弱可用状态\n\nSeataSeata是 2019 年 1 月份蚂蚁金服和阿里巴巴共同开源的分布式事务解决方案。致力于提供高性能和简单易用的分布式事务服务，为用户打造一站式的分布式解决方案。官网地址：http://seata.io/ 。Seata事务管理中有三个重要的角色：\n\nTC (Transaction Coordinator) - 事务协调者：维护全局和分支事务的状态，协调全局事务提交或回滚。\nTM (Transaction Manager) - 事务管理器：定义全局事务的范围、开始全局事务、提交或回滚全局事务。\nRM (Resource Manager) - 资源管理器：管理分支事务处理的资源，与TC交谈以注册分支事务和报告分支事务的状态，并驱动分支事务提交或回滚。\n\nSeata基于上述架构提供了四种不同的分布式事务解决方案：\n\nXA模式：强一致性分阶段事务模式，牺牲了一定的可用性，无业务侵入\nTCC模式：最终一致的分阶段事务模式，有业务侵入\nAT模式：最终一致的分阶段事务模式，无业务侵入，也是Seata的默认模式\nSAGA模式：长事务模式，有业务侵入\n\nPS：无论哪种方案，都离不开事务的协调者TC。\nSeata tc-server 部署1. 下载安装seata-server访问官网：http://seata.io/ ，下载安装解压压缩包\n2. 修改conf目录下registry.conf文件registry &#123;  # tc服务的注册中心类，这里选择nacos，也可以是eureka、zookeeper等  type = &quot;nacos&quot;  nacos &#123;    # seata tc 服务注册到 nacos的服务名称，可以自定义    application = &quot;seata-tc-server&quot;    serverAddr = &quot;127.0.0.1:8848&quot;    group = &quot;DEFAULT_GROUP&quot;    namespace = &quot;&quot;    cluster = &quot;SH&quot;    username = &quot;nacos&quot;    password = &quot;nacos&quot;  &#125;&#125;config &#123;  # 读取tc服务端的配置文件的方式，这里是从nacos配置中心读取，这样如果tc是集群，可以共享配置  type = &quot;nacos&quot;  # 配置nacos地址等信息  nacos &#123;    serverAddr = &quot;127.0.0.1:8848&quot;    namespace = &quot;&quot;    group = &quot;SEATA_GROUP&quot;    username = &quot;nacos&quot;    password = &quot;nacos&quot;    dataId = &quot;seataServer.properties&quot;  &#125;&#125;\n3. nacos添加配置信息让tc服务的集群可以共享配置，我们选择了nacos作为统一配置中心。因此服务端配置文件seataServer.properties文件需要在nacos中配好。\n# 数据存储方式，db代表数据库store.mode=dbstore.db.datasource=druidstore.db.dbType=mysqlstore.db.driverClassName=com.mysql.jdbc.Driverstore.db.url=jdbc:mysql://127.0.0.1:3306/seata?useUnicode=true&amp;rewriteBatchedStatements=truestore.db.user=rootstore.db.password=123store.db.minConn=5store.db.maxConn=30store.db.globalTable=global_tablestore.db.branchTable=branch_tablestore.db.queryLimit=100store.db.lockTable=lock_tablestore.db.maxWait=5000# 事务、日志等配置server.recovery.committingRetryPeriod=1000server.recovery.asynCommittingRetryPeriod=1000server.recovery.rollbackingRetryPeriod=1000server.recovery.timeoutRetryPeriod=1000server.maxCommitRetryTimeout=-1server.maxRollbackRetryTimeout=-1server.rollbackRetryTimeoutUnlockEnable=falseserver.undo.logSaveDays=7server.undo.logDeletePeriod=86400000# 客户端与服务端传输方式transport.serialization=seatatransport.compressor=none# 关闭metrics功能，提高性能metrics.enabled=falsemetrics.registryType=compactmetrics.exporterList=prometheusmetrics.exporterPrometheusPort=9898\nPS：注意修改数据库地址、用户名、密码\n5. 创建数据库表tc服务在管理分布式事务时，需要记录事务相关数据到数据库中，需要提前创建表。新建seata数据库，运行sql语句\nSET NAMES utf8mb4;SET FOREIGN_KEY_CHECKS = 0;-- ------------------------------ 分支事务表-- ----------------------------DROP TABLE IF EXISTS `branch_table`;CREATE TABLE `branch_table`  (  `branch_id` bigint(20) NOT NULL,  `xid` varchar(128) CHARACTER SET utf8 COLLATE utf8_general_ci NOT NULL,  `transaction_id` bigint(20) NULL DEFAULT NULL,  `resource_group_id` varchar(32) CHARACTER SET utf8 COLLATE utf8_general_ci NULL DEFAULT NULL,  `resource_id` varchar(256) CHARACTER SET utf8 COLLATE utf8_general_ci NULL DEFAULT NULL,  `branch_type` varchar(8) CHARACTER SET utf8 COLLATE utf8_general_ci NULL DEFAULT NULL,  `status` tinyint(4) NULL DEFAULT NULL,  `client_id` varchar(64) CHARACTER SET utf8 COLLATE utf8_general_ci NULL DEFAULT NULL,  `application_data` varchar(2000) CHARACTER SET utf8 COLLATE utf8_general_ci NULL DEFAULT NULL,  `gmt_create` datetime(6) NULL DEFAULT NULL,  `gmt_modified` datetime(6) NULL DEFAULT NULL,  PRIMARY KEY (`branch_id`) USING BTREE,  INDEX `idx_xid`(`xid`) USING BTREE) ENGINE = InnoDB CHARACTER SET = utf8 COLLATE = utf8_general_ci ROW_FORMAT = Compact;-- ------------------------------ 全局事务表-- ----------------------------DROP TABLE IF EXISTS `global_table`;CREATE TABLE `global_table`  (  `xid` varchar(128) CHARACTER SET utf8 COLLATE utf8_general_ci NOT NULL,  `transaction_id` bigint(20) NULL DEFAULT NULL,  `status` tinyint(4) NOT NULL,  `application_id` varchar(32) CHARACTER SET utf8 COLLATE utf8_general_ci NULL DEFAULT NULL,  `transaction_service_group` varchar(32) CHARACTER SET utf8 COLLATE utf8_general_ci NULL DEFAULT NULL,  `transaction_name` varchar(128) CHARACTER SET utf8 COLLATE utf8_general_ci NULL DEFAULT NULL,  `timeout` int(11) NULL DEFAULT NULL,  `begin_time` bigint(20) NULL DEFAULT NULL,  `application_data` varchar(2000) CHARACTER SET utf8 COLLATE utf8_general_ci NULL DEFAULT NULL,  `gmt_create` datetime NULL DEFAULT NULL,  `gmt_modified` datetime NULL DEFAULT NULL,  PRIMARY KEY (`xid`) USING BTREE,  INDEX `idx_gmt_modified_status`(`gmt_modified`, `status`) USING BTREE,  INDEX `idx_transaction_id`(`transaction_id`) USING BTREE) ENGINE = InnoDB CHARACTER SET = utf8 COLLATE = utf8_general_ci ROW_FORMAT = Compact;SET FOREIGN_KEY_CHECKS = 1;\n6. 启动TC服务运行bin目录下seata-server.bat。打开浏览器，访问nacos地址：http://localhost:8848 ，进入服务列表页面，可以看到seata-tc-server的信息\n微服务集成Seata\n引入Seata依赖&lt;dependency&gt;    &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt;    &lt;artifactId&gt;spring-cloud-starter-alibaba-seata&lt;/artifactId&gt;    &lt;exclusions&gt;        &lt;!--版本较低，1.3.0，因此排除--&gt;        &lt;exclusion&gt;            &lt;artifactId&gt;seata-spring-boot-starter&lt;/artifactId&gt;            &lt;groupId&gt;io.seata&lt;/groupId&gt;        &lt;/exclusion&gt;    &lt;/exclusions&gt;&lt;/dependency&gt;&lt;!--seata starter 采用1.4.2版本--&gt;&lt;dependency&gt;    &lt;groupId&gt;io.seata&lt;/groupId&gt;    &lt;artifactId&gt;seata-spring-boot-starter&lt;/artifactId&gt;    &lt;version&gt;$&#123;seata.version&#125;&lt;/version&gt;&lt;/dependency&gt;\n修改配置文件seata:  registry: # TC服务注册中心的配置，微服务根据这些信息去注册中心获取tc服务地址    # 参考tc服务自己的registry.conf中的配置    type: nacos    nacos: # tc      server-addr: 127.0.0.1:8848      namespace: &quot;&quot;      group: DEFAULT_GROUP      application: seata-tc-server # tc服务在nacos中的服务名称      cluster: SH  tx-service-group: seata-demo # 事务组，根据这个获取tc服务的cluster名称  service:    vgroup-mapping: # 事务组与TC服务cluster的映射关系      seata-demo: SH\n微服务如何根据这些配置寻找TC的地址呢？注册到Nacos中的微服务，确定一个具体实例需要四个信息：\n\n\nnamespace：命名空间\ngroup：分组\napplication：服务名\ncluster：集群名\n\n以上四个信息，在刚才的yaml文件中都能找到：\n\n\nnamespace为空，就是默认的public。结合起来，TC服务的信息就是：public@DEFAULT_GROUP@seata-tc-server@SH，这样就能确定TC服务集群了。然后就可以去Nacos拉取对应的实例信息了。\nSeata分布式事务解决方案XA模式XA是规范，目前主流数据库都实现了这种规范，实现的原理都是基于两阶段提交。正常情况：\n\n异常情况：\n\n\n一阶段：\n\n事务协调者通知每个事物参与者执行本地事务\n本地事务执行完成后报告事务执行状态给事务协调者，此时事务不提交，继续持有数据库锁\n\n二阶段：\n\n事务协调者基于一阶段的报告来判断下一步操作\n如果一阶段都成功，则通知所有事务参与者，提交事务\n如果一阶段任意一个参与者失败，则通知所有事务参与者回滚事务\n\n\n\nXA模式优缺点优点：\n\n事务的强一致性，满足ACID原则。\n常用数据库都支持，实现简单，并且没有代码侵入\n\n缺点：\n\n因为一阶段需要锁定数据库资源，等待二阶段结束才释放，性能较差\n依赖关系型数据库实现事务\n\nSeata XA模型：Seata对原始的XA模式做了简单的封装和改造，以适应自己的事务模型\n\n\nRM一阶段的工作：\n\n注册分支事务到TC\n执行分支业务sql但不提交\n报告执行状态到TC\n\nTC二阶段的工作：\n\nTC检测各分支事务执行状态a.如果都成功，通知所有RM提交事务b.如果有失败，通知所有RM回滚事务\n\nRM二阶段的工作：\n\n接收TC指令，提交或回滚事务\n\nSeata实现XA模式：\n\n修改application.yml文件（每个参与事务的微服务），开启XA模式seata:  data-source-proxy-mode: XA\n给发起全局事务的入口方法添加@GlobalTransactional注解\n重启服务并测试\n\nAT模式Seata AT模型：\n\n\n阶段一RM的工作：\n\n注册分支事务\n记录undo-log（数据快照）\n执行业务sql并提交\n报告事务状态\n\n阶段二提交时RM的工作：\n\n删除undo-log即可\n\n阶段二回滚时RM的工作：\n\n根据undo-log恢复数据到更新前\n\n简述AT与XA的区别\n\nXA模式一阶段不提交事务，锁定资源；AT模式一阶段直接提交，不锁定资源。\nXA模式依赖数据库机制实现回滚；AT模式利用数据快照实现数据回滚。\nXA模式强一致；AT模式最终一致\n\n脏写问题在多线程并发访问AT模式的分布式事务时，有可能出现脏写问题，如图：\n\n解决思路就是引入了全局锁的概念。在释放DB锁之前，先拿到全局锁。避免同一时刻有另外一个事务来操作当前数据。\n\n\n实现AT模式\n\n导入数据库表，记录全局锁/* Navicat Premium Data Transfer Source Server         : local Source Server Type    : MySQL Source Server Version : 50622 Source Host           : localhost:3306 Source Schema         : seata_demo Target Server Type    : MySQL Target Server Version : 50622 File Encoding         : 65001 Date: 20/06/2021 12:39:03*/SET NAMES utf8mb4;SET FOREIGN_KEY_CHECKS = 0;-- ------------------------------ Table structure for undo_log-- ----------------------------DROP TABLE IF EXISTS `undo_log`;CREATE TABLE `undo_log`  (  `branch_id` bigint(20) NOT NULL COMMENT &#x27;branch transaction id&#x27;,  `xid` varchar(100) CHARACTER SET utf8 COLLATE utf8_general_ci NOT NULL COMMENT &#x27;global transaction id&#x27;,  `context` varchar(128) CHARACTER SET utf8 COLLATE utf8_general_ci NOT NULL COMMENT &#x27;undo_log context,such as serialization&#x27;,  `rollback_info` longblob NOT NULL COMMENT &#x27;rollback info&#x27;,  `log_status` int(11) NOT NULL COMMENT &#x27;0:normal status,1:defense status&#x27;,  `log_created` datetime(6) NOT NULL COMMENT &#x27;create datetime&#x27;,  `log_modified` datetime(6) NOT NULL COMMENT &#x27;modify datetime&#x27;,  UNIQUE INDEX `ux_undo_log`(`xid`, `branch_id`) USING BTREE) ENGINE = InnoDB CHARACTER SET = utf8 COLLATE = utf8_general_ci COMMENT = &#x27;AT transaction mode undo table&#x27; ROW_FORMAT = Compact;-- ------------------------------ Records of undo_log-- ------------------------------ ------------------------------ Table structure for lock_table-- ----------------------------DROP TABLE IF EXISTS `lock_table`;CREATE TABLE `lock_table`  (  `row_key` varchar(128) CHARACTER SET utf8 COLLATE utf8_general_ci NOT NULL,  `xid` varchar(96) CHARACTER SET utf8 COLLATE utf8_general_ci NULL DEFAULT NULL,  `transaction_id` bigint(20) NULL DEFAULT NULL,  `branch_id` bigint(20) NOT NULL,  `resource_id` varchar(256) CHARACTER SET utf8 COLLATE utf8_general_ci NULL DEFAULT NULL,  `table_name` varchar(32) CHARACTER SET utf8 COLLATE utf8_general_ci NULL DEFAULT NULL,  `pk` varchar(36) CHARACTER SET utf8 COLLATE utf8_general_ci NULL DEFAULT NULL,  `gmt_create` datetime NULL DEFAULT NULL,  `gmt_modified` datetime NULL DEFAULT NULL,  PRIMARY KEY (`row_key`) USING BTREE,  INDEX `idx_branch_id`(`branch_id`) USING BTREE) ENGINE = InnoDB CHARACTER SET = utf8 COLLATE = utf8_general_ci ROW_FORMAT = Compact;SET FOREIGN_KEY_CHECKS = 1;\n修改application.yml文件，将事务模式修改为AT模式seata:  data-source-proxy-mode: AT # 默认就是AT\n重启服务并测试\n\nAT模式优缺点优点：\n\n一阶段完成直接提交事务，释放数据库资源，性能比较好\n利用全局锁实现读写隔离\n没有代码侵入，框架自动完成回滚和提交\n\n缺点：\n\n两阶段之间属于软状态，属于最终一致\n框架的快照功能会影响性能，但比XA模式要好很多\n\nTCC模式TCC模式通过补偿操作来实现数据恢复，依靠人工编码来实现。需实现三个方法：\n\nTry：资源的检测和预留； \nConfirm：完成资源操作业务；要求 Try 成功 Confirm 一定要能成功。\nCancel：预留资源释放，可以理解为try的反向操作。\n\n案例分析一个扣减用户余额的业务。假设账户A原来余额是100，需要余额扣减30元。\n\n阶段一（ Try ）：检查余额是否充足，如果充足则冻结金额增加30元，可用余额扣除30。此时，总金额 = 冻结金额 + 可用金额，数量依然是100不变。事务直接提交无需等待其它事务。\n**阶段二（Confirm)**：假如要提交（Confirm），则冻结金额扣减30。确认可以提交，因为之前可用金额已经扣减过了，这里只要清除冻结金额。此时，总金额 = 冻结金额 + 可用金额 = 0 + 70  = 70元。\n**阶段三(Canncel)**：如果要回滚（Cancel），则冻结金额扣减30，可用余额增加30。\n\nTCC模型图和AT模式几乎相同，只是数据回滚不是依赖数据快照而是通过人工编码实现。\n\n\nTCC模式优缺点优点：\n\n一阶段完成直接提交事务，释放数据库资源，性能好\n相比AT模型，无需生成快照，无需使用全局锁，性能最强\n不依赖数据库事务，而是依赖补偿操作，可以用于非事务型数据库\n\n缺点：\n\n有代码侵入，需要人为编写try、Confirm和Cancel接口，太麻烦\n软状态，事务是最终一致\n需要考虑Confirm和Cancel的失败情况，做好幂等处理\n\n事务悬挂和空回滚\n空回滚当某分支事务的try阶段阻塞时，可能导致全局事务超时而触发二阶段的cancel操作。在未执行try操作时先执行了cancel操作，这时cancel不能做回滚，就是空回滚。\n\n执行cancel操作时，应当判断try是否已经执行，如果尚未执行，则应该空回滚。2. 事务悬挂对于已经空回滚的业务，之前被阻塞的try操作恢复，继续执行try，就永远不可能confirm或cancel ，事务一直处于中间状态，这就是业务（事务）悬挂。执行try操作时，应当判断cancel是否已经执行过了，如果已经执行，应当阻止空回滚后的try操作，避免悬挂\nTCC模式实现解决空回滚和业务悬挂问题，必须要记录当前事务状态，是在try、还是cancel\n1. 案例分析定义数据表\nCREATE TABLE `account_freeze_tbl` (  `xid` varchar(128) NOT NULL,  `user_id` varchar(255) DEFAULT NULL COMMENT &#x27;用户id&#x27;,  `freeze_money` int(11) unsigned DEFAULT &#x27;0&#x27; COMMENT &#x27;冻结金额&#x27;,  `state` int(1) DEFAULT NULL COMMENT &#x27;事务状态，0:try，1:confirm，2:cancel&#x27;,  PRIMARY KEY (`xid`) USING BTREE) ENGINE=InnoDB DEFAULT CHARSET=utf8 ROW_FORMAT=COMPACT;\n\nxid：是全局事务id\nfreeze_money：用来记录用户冻结金额\nstate：用来记录事务状态\n\n那么业务该怎么做呢？\n\nTry业务：\n记录冻结金额和事务状态到account_freeze表\n扣减account表可用金额\n\n\nConfirm业务\n根据xid删除account_freeze表的冻结记录\n\n\nCancel业务\n修改account_freeze表，冻结金额为0，state为2\n修改account表，恢复可用金额\n\n\n如何判断是否空回滚？\ncancel业务中，根据xid查询account_freeze，如果为null则说明try还没做，需要空回滚\n\n\n如何避免业务悬挂？\ntry业务中，根据xid查询account_freeze ，如果已经存在则证明Cancel已经执行，拒绝执行try业务\n\n\n\n2. 声明TCC接口TCC的Try、Confirm、Cancel方法都需要在接口中基于注解来声明。新建一个接口，声明TCC三个接口：\npackage cn.itcast.account.service;import io.seata.rm.tcc.api.BusinessActionContext;import io.seata.rm.tcc.api.BusinessActionContextParameter;import io.seata.rm.tcc.api.LocalTCC;import io.seata.rm.tcc.api.TwoPhaseBusinessAction;@LocalTCCpublic interface AccountTCCService &#123;    @TwoPhaseBusinessAction(name = &quot;deduct&quot;, commitMethod = &quot;confirm&quot;, rollbackMethod = &quot;cancel&quot;)    void deduct(@BusinessActionContextParameter(paramName = &quot;userId&quot;) String userId,                @BusinessActionContextParameter(paramName = &quot;money&quot;)int money);    boolean confirm(BusinessActionContext ctx);    boolean cancel(BusinessActionContext ctx);&#125;\n\n3. 编写实现类新建一个类，实现TCC业务：\npackage cn.itcast.account.service.impl;import cn.itcast.account.entity.AccountFreeze;import cn.itcast.account.mapper.AccountFreezeMapper;import cn.itcast.account.mapper.AccountMapper;import cn.itcast.account.service.AccountTCCService;import io.seata.core.context.RootContext;import io.seata.rm.tcc.api.BusinessActionContext;import lombok.extern.slf4j.Slf4j;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.stereotype.Service;import org.springframework.transaction.annotation.Transactional;@Service@Slf4jpublic class AccountTCCServiceImpl implements AccountTCCService &#123;    @Autowired    private AccountMapper accountMapper;    @Autowired    private AccountFreezeMapper freezeMapper;    @Override    @Transactional    public void deduct(String userId, int money) &#123;        // 0.获取事务id        String xid = RootContext.getXID();        // 1.扣减可用余额        accountMapper.deduct(userId, money);        // 2.记录冻结金额，事务状态        AccountFreeze freeze = new AccountFreeze();        freeze.setUserId(userId);        freeze.setFreezeMoney(money);        freeze.setState(AccountFreeze.State.TRY);        freeze.setXid(xid);        freezeMapper.insert(freeze);    &#125;    @Override    public boolean confirm(BusinessActionContext ctx) &#123;        // 1.获取事务id        String xid = ctx.getXid();        // 2.根据id删除冻结记录        int count = freezeMapper.deleteById(xid);        return count == 1;    &#125;    @Override    public boolean cancel(BusinessActionContext ctx) &#123;        // 0.查询冻结记录        String xid = ctx.getXid();        AccountFreeze freeze = freezeMapper.selectById(xid);        // 1.恢复可用余额        accountMapper.refund(freeze.getUserId(), freeze.getFreezeMoney());        // 2.将冻结金额清零，状态改为CANCEL        freeze.setFreezeMoney(0);        freeze.setState(AccountFreeze.State.CANCEL);        int count = freezeMapper.updateById(freeze);        return count == 1;    &#125;&#125;\n\nSAGA模式Seata官网对于Saga的指南：https://seata.io/zh-cn/docs/user/saga.html\n原理：在 Saga 模式下，分布式事务内有多个参与者，每一个参与者都是一个冲正补偿服务，需要用户根据业务场景实现其正向操作和逆向回滚操作。分布式事务执行过程中，依次执行各参与者的正向操作，如果所有正向操作均执行成功，那么分布式事务提交。如果任何一个正向操作执行失败，那么分布式事务会去退回去执行前面各参与者的逆向回滚操作，回滚已提交的参与者，使分布式事务回到初始状态。\nSaga分为两个阶段：\n\n一阶段：直接提交本地事务\n二阶段：成功则什么都不做；失败则通过编写补偿业务来回滚\n\nSAGA优缺点优点：\n\n事务参与者可以基于事件驱动实现异步调用，吞吐高\n一阶段直接提交事务，无锁，性能好\n不用编写TCC中的三个阶段，实现简单\n\n缺点：\n\n软状态持续时间不确定，时效性差\n没有锁，没有事务隔离，会有脏写\n\n四种模式对比从以下几个方面来对比四种实现：\n\n一致性：能否保证事务的一致性？强一致还是最终一致？\n隔离性：事务之间的隔离性如何？\n代码侵入：是否需要对业务代码改造？\n性能：有无性能损耗？\n场景：常见的业务场景\n\nTC服务的高可用和异地容灾微服务基于事务组（tx-service-group)与TC集群的映射关系，来查找当前应该使用哪个TC集群。当SH集群故障时，只需要将vgroup-mapping中的映射关系改成HZ。则所有微服务就会切换到HZ的TC集群了。\n模拟异地容灾的TC集群计划启动两台seata的tc服务节点：| 节点名称 | ip地址    | 端口号 | 集群名称 || ——– | ——— | —— | ——– || seata    | 127.0.0.1 | 8091   | SH       || seata2   | 127.0.0.1 | 8092   | HZ       |\n前面我们已经启动了一台seata服务，端口是8091，集群名为SH。现在，将seata目录复制一份，起名为seata2，修改seata2/conf/registry.conf内容如下：\nregistry &#123;  # tc服务的注册中心类，这里选择nacos，也可以是eureka、zookeeper等  type = &quot;nacos&quot;  nacos &#123;    # seata tc 服务注册到 nacos的服务名称，可以自定义    application = &quot;seata-tc-server&quot;    serverAddr = &quot;127.0.0.1:8848&quot;    group = &quot;DEFAULT_GROUP&quot;    namespace = &quot;&quot;    cluster = &quot;HZ&quot;    username = &quot;nacos&quot;    password = &quot;nacos&quot;  &#125;&#125;config &#123;  # 读取tc服务端的配置文件的方式，这里是从nacos配置中心读取，这样如果tc是集群，可以共享配置  type = &quot;nacos&quot;  # 配置nacos地址等信息  nacos &#123;    serverAddr = &quot;127.0.0.1:8848&quot;    namespace = &quot;&quot;    group = &quot;SEATA_GROUP&quot;    username = &quot;nacos&quot;    password = &quot;nacos&quot;    dataId = &quot;seataServer.properties&quot;  &#125;&#125;\n进入seata2/bin目录，然后运行命令：\nseata-server.bat -p 8092\n打开nacos控制台，查看服务列表，点进详情查看：\n\n\n将事务组映射配置到nacos需要将tx-service-group与cluster的映射关系都配置到nacos配置中心，新建一个配置：\n# 事务组映射关系service.vgroupMapping.seata-demo=SHservice.enableDegrade=falseservice.disableGlobalTransaction=false# 与TC服务的通信配置transport.type=TCPtransport.server=NIOtransport.heartbeat=truetransport.enableClientBatchSendRequest=falsetransport.threadFactory.bossThreadPrefix=NettyBosstransport.threadFactory.workerThreadPrefix=NettyServerNIOWorkertransport.threadFactory.serverExecutorThreadPrefix=NettyServerBizHandlertransport.threadFactory.shareBossWorker=falsetransport.threadFactory.clientSelectorThreadPrefix=NettyClientSelectortransport.threadFactory.clientSelectorThreadSize=1transport.threadFactory.clientWorkerThreadPrefix=NettyClientWorkerThreadtransport.threadFactory.bossThreadSize=1transport.threadFactory.workerThreadSize=defaulttransport.shutdown.wait=3# RM配置client.rm.asyncCommitBufferLimit=10000client.rm.lock.retryInterval=10client.rm.lock.retryTimes=30client.rm.lock.retryPolicyBranchRollbackOnConflict=trueclient.rm.reportRetryCount=5client.rm.tableMetaCheckEnable=falseclient.rm.tableMetaCheckerInterval=60000client.rm.sqlParserType=druidclient.rm.reportSuccessEnable=falseclient.rm.sagaBranchRegisterEnable=false# TM配置client.tm.commitRetryCount=5client.tm.rollbackRetryCount=5client.tm.defaultGlobalTransactionTimeout=60000client.tm.degradeCheck=falseclient.tm.degradeCheckAllowTimes=10client.tm.degradeCheckPeriod=2000# undo日志配置client.undo.dataValidation=trueclient.undo.logSerialization=jacksonclient.undo.onlyCareUpdateColumns=trueclient.undo.logTable=undo_logclient.undo.compress.enable=trueclient.undo.compress.type=zipclient.undo.compress.threshold=64kclient.log.exceptionRate=100\n\n微服务读取nacos配置修改每一个微服务的application.yml文件，让微服务读取nacos中的client.properties文件：\nseata:  config:    type: nacos    nacos:      server-addr: 127.0.0.1:8848      username: nacos      password: nacos      group: SEATA_GROUP      data-id: client.properties\n重启微服务，现在微服务到底是连接tc的SH集群，还是tc的HZ集群，都统一由nacos的client.properties来决定了。\n分布式缓存参考Redis学习笔记。\n多级缓存多级缓存就是充分利用请求处理的每个环节，分别添加缓存，减轻Tomcat压力，提升服务性能：\n\n浏览器访问静态资源时，优先读取浏览器本地缓存\n访问非静态资源（ajax查询数据）时，访问服务端\n请求到达Nginx后，优先读取Nginx本地缓存\n如果Nginx本地缓存未命中，则去直接查询Redis（不经过Tomcat）\n如果Redis查询未命中，则查询Tomcat\n请求进入Tomcat后，优先查询JVM进程缓存\n如果JVM进程缓存未命中，则查询数据库\n\n在多级缓存架构中，Nginx内部需要编写本地缓存查询、Redis查询、Tomcat查询的业务逻辑，因此nginx服务不再是一个反向代理服务器，而是一个编写业务的Web服务器了。因此这样的业务Nginx服务也需要搭建集群来提高并发，再有专门的nginx服务来做反向代理，Tomcat服务将来也会部署为集群模式\n\n\n多级缓存的关键有两个：\n\n一个是在nginx中编写业务，实现nginx本地缓存、Redis、Tomcat的查询\n另一个就是在Tomcat中实现JVM进程缓存\n\nJVM进程缓存CaffeineCaffeine是一个基于Java8开发的，提供了近乎最佳命中率的高性能的本地缓存库。目前Spring内部的缓存使用的就是Caffeine。GitHub地址：https://github.com/ben-manes/caffeine\n缓存使用基本流程：\n@Testvoid testBasicOps() &#123;    // 构建cache对象    Cache&lt;String, String&gt; cache = Caffeine.newBuilder().build();    // 存数据    cache.put(&quot;gf&quot;, &quot;迪丽热巴&quot;);    // 取数据    String gf = cache.getIfPresent(&quot;gf&quot;);    System.out.println(&quot;gf = &quot; + gf);    // 取数据，包含两个参数：    // 参数一：缓存的key    // 参数二：Lambda表达式，表达式参数就是缓存的key，方法体是查询数据库的逻辑    // 优先根据key查询JVM缓存，如果未命中，则执行参数二的Lambda表达式    String defaultGF = cache.get(&quot;defaultGF&quot;, key -&gt; &#123;        // 根据key去数据库查询数据        return &quot;柳岩&quot;;    &#125;);    System.out.println(&quot;defaultGF = &quot; + defaultGF);&#125;\n\nCaffeine缓存驱逐策略：\n\n基于容量：设置缓存的数量上限// 创建缓存对象Cache&lt;String, String&gt; cache = Caffeine.newBuilder()    .maximumSize(1) // 设置缓存大小上限为 1    .build();\n基于时间：设置缓存的有效时间// 创建缓存对象Cache&lt;String, String&gt; cache = Caffeine.newBuilder()    // 设置缓存有效期为 10 秒，从最后一次写入开始计时     .expireAfterWrite(Duration.ofSeconds(10))     .build();\n基于引用：设置缓存为软引用或弱引用，利用GC来回收缓存数据。性能较差，不建议使用\n\nPS：在默认情况下，当一个缓存元素过期的时候，Caffeine不会自动立即将其清理和驱逐。而是在一次读或写操作后，或者在空闲时间完成对失效数据的驱逐。\n缓存实现示例eg：利用Caffeine实现下列需求：\n\n给根据id查询商品的业务添加缓存，缓存未命中时查询数据库\n给根据id查询商品库存的业务添加缓存，缓存未命中时查询数据库\n缓存初始大小为100\n缓存上限为10000\n\n\n定义两个Caffeine的缓存对象，分别保存商品、库存的缓存数据package com.heima.item.config;import com.github.benmanes.caffeine.cache.Cache;import com.github.benmanes.caffeine.cache.Caffeine;import com.heima.item.pojo.Item;import com.heima.item.pojo.ItemStock;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;@Configurationpublic class CaffeineConfig &#123;    @Bean    public Cache&lt;Long, Item&gt; itemCache()&#123;        return Caffeine.newBuilder()                .initialCapacity(100)                .maximumSize(10_000)                .build();    &#125;    @Bean    public Cache&lt;Long, ItemStock&gt; stockCache()&#123;        return Caffeine.newBuilder()                .initialCapacity(100)                .maximumSize(10_000)                .build();    &#125;&#125;\n修改item-service的ItemController类，添加缓存逻辑@RestController@RequestMapping(&quot;item&quot;)public class ItemController &#123;    @Autowired    private IItemService itemService;    @Autowired    private IItemStockService stockService;    @Autowired    private Cache&lt;Long, Item&gt; itemCache;    @Autowired    private Cache&lt;Long, ItemStock&gt; stockCache;        // ...其它略        @GetMapping(&quot;/&#123;id&#125;&quot;)    public Item findById(@PathVariable(&quot;id&quot;) Long id) &#123;        return itemCache.get(id, key -&gt; itemService.query()                .ne(&quot;status&quot;, 3).eq(&quot;id&quot;, key)                .one()        );    &#125;    @GetMapping(&quot;/stock/&#123;id&#125;&quot;)    public ItemStock findStockById(@PathVariable(&quot;id&quot;) Long id) &#123;        return stockCache.get(id, key -&gt; stockService.getById(key));    &#125;&#125;\n\nOpenRestry快速入门LuaLua 是一种轻量小巧的脚本语言，用标准C语言编写并以源代码形式开放， 其设计目的是为了嵌入应用程序中，从而为应用程序提供灵活的扩展和定制功能。官网：https://www.lua.org/\n为什么学习Lua？因为对Nginx进行编程需要使用Lua（Nginx本身也是C语言开发，允许基于Lua做拓展），因此要实现Nginx缓存必须了解Lua\nHellodWorld\n新建 hello.lua 文件\n添加Lua语句print(&quot;Hello World!&quot;)  \n运行lua hello.lua\n\n变量、循环Lua中支持的常见数据类型包括：\n\n\nPS：Lua提供了type()函数来判断一个变量的数据类型\n声明变量：Lua声明变量的时候无需指定数据类型，而是用local来声明变量为局部变量\n-- 声明字符串，可以用单引号或双引号，local str = &#x27;hello&#x27;-- 字符串拼接可以使用 ..local str2 = &#x27;hello&#x27; .. &#x27;world&#x27;-- 声明数字local num = 21-- 声明布尔类型local flag = true\nLua中的table类型既可以作为数组，又可以作为map。数组就是特殊的table，key是数组角标而已：\n-- 声明数组 ，key为角标的 tablelocal arr = &#123;&#x27;java&#x27;, &#x27;python&#x27;, &#x27;lua&#x27;&#125;-- 声明table，类似java的maplocal map =  &#123;name=&#x27;Jack&#x27;, age=21&#125;-- 访问数组，lua数组的角标从1开始print(arr[1])-- 访问table,可以用key来访问print(map[&#x27;name&#x27;])print(map.name)\n\n循环：\n-- 声明数组 key为索引的 tablelocal arr = &#123;&#x27;java&#x27;, &#x27;python&#x27;, &#x27;lua&#x27;&#125;-- 遍历数组for index,value in ipairs(arr) do    print(index, value) end-- 声明map，也就是tablelocal map = &#123;name=&#x27;Jack&#x27;, age=21&#125;-- 遍历tablefor key,value in pairs(map) do   print(key, value) end\n\n条件控制、函数函数：定义函数\nfunction 函数名( argument1, argument2..., argumentn)    -- 函数体    return 返回值end\n条件控制\nif(布尔表达式)then   --[ 布尔表达式为 true 时执行该语句块 --]else   --[ 布尔表达式为 false 时执行该语句块 --]end\nPS：与java不同，布尔表达式中的逻辑运算是基于英文单词\n\n\n安装OpenRestryOpenResty® 是一个基于 Nginx的高性能 Web 平台，用于方便地搭建能够处理超高并发、扩展性极高的动态 Web 应用、Web 服务和动态网关：\n\n具备Nginx的完整功能\n基于Lua语言进行扩展，集成了大量精良的 Lua 库、第三方模块\n允许使用Lua自定义业务逻辑、自定义库\n\n\n安装开发库yum install -y pcre-devel openssl-devel gcc --skip-broken\n安装OpenResty（CentOS）添加 openresty 仓库，可以便于未来安装或更新软件包（通过 yum check-update 命令）yum-config-manager --add-repo https://openresty.org/package/centos/openresty.repo\n如果提示说命令不存在，则运行：yum install -y yum-utils \n安装OpenRestyyum install -y openresty\n安装opm工具opm是OpenResty的一个管理工具，可以帮助我们安装一个第三方的Lua模块yum install -y openresty-opm\n目录结构默认情况下，OpenResty安装的目录是：/usr/local/openresty。OpenResty就是在Nginx基础上集成了一些Lua模块。\n配置nginx的环境变量\n\n\n打开配置文件vi /etc/profile\n添加内容（NGINX_HOME：后面是OpenResty安装目录下的nginx的目录）export NGINX_HOME=/usr/local/openresty/nginxexport PATH=$&#123;NGINX_HOME&#125;/sbin:$PATH\n配置生效source /etc/profile\n\n\n启动运行# 启动nginxnginx# 重新加载配置nginx -s reload# 停止nginx -s stop\n\n备注：加载OpenResty的lua模块：\n#lua 模块lua_package_path &quot;/usr/local/openresty/lualib/?.lua;;&quot;;#c模块     lua_package_cpath &quot;/usr/local/openresty/lualib/?.so;;&quot;;  \ncommon.lua\n-- 封装函数，发送http请求，并解析响应local function read_http(path, params)    local resp = ngx.location.capture(path,&#123;        method = ngx.HTTP_GET,        args = params,    &#125;)    if not resp then        -- 记录错误信息，返回404        ngx.log(ngx.ERR, &quot;http not found, path: &quot;, path , &quot;, args: &quot;, args)        ngx.exit(404)    end    return resp.bodyend-- 将方法导出local _M = &#123;      read_http = read_http&#125;  return _M\n释放Redis连接API：\n-- 关闭redis连接的工具方法，其实是放入连接池local function close_redis(red)    local pool_max_idle_time = 10000 -- 连接的空闲时间，单位是毫秒    local pool_size = 100 --连接池大小    local ok, err = red:set_keepalive(pool_max_idle_time, pool_size)    if not ok then        ngx.log(ngx.ERR, &quot;放入redis连接池失败: &quot;, err)    endend\n读取Redis数据的API：\n-- 查询redis的方法 ip和port是redis地址，key是查询的keylocal function read_redis(ip, port, key)    -- 获取一个连接    local ok, err = red:connect(ip, port)    if not ok then        ngx.log(ngx.ERR, &quot;连接redis失败 : &quot;, err)        return nil    end    -- 查询redis    local resp, err = red:get(key)    -- 查询失败处理    if not resp then        ngx.log(ngx.ERR, &quot;查询Redis失败: &quot;, err, &quot;, key = &quot; , key)    end    --得到的数据为空处理    if resp == ngx.null then        resp = nil        ngx.log(ngx.ERR, &quot;查询Redis数据为空, key = &quot;, key)    end    close_redis(red)    return respend\n开启共享词典：\n# 共享字典，也就是本地缓存，名称叫做：item_cache，大小150mlua_shared_dict item_cache 150m; \n\n监听请求我们希望达到的多级缓存架构如图：\n\n\nwindows上的nginx用来做反向代理服务，将前端的查询商品的ajax请求代理到OpenResty集群\nOpenResty集群用来编写多级缓存业务\n\n反向代理流程:\n\n浏览器发送请求,请求被nginx拦截\nnginx将请求代理到OpenResty集群\n\n1. 添加OpenResty对Lua模块的加载修改/usr/local/openresty/nginx/conf/nginx.conf文件，在其中的http下面，添加下面代码：\n#lua 模块lua_package_path &quot;/usr/local/openresty/lualib/?.lua;;&quot;;#c模块     lua_package_cpath &quot;/usr/local/openresty/lualib/?.so;;&quot;;  \n\n2. 监听路径，配置响应文件修改/usr/local/openresty/nginx/conf/nginx.conf文件，在nginx.conf的server下面，添加对/api/item这个路径的监听：\nlocation  /api/item &#123;    # 默认的响应类型    default_type application/json;    # 响应结果由lua/item.lua文件来决定    content_by_lua_file lua/item.lua;&#125;\n类似于SpringMVC中的@GetMapping(&quot;/api/item&quot;)路径映射。而content_by_lua_file lua/item.lua则相当于调用item.lua这个文件，执行其中的业务，把结果返回给用户，相当于java中调用service。\n3. 编写Lua文件\n在/usr/loca/openresty/nginx目录创建文件夹lua并在目录lua下新建item.lua文件\n在item.lua中编写业务逻辑ngx.say(&#x27;&#123;&quot;id&quot;:10001,&quot;name&quot;:&quot;SALSA AIR&quot;,&quot;title&quot;:&quot;RIMOWA 21寸托运箱拉杆箱 SALSA AIR系列果绿色 820.70.36.4&quot;,&quot;price&quot;:17900,&quot;image&quot;:&quot;https://m.360buyimg.com/mobilecms/s720x720_jfs/t6934/364/1195375010/84676/e9f2c55f/597ece38N0ddcbc77.jpg!q70.jpg.webp&quot;,&quot;category&quot;:&quot;拉杆箱&quot;,&quot;brand&quot;:&quot;RIMOWA&quot;,&quot;spec&quot;:&quot;&quot;,&quot;status&quot;:1,&quot;createTime&quot;:&quot;2019-04-30T16:00:00.000+00:00&quot;,&quot;updateTime&quot;:&quot;2019-04-30T16:00:00.000+00:00&quot;,&quot;stock&quot;:2999,&quot;sold&quot;:31290&#125;&#x27;)\nPS：这里返回的是假数据\n重新加载配置nginx -s reload\n请求参数处理\n获取请求参数APIOpenResty中提供了一些API用来获取不同类型的前端请求参数：\n获取请求参数eg：获取 http://localhost/api/item/1001 的id=1001参数以路径占位符方式传递的，则利用正则表达式匹配的方式来获取。location ~ /api/item/(\\d+) &#123;    # 默认的响应类型    default_type application/json;    # 响应结果由lua/item.lua文件来决定    content_by_lua_file lua/item.lua;&#125;\n修改lua文件获取id并拼接到结果中返回：-- 获取商品idlocal id = ngx.var[1]-- 拼接并返回ngx.say(&#x27;&#123;&quot;id&quot;:&#x27; .. id .. &#x27;,&quot;name&quot;:&quot;SALSA AIR&quot;,&quot;title&quot;:&quot;RIMOWA 21寸托运箱拉杆箱 SALSA AIR系列果绿色 820.70.36.4&quot;,&quot;price&quot;:17900,&quot;image&quot;:&quot;https://m.360buyimg.com/mobilecms/s720x720_jfs/t6934/364/1195375010/84676/e9f2c55f/597ece38N0ddcbc77.jpg!q70.jpg.webp&quot;,&quot;category&quot;:&quot;拉杆箱&quot;,&quot;brand&quot;:&quot;RIMOWA&quot;,&quot;spec&quot;:&quot;&quot;,&quot;status&quot;:1,&quot;createTime&quot;:&quot;2019-04-30T16:00:00.000+00:00&quot;,&quot;updateTime&quot;:&quot;2019-04-30T16:00:00.000+00:00&quot;,&quot;stock&quot;:2999,&quot;sold&quot;:31290&#125;&#x27;)\n\n查询Tomcat此时环境是OpenResty是在虚拟机，Tomcat是在Windows。\n\n关于OpenResty和Tomcat之间的访问问题有以下参考：\n\n教程视频中使用的是虚拟机，虚拟机ip和主机ip有对应关系（虎哥说的），关闭防火墙，即可完成连接\n弹幕说，用云服务的阿里云服务器的话，把课件中的项目放到阿里云运行，然后配置nginx代理地址之间转发到阿里云的地址即可\n弹幕说，用云服务器的话可以搜一下如何配置内网穿透\n弹幕说，服务器的话用公网ip就可以\n\n发送请求API\nlocal resp = ngx.location.capture(&quot;/path&quot;,&#123;    method = ngx.HTTP_GET,   -- 请求方式    args = &#123;a=1,b=2&#125;,  -- get方式传参数&#125;)\n返回的响应内容包括：\n\nresp.status：响应状态码\nresp.header：响应头，是一个table\nresp.body：响应体，就是响应数据\n\n这里的path是路径，并不包含IP和端口，这个请求会被nginx内部的server监听并处理。我们希望这个请求发送到Tomcat服务器，所以还需要编写一个server来对这个路径做反向代理：\nlocation /path &#123;    # 这里是windows电脑的ip和Java服务端口，需要确保windows防火墙处于关闭状态    proxy_pass http://192.168.150.1:8081; &#125;\n\n封装http工具封装一个发送Http请求的工具，基于ngx.location.capture来实现查询tomcat\n\n添加反向代理，到windows的Java服务。\n\n因为item-service中接口都是/item开头，所以监听/item路径代理到windows上的tomcat服务，添加一个location：\nlocation /item &#123;    proxy_pass http://192.168.150.1:8081;&#125;\n以后调用ngx.location.capture(&quot;/item&quot;)，就会发送请求到windows的tomcat服务。\n\n封装工具类\n\nOpenResty启动时会加载以下两个目录中的工具文件：\n\n所以，自定义的http工具也需要放到这个目录下，新建common.lua文件：\n-- 封装函数，发送http请求，并解析响应local function read_http(path, params)    local resp = ngx.location.capture(path,&#123;        method = ngx.HTTP_GET,        args = params,    &#125;)    if not resp then        -- 记录错误信息，返回404        ngx.log(ngx.ERR, &quot;http请求查询失败, path: &quot;, path , &quot;, args: &quot;, args)        ngx.exit(404)    end    return resp.bodyend-- 将方法导出local _M = &#123;      read_http = read_http&#125;  return _M\n这个工具将read_http函数封装到_M这个table类型的变量中，并且返回，这类似于导出。使用的时候，可以利用require(&#39;common&#39;)来导入该函数库，这里的common是函数库的文件名。\n\n实现商品查询\n\n修改/usr/local/openresty/lua/item.lua文件，利用刚刚封装的函数库实现对tomcat的查询：\n-- 引入自定义common工具模块，返回值是common中返回的 _Mlocal common = require(&quot;common&quot;)-- 从 common中获取read_http这个函数local read_http = common.read_http-- 获取路径参数local id = ngx.var[1]-- 根据id查询商品local itemJSON = read_http(&quot;/item/&quot;.. id, nil)-- 根据id查询商品库存local itemStockJSON = read_http(&quot;/item/stock/&quot;.. id, nil)\n\n序列化、反序列化OpenResty提供cjson模块用来处理JSON的序列化和反序列化，官方地址： https://github.com/openresty/lua-cjson/\n\n引入cjson模块\n\nlocal cjson = require &quot;cjson&quot;\n\n\n序列化\n\nlocal obj = &#123;    name = &#x27;jack&#x27;,    age = 21&#125;-- 把 table 序列化为 jsonlocal json = cjson.encode(obj)\n\n\n反序列化\n\nlocal json = &#x27;&#123;&quot;name&quot;: &quot;jack&quot;, &quot;age&quot;: 21&#125;&#x27;-- 反序列化 json为 tablelocal obj = cjson.decode(json);print(obj.name)\n\n修改之前的item.lua中的业务，添加json处理功能：\n-- 导入common函数库local common = require(&#x27;common&#x27;)local read_http = common.read_http-- 导入cjson库local cjson = require(&#x27;cjson&#x27;)-- 获取路径参数local id = ngx.var[1]-- 根据id查询商品local itemJSON = read_http(&quot;/item/&quot;.. id, nil)-- 根据id查询商品库存local itemStockJSON = read_http(&quot;/item/stock/&quot;.. id, nil)-- JSON转化为lua的tablelocal item = cjson.decode(itemJSON)local stock = cjson.decode(stockJSON)-- 组合数据item.stock = stock.stockitem.sold = stock.sold-- 把item序列化为json 返回结果ngx.say(cjson.encode(item))\n\n基于ID负载均衡以上示例代码中，tomcat均是单机部署。而实际开发中，tomcat一定是集群模式，因此OpenResty需要对tomcat集群做负载均衡。\n默认的负载均衡规则是轮询模式，当查询/item/10001时：\n\n第一次会访问8081端口的tomcat服务，在该服务内部就形成了JVM进程缓存\n第二次会访问8082端口的tomcat服务，该服务内部没有JVM缓存（因为JVM缓存无法共享），会查询数据库\n…\n\n因为轮询，第一次查询8081形成的JVM缓存并未生效，直到下一次再次访问到8081时才可以生效，显得JVM进程缓存并没有多大意义，这种负载均衡的效率很低。\nHash负载均衡nginx提供了基于请求路径做负载均衡的算法，根据请求路径做hash运算根据运算结果决定访问哪个服务，实现负载均衡。只要id不变，每次hash运算结果也不会变，那就可以保证同一个商品，一直访问同一个tomcat服务，确保JVM缓存生效。\n\n配置Tomcat集群\n\nupstream tomcat-cluster &#123;    hash $request_uri;    server 192.168.150.1:8081;    server 192.168.150.1:8082;&#125;\n\n\n修改对tomcat服务的反向代理，目标指向tomcat集群：\n\nlocation /item &#123;    proxy_pass http://tomcat-cluster;&#125;\n\n\n重新加载OpenResty\n\nnginx -s reload\n\nRedis缓存预热Redis缓存会面临冷启动问题：冷启动：服务刚刚启动时，Redis中并没有缓存，如果所有商品数据都在第一次查询时添加缓存，可能会给数据库带来较大压力。缓存预热：在实际开发中，我们可以利用大数据统计用户访问的热点数据，在项目启动时将这些热点数据提前查询并保存到Redis中。\n\n安装Redis\n微服务引入Redis依赖\n配置Redis\n编写初始化类\n\n缓存预热需要在项目启动时完成，并且必须是拿到RedisTemplate之后。利用InitializingBean接口来实现，因为InitializingBean可以在对象被Spring创建并且成员变量全部注入后执行。\npackage com.heima.item.config;import com.fasterxml.jackson.core.JsonProcessingException;import com.fasterxml.jackson.databind.ObjectMapper;import com.heima.item.pojo.Item;import com.heima.item.pojo.ItemStock;import com.heima.item.service.IItemService;import com.heima.item.service.IItemStockService;import org.springframework.beans.factory.InitializingBean;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.data.redis.core.StringRedisTemplate;import org.springframework.stereotype.Component;import java.util.List;@Componentpublic class RedisHandler implements InitializingBean &#123;    @Autowired    private StringRedisTemplate redisTemplate;    @Autowired    private IItemService itemService;    @Autowired    private IItemStockService stockService;    private static final ObjectMapper MAPPER = new ObjectMapper();    @Override    public void afterPropertiesSet() throws Exception &#123;        // 初始化缓存        // 1.查询商品信息        List&lt;Item&gt; itemList = itemService.list();        // 2.放入缓存        for (Item item : itemList) &#123;            // 2.1.item序列化为JSON            String json = MAPPER.writeValueAsString(item);            // 2.2.存入redis            redisTemplate.opsForValue().set(&quot;item:id:&quot; + item.getId(), json);        &#125;        // 3.查询商品库存信息        List&lt;ItemStock&gt; stockList = stockService.list();        // 4.放入缓存        for (ItemStock stock : stockList) &#123;            // 2.1.item序列化为JSON            String json = MAPPER.writeValueAsString(stock);            // 2.2.存入redis            redisTemplate.opsForValue().set(&quot;item:stock:id:&quot; + stock.getId(), json);        &#125;    &#125;&#125;\n\nOpenResty查询Redis当请求进入OpenResty之后：\n\n优先查询Redis缓存\n如果Redis缓存未命中，再查询Tomcat\n\n封装Redis工具OpenResty提供了操作Redis的模块，引入该模块就使用。但是为了方便，我们将Redis操作封装到之前的common.lua工具库中。修改上文中的/usr/local/openresty/lualib/common.lua文件：\n-- 导入redislocal redis = require(&#x27;resty.redis&#x27;)-- 初始化redislocal red = redis:new()red:set_timeouts(1000, 1000, 1000)-- 关闭redis连接的工具方法，其实是放入连接池local function close_redis(red)    local pool_max_idle_time = 10000 -- 连接的空闲时间，单位是毫秒    local pool_size = 100 --连接池大小    local ok, err = red:set_keepalive(pool_max_idle_time, pool_size)    if not ok then        ngx.log(ngx.ERR, &quot;放入redis连接池失败: &quot;, err)    endend-- 查询redis的方法 ip和port是redis地址，key是查询的keylocal function read_redis(ip, port, key)    -- 获取一个连接    local ok, err = red:connect(ip, port)    if not ok then        ngx.log(ngx.ERR, &quot;连接redis失败 : &quot;, err)        return nil    end    -- 查询redis    local resp, err = red:get(key)    -- 查询失败处理    if not resp then        ngx.log(ngx.ERR, &quot;查询Redis失败: &quot;, err, &quot;, key = &quot; , key)    end    --得到的数据为空处理    if resp == ngx.null then        resp = nil        ngx.log(ngx.ERR, &quot;查询Redis数据为空, key = &quot;, key)    end    close_redis(red)    return respend-- 封装函数，发送http请求，并解析响应local function read_http(path, params)    local resp = ngx.location.capture(path,&#123;        method = ngx.HTTP_GET,        args = params,    &#125;)    if not resp then        -- 记录错误信息，返回404        ngx.log(ngx.ERR, &quot;http查询失败, path: &quot;, path , &quot;, args: &quot;, args)        ngx.exit(404)    end    return resp.bodyend-- 将方法导出local _M = &#123;      read_http = read_http,    read_redis = read_redis&#125;  return _M\n\n实现Redis查询eg：\n\n根据id查询Redis\n如果查询失败则继续查询Tomcat\n将查询结果返回\n\n-- 导入common函数库local common = require(&#x27;common&#x27;)local read_http = common.read_httplocal read_redis = common.read_redis-- 导入cjson库local cjson = require(&#x27;cjson&#x27;)-- 封装查询函数function read_data(key, path, params)    -- 查询本地缓存    local val = read_redis(&quot;127.0.0.1&quot;, 6379, key)    -- 判断查询结果    if not val then        ngx.log(ngx.ERR, &quot;redis查询失败，尝试查询http， key: &quot;, key)        -- redis查询失败，去查询http        val = read_http(path, params)    end    -- 返回数据    return valend-- 获取路径参数local id = ngx.var[1]-- 查询商品信息local itemJSON = read_data(&quot;item:id:&quot; .. id,  &quot;/item/&quot; .. id, nil)-- 查询库存信息local stockJSON = read_data(&quot;item:stock:id:&quot; .. id, &quot;/item/stock/&quot; .. id, nil)-- JSON转化为lua的tablelocal item = cjson.decode(itemJSON)local stock = cjson.decode(stockJSON)-- 组合数据item.stock = stock.stockitem.sold = stock.sold-- 把item序列化为json 返回结果ngx.say(cjson.encode(item))\n\nNginx本地缓存OpenResty为Nginx提供了shard dict的功能，可以在nginx的多个worker之间共享数据，实现缓存功能。\n\n开启共享字典，在nginx.conf的http下添加配置\n\n# 共享字典，也就是本地缓存，名称叫做：item_cache，大小150mlua_shared_dict item_cache 150m; \n\n\n操作共享词典\n\n-- 获取本地缓存对象local item_cache = ngx.shared.item_cache-- 存储, 指定key、value、过期时间，单位s，默认为0代表永不过期item_cache:set(&#x27;key&#x27;, &#x27;value&#x27;, 1000)-- 读取local val = item_cache:get(&#x27;key&#x27;)\n\n\n本地缓存查询\n\n修改/usr/local/openresty/lua/item.lua文件:\n\n修改read_data查询函数，添加本地缓存逻辑\n修改item.lua中查询商品和库存的业务，实现最新的read_data函数\n多了缓存时间参数，过期后nginx缓存会自动删除，下次访问即可更新缓存。品基本信息设置超时时间为30分钟，库存为1分钟。\n\n\n\n因为库存更新频率较高，如果缓存时间过长，可能与数据库差异较大。\n-- 导入common函数库local common = require(&#x27;common&#x27;)local read_http = common.read_httplocal read_redis = common.read_redis-- 导入cjson库local cjson = require(&#x27;cjson&#x27;)-- 导入共享词典，本地缓存local item_cache = ngx.shared.item_cache-- 封装查询函数function read_data(key, expire, path, params)    -- 查询本地缓存    local val = item_cache:get(key)    if not val then        ngx.log(ngx.ERR, &quot;本地缓存查询失败，尝试查询Redis， key: &quot;, key)        -- 查询redis        val = read_redis(&quot;127.0.0.1&quot;, 6379, key)        -- 判断查询结果        if not val then            ngx.log(ngx.ERR, &quot;redis查询失败，尝试查询http， key: &quot;, key)            -- redis查询失败，去查询http            val = read_http(path, params)        end    end    -- 查询成功，把数据写入本地缓存    item_cache:set(key, val, expire)    -- 返回数据    return valend-- 获取路径参数local id = ngx.var[1]-- 查询商品信息local itemJSON = read_data(&quot;item:id:&quot; .. id, 1800,  &quot;/item/&quot; .. id, nil)-- 查询库存信息local stockJSON = read_data(&quot;item:stock:id:&quot; .. id, 60, &quot;/item/stock/&quot; .. id, nil)-- JSON转化为lua的tablelocal item = cjson.decode(itemJSON)local stock = cjson.decode(stockJSON)-- 组合数据item.stock = stock.stockitem.sold = stock.sold-- 把item序列化为json 返回结果ngx.say(cjson.encode(item))\n\n缓存同步缓存同步策略：设置有效期：给缓存设置有效期，到期后自动删除。再次查询时更新\n\n优势：简单、方便\n缺点：时效性差，缓存过期之前可能不一致\n场景：更新频率较低，时效性要求低的业务\n\n同步双写：在修改数据库的同时，直接修改缓存\n\n优势：时效性强，缓存与数据库强一致\n缺点：有代码侵入，耦合度高；\n场景：对一致性、时效性要求较高的缓存数据\n\n异步通知：修改数据库时发送事件通知，相关服务监听到通知后修改缓存数据\n\n优势：低耦合，可以同时通知多个缓存服务\n缺点：时效性一般，可能存在中间不一致状态\n场景：时效性要求一般，有多个服务需要同步\n\n异步实现可以基于MQ或者Canal：\n\n基于MQ的异步通知\n商品服务完成对数据的修改后，只需要发送一条消息到MQ中。\n缓存服务监听MQ消息，然后完成对缓存的更新\n\n依然有少量的代码侵入。\n\n基于Canal的通知\n商品服务完成商品修改后，业务直接结束，没有任何代码侵入\nCanal监听MySQL变化，当发现变化后，立即通知缓存服务\n缓存服务接收到canal通知，更新缓存\n\n代码零侵入\nCanalCanal是阿里巴巴旗下的一款开源项目，基于Java开发。基于数据库增量日志解析，提供增量数据订阅&amp;消费。GitHub的地址：https://github.com/alibaba/canal\nCanal是基于mysql的主从同步来实现的，MySQL主从同步的原理如下：\n\n\nMySQL master 将数据变更写入二进制日志( binary log），其中记录的数据叫做binary log events\nMySQL slave 将 master 的 binary log events拷贝到它的中继日志(relay log)\nMySQL slave 重放 relay log 中事件，将数据变更反映它自己的数据\n\nCanal就是把自己伪装成MySQL的一个slave节点，从而监听master的binary log变化。再把得到的变化信息通知给Canal的客户端，进而完成对其它数据库的同步。\n安装配置CanalCanal是基于MySQL的主从同步功能，因此必须先开启MySQL的主从功能\n\n开启binlog\n\n打开mysql容器挂载的日志文件，添加：\nlog-bin=/var/lib/mysql/mysql-binbinlog-do-db=heima\n\nlog-bin=/var/lib/mysql/mysql-bin：设置binary log文件的存放地址和文件名，叫做mysql-bin\nbinlog-do-db=heima：指定对哪个database记录binary log events，这里记录heima这个库\n\n最终效果：\n[mysqld]skip-name-resolvecharacter_set_server=utf8datadir=/var/lib/mysqlserver-id=1000log-bin=/var/lib/mysql/mysql-binbinlog-do-db=heima\n\n\n设置用户权限\n\n添加一个仅用于数据同步的账户，出于安全考虑，这里仅提供对heima这个库的操作权限\ncreate user canal@&#x27;%&#x27; IDENTIFIED by &#x27;canal&#x27;;GRANT SELECT, REPLICATION SLAVE, REPLICATION CLIENT,SUPER ON *.* TO &#x27;canal&#x27;@&#x27;%&#x27; identified by &#x27;canal&#x27;;FLUSH PRIVILEGES;\n重启Mysql\ndocker restart mysql\n\n安装过程略。安装好之后，运行容器：\ndocker run -p 11111:11111 --name canal \\-e canal.destinations=heima \\-e canal.instance.master.address=mysql:3306  \\-e canal.instance.dbUsername=canal  \\-e canal.instance.dbPassword=canal  \\-e canal.instance.connectionCharset=UTF-8 \\-e canal.instance.tsdb.enable=true \\-e canal.instance.gtidon=false  \\-e canal.instance.filter.regex=heima\\\\..* \\--network heima \\-d canal/canal-server:v1.1.5\n\n-p 11111:11111：这是canal的默认监听端口\n-e canal.instance.master.address=mysql:3306：数据库地址和端口，如果不知道mysql容器地址，可以通过docker inspect 容器id来查看\n-e canal.instance.dbUsername=canal：数据库用户名\n-e canal.instance.dbPassword=canal ：数据库密码\n-e canal.instance.filter.regex=：要监听的表名称\n\n表名称监听支持的语法：\nmysql 数据解析关注的表，Perl正则表达式.多个正则之间以逗号(,)分隔，转义符需要双斜杠(\\\\) 常见例子：1.  所有表：.*   or  .*\\\\..*2.  canal schema下所有表： canal\\\\..*3.  canal下的以canal打头的表：canal\\\\.canal.*4.  canal schema下的一张表：canal.test15.  多个规则组合使用然后以逗号隔开：canal\\\\..*,mysql.test1,mysql.test2 \n\n监听Canal当Canal监听到binlog变化时，会通知Canal的客户端。用Canal提供的Java客户端，监听Canal通知消息。当收到变化的消息时，完成对缓存的更新。\n这里我们会使用GitHub上的第三方开源的canal-starter客户端，https://github.com/NormanGyllenhaal/canal-client 与SpringBoot完美整合，自动装配，比官方客户端要简单好用很多。\n\n引入依赖\n\n&lt;dependency&gt;    &lt;groupId&gt;top.javatool&lt;/groupId&gt;    &lt;artifactId&gt;canal-spring-boot-starter&lt;/artifactId&gt;    &lt;version&gt;1.2.1-RELEASE&lt;/version&gt;&lt;/dependency&gt;\n\n\n编写配置\n\ncanal:  destination: heima # canal的集群名字，要与安装canal时设置的名称一致  server: 192.168.150.101:11111 # canal服务地址\n\n\n修改实体类\n\npackage com.heima.item.pojo;import com.baomidou.mybatisplus.annotation.IdType;import com.baomidou.mybatisplus.annotation.TableField;import com.baomidou.mybatisplus.annotation.TableId;import com.baomidou.mybatisplus.annotation.TableName;import lombok.Data;import org.springframework.data.annotation.Id;import org.springframework.data.annotation.Transient;import javax.persistence.Column;import java.util.Date;@Data@TableName(&quot;tb_item&quot;)public class Item &#123;    @TableId(type = IdType.AUTO)    @Id    private Long id;//商品id    @Column(name = &quot;name&quot;)    private String name;//商品名称    private String title;//商品标题    private Long price;//价格（分）    private String image;//商品图片    private String category;//分类名称    private String brand;//品牌名称    private String spec;//规格    private Integer status;//商品状态 1-正常，2-下架    private Date createTime;//创建时间    private Date updateTime;//更新时间    @TableField(exist = false)    @Transient    private Integer stock;    @TableField(exist = false)    @Transient    private Integer sold;&#125;\n\n\n编写监听器\n\n通过实现EntryHandler&lt;T&gt;接口编写监听器，监听Canal消息。注意两点：\n\n实现类通过@CanalTable(&quot;tb_item&quot;)指定监听的表信息\nEntryHandler的泛型是与表对应的实体类\n\npackage com.heima.item.canal;import com.github.benmanes.caffeine.cache.Cache;import com.heima.item.config.RedisHandler;import com.heima.item.pojo.Item;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.stereotype.Component;import top.javatool.canal.client.annotation.CanalTable;import top.javatool.canal.client.handler.EntryHandler;@CanalTable(&quot;tb_item&quot;)@Componentpublic class ItemHandler implements EntryHandler&lt;Item&gt; &#123;    @Autowired    private RedisHandler redisHandler;    @Autowired    private Cache&lt;Long, Item&gt; itemCache;    @Override    public void insert(Item item) &#123;        // 写数据到JVM进程缓存        itemCache.put(item.getId(), item);        // 写数据到redis        redisHandler.saveItem(item);    &#125;    @Override    public void update(Item before, Item after) &#123;        // 写数据到JVM进程缓存        itemCache.put(after.getId(), after);        // 写数据到redis        redisHandler.saveItem(after);    &#125;    @Override    public void delete(Item item) &#123;        // 删除数据到JVM进程缓存        itemCache.invalidate(item.getId());        // 删除数据到redis        redisHandler.deleteItemById(item.getId());    &#125;&#125;\n在这里对Redis的操作都封装到了RedisHandler这个对象中，是我们之前做缓存预热时编写的一个类，内容如下：\npackage com.heima.item.config;import com.fasterxml.jackson.core.JsonProcessingException;import com.fasterxml.jackson.databind.ObjectMapper;import com.heima.item.pojo.Item;import com.heima.item.pojo.ItemStock;import com.heima.item.service.IItemService;import com.heima.item.service.IItemStockService;import org.springframework.beans.factory.InitializingBean;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.data.redis.core.StringRedisTemplate;import org.springframework.stereotype.Component;import java.util.List;@Componentpublic class RedisHandler implements InitializingBean &#123;    @Autowired    private StringRedisTemplate redisTemplate;    @Autowired    private IItemService itemService;    @Autowired    private IItemStockService stockService;    private static final ObjectMapper MAPPER = new ObjectMapper();    @Override    public void afterPropertiesSet() throws Exception &#123;        // 初始化缓存        // 1.查询商品信息        List&lt;Item&gt; itemList = itemService.list();        // 2.放入缓存        for (Item item : itemList) &#123;            // 2.1.item序列化为JSON            String json = MAPPER.writeValueAsString(item);            // 2.2.存入redis            redisTemplate.opsForValue().set(&quot;item:id:&quot; + item.getId(), json);        &#125;        // 3.查询商品库存信息        List&lt;ItemStock&gt; stockList = stockService.list();        // 4.放入缓存        for (ItemStock stock : stockList) &#123;            // 2.1.item序列化为JSON            String json = MAPPER.writeValueAsString(stock);            // 2.2.存入redis            redisTemplate.opsForValue().set(&quot;item:stock:id:&quot; + stock.getId(), json);        &#125;    &#125;    public void saveItem(Item item) &#123;        try &#123;            String json = MAPPER.writeValueAsString(item);            redisTemplate.opsForValue().set(&quot;item:id:&quot; + item.getId(), json);        &#125; catch (JsonProcessingException e) &#123;            throw new RuntimeException(e);        &#125;    &#125;    public void deleteItemById(Long id) &#123;        redisTemplate.delete(&quot;item:id:&quot; + id);    &#125;&#125;","tags":["SpringClound"]},{"title":"maven依赖踩坑","url":"/2022/08/01/maven-yi-lai-cai-keng/","content":"1. pom爆红1.1 maven坐标正确这种情况可能是maven或IDEA自身的问题，这里给出一种解决方案。\n\n首先到maven中央仓库手动下载所需要的jar包\n将下载的jar包导入到maven本地仓库在jar包所在目录下打开cmd控制台，执行：mvn install:install-file -Dfile=jar包名称（带后缀） -DgroupId=jar包groupId -DartifactId=jar包artifactId -Dversion=jar包版本号 -Dpackaging=jar\n修改IDEA maven设置\n勾选圈出的选项，确定。之后重启IDEA，pom文件不再爆红。\n\n参考帖子\nhttps://www.cnblogs.com/think-world/p/12229763.html\nhttps://blog.csdn.net/qq_43242707/article/details/115277308\n\n"},{"title":"Mybatis-Plus学习笔记","url":"/2022/08/02/mybatis-plus-xue-xi-bi-ji/","content":"基本流程\n引入依赖Mybatis-Plus、数据库依赖（eg：Mysql）、Lombok（生成set、get、构造器等）\n&lt;dependency&gt;            &lt;groupId&gt;org.projectlombok&lt;/groupId&gt;            &lt;artifactId&gt;lombok&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt;            &lt;groupId&gt;com.baomidou&lt;/groupId&gt;            &lt;artifactId&gt;mybatis-plus-boot-starter&lt;/artifactId&gt;            &lt;version&gt;3.1.0&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt;            &lt;groupId&gt;mysql&lt;/groupId&gt;            &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt;&lt;/dependency&gt;\nPS：3.5.2 版本中@TableName、@MapperScan注解似乎没有了\n\n构造实体类\n@Data   //get、set方法@TableName(&quot;tb_user&quot;)@NoArgsConstructor  //无参构造器@AllArgsConstructor //有参构造器public class User &#123;    @TableId(&quot;ID&quot;)    private Long id;    @TableField(&quot;USER_NAME&quot;) private String userName; //驼峰命名,则无需注解    @TableField(&quot;PASSWORD&quot;)    private String password;&#125;\n编写Mapper，集成BaseMapper接口\npublic interface UserMapper extends BaseMapper&lt;User&gt; &#123; &#125;\n扫描mapper所在包在启动类或测试类上添加@MapperScan(&quot;包名&quot;)\n\n\n"},{"title":"Redis学习笔记","url":"/2022/08/06/redis-xue-xi-bi-ji/","content":"基础对象存储1. String\n\nJson格式：将Java对象转换为Json格式字符串，然后再进行存储。\n\n优点：占用空间较小（string类型数据优化较好）\n缺点：不适合对象频繁修改的场景。需要修改时，首先从redis中获取Json字符串，然后利用工具类例如FastJson、JackJson等转换为Java对象，进行修改后再转化为Json字符串存储到redis中。\n\n\n序列化方式：将Java对象序列化后存入redis string类型中。\n\n\n2. Hash将Java对象的每个属性转换为Hash的每个filed，属性值转换为value。\n\n优点：可以对对象的每个属性单独操作。\n\n缓存目的：减少数据库的IO压力，提高响应速度。\n流程：请求数据时，首先到缓存中查找数据，若有则直接返回数据；若没有则去查询数据库，将数据返回并将数据写入缓存。\n缓存淘汰：当内存占用过多时，需要对缓存进行淘汰。内存淘汰和超时剔除都是由redis提供的，主动更新需要自己手动维护缓存。\n\n内存淘汰：redis自动进行，当redis内存达到咱们设定的max-memery的时候，会自动触发淘汰机制，淘汰掉一些不重要的数据(可以自己设置策略方式)\n超时剔除：当我们给redis设置了过期时间ttl之后，redis会将超时的数据进行删除，方便咱们继续使用缓存\n主动更新：手动调用方法把缓存删掉，通常用于解决缓存和数据库不一致问题\n\n缓存更新：若数据库中的数据发生更改时，此时缓存中的数据便和数据库不一致，需要更新缓存，与数据库进行同步。\n\nCache Aside Pattern 人工编码方式：缓存调用者在更新完数据库后再去更新缓存，也称之为双写方案\nRead/Write Through Pattern : 由系统本身完成，数据库与缓存的问题交由系统本身去处理\nWrite Behind Caching Pattern ：调用者只操作缓存，其他线程去异步处理数据库，实现最终一致\n\n采用人工编码方式时，更新缓存有两种方式：\n\n更新缓存：每次更新数据库都更新缓存，无效写操作较多\n删除缓存：更新数据库时让缓存失效，查询时再更新缓存\n\n删除缓存的优点：如果数据库发生多次修改，而此期间没有数据访问请求，则缓存进行了多次的无效更新操作。相比之下，删除缓存则只有请求进入时进行更新，只进行一次更新操作。\n删除缓存：是先操作数据库再删缓存，还是先删缓存再操作数据库？\n\n先操作数据库再删缓存：首先线程1进入，删除缓存后，线程2进入。此时线程2查询缓存失败，操作数据库后更新缓存，然后线程1操作数据库，最终数据库中的数据为线程1的数据，缓存中为线程2的数据，造成不一致。\n先删缓存再操作数据库：首先线程1查询缓存，缓存失效，开始操作数据库，在线程1完成数据库操作后，写入缓存之前，线程2进入，由于此时缓存仍是失效的，开始操作数据库，然后删缓存。线程2删缓存后线程1执行写缓存，最终数据库中的数据为线程2的数据，缓存中为线程1的数据，造成不一致。\n此情况发生的条件是，线程1查缓存时缓存失效，而且由于线程1完成操作数据库到开始写入缓存之前的间隔远小于线程2执行操作数据库加删缓存所需时间（操作数据库耗时较大）。因此这种情况发生的概率远小于先操作数据库再删缓存。\n\n\n\n如何保证缓存与数据库的操作的同时成功或失败？\n\n单体系统，将缓存与数据库操作放在一个事务\n分布式系统，利用TCC等分布式事务方案\n\n缓存穿透缓存穿透：客户端请求的数据在缓存中和数据库中都不存在，这样缓存永远不会生效，这些请求都会打到数据库。\n常见的解决方案有两种：\n\n缓存空对象\n优点：实现简单，维护方便\n缺点：\n额外的内存消耗\n可能造成短期的不一致\n\n\n\n\n布隆过滤\n优点：内存占用较少，没有多余key\n缺点：\n实现复杂\n存在误判可能\n\n\n\n\n\n缓存空对象思路分析：当客户端访问不存在的数据时，先请求redis，redis中没有数据，此时会访问到数据库，但是数据库中也没有数据，这个数据穿透了缓存，直击数据库。简单的解决方案就是哪怕这个数据在数据库中也不存在，也把这个数据存入到redis中去，这样下次用户过来访问这个不存在的数据，那么在redis中也能找到这个数据就不会进入到数据库了。\n布隆过滤：布隆过滤器其实采用的是哈希思想来解决这个问题，通过一个庞大的二进制数组，走哈希思想去判断当前这个要查询的这个数据是否存在，如果布隆过滤器判断存在，则放行，这个请求会去访问redis，哪怕此时redis中的数据过期了，但是数据库中一定存在这个数据，在数据库中查询出来这个数据后，再将其放入到redis中，假设布隆过滤器判断这个数据不存在，则直接返回。这种方式优点在于节约内存空间，存在误判，误判原因在于：布隆过滤器走的是哈希思想，只要哈希思想，就可能存在哈希冲突\n\n\n缓存穿透的解决方案有哪些？\n\n缓存null值\n布隆过滤\n增强id的复杂度，避免被猜测id规律\n做好数据的基础格式校验\n加强用户权限校验\n做好热点参数的限流\n\n缓存雪崩缓存雪崩：在同一时段大量的缓存key同时失效或者Redis服务宕机，导致大量请求到达数据库，带来巨大压力。\n解决方案：\n\n给不同的Key的TTL添加随机值\n利用Redis集群提高服务的可用性\n给缓存业务添加降级限流策略\n给业务添加多级缓存\n\n缓存击穿缓存击穿：也称热点Key问题，就是一个被高并发访问并且缓存重建业务较复杂的key突然失效了，无数的请求访问会在瞬间给数据库带来巨大的冲击。\n常见的解决方案有两种：\n\n互斥锁\n逻辑过期\n\n逻辑分析：假设线程1在查询缓存之后，本来应该去查询数据库，然后把这个数据重新加载到缓存的，此时只要线程1走完这个逻辑，其他线程就都能从缓存中加载这些数据了，但是假设在线程1没有走完的时候，后续的线程2，线程3，线程4同时过来访问当前这个方法， 那么这些线程都不能从缓存中查询到数据，那么他们就会同一时刻来访问查询缓存，都没查到，接着同一时间去访问数据库，同时的去执行数据库代码，对数据库访问压力过大。\n\n\n解决方案一：使用锁来解决因为锁能实现互斥性。假设线程过来，只能一个人一个人的来访问数据库，从而避免对于数据库访问压力过大，但这也会影响查询的性能，因为此时会让查询的性能从并行变成了串行，我们可以采用tryLock方法 + double check来解决这样的问题。假设现在线程1过来访问，他查询缓存没有命中，但是此时他获得到了锁的资源，那么线程1就会一个人去执行逻辑，假设现在线程2过来，线程2在执行过程中，并没有获得到锁，那么线程2就可以进行到休眠，直到线程1把锁释放后，线程2获得到锁，然后再来执行逻辑，此时就能够从缓存中拿到数据了。\n\n\n解决方案二：逻辑过期方案方案分析：我们之所以会出现这个缓存击穿问题，主要原因是在于我们对key设置了过期时间，假设我们不设置过期时间，其实就不会有缓存击穿的问题，但是不设置过期时间，这样数据不就一直占用我们内存了吗，我们可以采用逻辑过期方案。我们把过期时间设置在 redis的value中，注意：这个过期时间并不会直接作用于redis，而是我们后续通过逻辑去处理。假设线程1去查询缓存，然后从value中判断出来当前的数据已经过期了，此时线程1去获得互斥锁，那么其他线程会进行阻塞，获得了锁的线程他会开启一个 线程去进行 以前的重构数据的逻辑，直到新开的线程完成这个逻辑后，才释放锁， 而线程1直接进行返回，假设现在线程3过来访问，由于线程线程2持有着锁，所以线程3无法获得锁，线程3也直接返回数据，只有等到新开的线程2把重建数据构建完后，其他线程才能走返回正确的数据。这种方案巧妙在于，异步的构建缓存，缺点在于在构建完缓存之前，返回的都是脏数据。\n\n\n两种方案对比：互斥锁方案：由于保证了互斥性，所以数据一致，且实现简单，因为仅仅只需要加一把锁而已，也没其他的事情需要操心，所以没有额外的内存消耗，缺点在于有锁就有死锁问题的发生，且只能串行执行性能肯定受到影响逻辑过期方案： 线程读取过程中不需要等待，性能好，有一个额外的线程持有锁去进行重构数据，但是在重构数据完成前，其他的线程只能返回之前的数据，且实现起来麻烦\n多级缓存锁悲观锁和乐观锁\n 悲观锁：可以实现对于数据的串行化执行，比如syn，和lock都是悲观锁的代表，同时，悲观锁中又可以再细分为公平锁，非公平锁，可重入锁，等等  乐观锁：会有一个版本号，每次操作数据会对版本号+1，再提交回数据时，会去校验是否比之前的版本大1 ，如果大1 ，则进行操作成功，这套机制的核心逻辑在于，如果在操作过程中，版本号只比原来大1 ，那么就意味着操作过程中没有人对他进行过修改，他的操作就是安全的，如果不大1，则数据被修改过，当然乐观锁还有一些变种的处理方式比如CAS（将数据本身视为版本号）\n分布式锁分布式锁：满足分布式系统或集群模式下多进程可见并且互斥的锁。\n\n\n分布式锁满足特性：\n\n可见性：多个线程都能看到相同的结果，注意：这个地方说的可见性并不是并发编程中指的内存可见性，只是说多个进程之间都能感知到变化的意思\n互斥：互斥是分布式锁的最基本的条件，使得程序串行执行\n高可用：程序不易崩溃，时时刻刻都保证较高的可用性\n高性能：由于加锁本身就让性能降低，所有对于分布式锁本身需要他就较高的加锁性能和释放锁性能\n安全性：安全也是程序中必不可少的一环\n\n常见三种分布式锁：\n\nMysql：mysql本身就带有锁机制，但是由于mysql性能本身一般，所以采用分布式锁的情况下，其实使用mysql作为分布式锁比较少见\nRedis：redis作为分布式锁是非常常见的一种使用方式，现在企业级开发中基本都使用redis或者zookeeper作为分布式锁，利用setnx这个方法，如果插入key成功，则表示获得到了锁，如果有人插入成功，其他人插入失败则表示无法获得到锁，利用这套逻辑来实现分布式锁\nZookeeper：zookeeper也是企业级开发中较好的一个实现分布式锁的方案，由于本套视频并不讲解zookeeper的原理和分布式锁的实现，所以不过多阐述\n\n实现分布式锁时需要实现的两个基本方法：\n\n获取锁：\n互斥：确保只能有一个线程获取锁\n非阻塞：尝试一次，成功返回true，失败返回false\n\n\n释放锁：\n手动释放\n超时释放：获取锁时添加一个超时时间\n\n\n\n核心思路：我们利用redis 的setNx 方法，当有多个线程进入时，我们就利用该方法，第一个线程进入时，redis 中就有这个key 了，返回了1，如果结果是1，则表示他抢到了锁，那么他去执行业务，然后再删除锁，退出锁逻辑，没有抢到锁的哥们，等待一定时间后重试即可\n分布式锁要点：\n\n死锁场景：拥有锁的线程阻塞或宕机，导致锁无法释放解决方案：通过对锁添加过期时间，防止出现死锁\n\n误删锁场景：线程1在业务过程中出现阻塞，导致锁释放。线程2拿到锁，进行业务操作，但是在操作过程中线程1恢复运行，释放了线程2的锁，这便是锁误删问题。解决方案：在每个线程释放锁的时候，去判断一下当前这把锁是否属于自己，不属于则不进行锁的删除。核心逻辑：在存入锁时，放入自己线程的标识，在删除锁时，判断当前这把锁的标识是不是自己存入的，如果是，则进行删除，如果不是，则不进行删除。\n\n\n代码实现（非最终版，还未引入Lua脚本解决原子性问题）\n\n加锁：private static final String ID_PREFIX = UUID.randomUUID().toString(true) + &quot;-&quot;;@Overridepublic boolean tryLock(long timeoutSec) &#123;   // 获取线程标示   String threadId = ID_PREFIX + Thread.currentThread().getId();   // 获取锁   Boolean success = stringRedisTemplate.opsForValue()                .setIfAbsent(KEY_PREFIX + name, threadId, timeoutSec, TimeUnit.SECONDS);   return Boolean.TRUE.equals(success);&#125;\n释放锁：public void unlock() &#123;    // 获取线程标示    String threadId = ID_PREFIX + Thread.currentThread().getId();    // 获取锁中的标示    String id = stringRedisTemplate.opsForValue().get(KEY_PREFIX + name);    // 判断标示是否一致    if(threadId.equals(id)) &#123;        // 释放锁        stringRedisTemplate.delete(KEY_PREFIX + name);    &#125;&#125;\n\n\n原子性问题场景：线程1持有锁后，在执行业务逻辑过程中，正准备删除锁，而且已经走到了条件判断的过程中，正准备删除锁，但是此时锁已经到期了，同时线程2进来并获取到锁。但线程1接着往后执行删除锁操作，相当于条件判断并没有起到作用，这就是删锁时的原子性问题。此问题是因为线程1的拿锁，比锁，删锁，实际上并不是原子性的。解决方案：使用Lua脚本保证拿锁、比锁、删锁是一个原子性动作。\n\n操作redis的拿锁比锁删锁的lua脚本\n-- 这里的 KEYS[1] 就是锁的key，这里的ARGV[1] 就是当前线程标示-- 获取锁中的标示，判断是否与当前线程标示一致if (redis.call(&#x27;GET&#x27;, KEYS[1]) == ARGV[1]) then  -- 一致，则删除锁  return redis.call(&#x27;DEL&#x27;, KEYS[1])end-- 不一致，则直接返回return 0\n\n释放锁（引入Lua脚本）：\nprivate static final DefaultRedisScript&lt;Long&gt; UNLOCK_SCRIPT;    static &#123;        UNLOCK_SCRIPT = new DefaultRedisScript&lt;&gt;();        //加载Lua脚本文件        UNLOCK_SCRIPT.setLocation(new ClassPathResource(&quot;unlock.lua&quot;));\t        UNLOCK_SCRIPT.setResultType(Long.class);    &#125;public void unlock() &#123;    // 调用lua脚本    stringRedisTemplate.execute(            UNLOCK_SCRIPT,            Collections.singletonList(KEY_PREFIX + name),            ID_PREFIX + Thread.currentThread().getId());&#125;\n\n\n锁续期（见Redisson）\n可重入（见Redisson）\n\nRedissionRedisson是一个在Redis的基础上实现的Java驻内存数据网格（In-Memory Data Grid）。它不仅提供了一系列的分布式的Java常用对象，还提供了许多分布式服务，其中就包含了各种分布式锁的实现。\n于setnx实现的分布式锁存在下面的问题：\n\n重入问题：重入问题是指 获得锁的线程可以再次进入到相同的锁的代码块中，可重入锁的意义在于防止死锁，比如HashTable这样的代码中，他的方法都是使用synchronized修饰的，假如他在一个方法内，调用另一个方法，那么此时如果是不可重入的，不就死锁了吗？所以可重入锁他的主要意义是防止死锁，我们的synchronized和Lock锁都是可重入的。\n不可重试：是指目前的分布式只能尝试一次，我们认为合理的情况是：当线程在获得锁失败后，他应该能再次尝试获得锁。\n超时释放：我们在加锁时增加了过期时间，这样的我们可以防止死锁，但是如果卡顿的时间超长，虽然我们采用了lua表达式防止删锁的时候，误删别人的锁，但是毕竟没有锁住，有安全隐患\n主从一致性： 如果Redis提供了主从集群，当我们向集群写数据时，主机需要异步的将数据同步给从机，而万一在同步过去之前，主机宕机了，就会出现死锁问题。\n\n快速入门\n引入依赖\n&lt;dependency&gt;\t&lt;groupId&gt;org.redisson&lt;/groupId&gt;\t&lt;artifactId&gt;redisson&lt;/artifactId&gt;\t&lt;version&gt;3.13.6&lt;/version&gt;&lt;/dependency&gt;\n配置客户端\n@Configurationpublic class RedissonConfig &#123;    @Bean    public RedissonClient redissonClient()&#123;        // 配置        Config config = new Config();        config.useSingleServer().setAddress(&quot;redis://192.168.150.101:6379&quot;)            .setPassword(&quot;123321&quot;);        // 创建RedissonClient对象        return Redisson.create(config);    &#125;&#125;\n使用Redission的分布式锁，注入对象\n@Resourceprivate RedissionClient redissonClient;\n\n可重入在Lock锁中，是借助于底层的一个voaltile的一个state变量来记录重入的状态的，比如当前没有人持有锁，那么state=0，假如有人持有这把锁，那么state=1，如果持有这把锁的人再次持有这把锁，那么state就会+1 ，如果是对于synchronized而言，他在c语言代码中会有一个count，原理和state类似，也是重入一次就加一，释放一次就-1 ，直到减少成0 时，表示当前这把锁没有被人持有。 \n在redission中，我们的也支持支持可重入锁\n在分布式锁中，他采用hash结构用来存储锁，其中大key表示表示这把锁是否存在，用小key表示当前这把锁被哪个线程持有，所以接下来我们一起分析一下当前的这个lua表达式这个地方一共有3个参数\n\nKEYS[1] ： 锁名称\nARGV[1]：  锁失效时间\nARGV[2]：  id + “:” + threadId; 锁的小key\n\nexists: 判断数据是否存在  name：是lock是否存在,如果==0，就表示当前这把锁不存在redis.call(‘hset’, KEYS[1], ARGV[2], 1);此时他就开始往redis里边去写数据 ，写成一个hash结构Lock{    id + “:” + threadId :  1}如果当前这把锁存在，则第一个条件不满足，再判断redis.call(‘hexists’, KEYS[1], ARGV[2]) == 1此时需要通过大key+小key判断当前这把锁是否是属于自己的，如果是自己的，则进行redis.call(‘hincrby’, KEYS[1], ARGV[2], 1)将当前这个锁的value进行+1 ，redis.call(‘pexpire’, KEYS[1], ARGV[1]); 然后再对其设置过期时间，如果以上两个条件都不满足，则表示当前这把锁抢锁失败，最后返回pttl，即为当前这把锁的失效时间如果小伙帮们看了前边的源码， 你会发现他会去判断当前这个方法的返回值是否为null，如果是null，则对应则前两个if对应的条件，退出抢锁逻辑，如果返回的不是null，即走了第三个分支，在源码处会进行while(true)的自旋抢锁。\n&quot;if (redis.call(&#x27;exists&#x27;, KEYS[1]) == 0) then &quot; +                  &quot;redis.call(&#x27;hset&#x27;, KEYS[1], ARGV[2], 1); &quot; +                  &quot;redis.call(&#x27;pexpire&#x27;, KEYS[1], ARGV[1]); &quot; +                  &quot;return nil; &quot; +              &quot;end; &quot; +              &quot;if (redis.call(&#x27;hexists&#x27;, KEYS[1], ARGV[2]) == 1) then &quot; +                  &quot;redis.call(&#x27;hincrby&#x27;, KEYS[1], ARGV[2], 1); &quot; +                  &quot;redis.call(&#x27;pexpire&#x27;, KEYS[1], ARGV[1]); &quot; +                  &quot;return nil; &quot; +              &quot;end; &quot; +              &quot;return redis.call(&#x27;pttl&#x27;, KEYS[1]);&quot;\n\n锁重试与WatchDog实践优化keykey命名规范\n建议遵循：[业务名称]:[数据名]:[id]的层级结构\nkey的长度不建议超过44字节  redis对字符串的编码方式有int，embstr，raw三种，key是纯数字时选择int编码，当key的长度超过44字节时会使用raw编码，小于44字节时会使用embstr 编码。\n避免包含特殊字符\n\nBigkeyBigkey：占用空间较大的key:value\n查看key占用空间：\nMEMORY USAGE keyName\t#对CPU的消耗较大，不建议使用\n查看字符串长度：\nSTRLEN keyName\t#推荐使用\n查看key中元素数量：\nLLEN keyName\t#查看列表中元素数量，推荐使用\n黑马推荐值：\n\n单个key的value小于10KB\n对于集合类型的key，建议元素数量小于1000\n\nBigkey问题：\n\n网络阻塞：对BigKey执行读请求时，少量的QPS就可能导致带宽使用率被占满，导致Redis实例，乃至所在物理机变慢\nRedis阻塞：对元素较多的hash、list、zset等做运算会耗时较旧，使主线程被阻塞\nCPU压力：BigKey的数据序列化和反序列化会导致CPU的使用率飙升，影响Redis实例和本机其它应用\n\n发现Bigkey\n\nredis命令：\nredis-cli -a 密码 --bigkeys\t#需要新开一个cmd窗口，不是在redis客户端里\nscan扫描：利用scan命令，编程扫描key\nSCAN cursor [MATCH pattern] [COUNT count]\n\n参数：    - cursor：游标    - pattern：匹配的模式    - count：指定从数据集里返回多少元素，默认值为 10\nscan 命令调用完后每次会返回2个元素，第一个是下一次迭代的光标，第一次光标会设置为0，当最后一次scan 返回的光标等于0时，表示整个scan遍历结束了，第二个返回的是List，一个匹配的key的数组\neg：\nimport com.heima.jedis.util.JedisConnectionFactory;import org.junit.jupiter.api.AfterEach;import org.junit.jupiter.api.BeforeEach;import org.junit.jupiter.api.Test;import redis.clients.jedis.Jedis;import redis.clients.jedis.ScanResult;import java.util.HashMap;import java.util.List;import java.util.Map;public class JedisTest &#123;    private Jedis jedis;    @BeforeEach    void setUp() &#123;        // 1.建立连接        // jedis = new Jedis(&quot;192.168.150.101&quot;, 6379);        jedis = JedisConnectionFactory.getJedis();        // 2.设置密码        jedis.auth(&quot;123321&quot;);        // 3.选择库        jedis.select(0);    &#125;    final static int STR_MAX_LEN = 10 * 1024;    final static int HASH_MAX_LEN = 500;    @Test    void testScan() &#123;        int maxLen = 0;        long len = 0;        String cursor = &quot;0&quot;;        do &#123;            // 扫描并获取一部分key            ScanResult&lt;String&gt; result = jedis.scan(cursor);            // 记录cursor            cursor = result.getCursor();            List&lt;String&gt; list = result.getResult();            if (list == null || list.isEmpty()) &#123;                break;            &#125;            // 遍历            for (String key : list) &#123;                // 判断key的类型                String type = jedis.type(key);                switch (type) &#123;                    case &quot;string&quot;:                        len = jedis.strlen(key);                        maxLen = STR_MAX_LEN;                        break;                    case &quot;hash&quot;:                        len = jedis.hlen(key);                        maxLen = HASH_MAX_LEN;                        break;                    case &quot;list&quot;:                        len = jedis.llen(key);                        maxLen = HASH_MAX_LEN;                        break;                    case &quot;set&quot;:                        len = jedis.scard(key);                        maxLen = HASH_MAX_LEN;                        break;                    case &quot;zset&quot;:                        len = jedis.zcard(key);                        maxLen = HASH_MAX_LEN;                        break;                    default:                        break;                &#125;                if (len &gt;= maxLen) &#123;                    System.out.printf(&quot;Found big key : %s, type: %s, length or size: %d %n&quot;, key, type, len);                &#125;            &#125;        &#125; while (!cursor.equals(&quot;0&quot;));    &#125;        @AfterEach    void tearDown() &#123;        if (jedis != null) &#123;            jedis.close();        &#125;    &#125;&#125;\n\n\n第三方工具利用第三方工具，如 Redis-Rdb-Tools 分析RDB快照文件，全面分析内存使用情况https://github.com/sripathikrishnan/redis-rdb-tools\n\n网络监控\n\n\n\n自定义工具，监控进出Redis的网络数据，超出预警值时主动告警\n一般阿里云搭建的云服务器就有相关监控页面\n\n删除BigkeyBigKey内存占用较多，即便时删除这样的key也需要耗费很长时间，导致Redis主线程阻塞，引发一系列问题。Redis 4.0以后：提供了异步删除的命令：unlink\n合适的数据类型eg：存储一个User对象，有三种存储方式方式一：json字符串| user:1 | {“name”: “Jack”, “age”: 21} || :—-: | :————————-: |\n优点：实现简单粗暴缺点：数据耦合，不够灵活\n方式二：字段打散\n\n\n\nuser:1:name\nJack\n\n\n\nuser:1:age\n21\n\n\n优点：可以灵活访问对象任意字段缺点：占用空间大、没办法做统一控制\n方式三：hash（推荐）\n\n    \n        user:1\n        name\n        jack\n    \n    \n        age\n        21\n    \n\n\n优点：底层使用ziplist，空间占用小，可以灵活访问对象的任意字段缺点：代码相对复杂\neg：假如有hash类型的key，其中有100万对field和value，field是自增id，这个key存在什么问题？如何优化？\n\n    \n        key\n        field\n        value\n    \n    \n        someKey\n        id:0\n        value0\n    \n    \n        .....\n        .....\n    \n    \n        id:999999\n        value999999\n    \n\n\n存在的问题：hash的entry数量超过512时，会使用哈希表而不是ZipList，内存占用较多\nredis hash类型底层有两种编码方式：ziplist（压缩列表）和hashtable（哈希表）。可以通过修改配置文件来改变ziplist和hashtable的转换条件\n# 配置当field-value超过512时(合起来1024),使用hashtable编码,至于为什么是1024,与ziplist有关,后面会讲述hash-max-ziplist-entries 512  # 配置当key的单个field或value长度超过64时,使用hashtable编码hash-max-ziplist-value 64  \n\n方案一拆分为string类型\n\n    \n        key\n        value\n    \n    \n        id:0\n        value0\n    \n    \n        .....\n        .....\n    \n    \n        id:999999\n        value999999\n    \n\n\n存在的问题：\n\nstring结构底层没有太多内存优化，内存占用较多\n想要批量获取这些数据比较麻烦\n\n方案二拆分为小的hash，将 id / 100 作为key， 将id % 100 作为field，这样每100个元素为一个Hash\n\n    \n        key\n        field\n        value\n    \n    \n        key:0\n        id:00\n        value0\n    \n    \n        .....\n        .....\n    \n    \n        id:99\n        value99\n    \n    \n        key:1\n        id:00\n        value100\n    \n    \n        .....\n        .....\n    \n    \n        id:99\n        value199\n    \n    \n        ....\n    \n    \n        key:9999\n        id:00\n        value999900\n    \n    \n        .....\n        .....\n    \n    \n        id:99\n        value999999\n    \n\n\njava代码：\npackage com.heima.test;import com.heima.jedis.util.JedisConnectionFactory;import org.junit.jupiter.api.AfterEach;import org.junit.jupiter.api.BeforeEach;import org.junit.jupiter.api.Test;import redis.clients.jedis.Jedis;import redis.clients.jedis.Pipeline;import redis.clients.jedis.ScanResult;import java.util.HashMap;import java.util.List;import java.util.Map;public class JedisTest &#123;    private Jedis jedis;    @BeforeEach    void setUp() &#123;        // 1.建立连接        // jedis = new Jedis(&quot;192.168.150.101&quot;, 6379);        jedis = JedisConnectionFactory.getJedis();        // 2.设置密码        jedis.auth(&quot;123321&quot;);        // 3.选择库        jedis.select(0);    &#125;    @Test    void testSetBigKey() &#123;        Map&lt;String, String&gt; map = new HashMap&lt;&gt;();        for (int i = 1; i &lt;= 650; i++) &#123;            map.put(&quot;hello_&quot; + i, &quot;world!&quot;);        &#125;        jedis.hmset(&quot;m2&quot;, map);    &#125;    //使用一个hash进行存储    @Test    void testBigHash() &#123;        Map&lt;String, String&gt; map = new HashMap&lt;&gt;();        for (int i = 1; i &lt;= 100000; i++) &#123;            map.put(&quot;key_&quot; + i, &quot;value_&quot; + i);        &#125;        jedis.hmset(&quot;test:big:hash&quot;, map);    &#125;\t//使用10000个string进行存储    @Test    void testBigString() &#123;        for (int i = 1; i &lt;= 100000; i++) &#123;            jedis.set(&quot;test:str:key_&quot; + i, &quot;value_&quot; + i);        &#125;    &#125;\t//使用100个小hash进行存储    @Test    void testSmallHash() &#123;        int hashSize = 100;        Map&lt;String, String&gt; map = new HashMap&lt;&gt;(hashSize);        for (int i = 1; i &lt;= 100000; i++) &#123;            int k = (i - 1) / hashSize;            int v = i % hashSize;            map.put(&quot;key_&quot; + v, &quot;value_&quot; + v);            if (v == 0) &#123;                jedis.hmset(&quot;test:small:hash_&quot; + k, map);            &#125;        &#125;    &#125;    @AfterEach    void tearDown() &#123;        if (jedis != null) &#123;            jedis.close();        &#125;    &#125;&#125;\n\n批处理批量插入命令Redis提供了很多Mxxx这样的命令，可以实现批量插入数据，例如：\n\nmset\nhmset\n\njava代码：\n@Testvoid testMxx() &#123;    String[] arr = new String[2000];    int j;    long b = System.currentTimeMillis();    for (int i = 1; i &lt;= 100000; i++) &#123;        j = (i % 1000) &lt;&lt; 1;        arr[j] = &quot;test:key_&quot; + i;        arr[j + 1] = &quot;value_&quot; + i;        if (j == 0) &#123;            jedis.mset(arr);        &#125;    &#125;    long e = System.currentTimeMillis();    System.out.println(&quot;time: &quot; + (e - b));&#125;\n\n管道PipelineMSET虽然可以批处理，但是却只能操作部分数据类型，因此如果有对复杂数据类型的批处理需要，建议使用Pipeline\n@Testvoid testPipeline() &#123;    // 创建管道    Pipeline pipeline = jedis.pipelined();    long b = System.currentTimeMillis();    for (int i = 1; i &lt;= 100000; i++) &#123;        // 放入命令到管道        pipeline.set(&quot;test:key_&quot; + i, &quot;value_&quot; + i);        if (i % 1000 == 0) &#123;            // 每放入1000条命令，批量执行            pipeline.sync();        &#125;    &#125;    long e = System.currentTimeMillis();    System.out.println(&quot;time: &quot; + (e - b));&#125;\n\n集群批处理如MSET或Pipeline这样的批处理需要在一次请求中携带多条命令，而此时如果Redis是一个集群，那批处理命令的多个key必须落在一个插槽中，否则就会导致执行失败。大家可以想一想这样的要求其实很难实现，因为我们在批处理时，可能一次要插入很多条数据，这些数据很有可能不会都落在相同的节点上，这就会导致报错了。4种解决方案\n\n第一种方案：串行执行，所以这种方式没有什么意义，当然，执行起来就很简单了，缺点就是耗时过久。\n第二种方案：串行slot，简单来说，就是执行前，客户端先计算一下对应的key的slot，一样slot的key就放到一个组里边，不同的，就放到不同的组里边，然后对每个组执行pipeline的批处理，他就能串行执行各个组的命令，这种做法比第一种方法耗时要少，但是缺点呢，相对来说复杂一点，所以这种方案还需要优化一下\n第三种方案：并行slot，相较于第二种方案，在分组完成后串行执行，第三种方案，就变成了并行执行各个命令，所以他的耗时就非常短，但是实现呢，也更加复杂。\n第四种：hash_tag，redis计算key的slot的时候，其实是根据key的有效部分来计算的，通过这种方式就能一次处理所有的key，这种方式耗时最短，实现也简单，但是如果通过操作key的有效部分，那么就会导致所有的key都落在一个节点上，产生数据倾斜的问题，所以我们推荐使用第三种方式。\n串行化执行代码：\npublic class JedisClusterTest &#123;    private JedisCluster jedisCluster;    @BeforeEach    void setUp() &#123;        // 配置连接池        JedisPoolConfig poolConfig = new JedisPoolConfig();        poolConfig.setMaxTotal(8);        poolConfig.setMaxIdle(8);        poolConfig.setMinIdle(0);        poolConfig.setMaxWaitMillis(1000);        HashSet&lt;HostAndPort&gt; nodes = new HashSet&lt;&gt;();        nodes.add(new HostAndPort(&quot;192.168.150.101&quot;, 7001));        nodes.add(new HostAndPort(&quot;192.168.150.101&quot;, 7002));        nodes.add(new HostAndPort(&quot;192.168.150.101&quot;, 7003));        nodes.add(new HostAndPort(&quot;192.168.150.101&quot;, 8001));        nodes.add(new HostAndPort(&quot;192.168.150.101&quot;, 8002));        nodes.add(new HostAndPort(&quot;192.168.150.101&quot;, 8003));        jedisCluster = new JedisCluster(nodes, poolConfig);    &#125;    @Test    void testMSet() &#123;        jedisCluster.mset(&quot;name&quot;, &quot;Jack&quot;, &quot;age&quot;, &quot;21&quot;, &quot;sex&quot;, &quot;male&quot;);    &#125;    @Test    void testMSet2() &#123;        Map&lt;String, String&gt; map = new HashMap&lt;&gt;(3);        map.put(&quot;name&quot;, &quot;Jack&quot;);        map.put(&quot;age&quot;, &quot;21&quot;);        map.put(&quot;sex&quot;, &quot;Male&quot;);        //对Map数据进行分组。根据相同的slot放在一个分组        //key就是slot，value就是一个组        Map&lt;Integer, List&lt;Map.Entry&lt;String, String&gt;&gt;&gt; result = map.entrySet()                .stream()                .collect(Collectors.groupingBy(                        entry -&gt; ClusterSlotHashUtil.calculateSlot(entry.getKey()))                );        //串行的去执行mset的逻辑        for (List&lt;Map.Entry&lt;String, String&gt;&gt; list : result.values()) &#123;            String[] arr = new String[list.size() * 2];            int j = 0;            for (int i = 0; i &lt; list.size(); i++) &#123;                j = i&lt;&lt;2;                Map.Entry&lt;String, String&gt; e = list.get(0);                arr[j] = e.getKey();                arr[j + 1] = e.getValue();            &#125;            jedisCluster.mset(arr);        &#125;    &#125;    @AfterEach    void tearDown() &#123;        if (jedisCluster != null) &#123;            jedisCluster.close();        &#125;    &#125;&#125;\n\nSpring集群批处理代码：\n@Test void testMSetInCluster() &#123;     Map&lt;String, String&gt; map = new HashMap&lt;&gt;(3);     map.put(&quot;name&quot;, &quot;Rose&quot;);     map.put(&quot;age&quot;, &quot;21&quot;);     map.put(&quot;sex&quot;, &quot;Female&quot;);     stringRedisTemplate.opsForValue().multiSet(map);     List&lt;String&gt; strings = stringRedisTemplate.opsForValue().multiGet(Arrays.asList(&quot;name&quot;, &quot;age&quot;, &quot;sex&quot;));     strings.forEach(System.out::println); &#125;\n\n在RedisAdvancedClusterAsyncCommandsImpl中，首先根据slotHash算出来一个partitioned的map，map中的key就是slot，而他的value就是对应的对应相同slot的key对应的数据通过 RedisFuture&lt;String&gt; mset = super.mset(op)进行异步的消息发送。如下：\n@Overridepublic RedisFuture&lt;String&gt; mset(Map&lt;K, V&gt; map) &#123;    Map&lt;Integer, List&lt;K&gt;&gt; partitioned = SlotHash.partition(codec, map.keySet());    if (partitioned.size() &lt; 2) &#123;        return super.mset(map);    &#125;    Map&lt;Integer, RedisFuture&lt;String&gt;&gt; executions = new HashMap&lt;&gt;();    for (Map.Entry&lt;Integer, List&lt;K&gt;&gt; entry : partitioned.entrySet()) &#123;        Map&lt;K, V&gt; op = new HashMap&lt;&gt;();        entry.getValue().forEach(k -&gt; op.put(k, map.get(k)));        RedisFuture&lt;String&gt; mset = super.mset(op);        executions.put(entry.getKey(), mset);    &#125;    return MultiNodeExecution.firstOfAsync(executions);&#125;\n\n持久化配置Redis的持久化虽然可以保证数据安全，但也会带来很多额外的开销，因此持久化请遵循下列建议：\n\n用来做缓存的Redis实例尽量不要开启持久化功能\n建议关闭RDB持久化功能，使用AOF持久化\n利用脚本定期在slave节点做RDB，实现数据备份\n设置合理的rewrite阈值，避免频繁的bgrewrite\n配置no-appendfsync-on-rewrite = yes，禁止在rewrite期间做aof，避免因AOF引起的阻塞\n部署有关建议：\nRedis实例的物理机要预留足够内存，应对fork和rewrite\n单个Redis实例内存上限不要太大，例如4G或8G。可以加快fork的速度、减少主从同步、数据迁移压力\n不要与CPU密集型应用部署在一起\n不要与高硬盘负载应用一起部署。例如：数据库、消息队列\n\n\n\n慢查询Redis执行时耗时超过某个阈值的命令，称为慢查询。\n慢查询的危害：由于Redis是单线程的，所以当客户端发出指令后，他们都会进入到redis底层的queue来执行，如果此时有一些慢查询的数据，就会导致大量请求阻塞，从而引起报错，所以我们需要解决慢查询问题。\n慢查询的阈值可以通过配置指定：\n\nslowlog-log-slower-than：慢查询阈值，单位是微秒。默认是10000，建议1000\n\n慢查询会被放入慢查询日志中，日志的长度有上限，可以通过配置指定：\n\nslowlog-max-len：慢查询日志（本质是一个队列）的长度。默认是128，建议1000\n\n使用config set修改配置\nconfig set slowlog-log-slower-than 1000\n\n查看慢查询：\n\nslowlog len：查询慢查询日志长度\nslowlog get [n]：读取n条慢查询日志\nslowlog reset：清空慢查询列表\n\n安全配置漏洞出现的核心的原因有以下几点：\n\nRedis未设置密码\n利用了Redis的config set命令动态修改Redis配置\n使用了Root账号权限启动Redis\n\n为了避免这样的漏洞，可以采用如下几种方案：\n\nRedis一定要设置密码\n禁止线上使用下面命令：keys、flushall、flushdb、config set等命令。可以利用rename-command禁用。\nbind：限制网卡，禁止外网网卡访问\n开启防火墙\n不要使用Root账户启动Redis\n尽量不是有默认的端口\n\n内存划分与配置当Redis内存不足时，可能导致Key频繁被删除、响应时间变长、QPS不稳定等问题。当内存使用率达到90%以上时就需要我们警惕，并快速定位到内存占用的原因。\n有关碎片问题分析Redis底层分配并不是这个key有多大，他就会分配多大，而是有他自己的分配策略，比如8,16,20等等，假定当前key只需要10个字节，此时分配8肯定不够，那么他就会分配16个字节，多出来的6个字节就不能被使用，这就是我们常说的 碎片问题\n进程内存问题分析：这片内存，通常我们都可以忽略不计\n缓冲区内存问题分析：一般包括客户端缓冲区、AOF缓冲区、复制缓冲区等。客户端缓冲区又包括输入缓冲区和输出缓冲区两种。这部分内存占用波动较大，所以这片内存也是我们需要重点分析的内存问题。\n\n\n\n内存占用\n说明\n\n\n\n数据内存\n是Redis最主要的部分，存储Redis的键值信息。主要问题是BigKey问题、内存碎片问题\n\n\n进程内存\nRedis主进程本身运⾏肯定需要占⽤内存，如代码、常量池等等；这部分内存⼤约⼏兆，在⼤多数⽣产环境中与Redis数据占⽤的内存相⽐可以忽略。\n\n\n缓冲区内存\n一般包括客户端缓冲区、AOF缓冲区、复制缓冲区等。客户端缓冲区又包括输入缓冲区和输出缓冲区两种。这部分内存占用波动较大，不当使用BigKey，可能导致内存溢出。\n\n\n通过一些命令查看到Redis目前的内存分配状态：\n\ninfo memory：查看内存分配的情况\nmemory xxx：查看key的主要占用情况\n\n内存缓冲区常见的有三种：\n\n复制缓冲区：主从复制的repl_backlog_buf，如果太小可能导致频繁的全量复制，影响性能。通过replbacklog-size来设置，默认1mb\nAOF缓冲区：AOF刷盘之前的缓存区域，AOF执行rewrite的缓冲区。无法设置容量上限\n客户端缓冲区：分为输入缓冲区和输出缓冲区，输入缓冲区最大1G且不能设置。输出缓冲区可以设置\n\n以上复制缓冲区和AOF缓冲区 不会有问题，最关键就是客户端缓冲区的问题\n客户端缓冲区：指的就是我们发送命令时，客户端用来缓存命令的一个缓冲区，也就是我们向redis输入数据的输入端缓冲区和redis向客户端返回数据的响应缓存区，输入缓冲区最大1G且不能设置，所以这一块我们根本不用担心，如果超过了这个空间，redis会直接断开，因为本来此时此刻就代表着redis处理不过来了，我们需要担心的就是输出端缓冲区\n\n我们在使用redis过程中，处理大量的big value，那么会导致我们的输出结果过多，如果输出缓存区过大，会导致redis直接断开，而默认配置的情况下， 其实他是没有大小的，这就比较坑了，内存可能一下子被占满，会直接导致咱们的redis断开，所以解决方案有两个1、设置一个大小2、增加我们带宽的大小，避免我们出现大量数据从而直接超过了redis的承受能力\n集群与主从集群虽然具备高可用特性，能实现自动故障恢复，但是如果使用不当，也会存在一些问题：\n\n集群完整性问题\n\n集群带宽问题\n\n数据倾斜问题\n\n客户端性能问题\n\n命令的集群兼容性问题\n\nlua和事务问题\n\n问题1、在Redis的默认配置中，如果发现任意一个插槽不可用，则整个集群都会停止对外服务：*大家可以设想一下，如果有几个slot不能使用，那么此时整个集群都不能用了，我们在开发中，其实最重要的是可用性，所以需要把如下配置修改成no，即有slot不能使用时，我们的redis集群还是可以对外提供服务\n\n\n问题2、集群带宽问题集群节点之间会不断的互相Ping来确定集群中其它节点的状态。每次Ping携带的信息至少包括：\n\n插槽信息\n集群状态信息\n\n集群中节点越多，集群状态信息数据量也越大，10个节点的相关信息可能达到1kb，此时每次集群互通需要的带宽会非常高，这样会导致集群中大量的带宽都会被ping信息所占用，这是一个非常可怕的问题，所以我们需要去解决这样的问题\n解决途径：\n\n避免大集群，集群节点数不要太多，最好少于1000，如果业务庞大，则建立多个集群。\n避免在单个物理机中运行太多Redis实例\n配置合适的cluster-node-timeout值\n\n问题3、命令的集群兼容性问题有关这个问题咱们已经探讨过了，当我们使用批处理的命令时，redis要求我们的key必须落在相同的slot上，然后大量的key同时操作时，是无法完成的，所以客户端必须要对这样的数据进行处理，这些方案我们之前已经探讨过了，所以不再这个地方赘述了。\n问题4、lua和事务的问题lua和事务都是要保证原子性问题，如果你的key不在一个节点，那么是无法保证lua的执行和事务的特性的，所以在集群模式是没有办法执行lua和事务的\n那我们到底是集群还是主从\n单体Redis（主从Redis）已经能达到万级别的QPS，并且也具备很强的高可用特性。如果主从能满足业务需求的情况下，所以如果不是在万不得已的情况下，尽量不搭建Redis集群\n参考资料\nRedis数据类型及编码格式——Hash篇：https://blog.csdn.net/qq_33983753/article/details/123063712\n\n待办\nredis实战.md——全局ID\nredis实战.md——一人一单：事务\n\n"},{"title":"设计模式","url":"/2022/08/27/she-ji-mo-shi/","content":""},{"title":"JUC学习笔记","url":"/2022/08/11/juc-xue-xi-bi-ji/","content":"基础概念JUC即Java并发编程工具包，java.util.concurren。\n用户线程和守护线程当用户线程不存在时，守护线程也会随之结束，守护线程的生命周期和JVM相同（守护线程似乎顾名思义，守护用户线程，用户线程不存在时守护线程也没有了存在的意义） \n管程即Monitor(监视器)，即平时所说的锁\n\nMonitor其实是一种同步机制,它的义务是保证(在同一时间)只有一个线程可以访问被保护的数据和代码\nJVM中同步时基于进入和退出的监视器对象(Monitor,管程),每个对象实例都有一个Monitor对象。\nMonitor对象和JVM对象一起销毁,底层由C来实现\n\n线程创建\n继承Thread类\n实现Runnable接口\n使用Callable接口\n使用线程池\n\n1. 继承Thread类public class ThreadDemo&#123;    public static void main(String[] args) &#123;        //4.创建Thread类的子类对象        MyThread myThread=new MyThread();        //5.调用start()方法开启线程        //[ 会自动调用run方法这是JVM做的事情,源码看不到 ]        myThread.start();        for (int i = 0; i &lt; 100; i++) &#123;            System.out.println(&quot;我是主线程&quot;+i);        &#125;    &#125;&#125;class MyThread extends Thread&#123;    //2.重写run方法    public void run()&#123;        //3.将要执行的代码写在run方法中       for(int i=0;i&lt;100;i++)&#123;           System.out.println(&quot;我是线程&quot;+i);       &#125;    &#125;&#125;\n\n2. 实现Runnable接口public class RunnableDemo &#123;    public static void main(String[] args) &#123;        //4.创建Runnable的子类对象        MyRunnale mr=new MyRunnale();         //5.将子类对象当做参数传递给Thread的构造函数,并开启线程        //MyRunnale taget=mr; 多态        new Thread(mr).start();        for (int i = 0; i &lt; 1000; i++) &#123;            System.out.println(&quot;我是主线程&quot;+i);        &#125;    &#125;&#125;//1.定义一个类实现Runnableclass MyRunnale implements Runnable&#123;    //2.重写run方法    @Override    public void run() &#123;        //3.将要执行的代码写在run方法中        for (int i = 0; i &lt; 1000; i++) &#123;            System.out.println(&quot;我是线程&quot;+i);        &#125;    &#125;&#125;\n\n3. 使用Callable接口需要借助FutureTask类来实现，类似适配器模式。\n/*创建线程的方式三: 实现callable接口 ---JDK 5.0 新增1.创建一个实现Callable接口的实现类2.实现call方法,将此线程需要执行的操作声明在call()中3.创建callable接口实现类的对象4.将此callable的对象作为参数传入到FutureTask构造器中,创建FutureTask的对象5.将FutureTask对象作为参数传递到Thread类的构造器中,创建Thread对象,并调用star6.获取callable接口中call方法的返回值* */public class ThreadNew &#123;    public static void main(String[] args) &#123;        //3.创建callable接口实现类的对象        NumThead m=new NumThead();        //4.将此callable的对象作为参数传入到FutureTask构造器中,创建FutureTask的对象                FutureTask futureTask = new FutureTask(m);        //5.将FutureTask对象作为参数传递到Thread类的构造器中,创建Thread对象,并调用start()方法        //FutureTask类继承了Runnable接口        //new Runnable = futrueTask;        new Thread(futureTask).start();        //6.获取callable接口中call方法的返回值        try &#123;            //get()方法返回值即为FutureTask构造器参数callable实现类重写的call方法的返回值            Object sum = futureTask.get();            System.out.println(&quot;总和是:&quot;+sum);        &#125; catch (Exception e) &#123;            e.printStackTrace();        &#125;    &#125;&#125;//1.创建一个实现Callable接口的实现类class  NumThead implements Callable&#123;   // class  NumThead implements Callable&lt;Integer&gt;&#123;    //2.实现call方法,将此线程需要执行的操作声明在call()中    @Override    public Object call() throws Exception &#123;    //public Integer call() throws Exception &#123;        int sum=0;        for(int i=1;i&lt;=100;i++)&#123;            System.out.println(i);            sum+=i;        &#125;        return sum;    &#125;&#125;\n\n多线程/有返回值/异步任务FutureTask实现了RunnableFuture接口，进而实现了Future和Runnable接口。\n\n可与Runnable实现无返回值的多线程创建\n与Callable接口一起实现有返回值的多线程创建，达到了多线程/有返回值/异步任务要求。\n\nFutureTaskget()：在Future完成计算前会使当前线程阻塞，知道计算完成isDone()：查询Future是否完成计算\n可以结合使用isDone()和get()，利用轮询的方式来获取Future的计算结果，但是会消耗CPU性能。\nwhile(true)&#123;\tif(futureTask.isDone())&#123;\t\tSystem.out.println(futureTask.get());\t&#125;&#125;\n\n4. 使用线程池编程步骤\n创建资源类，创建属性和操作方法\n创建多个线程，调用资源类的操作方法\n判断，同时防止虚假唤醒\n干活\n通知//创建资源类，定义属性和操作方法class Share &#123;\tprivate int number = 0；\t\t//+1方法\tpublic synchronized void incr()&#123;\t\t//判断，用while而不是if，防止虚假唤醒\t\twhile(number != 0)&#123;\t\t\tthis.wait();\t\t&#125;\t\t//干活\t\tnumber++;\t\tSystem.out.println(Thread.currentThread( ).getName()+&quot; :: &quot;+number);\t\t//通知\t\tthis.notifyAll();\t&#125;\t\t//-1方法\tpublic synchronized void decr()&#123;\t\t//判断，用while而不是if，防止虚假唤醒\t\twhile(number != 1)&#123;\t\t\tthis.wait();\t\t&#125;\t\t//干活\t\tnumber--;\t\tSystem.out.println(Thread.currentThread( ).getName()+&quot; :: &quot;+number);\t\t//通知\t\tthis.notifyAll();\t&#125;&#125;public class ThreadDemo1 &#123;\t//创建多线程，调用资源类的操作方法\tpublic static void main(String[ ] args) &#123;\t\tShare share = new Share();\t\t//创建多线程\t\tnew Thread(()-&gt;&#123;\t\t\tfor(int i = 1; i &lt; 10; i++)&#123;\t\t\t\ttry&#123;\t\t\t\t\tshare.incr();\t//+1\t\t\t\t&#125; catch(InterruptedException e)&#123;\t\t\t\t\te.printStackTrace();\t\t\t\t&#125;\t\t\t&#125;\t\t&#125;, &quot;AA&quot;).start();\t\t\t\tnew Thread(()-&gt;&#123;\t\t\tfor(int i = 1; i &lt; 10; i++)&#123;\t\t\t\ttry&#123;\t\t\t\t\tshare.decr();\t//-1\t\t\t\t&#125; catch(InterruptedException e)&#123;\t\t\t\t\te.printStackTrace();\t\t\t\t&#125;\t\t\t&#125;\t\t&#125;, &quot;BB&quot;).start();\t\t\t\tnew Thread(()-&gt;&#123;\t\t\tfor(int i = 1; i &lt; 10; i++)&#123;\t\t\t\ttry&#123;\t\t\t\t\tshare.incr();\t//+1\t\t\t\t&#125; catch(InterruptedException e)&#123;\t\t\t\t\te.printStackTrace();\t\t\t\t&#125;\t\t\t&#125;\t\t&#125;, &quot;CC&quot;).start();\t\t\t\tnew Thread(()-&gt;&#123;\t\t\tfor(int i = 1; i &lt; 10; i++)&#123;\t\t\t\ttry&#123;\t\t\t\t\tshare.decr();\t//-1\t\t\t\t&#125; catch(InterruptedException e)&#123;\t\t\t\t\te.printStackTrace();\t\t\t\t&#125;\t\t\t&#125;\t\t&#125;, &quot;DD&quot;).start();\t&#125;&#125;\n\n\n\n虚假唤醒由于wait()在哪里睡着就在哪里起来的特性，会出现在直接在if条件体中唤醒，继续向下执行，从而跳过条件判断。使用while循环解决虚假唤醒问题，即使在循环体中唤醒也要走一遍while循环条件的判断。\nsynchronized可被上锁的内容：\n\n代码块：被修饰的代码块称为同步语句块，其作用的范围是大括号{}括起来的代码，作用的对象是调用这个代码块的对象\n方法：被修饰的方法称为同步方法，其作用的范围是整个方法，作用的对象是调用这个方法的对象\n静态方法：作用的范围是整个静态方法，作用的对象是这个类的所有对象\n作用的范围是synchronized后面括号括起来的部分，作用主的对象是这个类的所有对象\n\nsynchronized是不能被子类继承的，子类方法要使用synchronized需显式声明。虽然synchronized不能被继承，但是子类调用父类的synchronized方法时，方法是同步的。\n单例多线程下的单例实现传统单例（懒汉式）\npublic class Singleton &#123;    private static Singleton instance;    private Singleton ()&#123;&#125;    public static Singleton getInstance() &#123;     if (instance == null) &#123;         instance = new Singleton();     &#125;     return instance;    &#125;&#125;\n问题：并发情况下，多个线程调用getInstance()，会创建多个对象，单例失效。解决方案：使用synchronized修饰getInstance()方法\npublic class Singleton &#123;    private static Singleton instance;    private Singleton ()&#123;&#125;    public static synchronized Singleton getInstance() &#123;//封死了        if (instance == null) &#123;            instance = new Singleton();        &#125;        return instance;    &#125;&#125;\n以上代码实际也有缺点：虽然做到了线程安全，并且解决了多实例的问题，但是它并不高效。因为在任何时候只能有一个线程调用getInstance()方法，其余线程都在空转等待。解决方案：因为同步操作只需要在第一次调用时才被需要，即第一次创建单例实例对象时。因此在进入同步代码块之前一次非null检查，在单例对象new出后，其余线程便不会进入同步代码块。（保证只有一个线程new出单例，但仍然可能有其他线程等待锁释放后进入同步代码块，但是这个数量要比没有双重检验锁之前少得多，因为有一部分线程被第一次检查拒之门外）双重检验锁\npublic class Singleton &#123;    private volatile static Singleton uniqueInstance;    private Singleton() &#123;    &#125;    public  static Singleton getUniqueInstance() &#123;       //先判断对象是否已经实例过，没有实例化过才进入加锁代码        if (uniqueInstance == null) &#123;//Single Checked            //类对象加锁            synchronized (Singleton.class) &#123;                if (uniqueInstance == null) &#123;//Double Checked                    uniqueInstance = new Singleton();                &#125;            &#125;        &#125;        return uniqueInstance;    &#125;&#125;\n\n底层机制为什么每个对象可以成为一个锁呢markOop.hpp\n\n\nMonitor(监视器锁)可以理解为一种同步工具，也可理解为一种同步机制，常常被描述为一个Java对象。Java对象是天生的Monitor，每一个Java对象都有成为Monitor的潜质，因为在Java的设计中 ，每一个Java对象自打娘胎里出来就带了一把看不见的锁，它叫做内部锁或者Monitor锁。\nMonitor的本质是依赖于底层操作系统的Mutex Lock实现，操作系统实现线程之间的切换需要从用户态到内核态的转换，成本非常高。Mutex Lock Monitor是在jvm底层实现的，底层代码是c++。本质是依赖于底层操作系统的Mutex Lock实现，操作系统实现线程之间的切换需要从用户态到内核态的转换，状态转换需要耗费很多的处理器时间成本非常高。所以synchronized是Java语言中的一个重量级操作。\nMonitor与java对象以及线程是如何关联 ？ \n\n如果一个java对象被某个线程锁住，则该java对象的Mark Word字段中LockWord指向monitor的起始地址 \nMonitor的Owner字段会存放拥有相关联对象锁的线程id\n\nMutex Lock 的切换需要从用户态转换到核心态中，因此状态转换需要耗费很多的处理器时间。\n同步代码块\npublic class SynchronizedDemo &#123;    public void method() &#123;        synchronized (this) &#123;            System.out.println(&quot;synchronized 代码块&quot;);        &#125;    &#125;&#125;\n通过JDK自带的javap命令查看SynchronizedDemo类的相关字节码信息:\n\n首先切换到类的对应目录执行javac SynchronizedDemo.java命令生成编译后的.class文件\n然后执行javap -c -s -v -l SynchronizedDemo.class\n\n可以看出synchronized同步语句块借助monitorenter和monitorexit指令\n\nmonitorenter指令指向同步代码块的开始位置\nmonitorexit指令则指明同步代码块的结束位置\n\n当执行monitorenter指令时，线程试图获取锁也就是获取对象监视器monitor(管程)的持有权。在Java虚拟机(HotSpot)中，Monitor是基于C++实现的，由ObjectMonitor实现的。每个对象中都内置了一个ObjectMonitor对象。另外wait/notify等方法也依赖于monitor对象，这就是为什么只有在同步的块或者方法中才能调用wait/notify等方法，否则会抛出java.lang.llegalMonitorStateException的异常的原因。\n\n在执行monitorenter时，会尝试获取对象的锁，如果锁的计数器为О则表示锁可以被获取，获取后将锁计数器设为1也就是加1。\n在执行monitorexit指令后，将锁计数器设为0，表明锁被释放。如果获取对象锁失败，那当前线程就要阻塞等待，直到锁被另外一个线程释放为止。\n\n同步方法\npublic class SynchronizedDemo2 &#123;    public synchronized void method() &#123;        System.out.println(&quot;synchronized 方法&quot;);    &#125;&#125;\n\n\nsynchronized原理总结\n\nsynchronized同步语句块的实现使用的是monitorenter和monitorexit 指令，其中monitorenter指令指向同步代码块的开始位置，monitorexit 指令则指明同步代码块的结束位置。\nsynchronized修饰的方法并没有monitorenter指令和monitorexit 指令，取得代之的确实是ACC_SYNCHRONIZED标识，该标识指明了该方法是一个同步方法。3．不过两者的本质都是对对象监视器monitor的获取。\n\n\n\n对象内存布局创建一个Java对象\nObject o = new Object();\n\n类型在方法区\no引用在栈区\nnew Object()在堆区\n\nJVM虚拟机（HotSpot）中，对象在堆内存中的存储布局分三个部分：\n\n对象头（Header）\n实例数据（Instance Data）\n对齐填充（Padding）：保证为8字节的倍数\n\n对象头对象头中包含两部分:\n\nMarkWord : Mark Word用于存储对象自身的运行时数据，如HashCode、GC分代年龄、锁状态标志、线程持有的锁、偏向线程ID等等\n类型指针:虚拟机通过这个指针确定该对象是哪个类的实例\n如果是数组对象的话，对象头还有一部分是存储数组的长度\n\n多线程下synchronized 的加锁就是对同一个对象的对象头中的MarkWord中的变量进行CAS操作。\n对象标记Mark Word\n\n\nGC年龄采用4位bit存储,最大为15,例如MaxTenuringThreshold参数默认值就是15，因为GC年龄占4位最大就是1111=15\n类元信息（类型指针）对象指向它的类元数据的指针虚拟机通过这个指针来确定这个对象是哪个类的实例\npublic class CustomerTest &#123;    public static void main(String[] args) &#123;        Customer cust = new Customer();    &#125;&#125;\n\n\n在64位系统中，Mark Word占了8个字节，类型指针占了8个字节，一共是16个字节。上述代码实例中对象o共占16字节大小，即Java中，对象内存最小为16字节（JVM开启压缩编码时，实际为12字节，但是对其填充为16字节）\n内存分析JOL依赖\n&lt;!--JAVA object layout官网:http://openjdk.java.net/projects/code-tools/jol/定位:分析对象在JVM的大小和分布--&gt;&lt;dependency&gt;    &lt;groupId&gt;org.openjdk.jol&lt;/groupId&gt;    &lt;artifactId&gt;jol-core&lt;/artifactId&gt;    &lt;version&gt;0.9&lt;/version&gt;&lt;/dependency&gt;\n使用示例\npublic class JOLDemo&#123;    public static void main(String[] args)&#123;        Object o = new Object();        System.out.println( ClassLayout.parseInstance(o).toPrintable());    &#125;&#125;\n测试结果\n\nPS：\n\n左边的二进制数据采用的是小端序，从左向右为从低位到高位，但是每一字节从左到右为从高位到低位\n类型指针只占4字节，是因为JVM默认开启类型指针压缩\n\n对象有属性值情况\n\n\n\n偏向锁使用synchronized加锁，JVM底层会对锁进行优化，具体可分为三种锁：偏向锁、轻量级锁、重量级锁。其中偏向锁和轻量级锁都不涉及CPU的用户态和内核态的切换（切换是十分消耗性能的）。\n三种锁分别对应三种情况\n\n只有一个线程来访问，有且唯一Only One\n有2个线程A、B来交替访问（具体线程不固定，可能A执行完后变成B、C交替执行）\n竞争激烈，多个线程来访问\n\n产生背景多线程的情况下，锁不仅不存在多线程竞争，还存在锁由同一线程多次获得的情况。偏向锁就是在这种情况下出现的，它的出现是为了解决只有在一个线程执行同步时提高性能。当一段同步代码一直被同一个线程多次访问，由于只有一个线程那么该线程在后续访问时便会自动获得锁\n锁标志位：01。（每个对象默认的锁标志位为01，无锁状态下偏向锁位为0，有锁状态下为1）\n\n\n偏向锁流程\n\n锁被第一次占有时，会在Mark Word中记录下线程ID，如果此线程后续再试图获得该锁，JVM会比较对象标记中的线程ID和此线程ID，结果一致直接放行，不用再获取锁，代码执行完也不需释放锁。偏向线程会一直持有锁，只有发生线程竞争时，锁才会释放。\n如果是其他线程试图获取锁，比较发现锁中的线程ID和线程ID不一致，便会产生竞争，进行CAS操作试图获取该锁：\n\n\n获得锁成功：之前的偏向线程可能已经执行完成或者不存在，将新线程的ID写入对象标记Mark Word中，此时锁类型依然为偏向锁，不会升级。（可以理解为白班和夜班的工作交接）\n获得锁失败：之前偏向线程依然在执行，锁获得失败。此时发生了线程竞争，此时锁升级为轻量级锁，保证多线程间进行锁竞争（可以理解为多人面试同一份工作）\n\n总结偏向锁使用一种等到竞争出现才释放锁的机制，只有当其他线程竞争锁时，持有偏向锁的原来线程才会被撤销。 撤销需要等待全局安全点(该时间点上没有字节码正在执行)，同时检查持有偏向锁的线程是否还在执行：\n\n第一个线程正在执行synchronized方法(处于同步块)，它还没有执行完，其它线程来抢夺，该偏向锁会被取消掉并出现锁升级。 此时轻量级锁由原持有偏向锁的线程持有，继续执行其同步代码，而正在竞争的线程会进入自旋等待获得该轻量级锁。 \n第一个线程执行完成synchronized方法(退出同步块)，则将对象头设置成无锁状态并撤销偏向锁，重新偏向 。\n\n优点：由于偏向锁执行同步代码块或方法不需要进行锁的获得和释放，JVM不用和操作系统协商设置Mutex(争取内核)，几乎没有额外开销，性能极高。\n关闭偏向锁关闭偏向锁:使用-XX:-UseBiasedLocking启动参数，偏向锁关闭之后程序默认会直接进入轻量级锁状态\n轻量级锁有线程来参与锁的竞争，但是获取锁的冲突时间极短。本质就是自旋锁\n轻量级锁是为了在线程近乎交替执行同步块时提高性能。 主要目的： 在没有多线程竞争的前提下，通过CAS减少重量级锁使用操作系统互斥量产生的性能消耗，说白了先自旋再阻塞。 升级时机： 当关闭偏向锁功能或多线程竞争偏向锁会导致偏向锁升级为轻量级锁\n锁标志位：00\n轻量锁流程（同偏向锁）偏向锁由线程A持有，线程B进行CAS操作试图获取锁。锁获取失败，则偏向锁升级为轻量级锁，此时轻量级锁由原持有偏向锁的线程持有，继续执行其同步代码，而正在竞争的线程B会进入自旋等待获得该轻量级锁。\n自旋次数java6之前，默认启用，默认情况下自旋的次数是10次-XX:PreBlockSpin=10来修改，或者自旋线程数超过cpu核数一半Java6之后自适应，自适应意味着自旋的次数不是固定不变的，而是根据：同一个锁上一次自旋的时间，拥有锁线程的状态来决定。\n轻量锁与偏向锁的区别争夺轻量级锁失败时，自旋尝试抢占锁。轻量级锁每次退出同步块都需要释放锁，而偏向锁是在竞争发生时才释放锁\n重量级锁有大量的线程参与锁的竞争，冲突性很高\n锁标识位：10\n\n\n三种锁对比\n\nsynchronized锁升级过程总结：一句话，就是先自旋，不行再阻塞。 实际上是把之前的悲观锁(重量级锁)变成在一定条件下使用偏向锁以及使用轻量级(自旋锁CAS)的形式\nsynchronized内部实现还是基于对象头的MarkWord来实现的。 JDK1.6之后拥有了无锁-&gt;偏向锁-&gt;轻量级锁-&gt;重量级锁的升级过程，而不是无论什么情况都使用重量级锁。\n\n偏向锁:适用于单线程适用的情况，在不存在锁竞争的时候进入同步方法/代码块则使用偏向锁。 \n轻量级锁：适用于竞争较不激烈的情况(这和乐观锁的使用范围类似)， 存在竞争时升级为轻量级锁，轻量级锁采用的是自旋锁，如果同步方法/代码块执行时间很短的话，采用轻量级锁虽然会占用cpu资源但是相对比使用重量级锁还是更高效。\n重量级锁：适用于竞争激烈的情况，如果同步方法/代码块执行时间很长，那么使用轻量级锁自旋带来的性能消耗就比使用重量级锁更严重，这时候就需要升级为重量级锁。\n\nJIT锁优化JIT：Just In Time Compiler，即时编译器\n\n锁消除\n/** * 锁消除 * 从JIT角度看相当于无视它，synchronized (o)不存在了,这个锁对象并没有被共用扩散到其它线程使用， * 极端的说就是根本没有加这个锁对象的底层机器码，消除了锁的使用 */public class LockClearUPDemo&#123;    static Object objectLock = new Object();//正常的    public void m1()    &#123;        //锁消除,JIT会无视它，synchronized(对象锁)不存在了。不正常的        Object o = new Object();        synchronized (o)        &#123;            System.out.println(&quot;-----hello LockClearUPDemo&quot;+&quot;\\t&quot;+o.hashCode()+&quot;\\t&quot;+objectLock.hashCode());        &#125;    &#125;    public static void main(String[] args)    &#123;        LockClearUPDemo demo = new LockClearUPDemo();        for (int i = 1; i &lt;=10; i++) &#123;            new Thread(() -&gt; &#123;                demo.m1();            &#125;,String.valueOf(i)).start();        &#125;    &#125;&#125;\n锁粗化\n/** * 锁粗化 * 假如方法中首尾相接，前后相邻的都是同一个锁对象，那JIT编译器就会把这几个synchronized块合并成一个大块， * 加粗加大范围，一次申请锁使用即可，避免次次的申请和释放锁，提升了性能 */public class LockBigDemo&#123;    static Object objectLock = new Object();    public static void main(String[] args)    &#123;        new Thread(() -&gt; &#123;            synchronized (objectLock) &#123;                System.out.println(&quot;11111&quot;);            &#125;            synchronized (objectLock) &#123;                System.out.println(&quot;22222&quot;);            &#125;            synchronized (objectLock) &#123;                System.out.println(&quot;33333&quot;);            &#125;        &#125;,&quot;a&quot;).start();        new Thread(() -&gt; &#123;            synchronized (objectLock) &#123;                System.out.println(&quot;44444&quot;);            &#125;            synchronized (objectLock) &#123;                System.out.println(&quot;55555&quot;);            &#125;            synchronized (objectLock) &#123;                System.out.println(&quot;66666&quot;);            &#125;        &#125;,&quot;b&quot;).start();    &#125;&#125;\n\nvolatilevolatile内存语义\n\n当写一个volatile变量时，JMM会把该线程对应的本地内存中的共享变量值立即刷新回主内存中。\n当读一个volatile变量时，JMM会把该线程对应的本地内存设置为无效，直接从主内存中读取共享变量\n所以volatile的写内存语义是直接刷新到主内存中，读的内存语义是直接从主内存中读取\n\nJMM内存模型JMM中规定\n\n所有的共享变量都存储于主内存。这里所说的变量指的是实例变量和类变量，不包含局部变量，因为局部变量是线程私有的,因此不存在竞争问题\n每一个线程还存在自己的工作内存，线程的工作内存，保留了被线程使用的变量的工作副本\n线程对变量的所有的操作(读，取)都必须在工作内存中完成，而不能直接读写主内存中的变量\n不同线程之间也不能直接访问对方工作内存中的变量，线程间变量的值的传递需要通过主内存中转来完成\n\n\n\n多线程环境下的问题可能有线程对共享变量的修改没有即时更新到主内存，或者线程没能够即时将共享变量的最新值同步到工作内存中，从而使得线程在使用共享变量的值时，该值并不是最新的。因此出现了变量的不可见性问题。\nvolatile的出现是为了解决变量在线程间的可见性问题\n解决可见性的几种方案方案1：加锁synchronized\n/**  * main 方法作为一个主线程  */  public static void main(String[] args) &#123;      MyThread myThread = new MyThread();      // 开启线程      myThread.start();      // 主线程执行      for (; ; ) &#123;          synchronized (myThread) &#123;              if (myThread.isFlag()) &#123;                  System.out.println(&quot;主线程访问到 flag 变量&quot;);                &#125;          &#125;      &#125;  &#125;/** * 子线程类 */class MyThread extends Thread &#123;    private boolean flag = false;    @Override    public void run() &#123;        try &#123;            Thread.sleep(1000);        &#125; catch (InterruptedException e) &#123;            e.printStackTrace();        &#125;        // 修改变量值        flag = true;        System.out.println(&quot;flag = &quot; + flag);    &#125;    public boolean isFlag() &#123;        return flag;    &#125;    public void setFlag(boolean flag) &#123;        this.flag = flag;    &#125;&#125;\n为什么加锁后就保证了变量的内存可见性了?\n\n因为当一个线程进入synchronizer代码块后，线程获取到锁，会清空本地内存，然后从主内存中拷贝共享变量的最新值到本地内存作为副本2． 将修改后的副本值刷新到主内存中，执行代码，最后线程释放锁\n\n方案2：volatile修饰共享变量\n/** * 变量的内存可见性例子 * * @author star */public class VolatileExample &#123;    /**     * main 方法作为一个主线程     */    public static void main(String[] args) &#123;        MyThread myThread = new MyThread();        // 开启线程        myThread.start();        // 主线程执行        for (; ; ) &#123;            if (myThread.isFlag()) &#123;                System.out.println(&quot;有点东西&quot;);            &#125;        &#125;    &#125;&#125;/** * 子线程类 */class MyThread extends Thread &#123;    private volatile boolean flag = false;    @Override    public void run() &#123;        try &#123;            Thread.sleep(1000);        &#125; catch (InterruptedException e) &#123;            e.printStackTrace();        &#125;        // 修改变量值        flag = true;        System.out.println(&quot;flag = &quot; + flag);    &#125;    public boolean isFlag() &#123;        return flag;    &#125;    public void setFlag(boolean flag) &#123;        this.flag = flag;    &#125;&#125;\nVolatile做了啥?使用volatile修饰共享变量后，每个线程要操作变量时会从主内存中将变量拷贝到本地内存作为副本，当线程操作变量副本并写回主内存后，会通过CPU总线嗅探机制告知其他线程该变量副本已经失效，需要重新从主内存中读取。volatile保证了不同线程对共享变量操作的可见性，也就是说一个线程修改了volatile修饰的变量，当修改后的变量写回主内存时，其他线程能立即看到最新值。\n总线嗅探机制由于CPU与内存之间加入了缓存，在进行数据操作时，先将数据从内存拷贝到缓存中，CPU直接操作的是缓存中的数据。但在多处理器下，将可能导致各自的缓存数据不一致(这也是可见性问题的由来)，为了保证各个处理器的缓存是一致的，就会实现缓存—致性协议，而嗅探是实现缓存一致性的常见机制。注意，缓存的一致性问题，不是多处理器导致，而是多缓存导致的。\n\n\n嗅探机制工作原理每个处理器通过监听在总线上传播的数据来检查自己的缓存值是不是过期了，如果处理器发现自己缓存行对应的内存地址修改，就会将当前处理器的缓存行设置无效状态，当处理器对这个数据进行修改操作的时候，会重新从主内存中把数据读到处理器缓存中。\n总线风暴基于CPU缓存一致性协议，JVM实现了volatile的可见性，但由于总线嗅探机制，会不断的监听总线，如果大量使用volatile会引起总线风暴。所以，volatile的使用要适合具体场景。\n原子性volatile的原子性问题volatile无法保证原子性\n\n在多线程环境下，volatile 关键字可以保证共享数据的可见性，但是并不能保证对数据操作的原子性。即多线程环境下，使用volatile修饰的变量是线程不安全的。要解决这个问题，我们可以使用锁机制，或者使用原子类(如AtomicInteger)\n对任意单个使用volatile修饰的变量的读/写是具有原子性，但类似于flag = !flag这种复合操作不具有原子性。简单地说就是，单纯的赋值操作是原子性的\n\n示例变量i由volatile修饰，i++操作并不是原子操作，分以下三步：\n\n从主内存读\n加操作\n写到主内存\n\n因为i++不是原子操作，多线程下可能有几种情况:\n\ni =1;没有其他线程干扰 i+1=2，结果正确\n其他线程先执行i+1，现在i=2，因为线程的可见性，i+1=3，最后的结果为3，结果正确\n其他线程执行了i+1，i=2，但是此时恰好是i+1已经读取过，生产中间值2，此时赋值后i=2，结果错误因此,volatile并不能保证变量的原子性\n\n代码示例\nclass MyNumber&#123;    volatile int number = 0;    public void addPlusPlus()    &#123;        number++;    &#125;&#125;public class VolatileNoAtomicDemo&#123;    public static void main(String[] args) throws InterruptedException    &#123;        MyNumber myNumber = new MyNumber();        for (int i = 1; i &lt;=10; i++) &#123;            new Thread(() -&gt; &#123;                for (int j = 1; j &lt;= 1000; j++) &#123;                    myNumber.addPlusPlus();                &#125;            &#125;,String.valueOf(i)).start();        &#125;                //暂停几秒钟线程        try &#123; TimeUnit.SECONDS.sleep(3); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125;        System.out.println(Thread.currentThread().getName() + &quot;\\t&quot; + myNumber.number);    &#125;&#125;\n从i++的字节码角度说明\n\n\n原子性指的是一个操作是不可中断的，即使是在多线程环境下，一个操作一旦开始就不会被其他线程影响。\npublic void add()&#123;        i++; //不具备原子性，该操作是先读取值，然后写回一个新值，相当于原来的值加上1，分3步完成&#125;\n如果第二个线程在第一个线程读取旧值和写回新值期间读取i的域值，那么第二个线程就会与第一个线程一起看到同一个值，并执行相同值的加1操作，这也就造成了线程安全失败。因此对于add方法必须使用synchronized修饰，以便保证线程安全\n多线程环境下，”数据计算”和”数据赋值”操作可能多次出现，即操作非原子。若数据在加载之后，若主内存count变量发生修改之后，由于线程工作内存中的值在此前已经加载，从而不会对变更操作做出相应变化，即私有内存和公共内存中变量不同步，进而导致数据不一致\n对于volatile变量，JVM只是保证从主内存加载到线程工作内存的值是最新的，也就是数据加载时是最新的。\n小结\n\n没使用volatile前，多线程间会发生线程A执行i++，而线程B对A的操作结果不知晓，进行了一次重复的操作，i最终只+1\n使用volatile后，解决了之前重复操作的问题，但是仍然有可能别的原因导致i最终只+1。原因是由于i++并非原子操作，可能在两个子操作的间隙之间，如+1操作和写入主内存之间，线程B执行了从主内存中读i，结果线程B读到的值是旧的，最总结果仍只+1\n可见volatile解决的是变量读时的可见性问题，但无法保证原子性，对于多线程修改共享变量的场景必须使用加锁同步\n由于volatile变量只能保证可见性，在不符合以下两条规则的运算场景中，仍然要通过加锁(使用synchronized、java.util.concurrent中的锁或原子类）来保证原子性:\n运算结果并不依赖变量的当前值，或者能够确保只有单一的线程修改变量的值\n变量不需要与其他的状态变量共同参与不变约束\n\n\n\n禁止指令重排序指令重排序为了提高性能，编译器和处理器常常会对既定的代码进行指令重排序\n\n\n一般重排序可以分为如下三种:\n\n编译器优化的重排序。编译器在不改变单线程程序语义的前提下，可以重新安排语句的执行顺序\n指令级并行的重排序。现代处理器采用了指令级并行技术来将多条指令重叠执行。如果不存在数据依赖性，处理器可以改变语句对应机器指令的执行顺序\n内存系统的重排序。由于处理器使用缓存和读/写缓冲区，这使得加载和存储操作看上去可能是在乱序执行的\n\nas-if-serial即不管怎么重排序，单线程下的执行结果不能被改变。编译器、runtime和处理器都必须遵守asif-serial语义\nhappens-before并发编程下指令重排序同样也会会带来一些安全隐患：如指令重排序导致的多个线程操作之间的不可见性。从JDK5开始，提出了happens-before的概念，如果一个操作执行的结果需要对另一个操作可见，那么这两个操作之间必须存在happens-before关系。这里提到的两个操作既可以是在一个线程之内，也可以是在不同线程之间\n规则如下\n\n次序规则一个线程内,按照代码顺序,写在前面的操作先行发生于写在后面的操作(强调的是一个线程)前一个操作的结果可以被后续的操作获取。将白点就是前面一个操作把变量X赋值为1,那后面一个操作肯定能知道X已经变成了1\n\n锁定规则一个unlock操作先行发生于后面((这里的”后面”是指时间上的先后))对同一个锁的lock操作(上一个线程unlock了,下一个线程才能获取到锁,进行lock)\n\nvolatile变量规则对一个volatile变量的写操作先行发生于后面对这个变量的读操作,前面的写对后面的读是可见的,这里的”后面”同样是指时间是的先后\n\n传递规则如果操作A先行发生于操作B,而操作B又先行发生于操作C,则可以得出A先行发生于操作C\n\n线程启动规则(Thread Start Rule)Thread对象的start( )方法先行发生于线程的每一个动作\n\n线程中断规则(Thread Interruption Rule)\n\n\n\n对线程interrupt( )方法的调用先发生于被中断线程的代码检测到中断事件的发生\n可以通过Thread.interrupted( )检测到是否发生中断\n\n\n线程终止规则(Thread Termination Rule)(线程中的所有操作都先行发生于对此线程的终止检测)\n\n对象终结规则(Finalizer Rule)对象没有完成初始化之前,是不能调用finalized( )方法的\n\n\n单例双重检验+volatile双重检验锁+volatile\npublic class Singleton &#123;    // volatile 保证可见性和禁止指令重排序    private static volatile Singleton singleton;    public static Singleton getInstance() &#123;        // 第一次检查        if (singleton == null) &#123;          // 同步代码块          synchronized(this.getClass()) &#123;              // 第二次检查              if (singleton == null) &#123;                    // 对象的实例化是一个非原子性操作                    singleton = new Singleton();                &#125;            &#125;        &#125;        return singleton;    &#125;&#125;\n上面代码中,new Singleton()是一个非原子性操作，对象实例化分为三步操作:\n\na：分配内存空间\nb：初始化实例\nc：返回内存地址给引用\n\n\n当两个线程A和B同时进入方法时，加入A抢夺到锁，则A继续执行，当A执行到new操作时，由于new操作不是原子操作，且synchronized也不能禁止重排序\n不禁止重排序的情况下可能是：a-c-b，当线程A执行a-c，即将执行b的时候，由于cpu时间片结束，则有可能会让步给线程B\n线程B进行第一次判断，singleton由于已经有了内存指向，并不为空，此时，对象还没有执行初始化，但已经判断为true，并且返回了\n\n此时，就产生了严重的错误，因此需要 volatile 来禁止重排序。PS：不能将new操作类比i++操作，需要JVM知识支撑。\n为什么volatile能禁止指令重排序呢答案：内存屏障。java编译器会在生成指令系列时在适当的位置会插入内存屏障指令来禁止特定类型的处理器重排序。\n禁止重排序规则表\n\n\n\n当第一个操作为volatile读时不论第二个操作是什么,都不能重排序。这个操作保证了volatile读之后的操作不会被重排到volatile读之前\n当第二个操作为volatile写时,不论第一个操作是什么,都不能重排序。这个操作保证了volatile写之前的操作不会被重排到volatile写之后\n当第一个操作为volatile写时,第二个操作为volatile读时,不能重排(写后读)\n\n4种内存屏障指令\n\n\n\n异步FutureFuture可以理解为未来任务，异步任务。\nFutureTaskDemo\npublic class CompletableFutureDemo&#123;    public static void main(String[] args) throws ExecutionException, InterruptedException, TimeoutException&#123;        FutureTask&lt;String&gt; futureTask = new FutureTask&lt;&gt;(() -&gt; &#123;            System.out.println(&quot;-----come in FutureTask&quot;);            try &#123; TimeUnit.SECONDS.sleep(3); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125;            return ThreadLocalRandom.current().nextInt(100);        &#125;);        Thread t1 = new Thread(futureTask,&quot;t1&quot;);        t1.start();        //3秒钟后才出来结果，还没有计算你提前来拿(只要一调用get方法，对于结果就是不见不散，会导致阻塞)        //System.out.println(Thread.currentThread().getName()+&quot;\\t&quot;+futureTask.get());        //3秒钟后才出来结果，我只想等待1秒钟，过时不候        System.out.println(Thread.currentThread().getName()+&quot;\\t&quot;+futureTask.get(1L,TimeUnit.SECONDS));        System.out.println(Thread.currentThread().getName()+&quot;\\t&quot;+&quot; run... here&quot;);    &#125;&#125;\n\n直接调用get()方法，会造成线程阻塞，直至计算完成\n使用get(1L,TimeUnit.SECONDS)方法，如果在指定时间内线程计算完成，则返回结果，否则过时不候\n\n问题：线程完成计算的时间是不确定的，如何以不阻塞的方式拿到线程结果呢？答案：轮询——while+isDone()\npublic class CompletableFutureDemo2 &#123;    public static void main(String[] args) throws ExecutionException, InterruptedException &#123;        FutureTask&lt;String&gt; futureTask = new FutureTask&lt;&gt;(() -&gt; &#123;            System.out.println(&quot;-----come in FutureTask&quot;);            try &#123; TimeUnit.SECONDS.sleep(3); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125;            return &quot;&quot;+ ThreadLocalRandom.current().nextInt(100);        &#125;);        new Thread(futureTask,&quot;t1&quot;).start();        System.out.println(Thread.currentThread().getName()+&quot;\\t&quot;+&quot;线程完成任务&quot;);        /**         * 用于阻塞式获取结果,如果想要异步获取结果,通常都会以轮询的方式去获取结果         */        while (true)&#123;            if(futureTask.isDone())&#123;                System.out.println(futureTask.get());                break;            &#125;        &#125;    &#125;&#125;\n但是，轮询会耗费CPU资源\nCompletableFutureCompletableFuture是对Future功能的拓展，简化异步编程的复杂性，功能非常强大。\n核心静态方法\n//1.runAsync 无 返回值public static CompletableFuture&lt;Void&gt; runAsync(Runnable runnable)public static CompletableFuture&lt;Void&gt; runAsync(Runnable runnable,Executor executor)  //2.supplyAsync 有 返回值//没有指定Executor的方法，直接使用默认的ForkJoinPool.commonPool() 作为它的线程池执行异步代码。如果指定线程池，则使用我们自定义的或者特别指定的线程池执行异步代码public static &lt;U&gt; CompletableFuture&lt;U&gt; supplyAsync(Supplier&lt;U&gt; supplier)public static &lt;U&gt; CompletableFuture&lt;U&gt; supplyAsync(Supplier&lt;U&gt; supplier,Executor executor)\n\nDemo无返回值（get()和join()区别：get会抛出异常，join不会）\npublic class CompletableFutureDemo3&#123;    public static void main(String[] args) throws ExecutionException, InterruptedException&#123;        CompletableFuture&lt;Void&gt; future = CompletableFuture.runAsync(() -&gt; &#123;            System.out.println(Thread.currentThread().getName()+&quot;\\t&quot;+&quot;-----come in&quot;);            //暂停几秒钟线程            try &#123; TimeUnit.SECONDS.sleep(1); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125;            System.out.println(&quot;-----task is over&quot;);        &#125;);        System.out.println(future.get());    &#125;&#125;\n\n有返回值\npublic class CompletableFutureDemo3&#123;    public static void main(String[] args) throws ExecutionException, InterruptedException&#123;        CompletableFuture&lt;Integer&gt; completableFuture = CompletableFuture.supplyAsync(() -&gt; &#123;            System.out.println(Thread.currentThread().getName() + &quot;\\t&quot; + &quot;-----come in&quot;);            //暂停几秒钟线程            try &#123;                TimeUnit.SECONDS.sleep(1);            &#125; catch (InterruptedException e) &#123;                e.printStackTrace();            &#125;            return ThreadLocalRandom.current().nextInt(100);        &#125;);        System.out.println(completableFuture.get());    &#125;&#125;\n\n回调方法从Java8开始引入了CompletableFuture，是Future的功能增强版，可以传入回调对象，当异步任务完成或者发生异常时，自动调用回调对象的回调方法\npublic class CompletableFutureDemo3&#123;    public static void main(String[] args) throws Exception&#123;        CompletableFuture&lt;Integer&gt; completableFuture = CompletableFuture.supplyAsync(() -&gt; &#123;            System.out.println(Thread.currentThread().getName() + &quot;\\t&quot; + &quot;-----come in&quot;);            int result = ThreadLocalRandom.current().nextInt(10);            //暂停几秒钟线程            try &#123; TimeUnit.SECONDS.sleep(1); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125;            System.out.println(&quot;-----计算结束耗时1秒钟，result： &quot;+result);            if(result &gt; 6)&#123;                int age = 10/0;            &#125;            return result;        &#125;).whenComplete((v,e) -&gt;&#123;            if(e == null)&#123;                System.out.println(&quot;-----result: &quot;+v);            &#125;        &#125;).exceptionally(e -&gt; &#123;            System.out.println(&quot;-----exception: &quot;+e.getCause()+&quot;\\t&quot;+e.getMessage());            return -44;        &#125;);        //主线程不要立刻结束，否则CompletableFuture默认使用的线程池会立刻关闭:暂停3秒钟线程        try &#123; TimeUnit.SECONDS.sleep(3); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125;    &#125;&#125;\n\nwhenComplete：负责运行正常的情况\n\nwhenComplete：当前线程执行任务，等待任务执行完后继续执行whenComplete任务\nwhenCompleteAsync：当前线程任务执行完后将whenCompleteAsync任务交给线程池中其他线程执行（如果是使用同一线程池，也可能会被交由当前线程执行）\n\nexceptionally：负责出现异常的情况\nhandle：whenComplete和exceptionally的结合版。方法执行后的处理，无论成功与失败都可处理\n/** * 方法执行完成后的处理 */      CompletableFuture&lt;Integer&gt; completableFuture2 = CompletableFuture.supplyAsync(() -&gt; &#123;          System.out.println(&quot;当前线程：&quot; + Thread.currentThread().getId());          System.out.println(&quot;CompletableFuture...&quot;);          return 10/1;      &#125;, service).handle((t,u)-&gt;&#123; // R apply(T t, U u);          System.out.println(&quot;handle:&quot;);          if (t != null)&#123;              System.out.println(&quot;存在返回结果:&quot; + t);              return 8;          &#125;          if (u != null)&#123;              System.out.println(&quot;存在日常:&quot; + u);              return 9;          &#125;          return 5;      &#125;);      Integer integer = completableFuture2.get();      System.out.println(integer);\n\n线程串行化即让多线程之间有序执行\nthenRun：不能获取到上一步的执行结果，无返回值thenAccept：能接受上一步结果，无返回值thenApply：能接受上一步结果，有返回值（带后缀Async表示会将任务交给线程池中的其他线程去处理）\nthenApplythenApplyAsync有重载版本，可以指定执行异步任务的线程池，如果不指定，默认使用ForkJoinPool.commonPool()\n@Test    public void test5() throws Exception &#123;        ForkJoinPool pool=new ForkJoinPool();        // 创建异步执行任务:        CompletableFuture&lt;Double&gt; cf = CompletableFuture.supplyAsync(()-&gt;&#123;            System.out.println(Thread.currentThread()+&quot; start job1,time-&gt;&quot;+System.currentTimeMillis());            try &#123;                Thread.sleep(2000);            &#125; catch (InterruptedException e) &#123;            &#125;            System.out.println(Thread.currentThread()+&quot; exit job1,time-&gt;&quot;+System.currentTimeMillis());            return 1.2;        &#125;,pool);        //cf关联的异步任务的返回值作为方法入参，传入到thenApply的方法中        //thenApply这里实际创建了一个新的CompletableFuture实例        CompletableFuture&lt;String&gt; cf2=cf.thenApply((result)-&gt;&#123;            System.out.println(Thread.currentThread()+&quot; start job2,time-&gt;&quot;+System.currentTimeMillis());            try &#123;                Thread.sleep(2000);            &#125; catch (InterruptedException e) &#123;            &#125;            System.out.println(Thread.currentThread()+&quot; exit job2,time-&gt;&quot;+System.currentTimeMillis());            return &quot;test:&quot;+result;        &#125;);        System.out.println(&quot;main thread start cf.get(),time-&gt;&quot;+System.currentTimeMillis());        //等待子任务执行完成        System.out.println(&quot;run result-&gt;&quot;+cf.get());        System.out.println(&quot;main thread start cf2.get(),time-&gt;&quot;+System.currentTimeMillis());        System.out.println(&quot;run result-&gt;&quot;+cf2.get());        System.out.println(&quot;main thread exit,time-&gt;&quot;+System.currentTimeMillis());    &#125;\n\nthenRun、thenAccept\n@Test    public void test6() throws Exception &#123;        ForkJoinPool pool=new ForkJoinPool();        // 创建异步执行任务:        CompletableFuture&lt;Double&gt; cf = CompletableFuture.supplyAsync(()-&gt;&#123;            System.out.println(Thread.currentThread()+&quot; start job1,time-&gt;&quot;+System.currentTimeMillis());            try &#123;                Thread.sleep(2000);            &#125; catch (InterruptedException e) &#123;            &#125;            System.out.println(Thread.currentThread()+&quot; exit job1,time-&gt;&quot;+System.currentTimeMillis());            return 1.2;        &#125;,pool);        //cf关联的异步任务的返回值作为方法入参，传入到thenApply的方法中        CompletableFuture cf2=cf.thenApply((result)-&gt;&#123;            System.out.println(Thread.currentThread()+&quot; start job2,time-&gt;&quot;+System.currentTimeMillis());            try &#123;                Thread.sleep(2000);            &#125; catch (InterruptedException e) &#123;            &#125;            System.out.println(Thread.currentThread()+&quot; exit job2,time-&gt;&quot;+System.currentTimeMillis());            return &quot;test:&quot;+result;        &#125;).thenAccept((result)-&gt; &#123; //接收上一个任务的执行结果作为入参，但是没有返回值            System.out.println(Thread.currentThread()+&quot; start job3,time-&gt;&quot;+System.currentTimeMillis());            try &#123;                Thread.sleep(2000);            &#125; catch (InterruptedException e) &#123;            &#125;            System.out.println(result);            System.out.println(Thread.currentThread()+&quot; exit job3,time-&gt;&quot;+System.currentTimeMillis());        &#125;).thenRun(()-&gt;&#123; //无入参，也没有返回值            System.out.println(Thread.currentThread()+&quot; start job4,time-&gt;&quot;+System.currentTimeMillis());            try &#123;                Thread.sleep(2000);            &#125; catch (InterruptedException e) &#123;            &#125;            System.out.println(&quot;thenRun do something&quot;);            System.out.println(Thread.currentThread()+&quot; exit job4,time-&gt;&quot;+System.currentTimeMillis());        &#125;);        System.out.println(&quot;main thread start cf.get(),time-&gt;&quot;+System.currentTimeMillis());        //等待子任务执行完成        System.out.println(&quot;run result-&gt;&quot;+cf.get());        System.out.println(&quot;main thread start cf2.get(),time-&gt;&quot;+System.currentTimeMillis());        //cf2 等待最后一个thenRun执行完成        System.out.println(&quot;run result-&gt;&quot;+cf2.get());        System.out.println(&quot;main thread exit,time-&gt;&quot;+System.currentTimeMillis());    &#125;\n\n组合处理thenCombine、thenAcceptBoth、runAfterBoth将两个CompletableFuture组合起来，只有这两个都正常执行完了才会执行某个任务。注意两个任务中只要有一个执行异常，则将该异常信息作为指定任务的执行结果。\n\nthenCombine：会将两个任务的执行结果作为方法入参传递到指定方法中，且该方法有返回值\nthenAcceptBoth：同样将两个任务的执行结果作为方法入参，但是无返回值\nrunAfterBoth：没有入参，也没有返回值\n\nDemo\n@Test    public void test7() throws Exception &#123;        ForkJoinPool pool=new ForkJoinPool();        // 创建异步执行任务:        CompletableFuture&lt;Double&gt; cf = CompletableFuture.supplyAsync(()-&gt;&#123;            System.out.println(Thread.currentThread()+&quot; start job1,time-&gt;&quot;+System.currentTimeMillis());            try &#123;                Thread.sleep(2000);            &#125; catch (InterruptedException e) &#123;            &#125;            System.out.println(Thread.currentThread()+&quot; exit job1,time-&gt;&quot;+System.currentTimeMillis());            return 1.2;        &#125;);        CompletableFuture&lt;Double&gt; cf2 = CompletableFuture.supplyAsync(()-&gt;&#123;            System.out.println(Thread.currentThread()+&quot; start job2,time-&gt;&quot;+System.currentTimeMillis());            try &#123;                Thread.sleep(1500);            &#125; catch (InterruptedException e) &#123;            &#125;            System.out.println(Thread.currentThread()+&quot; exit job2,time-&gt;&quot;+System.currentTimeMillis());            return 3.2;        &#125;);        //cf和cf2的异步任务都执行完成后，会将其执行结果作为方法入参传递给cf3,且有返回值        CompletableFuture&lt;Double&gt; cf3=cf.thenCombine(cf2,(a,b)-&gt;&#123;            System.out.println(Thread.currentThread()+&quot; start job3,time-&gt;&quot;+System.currentTimeMillis());            System.out.println(&quot;job3 param a-&gt;&quot;+a+&quot;,b-&gt;&quot;+b);            try &#123;                Thread.sleep(2000);            &#125; catch (InterruptedException e) &#123;            &#125;            System.out.println(Thread.currentThread()+&quot; exit job3,time-&gt;&quot;+System.currentTimeMillis());            return a+b;        &#125;);         //cf和cf2的异步任务都执行完成后，会将其执行结果作为方法入参传递给cf3,无返回值        CompletableFuture cf4=cf.thenAcceptBoth(cf2,(a,b)-&gt;&#123;            System.out.println(Thread.currentThread()+&quot; start job4,time-&gt;&quot;+System.currentTimeMillis());            System.out.println(&quot;job4 param a-&gt;&quot;+a+&quot;,b-&gt;&quot;+b);            try &#123;                Thread.sleep(1500);            &#125; catch (InterruptedException e) &#123;            &#125;            System.out.println(Thread.currentThread()+&quot; exit job4,time-&gt;&quot;+System.currentTimeMillis());        &#125;);         //cf4和cf3都执行完成后，执行cf5，无入参，无返回值        CompletableFuture cf5=cf4.runAfterBoth(cf3,()-&gt;&#123;            System.out.println(Thread.currentThread()+&quot; start job5,time-&gt;&quot;+System.currentTimeMillis());            try &#123;                Thread.sleep(1000);            &#125; catch (InterruptedException e) &#123;            &#125;            System.out.println(&quot;cf5 do something&quot;);            System.out.println(Thread.currentThread()+&quot; exit job5,time-&gt;&quot;+System.currentTimeMillis());        &#125;);         System.out.println(&quot;main thread start cf.get(),time-&gt;&quot;+System.currentTimeMillis());        //等待子任务执行完成        System.out.println(&quot;cf run result-&gt;&quot;+cf.get());        System.out.println(&quot;main thread start cf5.get(),time-&gt;&quot;+System.currentTimeMillis());        System.out.println(&quot;cf5 run result-&gt;&quot;+cf5.get());        System.out.println(&quot;main thread exit,time-&gt;&quot;+System.currentTimeMillis());    &#125;\n\napplyToEither、acceptEither、runAfterEither将两个CompletableFuture组合起来，只要其中一个执行完了就会执行某个任务。注意两个任务中只要有一个执行异常，则将该异常信息作为指定任务的执行结果。\n\napplyToEither：会将已经执行完成的任务的执行结果作为方法入参，并有返回值\nacceptEither：同样将已经执行完成的任务的执行结果作为方法入参，但是没有返回值\nrunAfterEither：没有方法入参，也没有返回值\n\n@Test    public void test8() throws Exception &#123;        // 创建异步执行任务:        CompletableFuture&lt;Double&gt; cf = CompletableFuture.supplyAsync(()-&gt;&#123;            System.out.println(Thread.currentThread()+&quot; start job1,time-&gt;&quot;+System.currentTimeMillis());            try &#123;                Thread.sleep(2000);            &#125; catch (InterruptedException e) &#123;            &#125;            System.out.println(Thread.currentThread()+&quot; exit job1,time-&gt;&quot;+System.currentTimeMillis());            return 1.2;        &#125;);        CompletableFuture&lt;Double&gt; cf2 = CompletableFuture.supplyAsync(()-&gt;&#123;            System.out.println(Thread.currentThread()+&quot; start job2,time-&gt;&quot;+System.currentTimeMillis());            try &#123;                Thread.sleep(1500);            &#125; catch (InterruptedException e) &#123;            &#125;            System.out.println(Thread.currentThread()+&quot; exit job2,time-&gt;&quot;+System.currentTimeMillis());            return 3.2;        &#125;);        //cf和cf2的异步任务都执行完成后，会将其执行结果作为方法入参传递给cf3,且有返回值        CompletableFuture&lt;Double&gt; cf3=cf.applyToEither(cf2,(result)-&gt;&#123;            System.out.println(Thread.currentThread()+&quot; start job3,time-&gt;&quot;+System.currentTimeMillis());            System.out.println(&quot;job3 param result-&gt;&quot;+result);            try &#123;                Thread.sleep(2000);            &#125; catch (InterruptedException e) &#123;            &#125;            System.out.println(Thread.currentThread()+&quot; exit job3,time-&gt;&quot;+System.currentTimeMillis());            return result;        &#125;);         //cf和cf2的异步任务都执行完成后，会将其执行结果作为方法入参传递给cf3,无返回值        CompletableFuture cf4=cf.acceptEither(cf2,(result)-&gt;&#123;            System.out.println(Thread.currentThread()+&quot; start job4,time-&gt;&quot;+System.currentTimeMillis());            System.out.println(&quot;job4 param result-&gt;&quot;+result);            try &#123;                Thread.sleep(1500);            &#125; catch (InterruptedException e) &#123;            &#125;            System.out.println(Thread.currentThread()+&quot; exit job4,time-&gt;&quot;+System.currentTimeMillis());        &#125;);         //cf4和cf3都执行完成后，执行cf5，无入参，无返回值        CompletableFuture cf5=cf4.runAfterEither(cf3,()-&gt;&#123;            System.out.println(Thread.currentThread()+&quot; start job5,time-&gt;&quot;+System.currentTimeMillis());            try &#123;                Thread.sleep(1000);            &#125; catch (InterruptedException e) &#123;            &#125;            System.out.println(&quot;cf5 do something&quot;);            System.out.println(Thread.currentThread()+&quot; exit job5,time-&gt;&quot;+System.currentTimeMillis());        &#125;);         System.out.println(&quot;main thread start cf.get(),time-&gt;&quot;+System.currentTimeMillis());        //等待子任务执行完成        System.out.println(&quot;cf run result-&gt;&quot;+cf.get());        System.out.println(&quot;main thread start cf5.get(),time-&gt;&quot;+System.currentTimeMillis());        System.out.println(&quot;cf5 run result-&gt;&quot;+cf5.get());        System.out.println(&quot;main thread exit,time-&gt;&quot;+System.currentTimeMillis());    &#125;\n\nthenComposethenCompose()：会在某个任务执行完成后，将该任务的执行结果作为方法入参然后执行指定的方法，该方法会返回一个新的CompletableFuture实例，如果该CompletableFuture实例的result不为null，则返回一个基于该result的新的CompletableFuture实例；如果该CompletableFuture实例为null，则然后执行这个新任务。\n@Testpublic void test9() throws Exception &#123;    // 创建异步执行任务:    CompletableFuture&lt;Double&gt; cf = CompletableFuture.supplyAsync(()-&gt;&#123;        System.out.println(Thread.currentThread()+&quot; start job1,time-&gt;&quot;+System.currentTimeMillis());        try &#123;            Thread.sleep(2000);        &#125; catch (InterruptedException e) &#123;        &#125;        System.out.println(Thread.currentThread()+&quot; exit job1,time-&gt;&quot;+System.currentTimeMillis());        return 1.2;    &#125;);    CompletableFuture&lt;String&gt; cf2= cf.thenCompose((param)-&gt;&#123;        System.out.println(Thread.currentThread()+&quot; start job2,time-&gt;&quot;+System.currentTimeMillis());        try &#123;            Thread.sleep(2000);        &#125; catch (InterruptedException e) &#123;        &#125;        System.out.println(Thread.currentThread()+&quot; exit job2,time-&gt;&quot;+System.currentTimeMillis());        return CompletableFuture.supplyAsync(()-&gt;&#123;            System.out.println(Thread.currentThread()+&quot; start job3,time-&gt;&quot;+System.currentTimeMillis());            try &#123;                Thread.sleep(2000);            &#125; catch (InterruptedException e) &#123;            &#125;            System.out.println(Thread.currentThread()+&quot; exit job3,time-&gt;&quot;+System.currentTimeMillis());            return &quot;job3 test&quot;;        &#125;);    &#125;);    System.out.println(&quot;main thread start cf.get(),time-&gt;&quot;+System.currentTimeMillis());    //等待子任务执行完成    System.out.println(&quot;cf run result-&gt;&quot;+cf.get());    System.out.println(&quot;main thread start cf2.get(),time-&gt;&quot;+System.currentTimeMillis());    System.out.println(&quot;cf2 run result-&gt;&quot;+cf2.get());    System.out.println(&quot;main thread exit,time-&gt;&quot;+System.currentTimeMillis());&#125;\n\nallOf、anyOf\n\nallOf返回的CompletableFuture是多个任务都执行完成后才会执行，只有有一个任务执行异常，则返回的CompletableFuture执行get方法时会抛出异常，如果都是正常执行，则get返回null\nanyOf返回的CompletableFuture是多个任务只要其中一个执行完成就会执行，其get返回的是已经执行完成的任务的执行结果，如果该任务执行异常，则抛出异常 @Test    public void test11() throws Exception &#123;        // 创建异步执行任务:        CompletableFuture&lt;Double&gt; cf = CompletableFuture.supplyAsync(()-&gt;&#123;            System.out.println(Thread.currentThread()+&quot; start job1,time-&gt;&quot;+System.currentTimeMillis());            try &#123;                Thread.sleep(2000);            &#125; catch (InterruptedException e) &#123;            &#125;            System.out.println(Thread.currentThread()+&quot; exit job1,time-&gt;&quot;+System.currentTimeMillis());            return 1.2;        &#125;);        CompletableFuture&lt;Double&gt; cf2 = CompletableFuture.supplyAsync(()-&gt;&#123;            System.out.println(Thread.currentThread()+&quot; start job2,time-&gt;&quot;+System.currentTimeMillis());            try &#123;                Thread.sleep(1500);            &#125; catch (InterruptedException e) &#123;            &#125;            System.out.println(Thread.currentThread()+&quot; exit job2,time-&gt;&quot;+System.currentTimeMillis());            return 3.2;        &#125;);        CompletableFuture&lt;Double&gt; cf3 = CompletableFuture.supplyAsync(()-&gt;&#123;            System.out.println(Thread.currentThread()+&quot; start job3,time-&gt;&quot;+System.currentTimeMillis());            try &#123;                Thread.sleep(1300);            &#125; catch (InterruptedException e) &#123;            &#125;//            throw new RuntimeException(&quot;test&quot;);            System.out.println(Thread.currentThread()+&quot; exit job3,time-&gt;&quot;+System.currentTimeMillis());            return 2.2;        &#125;);        //allof等待所有任务执行完成才执行cf4，如果有一个任务异常终止，则cf4.get时会抛出异常，都是正常执行，cf4.get返回null        //anyOf是只有一个任务执行完成，无论是正常执行或者执行异常，都会执行cf4，cf4.get的结果就是已执行完成的任务的执行结果        CompletableFuture cf4=CompletableFuture.allOf(cf,cf2,cf3).whenComplete((a,b)-&gt;&#123;           if(b!=null)&#123;               System.out.println(&quot;error stack trace-&gt;&quot;);               b.printStackTrace();           &#125;else&#123;               System.out.println(&quot;run succ,result-&gt;&quot;+a);           &#125;        &#125;);         System.out.println(&quot;main thread start cf4.get(),time-&gt;&quot;+System.currentTimeMillis());        //等待子任务执行完成        System.out.println(&quot;cf4 run result-&gt;&quot;+cf4.get());        System.out.println(&quot;main thread exit,time-&gt;&quot;+System.currentTimeMillis());    &#125;\n\nCountDownLatchCountDownLatch：允许count个线程阻塞在一个地方，直至这count个线程的任务都执行完毕。\nDemo我们要读取处理6个文件，这6个任务都是没有执行顺序依赖的任务，但是我们需要返回给用户的时候将这几个文件的处理的结果进行统计整理。为此我们定义了一个线程地和count为6的CountDownlatch对象。使用线程池处理读取任务，每一个线程处理完之后就将count-1，调用CountDownLatch对象的await()方法，直到所有文件读取完之后，才会接着执行后面的逻辑。\npublic class CountDownLatchExample1 &#123;    // 处理文件的数量    private static final int threadCount = 6;    public static void main(String[] args) throws InterruptedException &#123;        // 创建一个具有固定线程数量的线程池对象（推荐使用构造方法创建）        ExecutorService threadPool = Executors.newFixedThreadPool(10);        final CountDownLatch countDownLatch = new CountDownLatch(threadCount);        for (int i = 0; i &lt; threadCount; i++) &#123;            final int threadnum = i;            threadPool.execute(() -&gt; &#123;                try &#123;                    //处理文件的业务操作                    //......                &#125; catch (InterruptedException e) &#123;                    e.printStackTrace();                &#125; finally &#123;                    //表示一个文件已经被完成                    countDownLatch.countDown();                &#125;            &#125;);        &#125;        countDownLatch.await();        threadPool.shutdown();        System.out.println(&quot;finish&quot;);    &#125;&#125;\n\n优化一\nCompletableFuture&lt;Void&gt; task1 =    CompletableFuture.supplyAsync(()-&gt;&#123;        //自定义业务操作    &#125;);......CompletableFuture&lt;Void&gt; task6 =    CompletableFuture.supplyAsync(()-&gt;&#123;    //自定义业务操作    &#125;);......CompletableFuture&lt;Void&gt; headerFuture=CompletableFuture.allOf(task1,.....,task6);try &#123;    headerFuture.join();&#125; catch (Exception ex) &#123;    //......&#125;System.out.println(&quot;all done. &quot;);\n\n优化二使用集合添加任务\n//文件夹位置List&lt;String&gt; filePaths = Arrays.asList(...)// 异步处理所有文件List&lt;CompletableFuture&lt;String&gt;&gt; fileFutures = filePaths.stream()    .map(filePath -&gt; doSomeThing(filePath))    .collect(Collectors.toList());// 将他们合并起来CompletableFuture&lt;Void&gt; allFutures = CompletableFuture.allOf(    fileFutures.toArray(new CompletableFuture[fileFutures.size()]));\n\nForkJoinTask分支合并，将一个大任务，进行拆分(fork)成若干个小任务(拆到给出的临界值为止)，再将一个个的小任务运算的结果进行join汇总\n\n\n工作窃取模式工作窃取模式(work-stealing):当执行新的任务时它可以将其拆分成更小的任务执行，并将小任务加到线程队列中，当没有任务执行时，再从一个随机线程的队列中偷一个并把它放在自己的队列中相对于一般的线程池实现，fork/join框架的优势体现在对其中包含的任务的处理方式上，在一般的线程池中，如果一个线程正在执行的任务由于某些原因无法继续运行那么该线程会处于等待状态。而在forkfjoin框架实现中，如果某个子问题由于等待另外一个子问题的完成而无法继续运行。那么处理该子问题的线程会主动寻找其他尚未运行的子问题(窃取过来)来执行，这种方式减少了线程的等待时间，提高了性能\n\n\nForkJoinTask实现类\n\n\n\nRecursiveTask：有返回值的递归任务\n RecursiveAction：无返回值的递归事件\n\nDemo\npackage com.kuang.forkjoin;import java.util.concurrent.RecursiveTask;/** * 求和计算的任务！ * 3000   6000（ForkJoin）  9000（Stream并行流） * // 如何使用 forkjoin * // 1、forkjoinPool 通过它来执行 * // 2、计算任务 forkjoinPool.execute(ForkJoinTask task) * // 3. 计算类要继承 ForkJoinTask */public class ForkJoinDemo extends RecursiveTask&lt;Long&gt; &#123;    private Long start;  // 1    private Long end;    // 1990900000    // 临界值    private Long temp = 10000L;    public ForkJoinDemo(Long start, Long end) &#123;        this.start = start;        this.end = end;    &#125;    // 计算方法    @Override    protected Long compute() &#123;        if ((end-start)&lt;temp)&#123;            Long sum = 0L;            for (Long i = start; i &lt;= end; i++) &#123;                sum += i;            &#125;            return sum;        &#125;else &#123; // forkjoin 递归            long middle = (start + end) / 2; // 中间值            ForkJoinDemo task1 = new ForkJoinDemo(start, middle);            task1.fork(); // 拆分任务，把任务压入线程队列            ForkJoinDemo task2 = new ForkJoinDemo(middle+1, end);            task2.fork(); // 拆分任务，把任务压入线程队列            return task1.join() + task2.join();        &#125;    &#125;&#125;\n\nDemo\npackage com.kuang.forkjoin;import java.util.concurrent.ExecutionException;import java.util.concurrent.ForkJoinPool;import java.util.concurrent.ForkJoinTask;import java.util.stream.DoubleStream;import java.util.stream.IntStream;import java.util.stream.LongStream;/** * 同一个任务，别人效率高你几十倍！ */public class Test &#123;    public static void main(String[] args) throws ExecutionException, InterruptedException &#123;        // test1(); // 12224        // test2(); // 10038        // test3(); // 153    &#125;    // 普通程序员    public static void test1()&#123;        Long sum = 0L;        long start = System.currentTimeMillis();        for (Long i = 1L; i &lt;= 10_0000_0000; i++) &#123;            sum += i;        &#125;        long end = System.currentTimeMillis();        System.out.println(&quot;sum=&quot;+sum+&quot; 时间：&quot;+(end-start));    &#125;    // 会使用ForkJoin    public static void test2() throws ExecutionException, InterruptedException &#123;        long start = System.currentTimeMillis();        ForkJoinPool forkJoinPool = new ForkJoinPool();        ForkJoinTask&lt;Long&gt; task = new ForkJoinDemo(0L, 10_0000_0000L);        ForkJoinTask&lt;Long&gt; submit = forkJoinPool.submit(task);// 提交任务        Long sum = submit.get();        long end = System.currentTimeMillis();        System.out.println(&quot;sum=&quot;+sum+&quot; 时间：&quot;+(end-start));    &#125;    public static void test3()&#123;        long start = System.currentTimeMillis();        // Stream并行流 ()  (]        long sum = LongStream.rangeClosed(0L, 10_0000_0000L).parallel().reduce(0, Long::sum);        long end = System.currentTimeMillis();        System.out.println(&quot;sum=&quot;+&quot;时间：&quot;+(end-start));    &#125;&#125;\n\nLockLock和synchronized区别\n\nLock接口方式需要手动进行锁的获取和释放，是显式锁；使用synchronized时，锁获取和释放是JVM自动完成的，是隐式锁\n使用synchronized在发生异常时，锁会自动被释放，而Lock则不会（通常会在finally块中进行锁的手动释放）\nLock能使等待的线程响应中断，但synchronized不行\nLock可以知道有无成功获取锁，synchronized不行\nLock可以提高多个线程进行读操作的效率，当竞争资源非常激烈时，Lock的性能要优于synchronized\n\nAQS介绍AQS：AbstractQueuedSynchronizer，抽象队列同步器。\n\n\nAQS中的队列是CLH变体的虚拟双向队列FIFO（CLH : Craig.Landin and Hagersten队列，是一个单向链表）\n为什么使用双向队列？抢到资源的线程直接使用处理业务，则抢不到资源的必然涉及一种排队等候机制。抢占资源失败的线程继续去等待，那么就一定会有某种队列形成，这样的队列是什么数据结构呢?如果共享资源被占用，就需要一定的阻塞等待唤醒机制来保证锁分配。这个机制主要用的是CLH队列的变体实现的将暂时获取不到锁的线程加入到队列中，这个队列就是AQS同步队列的抽象表现。它将要请求共享资源的线程及自身的等待状态封装成队列的结点对象(Node),通过CAS、自旋以及LockSupport.park()的方式，维护state变量的状态,使并发达到同步的效果。\n\n\nAQS原理以可重入ReentrantLock举例说明\n进入reentrantLock.lock()方法\nReentrantLock reentrantLock = new ReentrantLock();reentrantLock.lock();\n\n发现调用的是sync.lock()\n\n\nlock方法的真正是由其子类FairSync和NonfairSync实现的，以下是其继承关系\n\n\n非公平锁NonfairSync和公平锁FairSync代码如下，可以发现非公平多了一步if判断\nfinal void lock() &#123;\tif (compareAndSetState(0, 1))\t\tsetExclusiveOwnerThread(Thread.currentThread()); \telse\t\tacquire(1);&#125;\n\n\n\n接下来以非公平锁来进行分析\n首先介绍队列中的节点结构\nstatic final class Node &#123;    /** Marker to indicate a node is waiting in shared mode */    static final Node SHARED = new Node();    /** Marker to indicate a node is waiting in exclusive mode */    static final Node EXCLUSIVE = null;    /** waitStatus value to indicate thread has cancelled */    /** 线程被取消了 */    static final int CANCELLED =  1;    /** waitStatus value to indicate successor&#x27;s thread needs unparking */    /** 后续线程需要唤醒 */    static final int SIGNAL    = -1;    /** waitStatus value to indicate thread is waiting on condition */    /** 等待condition唤醒 */    static final int CONDITION = -2;    /** waitStatus value to indicate the next acquireShared should unconditionally propagate */    /** 共享式同步状态获取将会无条件的传播下去 */    static final int PROPAGATE = -3;    //初始为0，状态就是以上几种    volatile int waitStatus;    volatile Node prev;    volatile Node next;    /** The thread that enqueued this node.  Initialized on construction and nulled out after use. */    volatile Thread thread;    /**     * Link to next node waiting on condition, or the special     * value SHARED.  Because condition queues are accessed only     * when holding in exclusive mode, we just need a simple     * linked queue to hold nodes while they are waiting on     * conditions. They are then transferred to the queue to     * re-acquire. And because conditions can only be exclusive,     * we save a field by using special value to indicate shared     * mode.     */    Node nextWaiter;    /**     * Returns true if node is waiting in shared mode.     */    final boolean isShared() &#123;        return nextWaiter == SHARED;    &#125;    /**     * Returns previous node, or throws NullPointerException if null.     * Use when predecessor cannot be null.  The null check could     * be elided, but is present to help the VM.     *     * @return the predecessor of this node     */    final Node predecessor() throws NullPointerException &#123;        Node p = prev;        if (p == null)            throw new NullPointerException();        else            return p;    &#125;    Node() &#123;    // Used to establish initial head or SHARED marker    &#125;    Node(Thread thread, Node mode) &#123;     // Used by addWaiter        this.nextWaiter = mode;        this.thread = thread;    &#125;    Node(Thread thread, int waitStatus) &#123; // Used by Condition        this.waitStatus = waitStatus;        this.thread = thread;    &#125;&#125;\n\n节点属性说明\n\n\nstate属性：AbstractQueuedSynchronizer#state\n\n0：表示执行窗口空闲，可以占用\n1：表示有线程在占用执行窗口\n\n1：如果是可重入锁，则表示重入次数\n\nprivate volatile int state;\n\nlock()非公平锁lock方法\nfinal void lock() &#123;\tif (compareAndSetState(0, 1))    \tsetExclusiveOwnerThread(Thread.currentThread());\telse    \tacquire(1);&#125;//compareAndSetState(0, 1)：如果state为0，则将state修改为1（即如果执行窗口空闲，则将状态修改为占用），成功返回true，失败返回false//setExclusiveOwnerThread(Thread.currentThread())：将当前线程设置为执行窗口独占线程\n\n情况一：执行窗口空闲，则当前线程直接占用窗口，不用进入到队列中等待进入setExclusiveOwnerThread()方法，在这里可以知晓执行窗口实际上就是AbstractOwnableSynchronizer的exclusiveOwnerThread属性。公平锁FairSync和非公平锁NonfairSync都是其子类，继承了该属性，由于是对象属性，所以每一把锁都有一个执行窗口。\npublic abstract class AbstractOwnableSynchronizer    implements java.io.Serializable &#123;    private static final long serialVersionUID = 3737899427754241961L;    protected AbstractOwnableSynchronizer() &#123; &#125;    private transient Thread exclusiveOwnerThread;    protected final void setExclusiveOwnerThread(Thread thread) &#123;        exclusiveOwnerThread = thread;    &#125;        protected final Thread getExclusiveOwnerThread() &#123;        return exclusiveOwnerThread;    &#125;&#125;\n\n情况二：如果执行窗口被占用，则进入acquire(1)，入队等待\npublic final void acquire(int arg) &#123;\tif (!tryAcquire(arg) &amp;&amp;\t\tacquireQueued(addWaiter(Node.EXCLUSIVE), arg))\t\tselfInterrupt();&#125;\n在if判断中，会执行tryAcquire(arg)再次尝试占用执行窗口，如果不成功则再加入到队列中。\n非公平锁NonfairSync重写了AbstractQueuedSynchronizer的tryAcquire()方法\nprotected final boolean tryAcquire(int acquires) &#123;\treturn nonfairTryAcquire(acquires);&#125;\n\n调用Sync的nonfairTryAcquire(int acquires)方法\nfinal boolean nonfairTryAcquire(int acquires) &#123;    final Thread current = Thread.currentThread();    int c = getState();\t//获得执行窗口状态    if (c == 0) &#123;\t//窗口空闲，尝试占用窗口        if (compareAndSetState(0, acquires)) &#123;            setExclusiveOwnerThread(current);            return true;        &#125;    &#125;    else if (current == getExclusiveOwnerThread()) &#123;\t//窗口被占用，但是占用线程为当前线程        int nextc = c + acquires;\t//可重入锁的重入次数        if (nextc &lt; 0) // overflow            throw new Error(&quot;Maximum lock count exceeded&quot;);        setState(nextc);        return true;    &#125;    return false;\t//窗口被占用，且不是当前线程&#125;\n\n尝试再次占用窗口失败后，执行acquireQueued(addWaiter(Node.EXCLUSIVE), arg)\nprivate Node addWaiter(Node mode) &#123;    Node node = new Node(Thread.currentThread(), mode);    // Try the fast path of enq; backup to full enq on failure    Node pred = tail;    if (pred != null) &#123;\t//队列尾节点不为空，则将当前线程设为尾节点        node.prev = pred;        if (compareAndSetTail(pred, node)) &#123;            pred.next = node;            return node;        &#125;    &#125;    enq(node);    return node;&#125;//初始化队列，并将当前线程插入到队尾（当pred为null时，只会执行一次）private Node enq(final Node node) &#123;    for (;;) &#123;        Node t = tail;        if (t == null) &#123; // Must initialize            if (compareAndSetHead(new Node()))\t//尾节点为空，则初始化队列，new Node(),头节点是一个虚节点（哨兵节点）                tail = head;        &#125; else &#123;\t//尾节点不为空，再次尝试将当前线程设为尾节点（这一步其实在addWaiter中已经出现一次了，出现两次可能类似双重null校验）            node.prev = t;            if (compareAndSetTail(t, node)) &#123;                t.next = node;                return t;            &#125;        &#125;\t&#125;&#125;//作用大概是检阅队列，设置节点状态final boolean acquireQueued(final Node node, int arg) &#123;    boolean failed = true;    try &#123;        boolean interrupted = false;        for (;;) &#123;            final Node p = node.predecessor();\t//获取前节点，final修饰不可变            if (p == head &amp;&amp; tryAcquire(arg)) &#123;\t//前节点是否为头节点，true则尝试当前线程占用窗口（因为头节点为虚节点，此时队列中实际只有当前线程），当占用线程释放锁时，唤醒此线程时才会进入if代码块                setHead(node);\t//当前线程占用窗口后，将其设为头节点（由于节点线程已占用窗口，此头节点也可视为虚节点）                p.next = null; // help GC（帮助GC垃圾回收）                failed = false;                return interrupted;            &#125;            if (shouldParkAfterFailedAcquire(p, node) &amp;&amp;                parkAndCheckInterrupt())                interrupted = true;        &#125;    &#125; finally &#123;        if (failed)\t//true，需要取消节点            cancelAcquire(node);    &#125;&#125;\n\nshouldParkAfterFailedAcquire(p, node)：修改队列中的节点及节点状态parkAndCheckInterrupt()：将当前线程挂起\n//简而言之，Node#waitStatus的值//0：正常同步节点的值//SIGNAL（-1）：表示此节点的后节点已被（或将要）被阻塞（通过`LockSupport.park()`方法），未完待续//CANCELLED（1）：表示此节点被取消//CONDITION（-2）：条件节点，目前不会作为被视作为同步节点，直到状态被改为`0`//PROPAGATE（-3）：传播节点private static boolean shouldParkAfterFailedAcquire(Node pred, Node node) &#123;    int ws = pred.waitStatus;    if (ws == Node.SIGNAL)\t\t//该节点已经设置了状态，要求释放以发出信号，因此它可以安全地停放        return true;    if (ws &gt; 0) &#123;\t\t//前节点被取消，循环向前直至找到未取消的节点        do &#123;            node.prev = pred = pred.prev;        &#125; while (pred.waitStatus &gt; 0);        pred.next = node;    &#125; else &#123;        //waitStatus 必须为 0 或 PROPAGATE        compareAndSetWaitStatus(pred, ws, Node.SIGNAL);    &#125;    return false;&#125;private final boolean parkAndCheckInterrupt() &#123;    LockSupport.park(this);\treturn Thread.interrupted();&#125;\n\n以下以三个线程A、B、C具体举例说明\nA线程尝试获取锁时，直接占用执行窗口\nB线程尝试获取锁：A线程正在执行，窗口被占用。将B线程节点加入队列，队列初始化，头节点（虚节点，ws为0），B线程节点为尾节点。开始第一次进入shouldParkAfterFailedAcquire方法，前节点（即头节点）ws为0，进入else代码块将前节点状态设SIGNAL，返回false，&amp;&amp;右边部分此次不执行由于外部循环，第二次进入方法时，直接返回true，开始执行&amp;&amp;右边部分parkAndCheckInterrupt()，将当前线程B挂起\n线程C尝试获取锁：A线程同样正在执行，窗口被占用将线程C节点加入队列，线程节点C为尾节点，前节点为线程B节点。同线程B，开始第一次进入shouldParkAfterFailedAcquire方法，前节点线程B的ws为0，进入else代码块将前节点状态设SIGNAL，返回false，&amp;&amp;右边部分此次不执行由于外部循环，第二次进入方法时，直接返回true，开始执行&amp;&amp;右边部分parkAndCheckInterrupt()，将当前线程C挂起PS：如果前节点的ws&gt;0则一直向前，直至遇到ws&lt;=0的节点\n可见后一个线程进入队列，将前一个线程节点的ws设为SIGNAL，然后线程挂起\nprivate void cancelAcquire(Node node) &#123;    // Ignore if node doesn&#x27;t exist    if (node == null)        return;    node.thread = null;    // Skip cancelled predecessors    Node pred = node.prev;    while (pred.waitStatus &gt; 0)        node.prev = pred = pred.prev;    // predNext is the apparent node to unsplice. CASes below will    // fail if not, in which case, we lost race vs another cancel    // or signal, so no further action is necessary.    Node predNext = pred.next;    // Can use unconditional write instead of CAS here.    // After this atomic step, other Nodes can skip past us.    // Before, we are free of interference from other threads.    node.waitStatus = Node.CANCELLED;    // If we are the tail, remove ourselves.    if (node == tail &amp;&amp; compareAndSetTail(node, pred)) &#123;        compareAndSetNext(pred, predNext, null);    &#125; else &#123;        // If successor needs signal, try to set pred&#x27;s next-link        // so it will get one. Otherwise wake it up to propagate.        int ws;        if (pred != head &amp;&amp;            ((ws = pred.waitStatus) == Node.SIGNAL ||             (ws &lt;= 0 &amp;&amp; compareAndSetWaitStatus(pred, ws, Node.SIGNAL))) &amp;&amp;            pred.thread != null) &#123;            Node next = node.next;            if (next != null &amp;&amp; next.waitStatus &lt;= 0)                compareAndSetNext(pred, predNext, next);        &#125; else &#123;            unparkSuccessor(node);        &#125;        node.next = node; // help GC    &#125;&#125;\n\nunlock()同样以非公平锁NonfairSync举例\nunlock()\npublic void unlock() &#123;        sync.release(1);    &#125;\n\nrelease()\npublic final boolean release(int arg) &#123;\tif (tryRelease(arg)) &#123;\t\tNode h = head;\t\tif (h != null &amp;&amp; h.waitStatus != 0)\t\t\tunparkSuccessor(h);\t\treturn true;\t&#125;\treturn false;&#125;\n\ntryRelease(arg)\nprotected final boolean tryRelease(int releases) &#123;    int c = getState() - releases;    if (Thread.currentThread() != getExclusiveOwnerThread())        throw new IllegalMonitorStateException();    boolean free = false;    if (c == 0) &#123;        free = true;        setExclusiveOwnerThread(null);    &#125;    setState(c);    return free;&#125;\n\nunparkSuccessor(h)：唤醒挂起的线程。\nprivate void unparkSuccessor(Node node) &#123;    int ws = node.waitStatus;        if (ws &lt; 0)        compareAndSetWaitStatus(node, ws, 0);    Node s = node.next;    if (s == null || s.waitStatus &gt; 0) &#123;        s = null;        for (Node t = tail; t != null &amp;&amp; t != node; t = t.prev)            if (t.waitStatus &lt;= 0)                s = t;    &#125;    if (s != null)        LockSupport.unpark(s.thread);&#125;\n如果头节点的后节点为空或者后节点的ws&gt;0，则从队列的尾节点开始向前唤醒挂起的线程，直至找到当前节点后的第一个ws&lt;=0的线程节点，唤醒此线程。前面介绍lock()部分的parkAndCheckInterrupt()时，线程会在此处挂起。\n线程通信让多线程之间按有序执行。\nCondition\n减法计数、信号量、线程标志\n原子操作类基本原子类\nAtomicInteger：整型原子类\nAtomicBoolean：布尔原子类\nAtomicLong：长整型原子类  \n\n数组原子类使用原子的方式更新数组里的某个元素\n\nAtomicIntegerArray：整形数组原子类\nAtomicLongArray：长整形数组原子类\nAtomicReferenceArray： 引用类型数组原子类\n\n引用原子类\nAtomicReference：引用类型原子类\nAtomicStampedReference：原子更新带有版本号的引用类型。该类将整数值与引用关联起来，可用于解决原子的更新数据和数据的版本号，可以解决使用CAS进行原子更新时可能出现的ABA问题\nAtomicMarkableReference ：原子更新带有标记位的引用类型\n\n对象属性修改原子类\nAtomicIntegerFieldUpdater：原子更新对象中int类型字段的值\nAtomicLongFieldUpdater：原子更新对象中Long类型字段的值\nAtomicReferenceFieldUpdater：原子更新引用类型字段的值\n\n原子操作增强原子类\nLongAdder\nLongAccumulator\nDoubleAdder\nDoubleAccumulator\n\n原子基本类型示例\nAtomicInteger保证i++在多线程情况下的安全\nclass AtomicIntegerTest &#123;    private AtomicInteger atomicInteger = new AtomicInteger();    //使用AtomicInteger之后，不需要对该方法加锁，也可以实现线程安全。    public int getNumber() &#123;        return count.get();    &#125;    public void setNumber() &#123;        atomicInteger.incrementAndGet();    &#125;&#125;\nCountDownLatch保证i++在多线程情况下的安全\npackage com.bilibili.juc.atomics;import java.util.concurrent.CountDownLatch;import java.util.concurrent.TimeUnit;import java.util.concurrent.atomic.AtomicInteger;class MyNumber &#123;    AtomicInteger atomicInteger = new AtomicInteger();    public void addPlusPlus() &#123;        atomicInteger.getAndIncrement();    &#125;&#125;/** * @auther zzyy * @create 2022-02-25 21:59 */public class AtomicIntegerDemo &#123;    public static final int SIZE = 50;    public static void main(String[] args) throws InterruptedException &#123;        MyNumber myNumber = new MyNumber();        CountDownLatch countDownLatch = new CountDownLatch(SIZE);        for (int i = 1; i &lt;= SIZE; i++) &#123;            new Thread(() -&gt; &#123;                try &#123;                    for (int j = 1; j &lt;= 1000; j++) &#123;                        myNumber.addPlusPlus();                    &#125;                &#125; finally &#123;                    countDownLatch.countDown();                &#125;            &#125;, String.valueOf(i)).start();        &#125;                //暂停几秒钟线程，等待上面50个线程全部计算完成后，再去获得最终值                //(2). 使用CountDownLatch去解决等待时间的问题        countDownLatch.await();                //(1). 如果不加上下面的停顿3秒的时间,会导致还没有进行i++ 50000次main线程就已经结束了        //try &#123; TimeUnit.SECONDS.sleep(2); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125;        System.out.println(Thread.currentThread().getName() + &quot;\\t&quot; + &quot;result: &quot; + myNumber.atomicInteger.get());    &#125;&#125;\n\n原子类型引用示例上面的普通原子类仅仅只能保证一个共享变量的原子操作，对于对象的原子操作有两种解决方案:\n\n使用JDK1.5开始就提供的AtomicReference类保证对象之间的原子性，把多个变量放到一个对象里面进行CAS操作\n使用锁。锁内的临界区代码可以保证只有当前线程能操作。\n\nAtomicReference对象封装\npackage com.bilibili.juc.cas;import lombok.AllArgsConstructor;import lombok.Getter;import lombok.ToString;import java.util.concurrent.atomic.AtomicReference;@Getter@ToString@AllArgsConstructorclass User&#123;    String userName;    int    age;&#125;/** * @auther zzyy * @create 2022-02-24 14:50 */public class AtomicReferenceDemo&#123;    public static void main(String[] args)    &#123;        AtomicReference&lt;User&gt; atomicReference = new AtomicReference&lt;&gt;();        User z3 = new User(&quot;z3&quot;,22);        User li4 = new User(&quot;li4&quot;,28);        atomicReference.set(z3);        System.out.println(atomicReference.compareAndSet(z3, li4)+&quot;\\t&quot;+atomicReference.get().toString());        System.out.println(atomicReference.compareAndSet(z3, li4)+&quot;\\t&quot;+atomicReference.get().toString());    &#125;&#125;\n\n利用AtomicReference，手写自旋锁\n/** * 题目：实现一个自旋锁 * 自旋锁好处：循环比较获取没有类似wait的阻塞。 * * 通过CAS操作完成自旋锁，A线程先进来调用myLock方法自己持有锁5秒钟，B随后进来后发现 * 当前有线程持有锁，不是null，所以只能通过自旋等待，直到A释放锁后B随后抢到。 */public class SpinLockDemo&#123;    AtomicReference&lt;Thread&gt; atomicReference = new AtomicReference&lt;&gt;();    public void myLock()    &#123;        Thread thread = Thread.currentThread();        System.out.println(Thread.currentThread().getName()+&quot;\\t come in&quot;);        while(!atomicReference.compareAndSet(null,thread))        &#123;        &#125;    &#125;    public void myUnLock()    &#123;        Thread thread = Thread.currentThread();        atomicReference.compareAndSet(thread,null);        System.out.println(Thread.currentThread().getName()+&quot;\\t myUnLock over&quot;);    &#125;    public static void main(String[] args)    &#123;        SpinLockDemo spinLockDemo = new SpinLockDemo();        new Thread(() -&gt; &#123;            spinLockDemo.myLock();            //暂停一会儿线程            try &#123; TimeUnit.SECONDS.sleep( 5 ); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125;            spinLockDemo.myUnLock();        &#125;,&quot;A&quot;).start();        //暂停一会儿线程，保证A线程先于B线程启动并完成        try &#123; TimeUnit.SECONDS.sleep( 1 ); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125;        new Thread(() -&gt; &#123;            spinLockDemo.myLock();            spinLockDemo.myUnLock();        &#125;,&quot;B&quot;).start();    &#125;&#125;\n\nAtomicStampedReference\nABA问题比如说一个线程1从内存位置V中取出A，这时候另一个线程2也从内存中取出A，并且线程2进行了一些操作将值变成了B，然后线程2又将V位置的数据变成A放回去这时候线程1进行CAS操作发现内存中仍然是A，预期OK，然后线程1操作成功尽管线程1的CAS操作成功，但是不代表这个过程就是没有问题的。\n解决CAS的ABA问题:ABA问题的解决思路是在变量前面追加上版本号时间戳戳记流水，择其一。从JDK 1.5开始，JDK的atomic包里提供了一个类AtomicstampedReference类来解决ABA[问题。\nABADemo\npublic class ABADemo&#123;    static AtomicInteger atomicInteger = new AtomicInteger(100);    static AtomicStampedReference atomicStampedReference = new AtomicStampedReference(100,1);    public static void main(String[] args)    &#123;        abaProblem();        abaResolve();    &#125;    public static void abaResolve()    &#123;        new Thread(() -&gt; &#123;            int stamp = atomicStampedReference.getStamp();            System.out.println(&quot;t3 ----第1次stamp  &quot;+stamp);            try &#123; TimeUnit.SECONDS.sleep(1); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125;            atomicStampedReference.compareAndSet(100,101,stamp,stamp+1);            System.out.println(&quot;t3 ----第2次stamp  &quot;+atomicStampedReference.getStamp());            atomicStampedReference.compareAndSet(101,100,atomicStampedReference.getStamp(),atomicStampedReference.getStamp()+1);            System.out.println(&quot;t3 ----第3次stamp  &quot;+atomicStampedReference.getStamp());        &#125;,&quot;t3&quot;).start();        new Thread(() -&gt; &#123;            int stamp = atomicStampedReference.getStamp();            System.out.println(&quot;t4 ----第1次stamp  &quot;+stamp);            //暂停几秒钟线程            try &#123; TimeUnit.SECONDS.sleep(3); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125;            boolean result = atomicStampedReference.compareAndSet(100, 20210308, stamp, stamp + 1);            System.out.println(Thread.currentThread().getName()+&quot;\\t&quot;+result+&quot;\\t&quot;+atomicStampedReference.getReference());        &#125;,&quot;t4&quot;).start();    &#125;    public static void abaProblem()    &#123;        new Thread(() -&gt; &#123;            atomicInteger.compareAndSet(100,101);            atomicInteger.compareAndSet(101,100);        &#125;,&quot;t1&quot;).start();        try &#123; TimeUnit.MILLISECONDS.sleep(200); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125;        new Thread(() -&gt; &#123;            atomicInteger.compareAndSet(100,20210308);            System.out.println(atomicInteger.get());        &#125;,&quot;t2&quot;).start();    &#125;&#125;\n\n对象属性修改原子类示例\n使用目的:以一种线程安全的方式操作非线程安全对象内的某些字段，是否可以不要锁定整个对象减少锁定的范围只关注长期、敏感性变化的某一个字段而不是整个对象以达到精确加锁+节约内存的目的\n\n使用要求更新的对象属性必须使用public volatile修饰符这种原子类型，是抽象类所以每次使用都必须使用静态方法newUpdater()创建一个更新器,并且需要设置想要更新的类和属性\n\n\nAtomicIntegerFieldUpdater\npackage com.bilibili.juc.atomics;import java.util.concurrent.CountDownLatch;import java.util.concurrent.TimeUnit;import java.util.concurrent.atomic.AtomicIntegerFieldUpdater;class BankAccount//资源类&#123;    String bankName = &quot;CCB&quot;;    //更新的对象属性必须使用 public volatile 修饰符。    public volatile int money = 0;//钱数    public void add()    &#123;        money++;    &#125;    //因为对象的属性修改类型原子类都是抽象类，所以每次使用都必须    // 使用静态方法newUpdater()创建一个更新器，并且需要设置想要更新的类和属性。    AtomicIntegerFieldUpdater&lt;BankAccount&gt; fieldUpdater =            AtomicIntegerFieldUpdater.newUpdater(BankAccount.class,&quot;money&quot;);    //不加synchronized，保证高性能原子性，局部微创小手术    public void transMoney(BankAccount bankAccount)    &#123;        fieldUpdater.getAndIncrement(bankAccount);    &#125;&#125;/** * @auther zzyy * 以一种线程安全的方式操作非线程安全对象的某些字段。 * * 需求： * 10个线程， * 每个线程转账1000， * 不使用synchronized,尝试使用AtomicIntegerFieldUpdater来实现。 */public class AtomicIntegerFieldUpdaterDemo&#123;    public static void main(String[] args) throws InterruptedException    &#123;        BankAccount bankAccount = new BankAccount();        CountDownLatch countDownLatch = new CountDownLatch(10);        for (int i = 1; i &lt;=10; i++) &#123;            new Thread(() -&gt; &#123;                try &#123;                    for (int j = 1; j &lt;=1000; j++) &#123;                        //bankAccount.add();                        bankAccount.transMoney(bankAccount);                    &#125;                &#125; finally &#123;                    countDownLatch.countDown();                &#125;            &#125;,String.valueOf(i)).start();        &#125;        countDownLatch.await();        System.out.println(Thread.currentThread().getName()+&quot;\\t&quot;+&quot;result: &quot;+bankAccount.money);    &#125;&#125;\n\nAtomicReferenceFieldUpdater\npackage com.bilibili.juc.atomics;import java.util.concurrent.TimeUnit;import java.util.concurrent.atomic.AtomicIntegerFieldUpdater;import java.util.concurrent.atomic.AtomicReferenceFieldUpdater;class MyVar //资源类&#123;    public volatile Boolean isInit = Boolean.FALSE;    AtomicReferenceFieldUpdater&lt;MyVar,Boolean&gt; referenceFieldUpdater =            AtomicReferenceFieldUpdater.newUpdater(MyVar.class,Boolean.class,&quot;isInit&quot;);    public void init(MyVar myVar)    &#123;        if (referenceFieldUpdater.compareAndSet(myVar,Boolean.FALSE,Boolean.TRUE))        &#123;            System.out.println(Thread.currentThread().getName()+&quot;\\t&quot;+&quot;----- start init,need 2 seconds&quot;);            //暂停几秒钟线程            try &#123; TimeUnit.SECONDS.sleep(3); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125;            System.out.println(Thread.currentThread().getName()+&quot;\\t&quot;+&quot;----- over init&quot;);        &#125;else&#123;            System.out.println(Thread.currentThread().getName()+&quot;\\t&quot;+&quot;----- 已经有线程在进行初始化工作。。。。。&quot;);        &#125;    &#125;&#125;/** * @auther zzyy * 需求： * 多线程并发调用一个类的初始化方法，如果未被初始化过，将执行初始化工作， * 要求只能被初始化一次，只有一个线程操作成功 */public class AtomicReferenceFieldUpdaterDemo&#123;    public static void main(String[] args)    &#123;        MyVar myVar = new MyVar();        for (int i = 1; i &lt;=5; i++) &#123;            new Thread(() -&gt; &#123;                myVar.init(myVar);            &#125;,String.valueOf(i)).start();        &#125;    &#125;&#125;//打印：D:\\App\\java1.8\\jdk\\bin\\java.exe &quot;-javaagent:D:\\App\\IntelliJ IDEA 2020.3.1\\lib\\idea_rt.jar=57957:D:\\App\\IntelliJ IDEA 2020.3.1\\bin&quot; -Dfile.encoding=GBK -classpath ...... com.bilibili.juc.atomics.AtomicReferenceFieldUpdaterDemo1\t----- start init,need 2 seconds3\t----- 已经有线程在进行初始化工作。。。。。2\t----- 已经有线程在进行初始化工作。。。。。4\t----- 已经有线程在进行初始化工作。。。。。5\t----- 已经有线程在进行初始化工作。。。。。1\t----- over initProcess finished with exit code 0\n\n增强原子类示例为什么引入LongAdder?AtomicLong是利用底层的CAS操作来提供并发性的，逻辑是采用自旋的方式不断更新目标值，直到更新成功，也即乐观锁的实现模式。在并发量比较低的情况下,线程冲突的概率比较小,自旋的次数不会很多。但是,高并发情况下,N个线程同时进行自旋操作,N-1个线程失败,导致CPU打满场景,此时AtomicLong的自旋会成为瓶颈。这就是LongAdder引入的初衷——解决高并发环境下AtomictLong的自旋瓶颈问题\nLongAdder和LongAccumulator区别\n\nLongAdder只能用来计算加法，且从零开始计算\nLongAccumulator提供了自定义的函数操作\n\nLongAccumulator\n//long类型的聚合器，需要传入一个long类型的二元操作，可以用来计算各种聚合操作，包括加乘等import java.util.concurrent.atomic.LongAccumulator;import java.util.concurrent.atomic.LongAdder;import java.util.function.LongBinaryOperator;public class LongAccumulatorDemo&#123;    LongAdder longAdder = new LongAdder();    public void add_LongAdder()    &#123;        longAdder.increment();    &#125;    //LongAccumulator longAccumulator = new LongAccumulator((x, y) -&gt; x + y,0);    LongAccumulator longAccumulator = new LongAccumulator(new LongBinaryOperator()    &#123;        @Override        public long applyAsLong(long left, long right)        &#123;            return left - right;        &#125;    &#125;,777);    public void add_LongAccumulator()    &#123;        longAccumulator.accumulate(1);    &#125;    public static void main(String[] args)    &#123;        LongAccumulatorDemo demo = new LongAccumulatorDemo();        demo.add_LongAccumulator();        demo.add_LongAccumulator();        System.out.println(demo.longAccumulator.longValue());    &#125;&#125;\n\nLongAdder\npublic class LongAdderAPIDemo&#123;    public static void main(String[] args)    &#123;        LongAdder longAdder = new LongAdder();        longAdder.increment();        longAdder.increment();        longAdder.increment();        System.out.println(longAdder.longValue());        LongAccumulator longAccumulator = new LongAccumulator((x,y) -&gt; x * y,2);        longAccumulator.accumulate(1);        longAccumulator.accumulate(2);        longAccumulator.accumulate(3);        System.out.println(longAccumulator.longValue());    &#125;&#125;\n\nLongAdder高性能对比\nclass ClickNumberNet&#123;    int number = 0;    public synchronized void clickBySync()    &#123;        number++;    &#125;    AtomicLong atomicLong = new AtomicLong(0);    public void clickByAtomicLong()    &#123;        atomicLong.incrementAndGet();    &#125;    LongAdder longAdder = new LongAdder();    public void clickByLongAdder()    &#123;        longAdder.increment();    &#125;    LongAccumulator longAccumulator = new LongAccumulator((x,y) -&gt; x + y,0);    public void clickByLongAccumulator()    &#123;        longAccumulator.accumulate(1);    &#125;&#125;/** * @auther zzyy * @create 2020-05-21 22:23 * 50个线程，每个线程100W次，总点赞数出来 */public class LongAdderDemo2&#123;    public static void main(String[] args) throws InterruptedException    &#123;        ClickNumberNet clickNumberNet = new ClickNumberNet();        long startTime;        long endTime;        CountDownLatch countDownLatch = new CountDownLatch(50);        CountDownLatch countDownLatch2 = new CountDownLatch(50);        CountDownLatch countDownLatch3 = new CountDownLatch(50);        CountDownLatch countDownLatch4 = new CountDownLatch(50);        startTime = System.currentTimeMillis();        for (int i = 1; i &lt;=50; i++) &#123;            new Thread(() -&gt; &#123;                try                &#123;                    for (int j = 1; j &lt;=100 * 10000; j++) &#123;                        clickNumberNet.clickBySync();                    &#125;                &#125;finally &#123;                    countDownLatch.countDown();                &#125;            &#125;,String.valueOf(i)).start();        &#125;        countDownLatch.await();        endTime = System.currentTimeMillis();        System.out.println(&quot;----costTime: &quot;+(endTime - startTime) +&quot; 毫秒&quot;+&quot;\\t clickBySync result: &quot;+clickNumberNet.number);        startTime = System.currentTimeMillis();        for (int i = 1; i &lt;=50; i++) &#123;            new Thread(() -&gt; &#123;                try                &#123;                    for (int j = 1; j &lt;=100 * 10000; j++) &#123;                        clickNumberNet.clickByAtomicLong();                    &#125;                &#125;finally &#123;                    countDownLatch2.countDown();                &#125;            &#125;,String.valueOf(i)).start();        &#125;        countDownLatch2.await();        endTime = System.currentTimeMillis();        System.out.println(&quot;----costTime: &quot;+(endTime - startTime) +&quot; 毫秒&quot;+&quot;\\t clickByAtomicLong result: &quot;+clickNumberNet.atomicLong);        startTime = System.currentTimeMillis();        for (int i = 1; i &lt;=50; i++) &#123;            new Thread(() -&gt; &#123;                try                &#123;                    for (int j = 1; j &lt;=100 * 10000; j++) &#123;                        clickNumberNet.clickByLongAdder();                    &#125;                &#125;finally &#123;                    countDownLatch3.countDown();                &#125;            &#125;,String.valueOf(i)).start();        &#125;        countDownLatch3.await();        endTime = System.currentTimeMillis();        System.out.println(&quot;----costTime: &quot;+(endTime - startTime) +&quot; 毫秒&quot;+&quot;\\t clickByLongAdder result: &quot;+clickNumberNet.longAdder.sum());        startTime = System.currentTimeMillis();        for (int i = 1; i &lt;=50; i++) &#123;            new Thread(() -&gt; &#123;                try                &#123;                    for (int j = 1; j &lt;=100 * 10000; j++) &#123;                        clickNumberNet.clickByLongAccumulator();                    &#125;                &#125;finally &#123;                    countDownLatch4.countDown();                &#125;            &#125;,String.valueOf(i)).start();        &#125;        countDownLatch4.await();        endTime = System.currentTimeMillis();        System.out.println(&quot;----costTime: &quot;+(endTime - startTime) +&quot; 毫秒&quot;+&quot;\\t clickByLongAccumulator result: &quot;+clickNumberNet.longAccumulator.longValue());    &#125;&#125;\n\nLongAdder原理分析继承关系\n\n\n继承Striped64类\nStriped64全局变量分析/** Number of CPUS, to place bound on table size 当前计算机CPU数量,Cell数组扩容时会使用到*/static final int NCPU = Runtime.getRuntime().availableProcessors();/** * Table of cells. When non-null, size is a power of 2. */transient volatile Cell[] cells;/** * Base value, used mainly when there is no contention, but also as * a fallback during table initialization races. Updated via CAS. 类似于AtomicLong中全局的value值。再没有竞争情况下数据直接累加到base上,或者cells扩容时,也需要将数据写入到base上 */transient volatile long base;/** * Spinlock (locked via CAS) used when resizing and/or creating Cells. 初始化cells或者扩容cells需要获取锁,0表示无锁状态,1表示其他线程已经持有了锁 */transient volatile int cellsBusy;\n\nStriped64内部类Cell/** * Padded variant of AtomicLong supporting only raw accesses plus CAS. * * JVM intrinsics note: It would be possible to use a release-only * form of CAS here, if it were provided. */@sun.misc.Contended static final class Cell &#123;    volatile long value;    Cell(long x) &#123; value = x; &#125;    final boolean cas(long cmp, long val) &#123;        return UNSAFE.compareAndSwapLong(this, valueOffset, cmp, val);    &#125;    // Unsafe mechanics    private static final sun.misc.Unsafe UNSAFE;    private static final long valueOffset;    static &#123;        try &#123;            UNSAFE = sun.misc.Unsafe.getUnsafe();            Class&lt;?&gt; ak = Cell.class;            valueOffset = UNSAFE.objectFieldOffset                (ak.getDeclaredField(&quot;value&quot;));        &#125; catch (Exception e) &#123;            throw new Error(e);        &#125;    &#125;&#125;\n\n分散热点技术\n\nLongAdder#add\n\n最初无竞争时,直接通过casBase进行更新base的处理，跳过if，当casBase比较激烈，则进入if判断\n调用longAccumulate:如果更新base失败后,首次新建一个Cell[]数组(默认长度是2)\n调用longAccumulate:如果Cell数组当中的某一个槽位为空\n调用longAccumulate:当多个线程竞争同一个cell比较激烈时,可能就要对Cell[]扩容\n\n   LongAdder.javapublic void add(long x) &#123;\t//as是striped64中的cells数组\t//b是striped64中的base\t//v是当前线程hash到的cell中存储的值\t//m是cells的长度减1,hash时作为掩码使用\t//a时当前线程hash到的cell       Cell[] as; long b, v; int m; Cell a;\t/**\t首次首线程(as = cells) != null)一定是false,此时走casBase方法,以CAS的方式更新base值,\t且只有当cas失败时,才会走到if中\t条件1:cells不为空,说明出现过竞争,cell[]已创建\t条件2:cas操作base失败,说明其他线程先一步修改了base正在出现竞争\t*/       if ((as = cells) != null || !casBase(b = base, b + x)) &#123;\t\t//true无竞争 fasle表示竞争激烈,多个线程hash到同一个cell,可能要扩容           boolean uncontended = true;\t\t/*\t\t条件1:cells为空,说明正在出现竞争,上面是从条件2过来的,说明!casBase(b = base, b + x))=true\t\t\t  会通过调用longAccumulate(x, null, uncontended)新建一个数组,默认长度是2\t\t条件2:默认会新建一个数组长度为2的数组,m = as.length - 1) &lt; 0 应该不会出现,\t\t条件3:当前线程所在的cell为空,说明当前线程还没有更新过cell,应初始化一个cell。\t\t\t  a = as[getProbe() &amp; m]) == null,如果cell为空,进行一个初始化的处理\t\t条件4:更新当前线程所在的cell失败,说明现在竞争很激烈,多个线程hash到同一个Cell,应扩容\t\t\t  (如果是cell中有一个线程操作,这个时候,通过a.cas(v = a.value, v + x)可以进行处理,返回的结果是true)\t\t**/           if (as == null || (m = as.length - 1) &lt; 0 ||\t\t    //getProbe( )方法返回的时线程中的threadLocalRandomProbe字段\t\t\t//它是通过随机数生成的一个值,对于一个确定的线程这个值是固定的(除非刻意修改它)               (a = as[getProbe() &amp; m]) == null ||               !(uncontended = a.cas(v = a.value, v + x)))\t\t\t//调用Striped64中的方法处理               longAccumulate(x, null, uncontended);       &#125;\n\nStriped64#longAccumulate\nfinal void longAccumulate(long x, LongBinaryOperator fn,\t\t\t\t\t\t  boolean wasUncontended) &#123;\t//存储线程的probe值\tint h;\t//如果getProbe()方法返回0,说明随机数未初始化\tif ((h = getProbe()) == 0) &#123; //这个if相当于给当前线程生成一个非0的hash值\t\t//使用ThreadLocalRandom为当前线程重新计算一个hash值,强制初始化\t\tThreadLocalRandom.current(); // force initialization\t\t//重新获取probe值,hash值被重置就好比一个全新的线程一样,所以设置了wasUncontended竞争状态为true\t\th = getProbe();\t\t//重新计算了当前线程的hash后认为此次不算是一次竞争,都未初始化,肯定还不存在竞争激烈\t\t//wasUncontended竞争状态为true\t\twasUncontended = true;\t&#125;\n\n\nCASE2：刚刚初始化Cell[]数组（首次新建）\n//CASE2:cells没有加锁且没有初始化,则尝试对它进行加锁,并初始化cells数组/*cellsBusy:初始化cells或者扩容cells需要获取锁,0表示无锁状态,1表示其他线程已经持有了锁cells == as == null  是成立的casCellsBusy:通过CAS操作修改cellsBusy的值,CAS成功代表获取锁,返回true,第一次进来没人抢占cell单元格,肯定返回true**/else if (cellsBusy == 0 &amp;&amp; cells == as &amp;&amp; casCellsBusy()) &#123;     //是否初始化的标记\tboolean init = false;\ttry &#123;                           // Initialize table(新建cells)\t\t// 前面else if中进行了判断,这里再次判断,采用双端检索的机制\t\tif (cells == as) &#123;\t\t\t//如果上面条件都执行成功就会执行数组的初始化及赋值操作,Cell[] rs = new Cell[2]标识数组的长度为2\t\t\tCell[] rs = new Cell[2];\t\t\t//rs[h &amp; 1] = new Cell(x)表示创建一个新的cell元素,value是x值,默认为1\t\t\t//h &amp; 1 类似于我们之前hashmap常用到的计算散列桶index的算法,\t\t\t//通常都是hash&amp;(table.len-1),同hashmap一个意思\t\t\t//看这次的value是落在0还是1\t\t\trs[h &amp; 1] = new Cell(x);\t\t\tcells = rs;\t\t\tinit = true;\t\t&#125;\t&#125; finally &#123;\t\tcellsBusy = 0;\t&#125;\tif (init)\t\tbreak;&#125;\n\nCASE3:兜底(多个线程尝试CAS修改失败的线程会走这个分支)\n//CASE3:cells正在进行初始化,则尝试直接在基数base上进行累加操作//这种情况是cell中都CAS失败了,有一个兜底的方法//该分支实现直接操作base基数,将值累加到base上,//也即其他线程正在初始化,多个线程正在更新base的值else if (casBase(v = base, ((fn == null) ? v + x :\t\t\t\t\t\t\tfn.applyAsLong(v, x))))\tbreak;     \n\nCASE1 : Cell数组不再为空且可能存在Cell数组扩容\nfor (;;) &#123;\tCell[] as; Cell a; int n; long v;\tif ((as = cells) != null &amp;&amp; (n = as.length) &gt; 0) &#123; // CASE1:cells已经初始化了\t    // 当前线程的hash值运算后映射得到的Cell单元为null,说明该Cell没有被使用\t\tif ((a = as[(n - 1) &amp; h]) == null) &#123;\t\t\t//Cell[]数组没有正在扩容\t\t\tif (cellsBusy == 0) &#123;       // Try to attach new Cell\t\t\t\t//先创建一个Cell\t\t\t\tCell r = new Cell(x);   // Optimistically create\t\t\t\t//尝试加锁,加锁后cellsBusy=1\t\t\t\tif (cellsBusy == 0 &amp;&amp; casCellsBusy()) &#123; \t\t\t\t\tboolean created = false;\t\t\t\t\ttry &#123;               // Recheck under lock\t\t\t\t\t\tCell[] rs; int m, j; //将cell单元赋值到Cell[]数组上\t\t\t\t\t\t//在有锁的情况下再检测一遍之前的判断 \t\t\t\t\t\tif ((rs = cells) != null &amp;&amp;\t\t\t\t\t\t\t(m = rs.length) &gt; 0 &amp;&amp;\t\t\t\t\t\t\trs[j = (m - 1) &amp; h] == null) &#123;\t\t\t\t\t\t\trs[j] = r;\t\t\t\t\t\t\tcreated = true;\t\t\t\t\t\t&#125;\t\t\t\t\t&#125; finally &#123;\t\t\t\t\t\tcellsBusy = 0;//释放锁\t\t\t\t\t&#125;\t\t\t\t\tif (created)\t\t\t\t\t\tbreak;\t\t\t\t\tcontinue;           // Slot is now non-empty\t\t\t\t&#125;\t\t\t&#125;\t\t\tcollide = false;\t\t&#125;\t\t/**\t\twasUncontended表示cells初始化后,当前线程竞争修改失败\t\twasUncontended=false,表示竞争激烈,需要扩容,这里只是重新设置了这个值为true,\t\t紧接着执行advanceProbe(h)重置当前线程的hash,重新循环\t\t*/\t\telse if (!wasUncontended)       // CAS already known to fail\t\t\twasUncontended = true;      // Continue after rehash\t\t//说明当前线程对应的数组中有了数据,也重置过hash值\t\t//这时通过CAS操作尝试对当前数中的value值进行累加x操作,x默认为1,如果CAS成功则直接跳出循环\t\telse if (a.cas(v = a.value, ((fn == null) ? v + x :\t\t\t\t\t\t\t\t\t fn.applyAsLong(v, x))))\t\t\tbreak;\t\t//如果n大于CPU最大数量,不可扩容,并通过下面的h=advanceProbe(h)方法修改线程的probe再重新尝试\t\telse if (n &gt;= NCPU || cells != as)\t\t\tcollide = false;    //扩容标识设置为false,标识永远不会再扩容\t\t//如果扩容意向collide是false则修改它为true,然后重新计算当前线程的hash值继续循环\t\telse if (!collide) \t\t\tcollide = true;\t\t//锁状态为0并且将锁状态修改为1(持有锁) \t\telse if (cellsBusy == 0 &amp;&amp; casCellsBusy()) &#123; \t\t\ttry &#123;\t\t\t\tif (cells == as) &#123;      // Expand table unless stale\t\t\t\t\t//按位左移1位来操作,扩容大小为之前容量的两倍\t\t\t\t\tCell[] rs = new Cell[n &lt;&lt; 1];\t\t\t\t\tfor (int i = 0; i &lt; n; ++i)\t\t\t\t\t\t//扩容后将之前数组的元素拷贝到新数组中\t\t\t\t\t\trs[i] = as[i];\t\t\t\t\tcells = rs; \t\t\t\t&#125;\t\t\t&#125; finally &#123;\t\t\t\t//释放锁设置cellsBusy=0,设置扩容状态,然后进行循环执行\t\t\t\tcellsBusy = 0;\t\t\t&#125;\t\t\tcollide = false;\t\t\tcontinue;                   // Retry with expanded table\t\t&#125;\t\th = advanceProbe(h);\t&#125;\n\nLongAdder#sumLongAdder# sum()会将所有Cell数组中的value和base累加作为返回值，核心的思想就是将之前AtomicLong一个value的更新压力分散到多个value中去,从而降级更新热点\npublic long sum() &#123;    Cell[] as = cells; Cell a;    long sum = base;    if (as != null) &#123;        for (int i = 0; i &lt; as.length; ++i) &#123;            if ((a = as[i]) != null)                sum += a.value;        &#125;    &#125;    return sum;&#125;\n\n为啥高并发下sum的值不精确? sum执行时,并没有限制对base和cells的更新(一句要命的话)。所以LongAdder不是强一致性,它是最终—致性的\n\n首先最终返回的sum局部变量,初始被赋值为base,而最终返回时,很可能base已经被更新了而此时局部变量sum不会更新,造成不—致\n其次这里对cell的读取也无法保证是最后一次写入的值。所以,sum方法只是在没有并发的情况下,可以获得正确的结果\n\n参考资料\nJUC并发编程目录—— https://blog.csdn.net/TZ845195485/article/details/109210095\n\n\n"}]