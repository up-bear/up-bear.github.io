[{"title":"Flutter学习笔记","url":"/2024/01/01/flutter-xue-xi-bi-ji/","content":"\n# 打包APK\n\n## 应用图标\n\n工具包：flutter_launcher_icons\n\nyml配置\n\n```yml\ndev_dependencies:\n  flutter_launcher_icons: \"^0.13.1\"\n\nflutter_launcher_icons:\n  android: \"launcher_icon\"\n  # ios平台开启\n  ios: true\n  # 图标位置\n  image_path: \"assets/icon/icon.png\"\n  min_sdk_android: 21 # android min sdk min:16, default 21\n  web:\n    generate: true\n    image_path: \"path/to/image.png\"\n    background_color: \"#hexcode\"\n    theme_color: \"#hexcode\"\n  windows:\n    generate: true\n    image_path: \"path/to/image.png\"\n    icon_size: 48 # min:48, max:256, default: 48\n  macos:\n    generate: true\n    image_path: \"path/to/image.png\"\n```\n\n运行命令\n\n```sh\nflutter pub get\nflutter pub run flutter_launcher_icons\n```\n\n## build APK\n\n```sh\nflutter build apk --debug\nflutter build apk --release\n# 打包中忽略 IconData的优化问题\nflutter build apk --release --no-tree-shake-icons\n```\n\n"},{"title":"MallChat笔记","url":"/2023/12/31/mallchat-bi-ji/","content":"# 微信登录\n## 扫公众号事件码 + 授权\n用户扫描二维码，关注公共号后，后端会获取到用户的 openid 和 事件码\n如果后端不需要其他用户信息，则可以直接登录。\n需要获取用户头像等信息，则公共号向用户推送授权链接，用户点击授权完成\n\n**缺点**\n获取用户授权的接口2022年7月就关停了，现在只有微信认证才能访问，难度比较大。\n那普通的公众号有没有办法做扫码登录呢？见下面\n\n## 扫公众号获取事件码 + 网站填写事件码\n\n用户扫码关注公共号后，公众号推送一个事件码，用户再网页填写该事件码\n\n**缺点**\n\n事件码容易被暴力撞库，因此要设计复杂，且有时间限制\n\n## 网站展示事件码 + 公众号填写事件码\n\n用户扫码后，在公共号填写事件码，然后公共号向后端推送用户信息\n\n"},{"title":"图书馆","url":"/2023/02/25/tu-shu-guan/","content":"\n# Spring IOC\n1. 博主：SharpCJ's blog。篇名：SpringIOC 二—— 容器 和 Bean的深入理解\n\n# Spring AOP\n1. 博主：SharpCJ's blog。篇名：Spring AOP——Spring 中面向切面编程 。https://www.cnblogs.com/joy99/p/10941543.html"},{"title":"leetcode刷题笔记","url":"/2022/11/04/leetcode-shua-ti-bi-ji/","content":"# 数据结构\n## 优先队列、最大/小堆\n优先队列：\n优先队列是一种概念，而不是一种具体的数据结构。\n\n满足以下条件的数据结构都可以叫优先队列：\n1. 可以快速插入新元素\n2. 可以快速取出所有元素的最值\n\n使用最大堆可以实现最大优先队列，使用最小堆实现最小优先队列\n\n最大堆和最小堆都是完全二叉树！\n\n最大堆：父节点大于所有子孙节点\n最小堆：父节点小于所有子孙节点\n\n![img 001](./leetCode刷题笔记/001.png)\n\n上图所示为一个最小堆。\n\n堆的插入：\n\n![img 002](./leetCode刷题笔记/002.png)\n\n取出最值：根节点即为最值。\n\n删除最值：首先将堆的最后一个节点复制到根节点（最值删除），并删除最后一个节点，然后将根节点不断向下调整，直至满足最大/小堆的定义。\n\n![img 003](./leetCode刷题笔记/003.png)\n\n### 参考链接\n1. https://blog.csdn.net/qq_35500719/article/details/127142965\n2. https://blog.csdn.net/ACM_hades/article/details/89671679\n\n\n## 单调队列\n1. 队列中元素其对应在**原来序列中的顺序必须是单调递增的**\n2. 队列中元素的大小必须是**单调递(增/减/自定义)**\n\n### 适用问题\n1. RMQ\n\n### 参考链接\n1. https://blog.csdn.net/LJD201724114126/article/details/80663855\n2. https://www.cnblogs.com/I-Love-You-520/p/13454305.html\n\n\n## 线段树\n\n# 经典方法\n## DP动态规划\n\n## 未解题目\n1. LCP 64 二叉树灯饰\n2. LCP 34 二叉树染色\n\n# 经典问题\n## RMQ区间最值问题\n**Range Minimum/Maximum Query**\n\nLeetCode 239. 滑动窗口最大值\n给你一个整数数组 nums，有一个大小为 k 的滑动窗口从数组的最左侧移动到数组的最右侧。你只可以看到在滑动窗口内的 k 个数字。滑动窗口每次只向右移动一位。\n\n```\n示例1：\n输入：nums = [1,3,-1,-3,5,3,6,7], k = 3\n\n输出：[3,3,5,5,6,7]\n\n解释：\n滑动窗口的位置                最大值\n---------------               -----\n[1  3  -1] -3  5  3  6  7       3\n 1 [3  -1  -3] 5  3  6  7       3\n 1  3 [-1  -3  5] 3  6  7       5\n 1  3  -1 [-3  5  3] 6  7       5\n 1  3  -1  -3 [5  3  6] 7       6\n 1  3  -1  -3  5 [3  6  7]      7\n \n示例2：\n输入：nums = [1], k = 1\n\n输出：[1]\n```\n\n**优先队列（堆）**\n可以使用优先队列（最大堆）。为了保证滑动窗口的合法性，以二元数组（index，nums[index]）的形式进行入队。二元数组的作用会在代码中用注释标识出来。\n\n```java\nclass Solution {\n    public int[] maxSlidingWindow(int[] nums, int k) {\n        PriorityQueue<int[]> q = new PriorityQueue<>((a,b)->b[1]-a[1]);\n        int n = nums.length, m = n - k + 1, idx = 0;\n        int[] ans = new int[m];\n        for (int i = 0; i < n; i++) {\n            q.add(new int[]{i, nums[i]});\n            if (i >= k - 1) {\n            \t//循环条件中的 i-k 正是当前位置 i 为右端点的窗口左界限，<i-k 说明该值滑出窗口 \n                while (q.peek()[0] <= i - k) q.poll();\n                ans[idx++] = q.peek()[1];\n            }\n        }\n        return ans;\n    }\n}\n```\n\n**单调队列**\n关于 RMQ 的另外一个优秀做法通常是使用「单调队列/单调栈」。\n\n随着窗口的不断平移，该过程会一直发生。若同一时刻存在两个数  和 （）所在一个窗口内，下标更大的数会被更晚移出窗口，此时如果有  的话，可以完全确定  将不会成为后续任何一个窗口的最大值，此时可以将必然不会是答案的  从候选中进行移除。\n\n不难发现，当我们将所有必然不可能作为答案的元素（即所有满足的小于等于  ）移除后，候选集合满足「单调递减」特性，即集合首位元素为当前窗口中的最大值（为了满足窗口长度为  的要求，在从集合头部取答案时需要先将下标小于的等于的  的元素移除）。\n\n为方便从尾部添加元素，从头部获取答案，我们可使用「双端队列」存储所有候选元素。\n\n```java\nclass Solution {\n    public int[] maxSlidingWindow(int[] nums, int k) {\n        Deque<Integer> d = new ArrayDeque<>();\n        int n = nums.length, m = n - k + 1;\n        int[] ans = new int[m];\n        for (int i = 0; i < n; i++) {\n            while (!d.isEmpty() && nums[d.peekLast()] <= nums[i]) d.pollLast();\n            d.addLast(i);\n            if (i >= k - 1) {\n                while (!d.isEmpty() && d.peekFirst() <= i - k) d.pollFirst();\n                ans[i - k + 1] = nums[d.peekFirst()];\n            }\n        }\n        return ans;\n    }\n}\n```\n> 如果 num[i] 比队列末尾小，则 num[i] 仍能入队，因为有可能成为窗口的最大值。\n> 第二个 while 循环，为了保证宽距为 k 窗口的合法性，清除已滑出窗口的元素 \n> ans[i - k + 1] = nums[d.peekFirst()] 清除不合法元素后，队列的首元素即为以当前 i 为窗口右边界的窗口最大值\n> \n\n### 参考链接\n1. https://mp.weixin.qq.com/s?__biz=MzU4NDE3MTEyMA==&mid=2247493262&idx=1&sn=2d8e192a5767b49b9a13a6192ab3b833\n\n再手写的话今天两道题的任务就G了，偷懒一下。。。\n\n# 1668.最大重复子字符串\n给你一个字符串 sequence ，如果字符串 word 连续重复 k 次形成的字符串是 sequence 的一个子字符串，那么单词 word 的 重复值为 k 。单词 word 的 最大重复值 是单词 word 在 sequence 中最大的重复值。如果 word 不是 sequence 的子串，那么重复值 k 为 0 。\n\n## 方法1：简单枚举+动态规划\n巧妙思路：巧妙利用了状态方程：f[i] = f[i-word.length]+1，数组`f`的元素值只与前面间隔`word.length`的元素有关（题目要求是连续重复的子字符串），最后数组`f`中的最大值即为最大重复值。\n```java\nclass Solution {\n    public int maxRepeating(String sequence, String word) {\n        int n = sequence.length(), m = word.length();\n        if (n < m) {\n            return 0;\n        }\n\n        int[] f = new int[n];\n        for (int i = m - 1; i < n; ++i) {\n            boolean valid = true;\n            for (int j = 0; j < m; ++j) {\n                if (sequence.charAt(i - m + j + 1) != word.charAt(j)) {\n                    valid = false;\n                    break;\n                }\n            }\n            if (valid) {\n                f[i] = (i == m - 1 ? 0 : f[i - m]) + 1;\n            }\n        }\n\n        return Arrays.stream(f).max().getAsInt();\n    }\n}\n```\n\n# 剑指Offer || 047.二叉树剪枝\n给定一个二叉树 根节点 root ，树的每个节点的值要么是 0，要么是 1。请剪除该二叉树中所有节点的值为 0 的子树（所属节点值和为0的子树）。\n节点 node 的子树为 node 本身，以及所有 node 的后代。\n\n## 个人思路\n从树的底部向上开始剪枝，采用**后序遍历**的方式遍历二叉树，先判断左右子树为非零子树后，再判断整棵树是否为非零树。\n如果左或右子树为零树，则将其赋值为`null`，完成剪枝动作。\n\n判断子树是否为零树方法：\n```java\npublic int treeSum(TreeNode node){\n    if(node == null)\n        return 0;\n    int v1, v2;\n    v1 = node.left != null ? ((node.left.val + treeSum(node.left)) >= 1 ? 1 : 0) : 0;\n    v2 = node.right != null ? ((node.right.val + treeSum(node.right)) >= 1 ? 1 : 0) : 0;\n    return (node.val + v1 + v2) >=1 ? 1 : 0;\n}\n```\n\n### 代码\n```java\nclass Solution {\n    public TreeNode pruneTree(TreeNode root) {\n        /**\n         * 方法：递归遍历二叉树，遍历方式采用后序遍历\n         * 思路：每一子树综合值为‘1’或者‘0’,如果根节点及两个子树值都为‘0‘，则删除该根节点及其子树\n         */\n\n        int v1, v2;\n        if(root.left != null){\n\n            pruneTree(root.left);\n            v1 = treeSum(root.left);\n        }\n        else\n            v1 = 0;\n\n        if(root.right != null){\n            pruneTree(root.right);\n            v2 = treeSum(root.right);\n        }\n        else\n            v2 = 0;\n\n        if(v1 == 0)\n            root.left = null;\n        if(v2 == 0)\n            root.right = null;\n\n        if((root.val + v1 + v2) == 0)\n            root = null;\n\n        return root;\n    }\n\n    public int treeSum(TreeNode node){\n        if(node == null)\n            return 0;\n\n        int v1, v2;\n\n        v1 = node.left != null ? ((node.left.val + treeSum(node.left)) >= 1 ? 1 : 0) : 0;\n        v2 = node.right != null ? ((node.right.val + treeSum(node.right)) >= 1 ? 1 : 0) : 0;\n\n        return (node.val + v1 + v2) >=1 ? 1 : 0;\n    }\n}\n//leetcode submit region end(Prohibit modification and deletion)\n\n    \n }\n```\n\n### 改进完善\n问题：当前判断子树是否为零树的方法`treeSum`，由于我们是从下到上去剪枝，会产生子树重复判断的问题。\n假定一个树有3层，且子树都是非零树，当剪枝操作进行到第2层，调用方法`treeSum`判断第2层子树时，第3层子树便重复判断了一次。\n\n改进：使用空间换时间的思想，用一种数据结构记录当前子树所有节点值之和（或者用布尔变量表示是否为零树），当判断一棵二叉树的子树时，只需到`对应的子树根节点`去判断即可。（该子树之前已经被判断过）\n\n## 方法1：递归\n树相关的题目首先考虑用递归解决。首先确定边界条件，当输入为空时，即可返回空。然后对左子树和右子树分别递归进行 pruneTree 操作。递归完成后，当这三个条件：左子树为空，右子树为空，当前节点的值为 0，同时满足时，才表示以当前节点为根的原二叉树的所有节点都为 0，需要将这棵子树移除，返回空。有任一条件不满足时，当前节点不应该移除，返回当前节点。\n\n```java\nclass Solution {\n    public TreeNode pruneTree(TreeNode root) {\n        if (root == null) {\n            return null;\n        }\n        root.left = pruneTree(root.left);\n        root.right = pruneTree(root.right);\n        if (root.left == null && root.right == null && root.val == 0) {\n            return null;\n        }\n        return root;\n    }\n}\n```\n\n## 思路对比\n看了官方的解题思路后，感觉是我递归了，但没有完全递归。。。\n官方递归代码之简洁，显得我自己的代码很sb。\n说明我有巨大的进步空间。\n\n# 795.区间子数组个数\n## 失败思路\n二级循环。\n\n失败原因：时间复杂度高，接近O(n平方)。\n\n代码如下：\n```java\nclass Solution {\n    public int numSubarrayBoundedMax(int[] nums, int left, int right) {\n        /**\n         * 思路1\n         * 双指针法：时间复杂度接近二级循环\n         * 问题：耗时久，时间复杂度高\n         */\n        int i = 0, j = 0;\n        int max;\n        int count = 0;\n        while (i < nums.length){\n            j = i;\n            max = nums[j];\n            while (j < nums.length){\n                if(nums[j] > max)\n                    max = nums[j];\n\n                if(max < left){\n                    j++;\n                    continue;\n                }\n                else if(max >= left && max <= right){\n                    count++;\n                    j++;\n                }\n                else\n                    break;\n            }\n            i++;\n        }\n\n        return count;\n    }\n}\n```\n\n## 方法1：一次遍历\n一个子数组的最大值范围在 [left,right] 表示子数组中不能含有大于 right 的元素，且至少含有一个处于 [left,right] 区间的元素。\n\n我们可以将数组中的元素分为三类，并分别用 0, 1, 2 来表示：\n- 小于 left，用 0 表示；\n- 大于等于 left 且小于等于 right，用 1 表示；\n- 大于 right，用 2 表示。\n\n那么本题可以转换为求解不包含 2，且至少包含一个 1 的子数组数目。我们遍历 i，并将右端点固定在 i，求解有多少合法的子区间。过程中需要维护两个变量：\n1. last1，表示上一次 1 出现的位置，如果不存在则为 -1\n2. last2，表示上一次 2 出现的位置，如果不存在则为 -1\n\n如果 last !=−1，那么子数组若以 i 为右端点，合法的左端点可以落在 (last2，last1] 之间。这样的左端点共有 last1−last2 个。\n\n因此，我们遍历 i ：\n1. 如果 left <= nums[i] <= right，则令 last1 = i\n2. 如果 nums[i] > right，令 last2 = i，last1 = -1\n\n如果 last != -1，则将 last1 - last2 累加到结果中。\n\n```java\nclass Solution {\n    public int numSubarrayBoundedMax(int[] nums, int left, int right) {\n        int res = 0, last1 = -1, last2 = -1;\n        for(int i = 0; i < nums.length; i++){\n            if(nums[i] >= left && nums[i] <= right){\n                last1 = i;\n            }else if(nums[i] > right){\n                last2 = i;\n                last1 = -1;\n            }\n            \n            if(last1 != -1){\n                res += last1 - last2;\n            }\n        }\n        \n        return res;\n    }\n}\n```\n\n### 题解思考\n该方法为什么只需要一次遍历？\n因为使用了两个变量`last1`和`last2`记录上一次`1`和`2`出现的位置，然后通过`last1 - last2`来计算子数组的数量，代替了第二次遍历。\n\n为什么能代替第二次遍历呢？\n该方法再`i`的遍历中，将当前`i`所在位置作为`子数组的右端点`，而`子数组的左端点`的数量由`last1 - last2`计算。\n\n这里着重说明一下两个变量的更新规则和累加规则：\n- last1 在`nums[i] < left`时是不更新的，因为这时的 nums[i] 只能作为右端点和前面的元素组成子数组，自己本身是不能作为左端点的！\n- 累加操作，只有在 last1 != -1 时进行，因为要在`last1 - last2`中选择左端点！\n\n该类似双指针，一开始我认为我的失败代码是双指针，简直笑死，算是真假李逵了。\n\n# 7.整数反转\n给你一个 32 位的有符号整数 x ，返回将 x 中的数字部分反转后的结果。\n如果反转后整数超过 32 位的有符号整数的范围 [−231,  231 − 1] ，就返回 0。\n假设环境不允许存储 64 位整数（有符号或无符号）。\n\n## 个人思路\n将 int 型的**最大值或最小值**装入数组 ms 中（不包括符号），同时将 **x** 也反转装入数组 xs 中（位数不够时前面补零）。\n最终输出结果时，将 xs 和 ms 对位比较，通过一个 int 变量 s，判断反转后的 x是否会超出界限\n- s 初始值 = 1\n- 如果 xs[i] < ms[i]，s = s*0\n- 如果 xs[i] == ms[i]，s = s*1\n- 如果 xs[i] > ms[i]，s = s*2；\n\n对位比较结束时，如果 s <= 1，则反转后的 **x** 不超出界限，否则返回0。\n\n### 代码\n```java\nclass Solution {\n    public int reverse(int x) {\n        /**\n         * 首先获取符号 +/-\n         * 将int型的 Max 和 Min存入最值数组中\n         * 将x也补零倒叙装入数组中\n         * 通过两个数组进行比较\n         */\n\n        if(x == 0)\n            return 0;\n\n        int len = 0;\n        int flag = 0;\n        int m = 0;\n        int[] ms;\n        int[] xs;\n        if( x > 0){\n            len = String.valueOf(Integer.MAX_VALUE).length();\n            flag = 1;\n            m = Integer.MAX_VALUE;\n            ms = new int[len];\n            xs = new int[len];\n        }else {\n            len = String.valueOf(Integer.MIN_VALUE).length()-1;\n            flag = -1;\n            m = Integer.MIN_VALUE;\n            ms = new int[len];\n            xs = new int[len];\n        }\n\n        for(int i = 0; i < len; i++){\n            ms[len - 1 - i] = flag * (m % 10);\n            m = m / 10;\n        }\n\n        int y = 0;\n        int s = 1;  //如果对位ys[i] < ms[i]，s = s*0；如果对位等于，s = s*1；如果对位大于，s = s*2；\n        int lenX = flag > 0 ? String.valueOf(x).length() : String.valueOf(x).length()-1;\n        for(int i = 0; i < len; i++){\n            if(i < len - lenX){\n                xs[i] = 0;\n            }else {\n                xs[i] = flag * (x % 10);\n                x = x / 10;\n            }\n\n            if(s <= 1) {\n                if (xs[i] < ms[i]) {\n                    s = s * 0;\n                } else if (xs[i] == ms[i]){\n                    s = s * 1;\n                }else {\n                    s = s * 2;\n                }\n            }else\n                break;\n\n            y = y*10 + xs[i];\n        }\n\n        if(s <= 1)\n            return flag * y;\n        else\n            return 0;\n    }\n}\n```\n\n### 不足之处\n解答成功:\n\t执行耗时:1 ms,击败了43.24% 的Java用户\n\t内存消耗:39 MB,击败了35.08% 的Java用户\n\n### 注意事项\n负数对10求余，结果为负数！\n```\nint x = -123;\nint y = x % 10;\n\n输出：y = -3\n```\n\n# 剑指Offer 55 - II.平衡二叉树 \n输入一棵二叉树的根节点，判断该树是不是平衡二叉树。如果某二叉树中任意节点的左右子树的深度相差不超过1，那么它就是一棵平衡二叉树。\n\n## 个人思路\n### 代码\n```java\nclass Solution {\n    public boolean isBalanced(TreeNode root) {\n        /**\n         * 前序遍历\n         *\n         */\n        if(root == null)\n            return true;\n\n        int ld = countDepth(root.left);\n        int rd = countDepth(root.right);\n\n        return (Math.abs(ld-rd) > 1 ? false : true) && isBalanced(root.left) && isBalanced(root.right);\n    }\n\n    public int countDepth(TreeNode node){\n        if(node == null)\n            return 0;\n\n        return 1 + Math.max(countDepth(node.left), countDepth(node.right));\n    }\n\n}\n```\n\n### 注意事项\n```java\n//注意后面还要判断左右子树是否为平衡树\nreturn 1 + Math.max(countDepth(node.left), countDepth(node.right));\n```\n\n# 剑指Offer 07.重建二叉树\n输入某二叉树的前序遍历和中序遍历的结果，请构建该二叉树并返回其根节点。\n假设输入的前序遍历和中序遍历的结果中都不含重复的数字。\n\n## 个人思路\n记录下思路加深记忆。\n\n前序数组：pre = {3,9,20,15,7}\n中序数组：in = {9,3,15,20,7}\n\n每次重建一个节点需要以下参数：\n- pre：前序数组\n- i1：前序数组中**树节点范围**开始下标\n- i2：前序数组中**树节点范围**末尾下标\n- in：中序数组\n- j1：中序数组**树节点范围**开始下标\n- j2：中序数组**树节点范围**末尾下标\n\n> **树节点范围**指的是当前所重建节点及其所有子孙节点\n> \n\n重建节点所需步骤：\n1. **pre[i1]**肯定为重建的根节点值\n2. **in**数组中和**pre[i1]**值相同的下标设为**j**\n3. **in[j]**左边为重建根节点左子树的所有节点，右边为重建根节点右子树的所有节点\n4. 重复以上操作重建根节点的左右子节点\n\n终止条件：\n1. i1 > i2：重建所需节点数量为空，返回**null**\n2. i1 = i2：重建只需一个节点，则不需要再递归重建其左右子节点，直接返回该重建节点\n\n### 代码\n```java\n/**\n * Definition for a binary tree node.\n * public class TreeNode {\n *     int val;\n *     TreeNode left;\n *     TreeNode right;\n *     TreeNode(int x) { val = x; }\n * }\n */\nclass Solution {\n    public TreeNode buildTree(int[] preorder, int[] inorder) {\n        if(preorder == null ||preorder.length == 0 || inorder == null || inorder.length == 0)\n            return null;\n\n        return build(preorder, 0, preorder.length-1, inorder, 0, inorder.length-1);\n    }\n\n    public TreeNode build(int[] pre, int i1, int i2, int[] in, int j1, int j2){\n        if(i1 > i2)\n            return null;\n\n        TreeNode node = new TreeNode(pre[i1]);\n\n        if(i1 == i2)\n            return node;\n\n        int j = j1;\n        for(; j <= j2; j++){\n            if(in[j] == pre[i1])\n                break;\n        }\n\n        node.left = build(pre, i1+1, i1+j-j1, in, j1, j-1);\n        node.right = build(pre, i1+j-j1+1, i2, in, j+1, j2);\n\n        return node;\n    }\n}\n```\n\n# 1110.删点成林\n给出二叉树的根节点 root，树上每个节点都有一个不同的值。\n如果节点值在 to_delete 中出现，我们就把该节点从树上删去，最后得到一个森林（一些不相交的树构成的集合）。\n返回森林中的每棵树。你可以按任意顺序组织答案。\n\n## 个人思路\n首先，判断一个节点是普通节点还是待删节点：\n- 普通节点：继续判断左右子节点，递归\n- 待删节点：将该节点赋值为`null`，并对待删节点执行**删除操作shear**\n\t- 将待删节点置为`null`需要借助其父节点，因为Java中的引用传递实质上也是值传递，只不过传递的是对象存储地址，因此在普通节点的递归函数`iterator`含有一个父节点参数！\n\t- 删除操作shear：首先尝试从`list`中移除待删节点（因为后面会将待删节点左右子节点放入`list`中，如果后面递归中发现其子节点也是待删节点，则需从链表中移除！删除失败也无关紧要嘛），然后将其非空子节点放入链表中。\n\n### 代码\n```java\n/**\n * Definition for a binary tree node.\n * public class TreeNode {\n *     int val;\n *     TreeNode left;\n *     TreeNode right;\n *     TreeNode() {}\n *     TreeNode(int val) { this.val = val; }\n *     TreeNode(int val, TreeNode left, TreeNode right) {\n *         this.val = val;\n *         this.left = left;\n *         this.right = right;\n *     }\n * }\n */\nclass Solution {\n    List<TreeNode> list = new ArrayList<>();\n    public List<TreeNode> delNodes(TreeNode root, int[] to_delete) {\n        Set<Integer> set = new HashSet<>();\n        for(int val : to_delete){\n            set.add(val);\n        }\n        TreeNode n0 = new TreeNode(0);\n        n0.left = root;\n        list.add(root);\n        iterator(n0, root, set);\n        return list;\n    }\n\n    //是否要删除\n    public boolean isIn(int val, Set<Integer> set){\n        return set.contains(val);\n    }\n\n    public void iterator(TreeNode root, TreeNode node, Set<Integer> set){\n        if(node == null)\n            return;\n\n        if(isIn(node.val, set)){\n            shear(node, set);\n            if(root.left == node)\n                root.left = null;\n            else\n                root.right = null;\n        }\n        else {\n            iterator(node, node.left, set);\n            iterator(node, node.right, set);\n        }\n    }\n\n    //删除操作\n    public void shear(TreeNode root, Set<Integer> set){\n        list.remove(root);\n        if(root.left != null) {\n            list.add(root.left);\n            iterator(root, root.left, set);\n        }\n        if(root.right != null) {\n            list.add(root.right);\n            iterator(root, root.right, set);\n        }\n    }\n}\n```\n\n### 不足之处\n方法运行耗时和内存消耗不理想（leetcode打败几%的用户），我的方法也只对二叉树做一次遍历啊，复杂度应该是`O(n)`啊，暂时没想通为什么。\n\n## labuladong\n关键在于理解到**一个节点不是待删节点，且没有父节点，则是一棵新树**\n其他细节：\n- 利用递归函数`doDelete`的返回值来完成节点的删除操作，即**分解问题**的思路\n- 使用布尔变量`hasParent`传递节点是否有父节点这一信息\n\n这就是刷题二十年的功力，妙啊！\n\n### 代码\n```java\n/**\n * Definition for a binary tree node.\n * public class TreeNode {\n *     int val;\n *     TreeNode left;\n *     TreeNode right;\n *     TreeNode() {}\n *     TreeNode(int val) { this.val = val; }\n *     TreeNode(int val, TreeNode left, TreeNode right) {\n *         this.val = val;\n *         this.left = left;\n *         this.right = right;\n *     }\n * }\n */\nclass Solution {\n    Set<Integer> delSet = new HashSet<>();\n    List<TreeNode> res = new ArrayList<>();\n    public List<TreeNode> delNodes(TreeNode root, int[] to_delete) {\n        for(int d : to_delete){\n            delSet.add(d);\n        }\n        doDelete(root, false);\n        return res;\n    }\n\n    private TreeNode doDelete(TreeNode root, boolean hasParent){\n        if(root == null){\n            return null;\n        }\n\n        boolean deleted = delSet.contains(root.val);\n        if(!deleted && !hasParent){\n            res.add(root);\n        }\n\n        root.left = doDelete(root.left, !deleted);\n        root.right = doDelete(root.right, !deleted);\n\n        return deleted ? null : root;\n    }\n}\n```\n\n# 116.填充每个节点的下一个右侧节点指针\n给定一个 完美二叉树 ，其所有叶子节点都在同一层，每个父节点都有两个子节点。二叉树定义如下：\n```\nstruct Node {\n  int val;\n  Node *left;\n  Node *right;\n  Node *next;\n}\n```\n填充它的每个 next 指针，让这个指针指向其下一个右侧节点。如果找不到下一个右侧节点，则将 next 指针设置为 NULL。\n\n初始状态下，所有 next 指针都被设置为 NULL。\n\n## 个人思路\n对每个结点进行的操作：\n- 将左右字节点连接\n- 将本节点的右子节点和**右边兄弟节点**的左子节点连接\n\n### 代码\n```java\nclass Solution {\n    public Node connect(Node root) {\n        //如果节点1的左右节点都不为 null，则将左子节点与右子节点连接\n        //然后判断节点1是否有右侧节点，如果有，则将节点1的右子节点和节点2的右子节点进行连接\n        traverse(root);\n        return root;\n    }\n    public void traverse(Node root){\n        if(root == null)\n            return;\n        if(root.left != null && root.right != null)\n            root.left.next  = root.right;\n        if(root.right != null && root.next != null)\n            root.right.next = root.next.left;\n        traverse(root.left);\n        traverse(root.right);\n    }\n}\n```\n\n## labuladong\n将此题目中的二叉树看作一个三叉树，**连接左右节点**整体看作第三个节点（从代码的递归函数形式看勉强算吧，感觉这个抽象不是很有意义）\n\n```java\n// 主函数\nNode connect(Node root) {\n    if (root == null) return null;\n    // 遍历「三叉树」，连接相邻节点\n    traverse(root.left, root.right);\n    return root;\n}\n\n// 三叉树遍历框架\nvoid traverse(Node node1, Node node2) {\n    if (node1 == null || node2 == null) {\n        return;\n    }\n    /**** 前序位置 ****/\n    // 将传入的两个节点穿起来\n    node1.next = node2;\n    \n    // 连接相同父节点的两个子节点\n    traverse(node1.left, node1.right);\n    traverse(node2.left, node2.right);\n    // 连接跨越父节点的两个子节点\n    traverse(node1.right, node2.left);\n}\n```\n\n# 114.二叉树展开为链表\n给你二叉树的根结点 root ，请你将它展开为一个单链表：\n- 展开后的单链表应该同样使用 TreeNode ，其中 right 子指针指向链表中下一个结点，而左子指针始终为 null 。\n- 展开后的单链表应该与二叉树 先序遍历 顺序相同。\n\n## 个人思路\n采用分解问题的思路\n\n每个节点进行的操作：\n- 返回当前子树的**最右端节点**\n- 将左子树迁移到子树的右边\n- 将右子树迁移到**最右端节点**下面\n\n代码的复杂之处就在于**如何找到并返回最右端节点**，相比之下**labuladong**的思路就要巧妙很多，代码也简洁易懂\n\n### 代码\n```java\nclass Solution {\n    public void flatten(TreeNode root) {\n        // 每个子树根节点操作如下：\n        // 1.TreeNode node = root.right\n        // root.right = root.left\n        // root.left = null\n        // 2.返回最右端的节点 root_maxRight\n        // root_maxRight.right = node\n        // 关键！！！\n        // 如果返回子树的最优端节点\n\n        change(root, null);\n    }\n\n    public TreeNode change(TreeNode root, TreeNode parent){\n\n        if(root == null)\n            return null;\n\n        TreeNode tempLeft = root.left;\n        TreeNode tempRight = root.right;\n        if(parent != null) {\n            parent.right = root;\n            parent.left = null;\n        }\n\n        TreeNode leftParent = change(tempLeft, root);\n        TreeNode rightParent = null;    \n        if(leftParent != null)\n            rightParent = change(tempRight, leftParent);\n        else\n            rightParent = change(root.right, root);\n\n        if(rightParent != null)\n            return rightParent;\n        else if(leftParent != null)\n            return leftParent;\n        else\n            return root;\n    }\n}\n```\n\n## labuladong\n思路的巧妙之处在于：在后序位置利用了前面已经被递归处理的节点肯定是**链式连接**的，使用一个简单的循环就可以找出**右子树需要连接的头节点**，也即**最右端节点**。\n\n```java\n// 定义：将以 root 为根的树拉平为链表\nvoid flatten(TreeNode root) {\n    // base case\n    if (root == null) return;\n    \n    // 利用定义，把左右子树拉平\n    flatten(root.left);\n    flatten(root.right);\n\n    /**** 后序遍历位置 ****/\n    // 1、左右子树已经被拉平成一条链表\n    TreeNode left = root.left;\n    TreeNode right = root.right;\n    \n    // 2、将左子树作为右子树\n    root.left = null;\n    root.right = left;\n\n    // 3、将原先的右子树接到当前右子树的末端\n    TreeNode p = root;\n    while (p.right != null) {\n        p = p.right;\n    }\n    p.right = right;\n}\n```\n\n## 拓展思考\n**labuladong**的代码胜在思路简单，代码优雅。但是我的代码在**寻找最右端节点**上不需要遍历之前已经处理过的节点，时间复杂度上应该会小胜一筹。嘻嘻。\n\n# 1372.二叉树中的最长交错路径\n给你一棵以 root 为根的二叉树，二叉树中的交错路径定义如下：\n- 选择二叉树中 任意 节点和一个方向（左或者右）\n- 如果前进方向为右，那么移动到当前节点的的右子节点，否则移动到它的左子节点\n- 改变前进方向：左变右或者右变左\n- 重复第二步和第三步，直到你在树中无法继续移动\n- 交错路径的长度定义为：访问过的节点数目 - 1（单个节点的路径长度为 0 ）\n\n请你返回给定树中最长 交错路径 的长度。\n\n## 个人思路\n题目的注意点：节点的走向必须左右交替进行\n\n采用遍历二叉树思路\n\n每个节点需要做的事情：\n- 接替父节点的路径，方向交替的走向其子节点（如果父节点选择左方向，则该节点应选右方向走向其右子节点），路径长度加一\n- 开辟一个新的路径，作为起始节点。选择与父节点相同的方向走向子节点，路径长度置零\n- 更新最大路径长度\n\n### 代码\n```java\nclass Solution {\n    int max = 0;\n    public int longestZigZag(TreeNode root) {\n        if(root != null){\n            traverse(root.left, 0, 0);\n            traverse(root.right, 0, 1);\n        }\n        return max;\n    }\n\n    /**\n     *\n     * @param root\n     * @param length 路径长度\n     * @param direction 0:左， 1：右\n     */\n    public void traverse(TreeNode root, int length, int direction){\n        if(root == null)\n            return;\n\n        if(length+1 > max)\n            max = length+1;\n\n        if(direction == 0) {\n            traverse(root.left, 0, 0);\n            traverse(root.right, length + 1, 1);\n        }else {\n            traverse(root.left, length+1, 0);\n            traverse(root.right, 0, 1);\n        }\n    }\n}\n```\n\n# 1696.跳跃游戏 VI\n给你一个下标从 0 开始的整数数组 nums 和一个整数 k 。\n\n一开始你在下标 0 处。每一步，你最多可以往前跳 k 步，但你不能跳出数组的边界。也就是说，你可以从下标 i 跳到 [i + 1， min(n - 1, i + k)] 包含 两个端点的任意位置。\n\n你的目标是到达数组最后一个位置（下标为 n - 1 ），你的 得分 为经过的所有数字之和。\n\n请你返回你能得到的 最大得分 。\n\n## 错误思路\n思路如下：题目限制每次最大跳`K`步，且首尾已经限制，追求跳跃总和最大。每次在接下来的`K`个元素中**顺序寻找第一个正数**，加入到总和中；如果`K`个元素全为负则寻找**最大的负数**加入到总和中。\n\n代码如下：\n```java\nclass Solution {\n    public int maxResult(int[] nums, int k) {\n        //base case: i=0, return nums[0],即f(0) = nums[0]\n        //状态转移方程: f(n) = max{f(n-m), m = 1,...,k} + nums[n]\n        //有两种写法：1. 从nums[n-1]倒着计算\n        //          2. 从nums[0]顺着计算\n        return dp(nums, k, nums.length-1);\n    }\n    int dp(int[] nums, int k, int i){\n        if(i == 0)\n            return nums[0];\n        int maxIndex = -1;\n        int max = Integer.MIN_VALUE;\n        for(int j = 0; j < k; j++){\n            if(i-1-j >= 0 && nums[i-1-j] > max){\n                max = nums[i-1-j];\n                maxIndex = i-1-j;\n                if(max > 0)\n                    break;\n            }\n        }\n        return nums[i] + dp(nums, k, maxIndex);\n    }\n}\n```\n\n## 错误原因\n如果测试数据中出现一长段连续负数，`-1, -100, -100, -100, 1`，假设`K=3`此时按照思路会依次选择`-1, -100, 1`，但是实际上应该选择`-100, 1`。证明思路有问题！！！\n\n## 反思\n这题也是用**动态规划**思路去解的，但是在解题的过程中太过注重问题细节，反观**labuladong**的题解，会发现**动态规划类型问题**的关键在于明确**状态转移方程**、如何定义**dp函数/数组**、怎么做**选择**，不用去过分关注解题的每一步是怎么进行，这些**动态规划框架**会帮你完成！！！\n\n## labuladong\n```java\n// 第一步，暴力递归解法（超时）\nclass Solution1 {\n    public int maxResult(int[] nums, int k) {\n        int n = nums.length;\n        return dp(nums, n - 1, k);\n    }\n\n    // 定义：到达 nums[p] 所能获得的最大分数是 dp(nums, p)\n    // 能跳到 nums[p]，必然是从 nums[p-k..p-1] 中的某个位置跳来的\n    // 故状态转移方程为：dp[p] = max(nums[p-k..p-1]) + nums[p]\n    int dp(int[] nums, int p, int k) {\n        if (p == 0) {\n            return nums[0];\n        }\n        if (p < 0) {\n            return Integer.MIN_VALUE;\n        }\n        // 实现状态转移方程\n        int res = Integer.MIN_VALUE;\n        for (int i = 1; i <= k; i++) {\n            res = Math.max(res, dp(nums, p - i, k));\n        }\n        res += nums[p];\n        return res;\n    }\n}\n\n// 第二步，带备忘录的递归解法（超时）\nclass Solution2 {\n    // 备忘录\n    int[] memo;\n\n    public int maxResult(int[] nums, int k) {\n        int n = nums.length;\n        memo = new int[n];\n        // 备忘录初始化为最小值\n        Arrays.fill(memo, Integer.MIN_VALUE);\n        return dp(nums, n - 1, k);\n    }\n\n    // 定义：到达 nums[p] 所能获得的最大分数是 dp(nums, p)\n    int dp(int[] nums, int p, int k) {\n        if (p == 0) {\n            return nums[0];\n        }\n        if (p < 0) {\n            return Integer.MIN_VALUE;\n        }\n        // 查备忘录，避免冗余计算\n        if (memo[p] != Integer.MIN_VALUE) {\n            return memo[p];\n        }\n        // 实现状态转移方程，结果存入备忘录\n        for (int i = 1; i <= k; i++) {\n            memo[p] = Math.max(memo[p], dp(nums, p - i, k));\n        }\n        memo[p] += nums[p];\n        return memo[p];\n    }\n}\n\n\n// 第三步，自顶向下的递归改为自底向上的迭代解法（超时）\nclass Solution3 {\n    public int maxResult(int[] nums, int k) {\n        int n = nums.length;\n        // 定义：到达 nums[p] 的最大分数为 dp[p]\n        int[] dp = new int[n];\n        // dp 数组初始化为最小值\n        Arrays.fill(dp, Integer.MIN_VALUE);\n        // base case\n        dp[0] = nums[0];\n        // 状态转移\n        for (int p = 1; p < n; p++) {\n            for (int i = 1; i <= k; i++) {\n                if (p - i < 0) {\n                    continue;\n                }\n                dp[p] = Math.max(dp[p], dp[p - i]);\n            }\n            dp[p] += nums[p];\n        }\n        return dp[n - 1];\n    }\n}\n\n// 第四步，利用单调队列结构消除内层循环（通过）\nclass Solution {\n    public int maxResult(int[] nums, int k) {\n        int n = nums.length;\n        MonotonicQueue<Integer> window = new MonotonicQueue<>();\n        // 定义：到达 nums[p] 的最大分数为 dp[p]\n        int[] dp = new int[n];\n        // dp 数组初始化为最小值\n        Arrays.fill(dp, Integer.MIN_VALUE);\n        // base case\n        dp[0] = nums[0];\n        window.push(dp[0]);\n        // 状态转移\n        for (int p = 1; p < n; p++) {\n            dp[p] = window.max() + nums[p];\n            // 维护窗口装着 dp[p-1..p-k]\n            if (window.size() == k) {\n                window.pop();\n            }\n            window.push(dp[p]);\n        }\n        return dp[n - 1];\n    }\n}\n\n/* \n单调队列的通用实现，可以高效维护最大值和最小值\n由于考虑泛型和通用性，提交的性能会略差，你可自行精简\n*/\nclass MonotonicQueue<E extends Comparable<E>> {}\n```\n\n# 343.整数拆分\n给定一个正整数 n ，将其拆分为 k 个 正整数 的和（ k >= 2 ），并使这些整数的乘积最大化。\n\n返回 你可以获得的最大乘积 。\n\n> 2 <= n <= 58\n> \n\n## 思路初试\n读完题目可以感觉到是**动态规划**题目，那么想出**状态转移方程**是最为重要的。\n\n很明显**状态即数字n的大小**，题目要求的是**求和为n的一系列数字的乘积最大**，那么可以想到构造方程：`f(n) = max{k * f(n-k), k=1,2,...,n-1}`\n用长度为n的数组`states`作为`bp Table`来完成剪枝\n\n> 题目中要求 n >=2，状态方程中n实际上可以为 1，但是这没有太大关系\n> \n\n代码如下：\n```java\nclass Solution {\n    int[] states;\n    public int integerBreak(int n) {\n        /**\n         * f(n) = max{(n-k)*f(k), k = 1,2,...,n-2,n-1}\n         */\n        states = new int[n+1];\n        return bp(n);\n    }\n    int bp(int n){\n        if(n == 1)\n            return 1;\n        if(states[n] != 0)\n            return states[n];\n        int max = Integer.MIN_VALUE;\n        for(int i = 1; i <= n-1; i++){\n            int temp = i*bp(n-i);\n            if(max < temp)\n                max = temp;\n        }\n        states[n] = max;\n        return states[n];\n    }\n}\n```\n\n提交运行，报错。`f(10)`结果为`27`。debug发现，求解过程中，`f(4)`结果为`3`，这显然是不对的，说明我们的状态方程出了问题。\n\n## 思路改进\n`f(4) = max{1*f(3), 2*f(2), 3*f(1)}`，这里`f(2)=1`，到这里就能看出问题所在了。`f(4)`应该为`2*2 = 4`，但是按照我们的状态方程，我们又把`后面的2`转换为`f(2)`求解，所以最终导致`f(4)`结果错误。\n\n分析发现，转换后的`f(n-k)`并不一定比`n-k`大。应改进状态方程，先得到原始的`n-k`和转换为`f(n-k)`中较大者，再乘`k`，改进后方程：`f(n) = max{k * max[n-k, f(n-k)], k=1,2,...,n-1}`\n\n正确代码如下：\n```java\nclass Solution {\n    int[] states;\n    public int integerBreak(int n) {\n        /**\n         * f(n) = max{(n-k) * max[n-k,f(k)], k = 1,2,...,n-2,n-1}\n         */\n        states = new int[n+1];\n        return bp(n);\n    }\n    int bp(int n){\n        if(n == 1)\n            return 1;\n        if(states[n] != 0)\n            return states[n];\n        int max = Integer.MIN_VALUE;\n        for(int i = 1; i <= n-1; i++){\n            int bp = bp(n-i);\n            int temp = i * (n-i > bp ? n-i : bp);\n            if(max < temp)\n                max = temp;\n        }\n        states[n] = max;\n        return states[n];\n    }\n}\n```\n\n# 221.最大正方形\n在一个由 '0' 和 '1' 组成的二维矩阵内，找到只包含 '1' 的最大正方形，并返回其面积。\n\n## 要点笔记\n解题关键和难点在于**状态方程**，一旦理解到了最大正方形的找法，一切都迎刃而解了！可惜自己做的时候百思不得其解，哈哈。\n\n状态方程见下**labuladong**\n\n还有需要注意的是，此题中的**base case**，为矩阵的首行和首列。\n\n## labuladong\n关键是你要观察出一个全是 1 的正方形有什么特点，如何根据小的正方形推导出大的正方形（状态转移方程）\n\n当`matrix[i][j]为1`，且它的左边、上边、左上边都存在正方形时，`matrix[i][j]`才能够作为一个更大的正方形的右下角：\n\n![img 221.最大正方形](./leetCode刷题笔记/221最大正方形.jpg)\n\n```java\nif (matrix[i][j] == 1)\n    // 类似「水桶效应」，最大边长取决于边长最短的那个正方形\n    dp[i][j] = min(dp[i-1][j], dp[i-1][j-1], dp[i][j-1]) + 1;\nelse\n    dp[i][j] = 0;\n```\n\n题解代码：\n```java\nclass Solution {\n    public int maximalSquare(char[][] matrix) {\n        int m = matrix.length, n = matrix[0].length;\n        // 定义：以 matrix[i][j] 为右下角元素的全为 1 正方形矩阵的最大边长为 dp[i][j]。\n        int[][] dp = new int[m][n];\n\n        // base case，第一行和第一列的正方形边长\n        for (int i = 0; i < m; i++) {\n            dp[i][0] = matrix[i][0] - '0';\n        }\n        for (int j = 0; j < n; j++) {\n            dp[0][j] = matrix[0][j] - '0';\n        }\n\n        // 进行状态转移\n        for (int i = 1; i < m; i++) {\n            for (int j = 1; j < n; j++) {\n                if (matrix[i][j] == '0') {\n                    // 值为 0 不可能是正方形的右下角\n                    continue;\n                }\n                dp[i][j] = Math.min(Math.min(\n                    dp[i - 1][j],\n                    dp[i][j - 1]),\n                    dp[i - 1][j - 1]\n                ) + 1;\n            }\n        }\n\n        int len = 0;\n        for (int i = 0; i < m; i++) {\n            for (int j = 0; j < n; j++) {\n                len = Math.max(len, dp[i][j]);\n            }\n        }\n        return len * len;\n    }\n\n}\n```\n\n# 剑指 Offer II 017 含有所有字符的最短字符（76.最小覆盖字串）\n给定两个字符串 s 和 t 。返回 s 中包含 t 的所有字符的最短子字符串。如果 s 中不存在符合条件的子字符串，则返回空字符串 \"\" 。\n\n如果 s 中存在多个符合条件的子字符串，返回任意一个。\n\n注意： 对于 t 中重复字符，我们寻找的子字符串中该字符数量必须不少于 t 中该字符数量。\n示例 1：\n\n输入：s = \"ADOBECODEBANC\", t = \"ABC\"\n输出：\"BANC\" \n解释：最短子字符串 \"BANC\" 包含了字符串 t 的所有字符 'A'、'B'、'C'\n示例 2：\n\n输入：s = \"a\", t = \"a\"\n输出：\"a\"\n示例 3：\n\n输入：s = \"a\", t = \"aa\"\n输出：\"\"\n解释：t 中两个字符 'a' 均应包含在 s 的子串中，因此没有符合条件的子字符串，返回空字符串。\n提示：\n- 1 <= s.length, t.length <= 10^5\n- s 和 t 由英文字母组成\n\n## 个人思路\n遇到求字串问题，优先考虑**滑动窗口**方法。\n\n滑动窗口的关键在于**缩小窗口的时机**和**如何缩小窗口**，而且重点在于后者！！！\n\n根据题目要求，所求字符串必须包含 t 的所有字符，且相应字符的数量必须不小于 t 中的数量。\n\n缩小窗口：等到**窗口合法**后，left++。注意 left 右移后，窗口仍有可能合法，所以需要**while循环**判断窗口的合法性。\n\n本方法的时间和空间复杂度都不是很好，可以看下面的改进方法。\n\n### 代码\n```java\nclass Solution {\n    public String minWindow(String s, String t) {\n        if(s.length() < t.length())\n            return \"\";\n        int il = 0, ir = s.length();    //结果字符串索引\n        int left = 0, right = 0;\n        HashMap<Character, Integer> map = new HashMap<>();\n        HashMap<Character, Integer> window = new HashMap<>();\n        for(int i = 0; i < t.length(); i++){\n            char c = t.charAt(i);\n            if(map.containsKey(c)){\n                map.put(c, map.get(c)+1);\n            }else {\n                map.put(c, 1);\n            }\n            window.put(c, 0);\n        }\n        while (right < s.length()){\n            char r = s.charAt(right);\n            right++;\n            //窗口数据更新\n            if(window.containsKey(r)){\n                window.put(r, window.get(r)+1);\n            }\n            //窗口左侧是否需要收缩\n            while (isValidWindow(map, window)){\n                if (right - left < ir - il + 1) {\n                    ir = right - 1;\n                    il = left;\n                }\n                char l = s.charAt(left);\n                left++;\n                //窗口数据更新\n                if(window.containsKey(l)){\n                    window.put(l, window.get(l)-1);\n                }\n            }\n        }\n        if(ir == s.length())\n            return \"\";\n        else\n            return s.substring(il, ir+1);\n    }\n    boolean isValidWindow(HashMap<Character, Integer> map, HashMap<Character, Integer> window){\n        for(Character c : window.keySet()){\n            if(window.get(c) < map.get(c))\n                return false;\n        }\n        return true;\n    }\n}\n```\n\n## 改进方法\n题解思路：利用双指针找到以下标right结尾，且含有t所有字符的最小长度区间[left,right]\n\n定义两个数组 cnt1与cnt2，将字母转化成数字，并以此为下标，出现次数作为值存进数组中，当cnt2[n]>=cnt1[n]，也就是cnt2中 n 所代表的字符出现次数，比cnt1中 n 所代表的字符出现次数多或相等，也就是含有。\n\n改进方法真的非常巧妙！！！\n### 代码\n```java\nclass Solution {\n    public String minWindow(String s, String t) {\n        int n = s.length();\n        int m = t.length();\n        String res = \"\";\n        if (n < m)\n            return res;\n        //cnt1:t的参照数组\n        int[] cnt1 = new int[60];\n        int[] cnt2 = new int[60];\n        //初始化cnt1\n        for(int i = 0; i < t.length(); i++){\n            cnt1[t.charAt(i)-'A']++;\n        }\n        int diff = 0;   //t中字符种类数量\n        for(int i : cnt1){\n            if(i!=0)\n                diff++;\n        }\n        int left = 0, right = 0;\n        int min = s.length()+1;\n        while (right < n){\n            char r = s.charAt(right);\n            right++;\n            cnt2[r-'A']++;\n            if(cnt1[r-'A'] == cnt2[r-'A'])\n                diff--;\n            //窗口满足条件,尝试缩小窗口\n            while (diff == 0){\n                if(min > right-left){\n                    min = right-left;\n                    res = s.substring(left, right);\n                }\n                //尝试缩小窗口\n                char l = s.charAt(left);\n                left++;\n                cnt2[l-'A']--;\n                //若移除字符 l 是否是 t 中的字符，且破环了窗口的合法性\n                if(cnt1[l-'A'] != 0 && cnt2[l-'A'] < cnt1[l-'A'])\n                    diff++;\n            }\n        }\n        return res;\n    }\n}\n```\n\n# 1004.最大连续1的个数 III\n给定一个二进制数组 nums 和一个整数 k，如果可以翻转最多 k 个 0 ，则返回 数组中连续 1 的最大个数 。\n\n示例 1：\n\n输入：nums = [1,1,1,0,0,0,1,1,1,1,0], K = 2\n输出：6\n解释：[1,1,1,0,0,1,1,1,1,1,1]\n粗体数字从 0 翻转到 1，最长的子数组长度为 6。\n示例 2：\n\n输入：nums = [0,0,1,1,0,0,1,1,1,0,1,1,0,0,0,1,1,1,1], K = 3\n输出：10\n解释：[0,0,1,1,1,1,1,1,1,1,1,1,0,0,0,1,1,1,1]\n粗体数字从 0 翻转到 1，最长的子数组长度为 10。\n\n提示：\n- 1 <= nums.length <= 105\n- nums[i] 不是 0 就是 1\n- 0 <= k <= nums.length\n- Related Topics\n- \n## 个人思路\n这个题目很好体现了**缩小窗口的时机**也很重要，当然**如何缩小窗口**也很重要。\n题目还有需要注意的是**如何维护窗口**，其他滑动窗口题目中**维护窗口**都很简单。\n\n### 代码\n```java\nclass Solution {\n    public int longestOnes(int[] nums, int k) {\n        int left = 0, right = 0;\n        int max = 0;\n        while(right < nums.length){\n            int r = nums[right];\n            right++;\n\n            if(r == 1){\n                max = Math.max(max, right-left);\n            }else {\n                //r == 0\n                if(k == 0){\n                    //不能再翻转 r,缩小窗口，移动left到下一个 0 的后面位置\n                    //这里条件不能写为 left < right ,因为循环体里 left++ 是在后面！！！\n                    // 因为 left = right-1时，还要进行 num[left] == 0的判断\n                    while (left < right){\n                        if(nums[left] == 0){\n                            k++;\n                            left++;\n                            break;\n                        }\n                        left++;\n                    }\n                    //前面将 left移动下一个 0 的后面的位置，k++。但是当前 r = 0，又消耗了一次 k，所以 k--\n                    k--;\n                }else {\n                    //翻转 r\n                    k--;\n                    max = Math.max(max, right-left);\n                }\n            }\n        }\n        return max;\n    }\n}\n```"},{"title":"设计模式","url":"/2022/08/27/she-ji-mo-shi/","content":"## ## 适配器模式\n\n```dart\n/*\n* 适配器模式：使用新接口包装旧接口，达到适配目的\n* 目标抽象类：定义业务新接口\n* 适配器类：实现业务新接口，并持有旧接口对象的引用\n* 被适配类：旧接口实现类\n* */\n\nclass AdapterInterface{\n  void newMethod(){}\n}\n\nclass Adapter implements AdapterInterface{\n  OldInterfaceImpl oldInterfaceImpl;\n\n  Adapter(this.oldInterfaceImpl);\n\n  @override\n  void newMethod() {\n    print('new method start');\n    oldInterfaceImpl.oldMethod();\n    print('new method end');\n  }\n\n}\n\nclass OldInterfaceImpl{\n  void oldMethod(){\n    print('this is old method');\n  }\n}\n```\n\n## 桥接模式\n\n```dart\n/*\n* 桥接模式：将抽象类的方法实现抽离出实现类，交由桥接接口及其实现类负责\n* 抽象化接口：原始的接口\n* - 具体抽象化类：拓展抽象化接口以实现更多功能（不太理解）\n* 桥接接口：定义实现“抽象化接口”方法的方法\n* - 具体实现类：实现桥接接口的方法（实际上就是“抽象化接口”的方法）\n*\n* TODO:不太理解\n* */\n\nabstract class Abstraction{\n  Bridge bridge;\n\n  Abstraction(this.bridge);\n\n  void draw();\n}\n\nclass Circle extends Abstraction{\n  Circle(super.bridge);\n  \n  @override\n  void draw() {\n    bridge.draw();\n  }\n  \n}\n\nabstract class Bridge{\n  void draw();\n}\n\nclass BridgeChild extends Bridge{\n  @override\n  void draw() {\n    print('I finish drawing one Circle');\n  }\n  \n}\n```\n\n## 建造者模式\n\n```dart\n/*\n* 建造者模式：组装复杂对象\n* 产品类：要组装的对象\n* 建造者：每一个组装步骤。\n* - 抽象建造者：定义每个建造步骤\n* - 具体建造者：实现每个建造步骤\n* 指挥者：通过多个建造步骤实现组装对象\n* */\n\nimport 'dart:core';\n\nclass Product {\n  String? name;\n  String? sex;\n  String? age;\n}\n\nabstract class Builder {\n  void setPart1();\n\n  void setPart2();\n\n  void setPart3();\n\n  Product result();\n}\n\nclass BuilderA extends Builder {\n  Product _product = Product();\n\n  @override\n  void setPart1() {\n    _product.name = 'Tom';\n  }\n\n  @override\n  void setPart2() {\n    _product.sex = '女';\n  }\n\n  @override\n  void setPart3() {\n    _product.age = '18';\n  }\n\n  @override\n  Product result() {\n    return _product;\n  }\n}\n\nclass Director{\n  void direct(Builder builder){\n    builder.setPart1();\n    print('建造步骤-1');\n    builder.setPart2();\n    print('建造步骤-2');\n    builder.setPart3();\n    print('建造步骤-3');\n  }\n}\n```\n\n## 责任链模式\n\n```dart\n/*\n* 责任链模式：请求处理的处理链，\n* 抽象处理器：定义处理器的接口，并且持有下一个处理器的引用\n* 具体处理器：实现抽象处理器的接口\n*\n* 在职责链模式中，每个处理者都有机会处理请求，但是处理者并不知道下一个处理者是谁，\n* 请求会依次经过处理者链中的每个处理者，直到有一个处理者处理它为止。因此，职责链\n* 模式可以避免请求的发送者和接收者之间的耦合关系，以及将请求的处理从发送者中分离出来。\n*\n* 职责链模式适用于以下情况：\n*\n* 多个对象都有机会处理请求，但是不知道哪个对象最终会处理请求。\n* 处理请求的对象集合可以动态配置，可以在运行时添加或删除处理对象。\n* 发送者不需要知道请求的处理细节，只需要知道请求会被处理。\n* 职责链模式常常应用于日志记录、异常处理、审批流程等场景。\n* */\n\nabstract class Chain {\n  Chain? nextChain;\n\n  void doRequest(String request);\n\n  void setChain(Chain chain) {\n    this.nextChain = chain;\n  }\n}\n\nclass Chain1 extends Chain {\n  @override\n  void doRequest(String request) {\n    if (request != null) {\n      if(request == 'request 1'){\n        print('Chain 1 do request');\n      }\n    } else {\n      if(nextChain != null) {\n        nextChain!.doRequest(request);\n      }\n    }\n  }\n}\n```\n\n## 命令模式\n\n```dart\n/*\n* 命令模式\n* 抽象命令：定义命令接口\n* 具体命令：定义具体命令，持有命令接受者的引用\n* 命令接受者：命令的实现的承包，实现具体命令\n* 调用者：持有具体命令的引用，调用命令的各个方法\n*\n* 一种行为设计模式，它将请求封装成一个对象，从而允许使用不同的请求、\n* 队列或者日志来参数化其他对象。命令模式的核心在于将请求和实现分离开，\n* 从而可以使请求具有独立的生命周期和实现。\n*\n* 命令模式是一种常见的设计模式，可以应用于各种场景中，例如：\n* 图形界面应用程序中的快捷键：将快捷键封装成一组命令对象，并将这些命令对象注册到快捷键管理器中，从而可以方便地进行调用和管理。\n* 服务器端应用程序中的请求处理：将请求封装成一组命令对象，并将这些命令对象注册到请求处理器中，从而可以方便地进行调用、传递和管理。\n* 游戏中的角色控制：将角色控制命令封装成一组命令对象，并将这些命令对象注册到角色管理器中，从而可以方便地进行调用、传递和管理。\n* */\n\n//抽象命令\nabstract class Command{\n  void command();\n}\n\n//具体命令\nclass StartCommand extends Command{\n  Accept accept;\n\n  StartCommand(this.accept);\n\n  @override\n  void command() {\n    print('具体命令开始');\n    accept.doCommand();\n    print('具体命令实现');\n  }\n\n}\n\n//抽象命令接受者/实现者\nabstract class Accept{\n  void doCommand();\n}\n\n//具体命令接受者/实现者\nclass AcceptImpl extends Accept{\n  void doCommand(){\n    print('具体命令的实现执行');\n  }\n}\n\n//命令调用者\nclass Invoke{\n  Command? command;\n  void setCommand(Command command){\n    this.command = command;\n  }\n\n  void startCommand(){\n    command?.command();\n  }\n\n}\n\n```\n\n## 组合模式\n\n```dart\n/*\n* 组合模式：树（层级）结构的对象集合\n* 抽象构件：叶子和组合构件的抽象\n* - 叶子构件：不含有子节点\n* - 组合构件：包含子节点的构件\n* */\n\n\nabstract class Component{\n  bool add(Component component);\n  bool remove(Component component);\n  void display();\n}\n\nclass Leaves extends Component{\n  @override\n  bool add(Component component) {\n    print('Leaves can not add');\n    return false;\n  }\n\n  @override\n  void display() {\n    print('I am a leaves');\n  }\n\n  @override\n  bool remove(Component component) {\n    print('Leaves can not remove');\n    return false;\n  }\n\n}\n\nclass Folder extends Component{\n  List<Component> list = [];\n\n  @override\n  bool add(Component component) {\n    list.add(component);\n    return true;\n  }\n\n  @override\n  void display() {\n    for(Component component in list){\n      component.display();\n    }\n  }\n\n  @override\n  bool remove(Component component) {\n    list.remove(component);\n    return true;\n  }\n\n}\n```\n\n## 装饰器模式\n\n```dart\n/*\n* 装饰器模式：拓展原有对象的功能\n* 抽象接口：被装饰类和装饰器类的接口定义\n* - 被装饰类\n* - 装饰器类\n* */\n\nabstract class Component {\n  void display();\n}\n\nclass ComponentA implements Component{\n  @override\n  void display() {\n    print('Component-A');\n  }\n\n}\n\nabstract class Decorator implements Component{\n  Component component;\n\n  Decorator(this.component);\n\n  @override\n  void display();\n\n}\n\nclass DecoratorExd extends Decorator{\n  DecoratorExd(super.component);\n\n  @override\n  void display() {\n    print('进行功能增强');\n    component.display();\n  }\n\n}\n```\n\n## 外观模式\n\n```dart\n/*\n* 外观模式：将复杂操作和细节隐藏起来\n* Facade：外观类\n* 子系统类：系统功能类\n* */\n\nclass System1 {\n  void display() {\n    print('system-1 display');\n  }\n}\n\nclass System2 {\n  void display() {\n    print('system-2 display');\n  }\n}\n\nclass Facade{\n  late System1 system1;\n  late System2 system2;\n\n  Facade(){\n    system1 = System1();\n    system2 = System2();\n  }\n\n  void display(){\n    system1.display();\n    system2.display();\n  }\n}\n```\n\n## 简单工厂模式\n\n```dart\n/// 简单工厂模式\nclass Factory{\n  static Product creat(String type){\n    Product product;\n    switch(type){\n      case 'A':\n        product = A('A');\n        break;\n      case 'B':\n        product = B('B');\n        break;\n      default:\n        product = A('dufault');\n    }\n    return product;\n  }\n}\n\nabstract class Product{\n  Product(this.name);\n  String? name;\n  void sayName();\n}\n\nclass A extends Product{\n  A(super.name);\n\n  @override\n  void sayName() {\n    print(name);\n  }\n}\n\nclass B extends Product{\n  B(super.name);\n  @override\n  void sayName() {\n    print(name);\n  }\n}\n\n/// 工厂方法模式\nabstract class AbstractFactory{\n  AbstractProduct create();\n}\n\nabstract class AbstractProduct{\n  void say();\n}\n\nclass FactoryA extends AbstractFactory{\n  @override\n  AbstractProduct create() {\n    return ProductA();\n  }\n}\n\nclass ProductA extends AbstractProduct{\n  @override\n  void say(){\n    print('Product-A');\n  }\n}\n```\n\n## 享元模式（轻量模式）\n\n```dart\n/*\n* 享元模式：FlyWeight，更愿称之为轻量模式。避免重复创建对象，节省开销。\n* 抽象享元类：创建对象的抽象类\n* 具体享元类：抽象享元的实现类\n* 享元工厂：创建/获取享元对象\n* */\n\n//抽象享元类\nabstract class Car{\n  void run();\n}\n\n//具体享元类\nclass Bike implements Car{\n  @override\n  void run() {\n    print('Bike can run!');\n  }\n\n}\n\n//享元工厂\nclass CarFactory{\n  static Map _cars = <String, Car>{};\n\n  static Car getOrCreateCar(String key){\n    Car? car = _cars[key];//没有，null，所以car需要可null声明\n    if(car == null){\n      _cars[key] = Bike();\n      return _cars[key];\n    }else{\n      return car;\n    }\n  }\n\n}\n```\n\n## 迭代器模式\n\n```dart\n/*\n* 迭代器模式\n* 抽象聚合类：抽象集合类，定义接口\n* 具体聚合类：具体集合类，实现接口，（持有集合引用）\n* 抽象迭代器：定义抽象操作\n* 具体迭代器：实现具体迭代操作\n*\n* 迭代器模式的场景包括：\n需要遍历一个聚合对象（如一个列表、数组等）中的元素，但是不想暴露聚合对象的内部结构。\n需要对聚合对象进行多种方式的遍历，如顺序遍历、倒序遍历等。\n需要在遍历过程中实现某些操作，如筛选、过滤等。\n需要在多个不同的聚合对象上进行相同的操作，而不需要关心它们的具体实现。\n需要提供一种统一的遍历接口，以便客户端可以使用相同的方式处理不同的聚合对象。\n\n例子：\n遍历一个网站上的文章列表，以便按照用户的需求进行排序、搜索等操作。\n遍历一个电商平台上的商品列表，以便实现商品的分类、筛选、排序等操作。\n遍历一个音乐播放器中的歌曲列表，以便实现歌曲的随机播放、循环播放等操作。\n遍历一个数据库中的数据表，以便实现数据的增删改查等操作。\n* */\n\n//抽象聚合类（抽象集合）\nabstract class Aggregate {\n  //定义添加方法\n  void add(Object object);\n\n  //定义移除方法\n  void remove(Object object);\n\n  //定义获取迭代器方法\n  Iterator getIterator();\n}\n\n//具体聚合类\nclass CustomCollection implements Aggregate {\n  List<String> strs = [];\n\n  @override\n  void add(Object object) {\n    strs.add(object as String);\n  }\n\n  @override\n  void remove(Object object) {\n    if (object is String) {\n      strs.remove(object);\n    }\n  }\n\n  @override\n  Iterator getIterator() {\n    return IteratorImpl(strs);\n  }\n}\n\n//抽象迭代器\nabstract class Iterator {\n  //获取下一个元素\n  Object next();\n\n  //是否有下一个元素\n  bool hasNext();\n}\n\n//具体迭代器\nclass IteratorImpl extends Iterator {\n  List<Object> list = [];\n  int index = 0;\n\n  IteratorImpl(this.list);\n\n  bool hasNext() {\n    return index < list.length;\n  }\n\n  Object next() {\n    return index < list.length ? list[index++] : Null;\n  }\n}\n\n```\n\n## 中介模式\n\n```dart\n/*\n* 中介者模式：各个同事类之间通过中介进行通信交互\n* 抽象中介：定义与同事类通信的方法\n* 具体中介：实现与同事类通信的方法\n* 抽象同事：定义与中介通信的方法，并持有中介的引用\n* 具体同事：实现与中介通信的方法\n*\n* 提供一个中介对象来协调一组对象之间的交互。中介者对象封装了一些对象之间的通信方式，\n* 使得它们不需要直接相互引用，从而降低它们之间的依赖性和耦合度。中介者模式常用于复杂\n* 的系统中，例如GUI系统、企业应用程序等。在这些系统中，对象之间的关系非常复杂，因此\n* 使用中介者模式可以使得系统更易于维护和扩展。\n*\n*\n* */\n\n//抽象中介\nabstract class Mediator{\n  void sendMessage(String message, Colleague colleague);\n}\n\n//具体中介\n//注册同事\nclass MediatorImpl implements Mediator{\n  Map<String, Colleague> map;\n\n  MediatorImpl(this.map);\n\n  void register(Colleague colleague){\n    String id = colleague.userId;\n    if(!map.containsKey(id)){\n      map[id] = colleague;\n      colleague.mediator = this;\n    }\n  }\n\n  @override\n  void sendMessage(String message, Colleague colleague) {\n    String id = colleague.userId;\n    if(map.containsKey(id)){\n      colleague.receiveMessage(message);\n    }else{\n      print('该用户未注册');\n    }\n  }\n\n}\n\n//抽象同事\n//发送消息，接收消息\nabstract class Colleague{\n  final String userId;\n  Mediator? mediator;\n  Colleague(this.userId);\n  Colleague.withMediator(this.mediator, this.userId);\n\n  void sendMessage(String message){\n    mediator?.sendMessage(message, this);\n  }\n\n  void receiveMessage(String message);\n}\n\n//具体同事\nclass User extends Colleague{\n  User(super.userId);\n\n  @override\n  void receiveMessage(String message) {\n    print('$userId has received message: $message');\n  }\n\n}\n```\n\n## 备忘录模式\n\n```dart\n/*\n* 备忘录模式\n* 发起者（存储对象）：\n* 备忘录（存储器）：\n* 管理者：\n*\n* 备忘录模式（Memento Pattern）在面向对象设计中被广泛应用，其主要作用是在不破坏封装性的前提下，捕获一个对象的内部状态，并在该对象之外保存这个状态，从而可以在需要的时候将对象恢复到先前的状态。\n下面是一些备忘录模式的应用场景：\n撤销操作：在许多应用程序中，用户执行操作时需要有“撤销”操作。通过备忘录模式，可以在执行操作前将当前对象的状态保存到备忘录中，当需要撤销时，从备忘录中获取之前保存的状态并恢复对象。\n数据库事务回滚：在数据库系统中，事务是一组被视为一个单独工作单元的操作。在执行事务时，如果发生了错误，需要将整个事务回滚到最初的状态。备忘录模式可以用来实现这种回滚，将事务执行前的状态保存到备忘录中，当出现错误时可以从备忘录中恢复原始状态。\n游戏存档：在许多游戏中，玩家需要保存游戏进度，以便在之后的时间里恢复到该点。备忘录模式可以用来保存游戏状态，让玩家在需要时回到先前的状态。\n操作系统恢复：当操作系统出现错误或崩溃时，需要将系统的状态恢复到某个先前的时间点。备忘录模式可以利用系统快照机制，将系统的状态保存到备忘录中，从而实现系统恢复。\n* */\n\n//备忘录\nclass TextMemento {\n  String text;\n\n  TextMemento(this.text);\n}\n\n//存储对象\nclass Text {\n  String text;\n\n  Text(this.text);\n\n  TextMemento createMemento() {\n    return TextMemento(text);\n  }\n\n  void restoreFromMemento(TextMemento memento){\n    text = memento.text;\n  }\n}\n\n//管理者\nclass History{\n  List<TextMemento> list = <TextMemento>[];\n  void push(TextMemento memento){\n    list.add(memento);\n  }\n  TextMemento pop(){\n    return list.removeLast();\n  }\n}\n```\n\n## 观察者模式\n\n```dart\n/*\n* 观察者模式\n*\n* 抽象观察对象:状态变更通知所有观察者\n* 具体观察对象\n* 抽象观察者\n* 具体观察对象\n* */\n\nabstract class Subject{\n  void addObserver(Observer observer);\n  void removeObserver(Observer observer);\n  void notifyObserver();\n}\n\nclass SubjectA implements Subject{\n  List<Observer> _observers = <Observer>[];\n  int _state;\n\n  SubjectA(this._state);\n\n  set state(int state){\n    _state = state;\n    notifyObserver();\n  }\n\n  int get state =>_state;\n\n  @override\n  void notifyObserver() {\n    for(Observer observer in _observers){\n      observer.response();\n    }\n  }\n\n  @override\n  void addObserver(Observer observer) {\n    _observers.add(observer);\n  }\n\n  @override\n  void removeObserver(Observer observer) {\n    _observers.remove(observer);\n  }\n\n}\n\nabstract class Observer{\n  void response();\n}\n\nclass ObserverA implements Observer{\n  @override\n  void response() {\n    print('Observer A 接收到通知');\n  }\n\n}\n```\n\n## 原型模式（浅克隆/深克隆）\n\n```dart\n```\n\n## 代理模式\n\n```dart\n/*\n* 代理模式：对被代理类进行功能增强\n* 抽象接口：定义接口方法\n* 真实类（被代理类）：实现抽象接口\n* 代理类：实现抽象接口，并持有真实类的引用\n* */\n\nabstract class Interface {\n  void display();\n}\n\nclass Real implements Interface {\n  @override\n  void display() {\n    print(\"real class display\");\n  }\n}\n\nclass Proxy implements Interface {\n  Interface? real;\n\n  void setReal(Interface real){\n    this.real = real;\n  }\n\n  @override\n  void display() {\n    print('代理开始');\n    real?.display();\n    print('代理结束');\n  }\n}\n```\n\n## 单例模式\n\n```dart\n/*\n* 单例模式\n* 该实现为饿汉式\n* 懒汉式，需要在工厂构造方法中实例化单例\n* */\nclass Singleton{\n  //私有静态变量，只能通过工厂构造方法获取单例\n  static Singleton _singleton = Singleton._create();\n\n  // 私有命名构造方法\n  Singleton._create();\n\n  //工厂构造方法，只能访问静态方法、静态属性\n  factory Singleton(){\n    return _singleton;\n  }\n}\n```\n\n## 状态模式\n\n```dart\n/*\n* 状态模式：状态发生改变时，行为也随之改变\n*\n* 上下文Context\n* 抽象状态State\n* 具体状态\n* */\n\n//抽象状态\nabstract class Light {\n  void handle();\n}\n\n//具体状态\nclass RedLight implements Light {\n  @override\n  void handle() {\n    print('Red Light:红灯');\n  }\n}\n\nclass GreenLight implements Light{\n  @override\n  void handle() {\n    print('Green Light:绿灯');\n  }\n\n}\n\n//上下文\nclass Context {\n  Light? state;\n\n  Context();\n\n  void handle(){\n    state?.handle();\n  }\n}\n```\n\n## 策略模式\n\n```dart\n/*\n* 策略模式\n*\n* 环境Context（上下文）\n* 抽象策略\n* 具体策略\n*\n* TODO:和状态模式有什么区别？\n* */\n\nabstract class Strategy{\n  void doOperation(int a, int b);\n}\n\n//具体策略\nclass StrategyOne implements Strategy{\n  @override\n  void doOperation(int a, int b) {\n    print(a-b);\n  }\n\n}\n\nclass StrategyTwo implements Strategy{\n  @override\n  void doOperation(int a, int b) {\n    print(a+b);\n  }\n\n}\n\nclass Context{\n  Strategy strategy;\n  Context(this.strategy);\n  void doOperation(int a, int b){\n    strategy.doOperation(a, b);\n  }\n}\n```\n\n## 模板模式\n\n```dart\n/*\n* 模板方法：定义了算法的骨架，具体细节交由算法实现类完成\n*\n* 抽象模板类：算法骨架类\n* 具体算法类：实现骨架类的算法细节\n*\n* */\n\nabstract class Template {\n  void display() {\n    print('AAA');\n    run();\n    print('BBB');\n  }\n\n  run();\n}\n\nclass TemplateImplA extends Template{\n  @override\n  run() {\n    print('TemplateImplA');\n  }\n\n}\n\nclass TemplateImplB extends Template{\n  @override\n  run() {\n    print('TemplateImplB');\n  }\n\n}\n```\n\n"},{"title":"JUC学习笔记","url":"/2022/08/11/juc-xue-xi-bi-ji/","content":"# 基础概念\n**JUC**\n即Java并发编程工具包，java.util.concurren。\n\n**用户线程和守护线程**\n当用户线程不存在时，守护线程也会随之结束，守护线程的生命周期和JVM相同（守护线程似乎顾名思义，守护用户线程，用户线程不存在时守护线程也没有了存在的意义） \n\n**管程**\n即Monitor(监视器)，即平时所说的锁\n\n- Monitor其实是一种同步机制,它的义务是保证(在同一时间)只有一个线程可以访问被保护的数据和代码\n- JVM中同步时基于进入和退出的监视器对象(Monitor,管程),每个对象实例都有一个Monitor对象。\n- Monitor对象和JVM对象一起销毁,底层由C来实现\n\n# 线程创建\n- 继承Thread类\n- 实现Runnable接口\n- 使用Callable接口\n- 使用线程池\n\n## 1. 继承Thread类\n```java\n\tpublic class ThreadDemo{\n\t    public static void main(String[] args) {\n\t        //4.创建Thread类的子类对象\n\t        MyThread myThread=new MyThread();\n\t        //5.调用start()方法开启线程\n\t        //[ 会自动调用run方法这是JVM做的事情,源码看不到 ]\n\t        myThread.start();\n\t        for (int i = 0; i < 100; i++) {\n\t            System.out.println(\"我是主线程\"+i);\n\t        }\n\t    }\n\t}\n\tclass MyThread extends Thread{\n\t    //2.重写run方法\n\t    public void run(){\n\t        //3.将要执行的代码写在run方法中\n\t       for(int i=0;i<100;i++){\n\t           System.out.println(\"我是线程\"+i);\n\t       }\n\t    }\n\t}\n\n```\n\n## 2. 实现Runnable接口\n```java\npublic class RunnableDemo {\n    public static void main(String[] args) {\n        //4.创建Runnable的子类对象\n        MyRunnale mr=new MyRunnale(); \n        //5.将子类对象当做参数传递给Thread的构造函数,并开启线程\n        //MyRunnale taget=mr; 多态\n        new Thread(mr).start();\n        for (int i = 0; i < 1000; i++) {\n            System.out.println(\"我是主线程\"+i);\n        }\n    }\n}\n\n//1.定义一个类实现Runnable\nclass MyRunnale implements Runnable{\n    //2.重写run方法\n    @Override\n    public void run() {\n        //3.将要执行的代码写在run方法中\n        for (int i = 0; i < 1000; i++) {\n            System.out.println(\"我是线程\"+i);\n        }\n    }\n}\n\n```\n\n## 3. 使用Callable接口\n需要借助FutureTask类来实现，类似适配器模式。\n```java\n\t/*\n\t创建线程的方式三: 实现callable接口 ---JDK 5.0 新增\n\t1.创建一个实现Callable接口的实现类\n\t2.实现call方法,将此线程需要执行的操作声明在call()中\n\t3.创建callable接口实现类的对象\n\t4.将此callable的对象作为参数传入到FutureTask构造器中,创建FutureTask的对象\n\t5.将FutureTask对象作为参数传递到Thread类的构造器中,创建Thread对象,并调用star\n\t6.获取callable接口中call方法的返回值\n\t* */\n\tpublic class ThreadNew {\n\t    public static void main(String[] args) {\n\t        //3.创建callable接口实现类的对象\n\t        NumThead m=new NumThead();\n\t        //4.将此callable的对象作为参数传入到FutureTask构造器中,创建FutureTask的对象\n\t        \n\t        FutureTask futureTask = new FutureTask(m);\n\t        //5.将FutureTask对象作为参数传递到Thread类的构造器中,创建Thread对象,并调用start()方法\n\t        //FutureTask类继承了Runnable接口\n\t        //new Runnable = futrueTask;\n\t        new Thread(futureTask).start();\n\t\n\t        //6.获取callable接口中call方法的返回值\n\t        try {\n\t            //get()方法返回值即为FutureTask构造器参数callable实现类重写的call方法的返回值\n\t            Object sum = futureTask.get();\n\t            System.out.println(\"总和是:\"+sum);\n\t        } catch (Exception e) {\n\t            e.printStackTrace();\n\t        }\n\t    }\n\t\n\t}\n\t//1.创建一个实现Callable接口的实现类\n\tclass  NumThead implements Callable{\n\t   // class  NumThead implements Callable<Integer>{\n\t    //2.实现call方法,将此线程需要执行的操作声明在call()中\n\t    @Override\n\t    public Object call() throws Exception {\n\t    //public Integer call() throws Exception {\n\t        int sum=0;\n\t        for(int i=1;i<=100;i++){\n\t            System.out.println(i);\n\t            sum+=i;\n\t        }\n\t        return sum;\n\t    }\n\t}\n\n```\n\n**多线程/有返回值/异步任务**\nFutureTask实现了RunnableFuture接口，进而实现了Future和Runnable接口。\n- 可与Runnable实现无返回值的多线程创建\n- 与Callable接口一起实现有返回值的多线程创建，达到了`多线程/有返回值/异步任务`要求。\n\n**FutureTask**\nget()：在Future完成计算前会使当前线程阻塞，知道计算完成\nisDone()：查询Future是否完成计算\n\n可以结合使用isDone()和get()，利用轮询的方式来获取Future的计算结果，但是会消耗CPU性能。\n```java\nwhile(true){\n\tif(futureTask.isDone()){\n\t\tSystem.out.println(futureTask.get());\n\t}\n}\n```\n\n## 4. 使用线程池\n\n## 编程步骤\n1. 创建资源类，创建属性和操作方法\n2. 创建多个线程，调用资源类的操作方法\n\t- 判断，同时防止虚假唤醒\n\t- 干活\n\t- 通知\n```java\n//创建资源类，定义属性和操作方法\nclass Share {\n\tprivate int number = 0；\n\t\n\t//+1方法\n\tpublic synchronized void incr(){\n\t\t//判断，用while而不是if，防止虚假唤醒\n\t\twhile(number != 0){\n\t\t\tthis.wait();\n\t\t}\n\t\t//干活\n\t\tnumber++;\n\t\tSystem.out.println(Thread.currentThread( ).getName()+\" :: \"+number);\n\t\t//通知\n\t\tthis.notifyAll();\n\t}\n\t\n\t//-1方法\n\tpublic synchronized void decr(){\n\t\t//判断，用while而不是if，防止虚假唤醒\n\t\twhile(number != 1){\n\t\t\tthis.wait();\n\t\t}\n\t\t//干活\n\t\tnumber--;\n\t\tSystem.out.println(Thread.currentThread( ).getName()+\" :: \"+number);\n\t\t//通知\n\t\tthis.notifyAll();\n\t}\n}\n\npublic class ThreadDemo1 {\n\t//创建多线程，调用资源类的操作方法\n\tpublic static void main(String[ ] args) {\n\t\tShare share = new Share();\n\t\t//创建多线程\n\t\tnew Thread(()->{\n\t\t\tfor(int i = 1; i < 10; i++){\n\t\t\t\ttry{\n\t\t\t\t\tshare.incr();\t//+1\n\t\t\t\t} catch(InterruptedException e){\n\t\t\t\t\te.printStackTrace();\n\t\t\t\t}\n\t\t\t}\n\t\t}, \"AA\").start();\n\t\t\n\t\tnew Thread(()->{\n\t\t\tfor(int i = 1; i < 10; i++){\n\t\t\t\ttry{\n\t\t\t\t\tshare.decr();\t//-1\n\t\t\t\t} catch(InterruptedException e){\n\t\t\t\t\te.printStackTrace();\n\t\t\t\t}\n\t\t\t}\n\t\t}, \"BB\").start();\n\t\t\n\t\tnew Thread(()->{\n\t\t\tfor(int i = 1; i < 10; i++){\n\t\t\t\ttry{\n\t\t\t\t\tshare.incr();\t//+1\n\t\t\t\t} catch(InterruptedException e){\n\t\t\t\t\te.printStackTrace();\n\t\t\t\t}\n\t\t\t}\n\t\t}, \"CC\").start();\n\t\t\n\t\tnew Thread(()->{\n\t\t\tfor(int i = 1; i < 10; i++){\n\t\t\t\ttry{\n\t\t\t\t\tshare.decr();\t//-1\n\t\t\t\t} catch(InterruptedException e){\n\t\t\t\t\te.printStackTrace();\n\t\t\t\t}\n\t\t\t}\n\t\t}, \"DD\").start();\n\t}\n}\n```\n\n**虚假唤醒**\n由于wait()**在哪里睡着就在哪里起来**的特性，会出现在直接在**if**条件体中唤醒，继续向下执行，从而跳过条件判断。使用**while**循环解决虚假唤醒问题，即使在循环体中唤醒也要走一遍**while**循环条件的判断。\n\n# synchronized\n可被上锁的内容：\n- 代码块：被修饰的代码块称为同步语句块，其作用的范围是大括号{}括起来的代码，作用的对象是调用这个代码块的对象\n- 方法：被修饰的方法称为同步方法，其作用的范围是整个方法，作用的对象是调用这个方法的对象\n- 静态方法：作用的范围是整个静态方法，作用的对象是这个类的所有对象\n- 作用的范围是synchronized后面括号括起来的部分，作用主的对象是这个类的所有对象\n\nsynchronized是不能被子类继承的，子类方法要使用synchronized需显式声明。虽然synchronized不能被继承，但是子类调用父类的synchronized方法时，方法是同步的。\n\n## 单例\n**多线程下的单例实现**\n传统单例（懒汉式）\n```java\npublic class Singleton {\n    private static Singleton instance;\n    private Singleton (){}\n\n    public static Singleton getInstance() {\n     if (instance == null) {\n         instance = new Singleton();\n     }\n     return instance;\n    }\n}\n```\n问题：并发情况下，多个线程调用getInstance()，会创建多个对象，单例失效。\n解决方案：使用`synchronized`修饰getInstance()方法\n```java\npublic class Singleton {\n    private static Singleton instance;\n    private Singleton (){}\n    public static synchronized Singleton getInstance() {//封死了\n        if (instance == null) {\n            instance = new Singleton();\n        }\n        return instance;\n    }\n}\n```\n以上代码实际也有缺点：虽然做到了线程安全，并且解决了多实例的问题，但是它并不高效。因为在任何时候只能有一个线程调用getInstance()方法，其余线程都在空转等待。\n解决方案：因为同步操作只需要在第一次调用时才被需要，即第一次创建单例实例对象时。因此在进入同步代码块之前一次非`null`检查，在单例对象`new`出后，其余线程便不会进入同步代码块。（保证只有一个线程`new`出单例，但仍然可能有其他线程等待锁释放后进入同步代码块，但是这个数量要比没有双重检验锁之前少得多，因为有一部分线程被第一次检查拒之门外）\n**双重检验锁**\n```java\npublic class Singleton {\n\n    private volatile static Singleton uniqueInstance;\n\n    private Singleton() {\n    }\n\n    public  static Singleton getUniqueInstance() {\n       //先判断对象是否已经实例过，没有实例化过才进入加锁代码\n        if (uniqueInstance == null) {//Single Checked\n            //类对象加锁\n            synchronized (Singleton.class) {\n                if (uniqueInstance == null) {//Double Checked\n                    uniqueInstance = new Singleton();\n                }\n            }\n        }\n        return uniqueInstance;\n    }\n}\n```\n\n## 底层机制\n**为什么每个对象可以成为一个锁呢**\nmarkOop.hpp\n{% asset_img 013.png %}\n\nMonitor(监视器锁)可以理解为一种同步工具，也可理解为一种同步机制，常常被描述为一个Java对象。Java对象是天生的Monitor，每一个Java对象都有成为Monitor的潜质，因为在Java的设计中 ，每一个Java对象自打娘胎里出来就带了一把看不见的锁，它叫做内部锁或者Monitor锁。\n\nMonitor的本质是依赖于底层操作系统的Mutex Lock实现，操作系统实现线程之间的切换需要从用户态到内核态的转换，成本非常高。\nMutex Lock Monitor是在jvm底层实现的，底层代码是c++。本质是依赖于底层操作系统的Mutex Lock实现，操作系统实现线程之间的切换需要从用户态到内核态的转换，状态转换需要耗费很多的处理器时间成本非常高。所以synchronized是Java语言中的一个重量级操作。\n\nMonitor与java对象以及线程是如何关联 ？ \n1. 如果一个java对象被某个线程锁住，则该java对象的Mark Word字段中LockWord指向monitor的起始地址 \n2. Monitor的Owner字段会存放拥有相关联对象锁的线程id\n\nMutex Lock 的切换需要从用户态转换到核心态中，因此状态转换需要耗费很多的处理器时间。\n\n**同步代码块**\n```java\npublic class SynchronizedDemo {\n    public void method() {\n        synchronized (this) {\n            System.out.println(\"synchronized 代码块\");\n        }\n    }\n}\n```\n通过JDK自带的javap命令查看SynchronizedDemo类的相关字节码信息:\n1. 首先切换到类的对应目录执行javac SynchronizedDemo.java命令生成编译后的.class文件\n2. 然后执行javap -c -s -v -l SynchronizedDemo.class\n{% asset_img 001.png %}\n\n可以看出`synchronized同步语句块`借助monitorenter和monitorexit指令\n- monitorenter指令指向同步代码块的开始位置\n- monitorexit指令则指明同步代码块的结束位置\n\n当执行`monitorenter`指令时，线程试图获取锁也就是获取`对象监视器monitor(管程)`的持有权。在Java虚拟机(HotSpot)中，Monitor是基于C++实现的，由ObjectMonitor实现的。每个对象中都内置了一个ObjectMonitor对象。另外`wait/notify`等方法也依赖于`monitor`对象，这就是为什么只有在同步的块或者方法中才能调用wait/notify等方法，否则会抛出java.lang.llegalMonitorStateException的异常的原因。\n- 在执行monitorenter时，会尝试获取对象的锁，如果锁的计数器为О则表示锁可以被获取，获取后将锁计数器设为1也就是加1。\n- 在执行monitorexit指令后，将锁计数器设为0，表明锁被释放。如果获取对象锁失败，那当前线程就要阻塞等待，直到锁被另外一个线程释放为止。\n\n**同步方法**\n```java\npublic class SynchronizedDemo2 {\n    public synchronized void method() {\n        System.out.println(\"synchronized 方法\");\n    }\n}\n```\n{% asset_img 002.png %}\n\n**synchronized原理总结**\n1. synchronized同步语句块的实现使用的是monitorenter和monitorexit 指令，其中monitorenter指令指向同步代码块的开始位置，monitorexit 指令则指明同步代码块的结束位置。\n2. synchronized修饰的方法并没有monitorenter指令和monitorexit 指令，取得代之的确实是ACC_SYNCHRONIZED标识，该标识指明了该方法是一个同步方法。\n3．不过两者的本质都是对对象监视器monitor的获取。\n\n{% asset_img 015.png %}\n\n## 对象内存布局\n创建一个Java对象\n```java\nObject o = new Object();\n```\n- 类型在方法区\n- o引用在栈区\n- new Object()在堆区\n{% asset_img 005.jpg %}\n\nJVM虚拟机（HotSpot）中，对象在堆内存中的存储布局分三个部分：\n- 对象头（Header）\n- 实例数据（Instance Data）\n- 对齐填充（Padding）：保证为8字节的倍数\n{% asset_img 004.jpg %}\n\n**对象头**\n对象头中包含两部分:\n- MarkWord : Mark Word用于存储对象自身的运行时数据，如HashCode、GC分代年龄、锁状态标志、线程持有的锁、偏向线程ID等等\n- 类型指针:虚拟机通过这个指针确定该对象是哪个类的实例\n- 如果是数组对象的话，对象头还有一部分是存储数组的长度\n{% asset_img 006.png %}\n\n多线程下synchronized 的加锁就是对同一个对象的对象头中的MarkWord中的变量进行CAS操作。\n\n**对象标记Mark Word**\n{% asset_img 007.png %}\n{% asset_img 008.png %}\nGC年龄采用4位bit存储,最大为15,例如MaxTenuringThreshold参数默认值就是15，因为GC年龄占4位最大就是1111=15\n\n**类元信息（类型指针）**\n对象指向它的类元数据的指针\n虚拟机通过这个指针来确定这个对象是哪个类的实例\n\n```java\npublic class CustomerTest {\n    public static void main(String[] args) {\n        Customer cust = new Customer();\n    }\n}\n```\n{% asset_img 009.png %}\n\n在64位系统中，Mark Word占了8个字节，类型指针占了8个字节，一共是16个字节。上述代码实例中对象`o`共占16字节大小，即Java中，对象内存最小为16字节（JVM开启压缩编码时，实际为12字节，但是对其填充为16字节）\n\n## 内存分析JOL\n依赖\n```xml\n\t<!--\n\tJAVA object layout\n\t官网:http://openjdk.java.net/projects/code-tools/jol/\n\t定位:分析对象在JVM的大小和分布\n\t-->\n\t<dependency>\n\t    <groupId>org.openjdk.jol</groupId>\n\t    <artifactId>jol-core</artifactId>\n\t    <version>0.9</version>\n\t</dependency>\n```\n使用示例\n```java\npublic class JOLDemo{\n    public static void main(String[] args){\n        Object o = new Object();\n        System.out.println( ClassLayout.parseInstance(o).toPrintable());\n    }\n}\n```\n测试结果\n{% asset_img 010.png %}\nPS：\n- 左边的二进制数据采用的是小端序，从左向右为从低位到高位，但是每一字节从左到右为从高位到低位\n- 类型指针只占4字节，是因为JVM默认开启类型指针压缩\n\n对象有属性值情况\n{% asset_img 011.png %}\n{% asset_img 012.png %}\n\n## 偏向锁\n使用synchronized加锁，JVM底层会对锁进行优化，具体可分为三种锁：偏向锁、轻量级锁、重量级锁。其中**偏向锁**和**轻量级锁**都不涉及CPU的用户态和内核态的切换（切换是十分消耗性能的）。\n\n三种锁分别对应三种情况\n1. 只有一个线程来访问，有且唯一Only One\n2. 有2个线程A、B来交替访问（具体线程不固定，可能A执行完后变成B、C交替执行）\n3. 竞争激烈，多个线程来访问\n\n**产生背景**\n多线程的情况下，锁不仅不存在多线程竞争，还存在锁由同一线程多次获得的情况。\n偏向锁就是在这种情况下出现的，它的出现是为了解决只有在一个线程执行同步时提高性能。当一段同步代码一直被同一个线程多次访问，由于只有一个线程那么该线程在后续访问时便会自动获得锁\n\n锁标志位：01。（每个对象默认的锁标志位为`01`，无锁状态下偏向锁位为`0`，有锁状态下为`1`）\n{% asset_img 014.png %}\n\n**偏向锁流程**\n1. 锁被第一次占有时，会在Mark Word中记录下`线程ID`，如果此线程后续再试图获得该锁，JVM会比较对象标记中的`线程ID`和此线程ID，结果一致直接放行，不用再获取锁，代码执行完也不需释放锁。偏向线程会一直持有锁，只有发生线程竞争时，锁才会释放。\n2. 如果是其他线程试图获取锁，比较发现锁中的`线程ID`和线程ID不一致，便会产生竞争，进行CAS操作试图获取该锁：\n- 获得锁成功：之前的偏向线程可能已经执行完成或者不存在，将新线程的ID写入对象标记Mark Word中，此时锁类型依然为偏向锁，不会升级。（可以理解为白班和夜班的工作交接）\n- 获得锁失败：之前偏向线程依然在执行，锁获得失败。此时发生了线程竞争，此时锁升级为轻量级锁，保证多线程间进行锁竞争（可以理解为多人面试同一份工作）\n\n**总结**\n偏向锁使用一种等到竞争出现才释放锁的机制，只有当其他线程竞争锁时，持有偏向锁的原来线程才会被撤销。 撤销需要等待全局安全点(该时间点上没有字节码正在执行)，同时检查持有偏向锁的线程是否还在执行：\n- 第一个线程正在执行synchronized方法(处于同步块)，它还没有执行完，其它线程来抢夺，该偏向锁会被取消掉并出现锁升级。 此时轻量级锁由原持有偏向锁的线程持有，继续执行其同步代码，而正在竞争的线程会进入自旋等待获得该轻量级锁。 \n- 第一个线程执行完成synchronized方法(退出同步块)，则将对象头设置成无锁状态并撤销偏向锁，重新偏向 。\n\n优点：由于偏向锁执行同步代码块或方法不需要进行锁的获得和释放，JVM不用和操作系统协商设置Mutex(争取内核)，几乎没有额外开销，性能极高。\n\n**关闭偏向锁**\n关闭偏向锁:使用-XX:-UseBiasedLocking启动参数，偏向锁关闭之后程序默认会直接进入轻量级锁状态\n\n## 轻量级锁\n有线程来参与锁的竞争，但是获取锁的冲突时间极短。本质就是自旋锁\n\n轻量级锁是为了在线程近乎交替执行同步块时提高性能。 主要目的： 在没有多线程竞争的前提下，通过CAS减少重量级锁使用操作系统互斥量产生的性能消耗，说白了先自旋再阻塞。 升级时机： 当关闭偏向锁功能或多线程竞争偏向锁会导致偏向锁升级为轻量级锁\n\n锁标志位：00\n\n**轻量锁流程（同偏向锁）**\n偏向锁由线程A持有，线程B进行CAS操作试图获取锁。\n锁获取失败，则偏向锁升级为轻量级锁，此时轻量级锁由原持有偏向锁的线程持有，继续执行其同步代码，而正在竞争的线程B会进入自旋等待获得该轻量级锁。\n\n自旋次数\njava6之前，默认启用，默认情况下自旋的次数是10次`-XX:PreBlockSpin=10`来修改，或者自旋线程数超过cpu核数一半\nJava6之后自适应，自适应意味着自旋的次数不是固定不变的，而是根据：同一个锁上一次自旋的时间，拥有锁线程的状态来决定。\n\n**轻量锁与偏向锁的区别**\n争夺轻量级锁失败时，自旋尝试抢占锁。轻量级锁每次退出同步块都需要释放锁，而偏向锁是在竞争发生时才释放锁\n\n## 重量级锁\n有大量的线程参与锁的竞争，冲突性很高\n\n锁标识位：10\n{% asset_img 016.png %}\n\n**三种锁对比**\n{% asset_img 017.png %}\nsynchronized锁升级过程总结：一句话，就是先自旋，不行再阻塞。 实际上是把之前的悲观锁(重量级锁)变成在一定条件下使用偏向锁以及使用轻量级(自旋锁CAS)的形式\n\nsynchronized内部实现还是基于对象头的MarkWord来实现的。 JDK1.6之后拥有了无锁->偏向锁->轻量级锁->重量级锁的升级过程，而不是无论什么情况都使用重量级锁。\n- 偏向锁:适用于单线程适用的情况，在不存在锁竞争的时候进入同步方法/代码块则使用偏向锁。 \n- 轻量级锁：适用于竞争较不激烈的情况(这和乐观锁的使用范围类似)， 存在竞争时升级为轻量级锁，轻量级锁采用的是自旋锁，如果同步方法/代码块执行时间很短的话，采用轻量级锁虽然会占用cpu资源但是相对比使用重量级锁还是更高效。\n- 重量级锁：适用于竞争激烈的情况，如果同步方法/代码块执行时间很长，那么使用轻量级锁自旋带来的性能消耗就比使用重量级锁更严重，这时候就需要升级为重量级锁。\n\n## JIT锁优化\nJIT：Just In Time Compiler，即时编译器\n1. 锁消除\n```java\n/**\n * 锁消除\n * 从JIT角度看相当于无视它，synchronized (o)不存在了,这个锁对象并没有被共用扩散到其它线程使用，\n * 极端的说就是根本没有加这个锁对象的底层机器码，消除了锁的使用\n */\npublic class LockClearUPDemo\n{\n    static Object objectLock = new Object();//正常的\n\n    public void m1()\n    {\n        //锁消除,JIT会无视它，synchronized(对象锁)不存在了。不正常的\n        Object o = new Object();\n\n        synchronized (o)\n        {\n            System.out.println(\"-----hello LockClearUPDemo\"+\"\\t\"+o.hashCode()+\"\\t\"+objectLock.hashCode());\n        }\n    }\n\n    public static void main(String[] args)\n    {\n        LockClearUPDemo demo = new LockClearUPDemo();\n\n        for (int i = 1; i <=10; i++) {\n            new Thread(() -> {\n                demo.m1();\n            },String.valueOf(i)).start();\n        }\n    }\n}\n```\n\n2. 锁粗化\n```java\n/**\n * 锁粗化\n * 假如方法中首尾相接，前后相邻的都是同一个锁对象，那JIT编译器就会把这几个synchronized块合并成一个大块，\n * 加粗加大范围，一次申请锁使用即可，避免次次的申请和释放锁，提升了性能\n */\npublic class LockBigDemo\n{\n    static Object objectLock = new Object();\n\n\n    public static void main(String[] args)\n    {\n        new Thread(() -> {\n            synchronized (objectLock) {\n                System.out.println(\"11111\");\n            }\n            synchronized (objectLock) {\n                System.out.println(\"22222\");\n            }\n            synchronized (objectLock) {\n                System.out.println(\"33333\");\n            }\n        },\"a\").start();\n\n        new Thread(() -> {\n            synchronized (objectLock) {\n                System.out.println(\"44444\");\n            }\n            synchronized (objectLock) {\n                System.out.println(\"55555\");\n            }\n            synchronized (objectLock) {\n                System.out.println(\"66666\");\n            }\n        },\"b\").start();\n\n    }\n}\n```\n\n# volatile\n**volatile内存语义**\n- 当写一个volatile变量时，JMM会把该线程对应的本地内存中的共享变量值立即刷新回主内存中。\n- 当读一个volatile变量时，JMM会把该线程对应的本地内存设置为无效，直接从主内存中读取共享变量\n- 所以volatile的写内存语义是直接刷新到主内存中，读的内存语义是直接从主内存中读取\n\n## JMM内存模型\nJMM中规定\n- 所有的共享变量都存储于主内存。这里所说的变量指的是实例变量和类变量，不包含局部变量，因为局部变量是线程私有的,因此不存在竞争问题\n- 每一个线程还存在自己的工作内存，线程的工作内存，保留了被线程使用的变量的工作副本\n- 线程对变量的所有的操作(读，取)都必须在工作内存中完成，而不能直接读写主内存中的变量\n- 不同线程之间也不能直接访问对方工作内存中的变量，线程间变量的值的传递需要通过主内存中转来完成\n\n{% asset_img 018.jpg %}\n\n多线程环境下的问题\n可能有线程对共享变量的修改没有即时更新到主内存，或者线程没能够即时将共享变量的最新值同步到工作内存中，从而使得线程在使用共享变量的值时，该值并不是最新的。因此出现了变量的不可见性问题。\n\n`volatile`的出现是为了解决变量在线程间的可见性问题\n\n解决可见性的几种方案\n**方案1：加锁synchronized**\n\n```java\n/**\n  * main 方法作为一个主线程\n  */\n  public static void main(String[] args) {\n      MyThread myThread = new MyThread();\n      // 开启线程\n      myThread.start();\n\n      // 主线程执行\n      for (; ; ) {\n          synchronized (myThread) {\n              if (myThread.isFlag()) {\n                  System.out.println(\"主线程访问到 flag 变量\");\n                }\n          }\n      }\n  }\n/**\n * 子线程类\n */\nclass MyThread extends Thread {\n\n    private boolean flag = false;\n\n    @Override\n    public void run() {\n        try {\n            Thread.sleep(1000);\n        } catch (InterruptedException e) {\n            e.printStackTrace();\n        }\n        // 修改变量值\n        flag = true;\n        System.out.println(\"flag = \" + flag);\n    }\n\n    public boolean isFlag() {\n        return flag;\n    }\n\n    public void setFlag(boolean flag) {\n        this.flag = flag;\n    }\n}\n```\n为什么加锁后就保证了变量的内存可见性了?\n1. 因为当一个线程进入synchronizer代码块后，线程获取到锁，会清空本地内存，然后从主内存中拷贝共享变量的最新值到本地内存作为副本\n2． 将修改后的副本值刷新到主内存中，执行代码，最后线程释放锁\n\n**方案2：volatile修饰共享变量**\n```java\n/**\n * 变量的内存可见性例子\n *\n * @author star\n */\npublic class VolatileExample {\n\n    /**\n     * main 方法作为一个主线程\n     */\n    public static void main(String[] args) {\n        MyThread myThread = new MyThread();\n        // 开启线程\n        myThread.start();\n\n        // 主线程执行\n        for (; ; ) {\n            if (myThread.isFlag()) {\n                System.out.println(\"有点东西\");\n            }\n        }\n    }\n\n}\n/**\n * 子线程类\n */\nclass MyThread extends Thread {\n\n    private volatile boolean flag = false;\n\n    @Override\n    public void run() {\n        try {\n            Thread.sleep(1000);\n        } catch (InterruptedException e) {\n            e.printStackTrace();\n        }\n        // 修改变量值\n        flag = true;\n        System.out.println(\"flag = \" + flag);\n    }\n\n    public boolean isFlag() {\n        return flag;\n    }\n\n    public void setFlag(boolean flag) {\n        this.flag = flag;\n    }\n}\n```\nVolatile做了啥?\n使用volatile修饰共享变量后，每个线程要操作变量时会从主内存中将变量拷贝到本地内存作为副本，当线程操作变量副本并写回主内存后，会通过CPU**总线嗅探机制**告知其他线程该变量副本已经失效，需要重新从主内存中读取。\nvolatile保证了不同线程对共享变量操作的可见性，也就是说一个线程修改了volatile修饰的变量，当修改后的变量写回主内存时，其他线程能立即看到最新值。\n\n## 总线嗅探机制\n由于CPU与内存之间加入了缓存，在进行数据操作时，先将数据从内存拷贝到缓存中，CPU直接操作的是缓存中的数据。但在多处理器下，将可能导致各自的缓存数据不一致(这也是可见性问题的由来)，为了保证各个处理器的缓存是一致的，就会实现缓存—致性协议，而嗅探是实现缓存一致性的常见机制。\n注意，缓存的一致性问题，不是多处理器导致，而是多缓存导致的。\n{% asset_img 019.png %}\n\n**嗅探机制工作原理**\n每个处理器通过监听在总线上传播的数据来检查自己的缓存值是不是过期了，如果处理器发现自己缓存行对应的内存地址修改，就会将当前处理器的缓存行设置无效状态，当处理器对这个数据进行修改操作的时候，会重新从主内存中把数据读到处理器缓存中。\n\n**总线风暴**\n基于CPU缓存一致性协议，JVM实现了volatile的可见性，但由于总线嗅探机制，会不断的监听总线，如果大量使用volatile会引起总线风暴。所以，volatile的使用要适合具体场景。\n\n## 原子性\n**volatile的原子性问题**\nvolatile无法保证原子性\n- 在多线程环境下，volatile 关键字可以保证共享数据的可见性，但是并不能保证对数据操作的原子性。即多线程环境下，使用volatile修饰的变量是线程不安全的。要解决这个问题，我们可以使用锁机制，或者使用原子类(如AtomicInteger)\n- 对任意单个使用volatile修饰的变量的读/写是具有原子性，但类似于flag = !flag这种复合操作不具有原子性。简单地说就是，**单纯的赋值操作是原子性的**\n\n示例\n变量`i`由`volatile`修饰，`i++`操作并不是原子操作，分以下三步：\n1. 从主内存读\n2. 加操作\n3. 写到主内存\n\n因为i++不是原子操作，多线程下可能有几种情况:\n1. i =1;没有其他线程干扰 i+1=2，结果正确\n2. 其他线程先执行i+1，现在i=2，因为线程的可见性，i+1=3，最后的结果为3，结果正确\n3. 其他线程执行了i+1，i=2，但是此时恰好是i+1已经读取过，生产中间值2，此时赋值后i=2，结果错误因此,volatile并不能保证变量的原子性\n\n代码示例\n```java\nclass MyNumber\n{\n    volatile int number = 0;\n\n    public void addPlusPlus()\n    {\n        number++;\n    }\n}\n\npublic class VolatileNoAtomicDemo\n{\n    public static void main(String[] args) throws InterruptedException\n    {\n        MyNumber myNumber = new MyNumber();\n\n        for (int i = 1; i <=10; i++) {\n            new Thread(() -> {\n                for (int j = 1; j <= 1000; j++) {\n                    myNumber.addPlusPlus();\n                }\n            },String.valueOf(i)).start();\n        }\n        \n        //暂停几秒钟线程\n        try { TimeUnit.SECONDS.sleep(3); } catch (InterruptedException e) { e.printStackTrace(); }\n        System.out.println(Thread.currentThread().getName() + \"\\t\" + myNumber.number);\n    }\n}\n```\n从i++的字节码角度说明\n{% asset_img 021.png %}\n\n原子性指的是一个操作是不可中断的，即使是在多线程环境下，一个操作一旦开始就不会被其他线程影响。\n```java\npublic void add()\n{\n        i++; //不具备原子性，该操作是先读取值，然后写回一个新值，相当于原来的值加上1，分3步完成\n}\n```\n如果第二个线程在第一个线程读取旧值和写回新值期间读取i的域值，那么第二个线程就会与第一个线程一起看到同一个值，并执行相同值的加1操作，这也就造成了线程安全失败。因此对于add方法必须使用synchronized修饰，以便保证线程安全\n\n多线程环境下，\"数据计算\"和\"数据赋值\"操作可能多次出现，即操作非原子。若数据在加载之后，若主内存count变量发生修改之后，由于线程工作内存中的值在此前已经加载，从而不会对变更操作做出相应变化，即私有内存和公共内存中变量不同步，进而导致数据不一致\n\n对于volatile变量，JVM只是保证从主内存加载到线程工作内存的值是最新的，也就是数据加载时是最新的。\n\n小结\n- 没使用`volatile`前，多线程间会发生线程A执行`i++`，而线程B对A的操作结果不知晓，进行了一次重复的操作，`i`最终只+1\n- 使用`volatile`后，解决了之前重复操作的问题，但是仍然有可能别的原因导致`i`最终只+1。原因是由于`i++`并非原子操作，可能在两个子操作的间隙之间，如`+1`操作和`写入主内存`之间，线程B执行了`从主内存中读i`，结果线程B读到的值是旧的，最总结果仍只+1\n- 可见volatile解决的是变量读时的可见性问题，但无法保证原子性，对于多线程修改共享变量的场景必须使用加锁同步\n- 由于volatile变量只能保证可见性，在不符合以下两条规则的运算场景中，仍然要通过加锁(使用synchronized、java.util.concurrent中的锁或原子类）来保证原子性:\n  - 运算结果并不依赖变量的当前值，或者能够确保只有单一的线程修改变量的值\n  - 变量不需要与其他的状态变量共同参与不变约束\n\n## 禁止指令重排序\n**指令重排序**\n为了提高性能，编译器和处理器常常会对既定的代码进行指令重排序\n{% asset_img 020.jpg %}\n\n一般重排序可以分为如下三种:\n- 编译器优化的重排序。编译器在不改变单线程程序语义的前提下，可以重新安排语句的执行顺序\n- 指令级并行的重排序。现代处理器采用了指令级并行技术来将多条指令重叠执行。如果不存在数据依赖性，处理器可以改变语句对应机器指令的执行顺序\n- 内存系统的重排序。由于处理器使用缓存和读/写缓冲区，这使得加载和存储操作看上去可能是在乱序执行的\n\n**as-if-serial**\n即不管怎么重排序，单线程下的执行结果不能被改变。编译器、runtime和处理器都必须遵守asif-serial语义\n\n**happens-before**\n并发编程下指令重排序同样也会会带来一些安全隐患：如指令重排序导致的多个线程操作之间的不可见性。从JDK5开始，提出了happens-before的概念，如果一个操作执行的结果需要对另一个操作可见，那么这两个操作之间必须存在happens-before关系。这里提到的两个操作既可以是在一个线程之内，也可以是在不同线程之间\n\n**规则如下**\n1. 次序规则\n   一个线程内,按照代码顺序,写在前面的操作先行发生于写在后面的操作(强调的是一个线程)\n   前一个操作的结果可以被后续的操作获取。将白点就是前面一个操作把变量X赋值为1,那后面一个操作肯定能知道X已经变成了1\n\n2. 锁定规则\n   一个unlock操作先行发生于后面((这里的\"后面\"是指时间上的先后))对同一个锁的lock操作(上一个线程unlock了,下一个线程才能获取到锁,进行lock)\n   \n3. volatile变量规则\n   对一个volatile变量的写操作先行发生于后面对这个变量的读操作,前面的写对后面的读是可见的,这里的\"后面\"同样是指时间是的先后\n   \n4. 传递规则\n如果操作A先行发生于操作B,而操作B又先行发生于操作C,则可以得出A先行发生于操作C\n\n5. 线程启动规则(Thread Start Rule)\nThread对象的start( )方法先行发生于线程的每一个动作\n\n6. 线程中断规则(Thread Interruption Rule)\n- 对线程interrupt( )方法的调用先发生于被中断线程的代码检测到中断事件的发生\n- 可以通过Thread.interrupted( )检测到是否发生中断\n\n7. 线程终止规则(Thread Termination Rule)\n(线程中的所有操作都先行发生于对此线程的终止检测)\n\n8. 对象终结规则(Finalizer Rule)\n对象没有完成初始化之前,是不能调用finalized( )方法的\n\n**单例双重检验+volatile**\n双重检验锁+volatile\n```java\npublic class Singleton {\n    // volatile 保证可见性和禁止指令重排序\n    private static volatile Singleton singleton;\n\n    public static Singleton getInstance() {\n        // 第一次检查\n        if (singleton == null) {\n          // 同步代码块\n          synchronized(this.getClass()) {\n              // 第二次检查\n              if (singleton == null) {\n                    // 对象的实例化是一个非原子性操作\n                    singleton = new Singleton();\n                }\n            }\n        }\n        return singleton;\n    }\n}\n```\n上面代码中,new Singleton()是一个非原子性操作，对象实例化分为三步操作:\n1. a：分配内存空间\n2. b：初始化实例\n3. c：返回内存地址给引用\n\n- 当两个线程A和B同时进入方法时，加入A抢夺到锁，则A继续执行，当A执行到new操作时，由于new操作不是原子操作，且synchronized也不能禁止重排序\n- 不禁止重排序的情况下可能是：a-c-b，当线程A执行a-c，即将执行b的时候，由于cpu时间片结束，则有可能会让步给线程B\n- 线程B进行第一次判断，singleton由于已经有了内存指向，并不为空，此时，对象还没有执行初始化，但已经判断为true，并且返回了\n\n此时，就产生了严重的错误，因此需要 volatile 来禁止重排序。\nPS：不能将`new`操作类比`i++`操作，需要JVM知识支撑。\n\n**为什么`volatile`能禁止指令重排序呢**\n答案：内存屏障。java编译器会在生成指令系列时在适当的位置会插入内存屏障指令来禁止特定类型的处理器重排序。\n\n禁止重排序规则表\n{% asset_img 022.jpg %}\n\n- 当第一个操作为volatile读时不论第二个操作是什么,都不能重排序。这个操作保证了volatile读之后的操作不会被重排到volatile读之前\n- 当第二个操作为volatile写时,不论第一个操作是什么,都不能重排序。这个操作保证了volatile写之前的操作不会被重排到volatile写之后\n- 当第一个操作为volatile写时,第二个操作为volatile读时,不能重排(写后读)\n\n**4种内存屏障指令**\n{% asset_img 023.jpg %}\n\n\n# 异步Future\nFuture可以理解为未来任务，异步任务。\n\n## FutureTask\nDemo\n```java\npublic class CompletableFutureDemo{\n    public static void main(String[] args) throws ExecutionException, InterruptedException, TimeoutException{\n        FutureTask<String> futureTask = new FutureTask<>(() -> {\n            System.out.println(\"-----come in FutureTask\");\n            try { TimeUnit.SECONDS.sleep(3); } catch (InterruptedException e) { e.printStackTrace(); }\n            return ThreadLocalRandom.current().nextInt(100);\n        });\n\n        Thread t1 = new Thread(futureTask,\"t1\");\n        t1.start();\n\n        //3秒钟后才出来结果，还没有计算你提前来拿(只要一调用get方法，对于结果就是不见不散，会导致阻塞)\n        //System.out.println(Thread.currentThread().getName()+\"\\t\"+futureTask.get());\n\n        //3秒钟后才出来结果，我只想等待1秒钟，过时不候\n        System.out.println(Thread.currentThread().getName()+\"\\t\"+futureTask.get(1L,TimeUnit.SECONDS));\n\n        System.out.println(Thread.currentThread().getName()+\"\\t\"+\" run... here\");\n\n    }\n}\n\n```\n- 直接调用`get()`方法，会造成线程阻塞，直至计算完成\n- 使用`get(1L,TimeUnit.SECONDS)`方法，如果在指定时间内线程计算完成，则返回结果，否则过时不候\n\n问题：线程完成计算的时间是不确定的，如何以不阻塞的方式拿到线程结果呢？\n答案：轮询——while+isDone()\n```java\npublic class CompletableFutureDemo2 {\n\n    public static void main(String[] args) throws ExecutionException, InterruptedException {\n        FutureTask<String> futureTask = new FutureTask<>(() -> {\n            System.out.println(\"-----come in FutureTask\");\n            try { TimeUnit.SECONDS.sleep(3); } catch (InterruptedException e) { e.printStackTrace(); }\n            return \"\"+ ThreadLocalRandom.current().nextInt(100);\n        });\n\n        new Thread(futureTask,\"t1\").start();\n\n        System.out.println(Thread.currentThread().getName()+\"\\t\"+\"线程完成任务\");\n\n        /**\n         * 用于阻塞式获取结果,如果想要异步获取结果,通常都会以轮询的方式去获取结果\n         */\n        while (true){\n            if(futureTask.isDone()){\n                System.out.println(futureTask.get());\n                break;\n            }\n        }\n    }\n}\n```\n但是，轮询会耗费CPU资源\n\n## CompletableFuture\n`CompletableFuture`是对Future功能的拓展，简化异步编程的复杂性，功能非常强大。\n\n**核心静态方法**\n```java\n//1.runAsync 无 返回值\npublic static CompletableFuture<Void> runAsync(Runnable runnable)\npublic static CompletableFuture<Void> runAsync(Runnable runnable,Executor executor)  \n\n//2.supplyAsync 有 返回值\n//没有指定Executor的方法，直接使用默认的ForkJoinPool.commonPool() 作为它的线程池执行异步代码。如果指定线程池，则使用我们自定义的或者特别指定的线程池执行异步代码\npublic static <U> CompletableFuture<U> supplyAsync(Supplier<U> supplier)\npublic static <U> CompletableFuture<U> supplyAsync(Supplier<U> supplier,Executor executor)\n```\n\nDemo\n无返回值\n（`get()`和`join()`区别：get会抛出异常，join不会）\n```java\npublic class CompletableFutureDemo3{\n    public static void main(String[] args) throws ExecutionException, InterruptedException{\n        CompletableFuture<Void> future = CompletableFuture.runAsync(() -> {\n            System.out.println(Thread.currentThread().getName()+\"\\t\"+\"-----come in\");\n            //暂停几秒钟线程\n            try { TimeUnit.SECONDS.sleep(1); } catch (InterruptedException e) { e.printStackTrace(); }\n            System.out.println(\"-----task is over\");\n        });\n        System.out.println(future.get());\n    }\n}\n```\n\n有返回值\n```java\npublic class CompletableFutureDemo3{\n    public static void main(String[] args) throws ExecutionException, InterruptedException{\n        CompletableFuture<Integer> completableFuture = CompletableFuture.supplyAsync(() -> {\n            System.out.println(Thread.currentThread().getName() + \"\\t\" + \"-----come in\");\n            //暂停几秒钟线程\n            try {\n                TimeUnit.SECONDS.sleep(1);\n            } catch (InterruptedException e) {\n                e.printStackTrace();\n            }\n            return ThreadLocalRandom.current().nextInt(100);\n        });\n\n        System.out.println(completableFuture.get());\n    }\n}\n```\n\n**回调方法**\n从Java8开始引入了CompletableFuture，是Future的功能增强版，可以传入回调对象，当异步任务完成或者发生异常时，自动调用回调对象的回调方法\n```java\npublic class CompletableFutureDemo3{\n    public static void main(String[] args) throws Exception{\n        CompletableFuture<Integer> completableFuture = CompletableFuture.supplyAsync(() -> {\n            System.out.println(Thread.currentThread().getName() + \"\\t\" + \"-----come in\");\n            int result = ThreadLocalRandom.current().nextInt(10);\n            //暂停几秒钟线程\n            try { TimeUnit.SECONDS.sleep(1); } catch (InterruptedException e) { e.printStackTrace(); }\n            System.out.println(\"-----计算结束耗时1秒钟，result： \"+result);\n            if(result > 6){\n                int age = 10/0;\n            }\n            return result;\n        }).whenComplete((v,e) ->{\n            if(e == null){\n                System.out.println(\"-----result: \"+v);\n            }\n        }).exceptionally(e -> {\n            System.out.println(\"-----exception: \"+e.getCause()+\"\\t\"+e.getMessage());\n            return -44;\n        });\n\n        //主线程不要立刻结束，否则CompletableFuture默认使用的线程池会立刻关闭:暂停3秒钟线程\n        try { TimeUnit.SECONDS.sleep(3); } catch (InterruptedException e) { e.printStackTrace(); }\n    }\n}\n```\n\nwhenComplete：负责运行正常的情况\n- whenComplete：当前线程执行任务，等待任务执行完后继续执行whenComplete任务\n- whenCompleteAsync：当前线程任务执行完后将whenCompleteAsync任务交给线程池中其他线程执行（如果是使用同一线程池，也可能会被交由当前线程执行）\n\nexceptionally：负责出现异常的情况\n\nhandle：whenComplete和exceptionally的结合版。方法执行后的处理，无论成功与失败都可处理\n```java\n\t\t/**\n\t\t * 方法执行完成后的处理\n\t\t */\n        CompletableFuture<Integer> completableFuture2 = CompletableFuture.supplyAsync(() -> {\n            System.out.println(\"当前线程：\" + Thread.currentThread().getId());\n            System.out.println(\"CompletableFuture...\");\n            return 10/1;\n        }, service).handle((t,u)->{ // R apply(T t, U u);\n            System.out.println(\"handle:\");\n            if (t != null){\n                System.out.println(\"存在返回结果:\" + t);\n                return 8;\n            }\n            if (u != null){\n                System.out.println(\"存在日常:\" + u);\n                return 9;\n            }\n            return 5;\n\n        });\n        Integer integer = completableFuture2.get();\n        System.out.println(integer);\n```\n\n### 线程串行化\n即让多线程之间有序执行\n\nthenRun：不能获取到上一步的执行结果，无返回值\nthenAccept：能接受上一步结果，无返回值\nthenApply：能接受上一步结果，有返回值\n（带后缀Async表示会将任务交给线程池中的其他线程去处理）\n\nthenApply\nthenApplyAsync有重载版本，可以指定执行异步任务的线程池，如果不指定，默认使用ForkJoinPool.commonPool()\n```java\n@Test\n    public void test5() throws Exception {\n        ForkJoinPool pool=new ForkJoinPool();\n        // 创建异步执行任务:\n        CompletableFuture<Double> cf = CompletableFuture.supplyAsync(()->{\n            System.out.println(Thread.currentThread()+\" start job1,time->\"+System.currentTimeMillis());\n            try {\n                Thread.sleep(2000);\n            } catch (InterruptedException e) {\n            }\n            System.out.println(Thread.currentThread()+\" exit job1,time->\"+System.currentTimeMillis());\n            return 1.2;\n        },pool);\n        //cf关联的异步任务的返回值作为方法入参，传入到thenApply的方法中\n        //thenApply这里实际创建了一个新的CompletableFuture实例\n        CompletableFuture<String> cf2=cf.thenApply((result)->{\n            System.out.println(Thread.currentThread()+\" start job2,time->\"+System.currentTimeMillis());\n            try {\n                Thread.sleep(2000);\n            } catch (InterruptedException e) {\n            }\n            System.out.println(Thread.currentThread()+\" exit job2,time->\"+System.currentTimeMillis());\n            return \"test:\"+result;\n        });\n        System.out.println(\"main thread start cf.get(),time->\"+System.currentTimeMillis());\n        //等待子任务执行完成\n        System.out.println(\"run result->\"+cf.get());\n        System.out.println(\"main thread start cf2.get(),time->\"+System.currentTimeMillis());\n        System.out.println(\"run result->\"+cf2.get());\n        System.out.println(\"main thread exit,time->\"+System.currentTimeMillis());\n    }\n```\n\nthenRun、thenAccept\n```java\n@Test\n    public void test6() throws Exception {\n        ForkJoinPool pool=new ForkJoinPool();\n        // 创建异步执行任务:\n        CompletableFuture<Double> cf = CompletableFuture.supplyAsync(()->{\n            System.out.println(Thread.currentThread()+\" start job1,time->\"+System.currentTimeMillis());\n            try {\n                Thread.sleep(2000);\n            } catch (InterruptedException e) {\n            }\n            System.out.println(Thread.currentThread()+\" exit job1,time->\"+System.currentTimeMillis());\n            return 1.2;\n        },pool);\n        //cf关联的异步任务的返回值作为方法入参，传入到thenApply的方法中\n        CompletableFuture cf2=cf.thenApply((result)->{\n            System.out.println(Thread.currentThread()+\" start job2,time->\"+System.currentTimeMillis());\n            try {\n                Thread.sleep(2000);\n            } catch (InterruptedException e) {\n            }\n            System.out.println(Thread.currentThread()+\" exit job2,time->\"+System.currentTimeMillis());\n            return \"test:\"+result;\n        }).thenAccept((result)-> { //接收上一个任务的执行结果作为入参，但是没有返回值\n            System.out.println(Thread.currentThread()+\" start job3,time->\"+System.currentTimeMillis());\n            try {\n                Thread.sleep(2000);\n            } catch (InterruptedException e) {\n            }\n            System.out.println(result);\n            System.out.println(Thread.currentThread()+\" exit job3,time->\"+System.currentTimeMillis());\n        }).thenRun(()->{ //无入参，也没有返回值\n            System.out.println(Thread.currentThread()+\" start job4,time->\"+System.currentTimeMillis());\n            try {\n                Thread.sleep(2000);\n            } catch (InterruptedException e) {\n            }\n            System.out.println(\"thenRun do something\");\n            System.out.println(Thread.currentThread()+\" exit job4,time->\"+System.currentTimeMillis());\n        });\n        System.out.println(\"main thread start cf.get(),time->\"+System.currentTimeMillis());\n        //等待子任务执行完成\n        System.out.println(\"run result->\"+cf.get());\n        System.out.println(\"main thread start cf2.get(),time->\"+System.currentTimeMillis());\n        //cf2 等待最后一个thenRun执行完成\n        System.out.println(\"run result->\"+cf2.get());\n        System.out.println(\"main thread exit,time->\"+System.currentTimeMillis());\n    }\n```\n\n### 组合处理\n**thenCombine、thenAcceptBoth、runAfterBoth**\n将两个CompletableFuture组合起来，只有这两个都正常执行完了才会执行某个任务。注意两个任务中只要有一个执行异常，则将该异常信息作为指定任务的执行结果。\n- thenCombine：会将两个任务的执行结果作为方法入参传递到指定方法中，且该方法有返回值\n- thenAcceptBoth：同样将两个任务的执行结果作为方法入参，但是无返回值\n- runAfterBoth：没有入参，也没有返回值\n\nDemo\n```java\n@Test\n    public void test7() throws Exception {\n        ForkJoinPool pool=new ForkJoinPool();\n        // 创建异步执行任务:\n        CompletableFuture<Double> cf = CompletableFuture.supplyAsync(()->{\n            System.out.println(Thread.currentThread()+\" start job1,time->\"+System.currentTimeMillis());\n            try {\n                Thread.sleep(2000);\n            } catch (InterruptedException e) {\n            }\n            System.out.println(Thread.currentThread()+\" exit job1,time->\"+System.currentTimeMillis());\n            return 1.2;\n        });\n        CompletableFuture<Double> cf2 = CompletableFuture.supplyAsync(()->{\n            System.out.println(Thread.currentThread()+\" start job2,time->\"+System.currentTimeMillis());\n            try {\n                Thread.sleep(1500);\n            } catch (InterruptedException e) {\n            }\n            System.out.println(Thread.currentThread()+\" exit job2,time->\"+System.currentTimeMillis());\n            return 3.2;\n        });\n        //cf和cf2的异步任务都执行完成后，会将其执行结果作为方法入参传递给cf3,且有返回值\n        CompletableFuture<Double> cf3=cf.thenCombine(cf2,(a,b)->{\n            System.out.println(Thread.currentThread()+\" start job3,time->\"+System.currentTimeMillis());\n            System.out.println(\"job3 param a->\"+a+\",b->\"+b);\n            try {\n                Thread.sleep(2000);\n            } catch (InterruptedException e) {\n            }\n            System.out.println(Thread.currentThread()+\" exit job3,time->\"+System.currentTimeMillis());\n            return a+b;\n        });\n \n        //cf和cf2的异步任务都执行完成后，会将其执行结果作为方法入参传递给cf3,无返回值\n        CompletableFuture cf4=cf.thenAcceptBoth(cf2,(a,b)->{\n            System.out.println(Thread.currentThread()+\" start job4,time->\"+System.currentTimeMillis());\n            System.out.println(\"job4 param a->\"+a+\",b->\"+b);\n            try {\n                Thread.sleep(1500);\n            } catch (InterruptedException e) {\n            }\n            System.out.println(Thread.currentThread()+\" exit job4,time->\"+System.currentTimeMillis());\n        });\n \n        //cf4和cf3都执行完成后，执行cf5，无入参，无返回值\n        CompletableFuture cf5=cf4.runAfterBoth(cf3,()->{\n            System.out.println(Thread.currentThread()+\" start job5,time->\"+System.currentTimeMillis());\n            try {\n                Thread.sleep(1000);\n            } catch (InterruptedException e) {\n            }\n            System.out.println(\"cf5 do something\");\n            System.out.println(Thread.currentThread()+\" exit job5,time->\"+System.currentTimeMillis());\n        });\n \n        System.out.println(\"main thread start cf.get(),time->\"+System.currentTimeMillis());\n        //等待子任务执行完成\n        System.out.println(\"cf run result->\"+cf.get());\n        System.out.println(\"main thread start cf5.get(),time->\"+System.currentTimeMillis());\n        System.out.println(\"cf5 run result->\"+cf5.get());\n        System.out.println(\"main thread exit,time->\"+System.currentTimeMillis());\n    }\n```\n\n**applyToEither、acceptEither、runAfterEither**\n将两个CompletableFuture组合起来，只要其中一个执行完了就会执行某个任务。注意两个任务中只要有一个执行异常，则将该异常信息作为指定任务的执行结果。\n- applyToEither：会将已经执行完成的任务的执行结果作为方法入参，并有返回值\n- acceptEither：同样将已经执行完成的任务的执行结果作为方法入参，但是没有返回值\n- runAfterEither：没有方法入参，也没有返回值\n\n```java\n@Test\n    public void test8() throws Exception {\n        // 创建异步执行任务:\n        CompletableFuture<Double> cf = CompletableFuture.supplyAsync(()->{\n            System.out.println(Thread.currentThread()+\" start job1,time->\"+System.currentTimeMillis());\n            try {\n                Thread.sleep(2000);\n            } catch (InterruptedException e) {\n            }\n            System.out.println(Thread.currentThread()+\" exit job1,time->\"+System.currentTimeMillis());\n            return 1.2;\n        });\n        CompletableFuture<Double> cf2 = CompletableFuture.supplyAsync(()->{\n            System.out.println(Thread.currentThread()+\" start job2,time->\"+System.currentTimeMillis());\n            try {\n                Thread.sleep(1500);\n            } catch (InterruptedException e) {\n            }\n            System.out.println(Thread.currentThread()+\" exit job2,time->\"+System.currentTimeMillis());\n            return 3.2;\n        });\n        //cf和cf2的异步任务都执行完成后，会将其执行结果作为方法入参传递给cf3,且有返回值\n        CompletableFuture<Double> cf3=cf.applyToEither(cf2,(result)->{\n            System.out.println(Thread.currentThread()+\" start job3,time->\"+System.currentTimeMillis());\n            System.out.println(\"job3 param result->\"+result);\n            try {\n                Thread.sleep(2000);\n            } catch (InterruptedException e) {\n            }\n            System.out.println(Thread.currentThread()+\" exit job3,time->\"+System.currentTimeMillis());\n            return result;\n        });\n \n        //cf和cf2的异步任务都执行完成后，会将其执行结果作为方法入参传递给cf3,无返回值\n        CompletableFuture cf4=cf.acceptEither(cf2,(result)->{\n            System.out.println(Thread.currentThread()+\" start job4,time->\"+System.currentTimeMillis());\n            System.out.println(\"job4 param result->\"+result);\n            try {\n                Thread.sleep(1500);\n            } catch (InterruptedException e) {\n            }\n            System.out.println(Thread.currentThread()+\" exit job4,time->\"+System.currentTimeMillis());\n        });\n \n        //cf4和cf3都执行完成后，执行cf5，无入参，无返回值\n        CompletableFuture cf5=cf4.runAfterEither(cf3,()->{\n            System.out.println(Thread.currentThread()+\" start job5,time->\"+System.currentTimeMillis());\n            try {\n                Thread.sleep(1000);\n            } catch (InterruptedException e) {\n            }\n            System.out.println(\"cf5 do something\");\n            System.out.println(Thread.currentThread()+\" exit job5,time->\"+System.currentTimeMillis());\n        });\n \n        System.out.println(\"main thread start cf.get(),time->\"+System.currentTimeMillis());\n        //等待子任务执行完成\n        System.out.println(\"cf run result->\"+cf.get());\n        System.out.println(\"main thread start cf5.get(),time->\"+System.currentTimeMillis());\n        System.out.println(\"cf5 run result->\"+cf5.get());\n        System.out.println(\"main thread exit,time->\"+System.currentTimeMillis());\n    }\n```\n\n**thenCompose**\nthenCompose()：会在某个任务执行完成后，将该任务的执行结果作为方法入参然后执行指定的方法，该方法会返回一个新的CompletableFuture实例，如果该CompletableFuture实例的result不为null，则返回一个基于该result的新的CompletableFuture实例；如果该CompletableFuture实例为null，则然后执行这个新任务。\n\n```java\n    @Test\n    public void test9() throws Exception {\n        // 创建异步执行任务:\n        CompletableFuture<Double> cf = CompletableFuture.supplyAsync(()->{\n            System.out.println(Thread.currentThread()+\" start job1,time->\"+System.currentTimeMillis());\n            try {\n                Thread.sleep(2000);\n            } catch (InterruptedException e) {\n            }\n            System.out.println(Thread.currentThread()+\" exit job1,time->\"+System.currentTimeMillis());\n            return 1.2;\n        });\n        CompletableFuture<String> cf2= cf.thenCompose((param)->{\n            System.out.println(Thread.currentThread()+\" start job2,time->\"+System.currentTimeMillis());\n            try {\n                Thread.sleep(2000);\n            } catch (InterruptedException e) {\n            }\n            System.out.println(Thread.currentThread()+\" exit job2,time->\"+System.currentTimeMillis());\n            return CompletableFuture.supplyAsync(()->{\n                System.out.println(Thread.currentThread()+\" start job3,time->\"+System.currentTimeMillis());\n                try {\n                    Thread.sleep(2000);\n                } catch (InterruptedException e) {\n                }\n                System.out.println(Thread.currentThread()+\" exit job3,time->\"+System.currentTimeMillis());\n                return \"job3 test\";\n            });\n        });\n        System.out.println(\"main thread start cf.get(),time->\"+System.currentTimeMillis());\n        //等待子任务执行完成\n        System.out.println(\"cf run result->\"+cf.get());\n        System.out.println(\"main thread start cf2.get(),time->\"+System.currentTimeMillis());\n        System.out.println(\"cf2 run result->\"+cf2.get());\n        System.out.println(\"main thread exit,time->\"+System.currentTimeMillis());\n    }\n```\n\n**allOf、anyOf**\n- allOf返回的CompletableFuture是多个任务都执行完成后才会执行，只有有一个任务执行异常，则返回的CompletableFuture执行get方法时会抛出异常，如果都是正常执行，则get返回null\n- anyOf返回的CompletableFuture是多个任务只要其中一个执行完成就会执行，其get返回的是已经执行完成的任务的执行结果，如果该任务执行异常，则抛出异常\n```java\n @Test\n    public void test11() throws Exception {\n        // 创建异步执行任务:\n        CompletableFuture<Double> cf = CompletableFuture.supplyAsync(()->{\n            System.out.println(Thread.currentThread()+\" start job1,time->\"+System.currentTimeMillis());\n            try {\n                Thread.sleep(2000);\n            } catch (InterruptedException e) {\n            }\n            System.out.println(Thread.currentThread()+\" exit job1,time->\"+System.currentTimeMillis());\n            return 1.2;\n        });\n        CompletableFuture<Double> cf2 = CompletableFuture.supplyAsync(()->{\n            System.out.println(Thread.currentThread()+\" start job2,time->\"+System.currentTimeMillis());\n            try {\n                Thread.sleep(1500);\n            } catch (InterruptedException e) {\n            }\n            System.out.println(Thread.currentThread()+\" exit job2,time->\"+System.currentTimeMillis());\n            return 3.2;\n        });\n        CompletableFuture<Double> cf3 = CompletableFuture.supplyAsync(()->{\n            System.out.println(Thread.currentThread()+\" start job3,time->\"+System.currentTimeMillis());\n            try {\n                Thread.sleep(1300);\n            } catch (InterruptedException e) {\n            }\n//            throw new RuntimeException(\"test\");\n            System.out.println(Thread.currentThread()+\" exit job3,time->\"+System.currentTimeMillis());\n            return 2.2;\n        });\n        //allof等待所有任务执行完成才执行cf4，如果有一个任务异常终止，则cf4.get时会抛出异常，都是正常执行，cf4.get返回null\n        //anyOf是只有一个任务执行完成，无论是正常执行或者执行异常，都会执行cf4，cf4.get的结果就是已执行完成的任务的执行结果\n        CompletableFuture cf4=CompletableFuture.allOf(cf,cf2,cf3).whenComplete((a,b)->{\n           if(b!=null){\n               System.out.println(\"error stack trace->\");\n               b.printStackTrace();\n           }else{\n               System.out.println(\"run succ,result->\"+a);\n           }\n        });\n \n        System.out.println(\"main thread start cf4.get(),time->\"+System.currentTimeMillis());\n        //等待子任务执行完成\n        System.out.println(\"cf4 run result->\"+cf4.get());\n        System.out.println(\"main thread exit,time->\"+System.currentTimeMillis());\n    }\n```\n\n\n## ForkJoinTask\n分支合并，将一个大任务，进行拆分(fork)成若干个小任务(拆到给出的临界值为止)，再将一个个的小任务运算的结果进行join汇总\n{% asset_img %}\n\n**工作窃取模式**\n工作窃取模式(work-stealing):当执行新的任务时它可以将其拆分成更小的任务执行，并将小任务加到线程队列中，当没有任务执行时，再从一个随机线程的队列中偷一个并把它放在自己的队列中\n相对于一般的线程池实现，fork/join框架的优势体现在对其中包含的任务的处理方式上，在一般的线程池中，如果一个线程正在执行的任务由于某些原因无法继续运行那么该线程会处于等待状态。而在forkfjoin框架实现中，如果某个子问题由于等待另外一个子问题的完成而无法继续运行。那么处理该子问题的线程会主动寻找其他尚未运行的子问题(窃取过来)来执行，这种方式减少了线程的等待时间，提高了性能\n{% asset_img 029.png %}\n\n**ForkJoinTask实现类**\n{% asset_img 030.png %}\n\n1. RecursiveTask：有返回值的递归任务\n2.  RecursiveAction：无返回值的递归事件\n\nDemo\n\n```java\npackage com.kuang.forkjoin;\n\nimport java.util.concurrent.RecursiveTask;\n\n/**\n * 求和计算的任务！\n * 3000   6000（ForkJoin）  9000（Stream并行流）\n * // 如何使用 forkjoin\n * // 1、forkjoinPool 通过它来执行\n * // 2、计算任务 forkjoinPool.execute(ForkJoinTask task)\n * // 3. 计算类要继承 ForkJoinTask\n */\npublic class ForkJoinDemo extends RecursiveTask<Long> {\n\n    private Long start;  // 1\n    private Long end;    // 1990900000\n\n    // 临界值\n    private Long temp = 10000L;\n\n    public ForkJoinDemo(Long start, Long end) {\n        this.start = start;\n        this.end = end;\n    }\n\n    // 计算方法\n    @Override\n    protected Long compute() {\n        if ((end-start)<temp){\n            Long sum = 0L;\n            for (Long i = start; i <= end; i++) {\n                sum += i;\n            }\n            return sum;\n        }else { // forkjoin 递归\n            long middle = (start + end) / 2; // 中间值\n            ForkJoinDemo task1 = new ForkJoinDemo(start, middle);\n            task1.fork(); // 拆分任务，把任务压入线程队列\n            ForkJoinDemo task2 = new ForkJoinDemo(middle+1, end);\n            task2.fork(); // 拆分任务，把任务压入线程队列\n\n            return task1.join() + task2.join();\n        }\n    }\n}\n\n```\n\nDemo\n```java\npackage com.kuang.forkjoin;\n\nimport java.util.concurrent.ExecutionException;\nimport java.util.concurrent.ForkJoinPool;\nimport java.util.concurrent.ForkJoinTask;\nimport java.util.stream.DoubleStream;\nimport java.util.stream.IntStream;\nimport java.util.stream.LongStream;\n\n/**\n * 同一个任务，别人效率高你几十倍！\n */\npublic class Test {\n    public static void main(String[] args) throws ExecutionException, InterruptedException {\n        // test1(); // 12224\n        // test2(); // 10038\n        // test3(); // 153\n    }\n\n    // 普通程序员\n    public static void test1(){\n        Long sum = 0L;\n        long start = System.currentTimeMillis();\n        for (Long i = 1L; i <= 10_0000_0000; i++) {\n            sum += i;\n        }\n        long end = System.currentTimeMillis();\n        System.out.println(\"sum=\"+sum+\" 时间：\"+(end-start));\n    }\n\n    // 会使用ForkJoin\n    public static void test2() throws ExecutionException, InterruptedException {\n        long start = System.currentTimeMillis();\n\n        ForkJoinPool forkJoinPool = new ForkJoinPool();\n        ForkJoinTask<Long> task = new ForkJoinDemo(0L, 10_0000_0000L);\n        ForkJoinTask<Long> submit = forkJoinPool.submit(task);// 提交任务\n        Long sum = submit.get();\n\n        long end = System.currentTimeMillis();\n\n        System.out.println(\"sum=\"+sum+\" 时间：\"+(end-start));\n    }\n\n    public static void test3(){\n        long start = System.currentTimeMillis();\n        // Stream并行流 ()  (]\n        long sum = LongStream.rangeClosed(0L, 10_0000_0000L).parallel().reduce(0, Long::sum);\n        long end = System.currentTimeMillis();\n        System.out.println(\"sum=\"+\"时间：\"+(end-start));\n    }\n}\n```\n\n# LockSupport与线程中断\n## 线程中断\nJava不提倡强中中断其他线程，线程只能自行中断。\n\n中断只是一种协作机制，Java没有给中断增加任何语法，中断的过程完全需要程序员自己实现。若要中断一个线程，需要手动调用该线程的interrupt方法，但该方法也仅仅是将线程对象的中断标识设成true；接着你需要自己写代码不断地检测当前线程的标识位，如果为true，表示别的线程要求这条线程中断， 此时究竟该做什么需要你自己写代码实现。\n\n每个线程对象中都有一个标识，用于表示线程是否被中断；该标识位为true表示中断，为false表示未中断；通过调用线程对象的interrupt方法将该线程的标识位设为true；可以在别的线程中调用，也可以在自己的线程中调用\n\nThread线程中断相关API\n- public void interrupt()：实例方法，仅仅是设置线程的中断状态为true，不会停止线程\n- public static boolean interrupted()：静态方法\n  - 判断线程是否被中断，并清除当前中断状态。这个方法做了两件事：\n    - 1 返回当前线程的中断状态\n    - 将当前线程的中断状态设为false\n\n具体来说，当对一个线程，调用interrupt()时:\n如果线程处于正常活动状态，那么会将该线程的中断标志设置为true，仅此而已。被设置中断标志的线程将继续正常运行，不受影响。所以，interrupt()并不能真正的中断线程，需要被调用的线程自己进行配合才行。\n②如果线程处于被阻塞状态（例如处于sleep, wait, join等状态)，在别的线程中调用当前线程对象的linterrupt方法\n那么\n线程将立即退出被阻塞状态，并抛出一个InterruptedException异常。\n\n\nDemo\n使用`volatile`实现线程中断\n```java\npublic class InterruptDemo\n{\nprivate static volatile boolean isStop = false;\n\npublic static void main(String[] args)\n{\n    new Thread(() -> {\n        while(true)\n        {\n            if(isStop)\n            {\n                System.out.println(Thread.currentThread().getName()+\"线程------isStop = true,自己退出了\");\n                break;\n            }\n            System.out.println(\"-------hello interrupt\");\n        }\n    },\"t1\").start();\n\n    //暂停几秒钟线程\n    try { TimeUnit.SECONDS.sleep(1); } catch (InterruptedException e) { e.printStackTrace(); }\n    isStop = true;\n}\n}\n```\n\nDemo\n通过原子类`AtomicBoolean`\n```java\npublic class StopThreadDemo\n{\n    private final static AtomicBoolean atomicBoolean = new AtomicBoolean(true);\n\n    public static void main(String[] args)\n    {\n        Thread t1 = new Thread(() -> {\n            while(atomicBoolean.get())\n            {\n                try { TimeUnit.MILLISECONDS.sleep(500); } catch (InterruptedException e) { e.printStackTrace(); }\n                System.out.println(\"-----hello\");\n            }\n        }, \"t1\");\n        t1.start();\n\n        try { TimeUnit.SECONDS.sleep(3); } catch (InterruptedException e) { e.printStackTrace(); }\n\n        atomicBoolean.set(false);\n    }\n}\n```\n\nDemo\n通过`Thread`相关API实现线程中断\n```java\npublic class InterruptDemo\n{\n    public static void main(String[] args)\n    {\n        Thread t1 = new Thread(() -> {\n            while(true)\n            {\n                if(Thread.currentThread().isInterrupted())\n                {\n                    System.out.println(\"-----t1 线程被中断了，break，程序结束\");\n                    break;\n                }\n                System.out.println(\"-----hello\");\n            }\n        }, \"t1\");\n        t1.start();\n\n        System.out.println(\"**************\"+t1.isInterrupted());\n        //暂停5毫秒\n        try { TimeUnit.MILLISECONDS.sleep(5); } catch (InterruptedException e) { e.printStackTrace(); }\n        t1.interrupt();\n        System.out.println(\"**************\"+t1.isInterrupted());\n    }\n}\n```\n\n## LockSupport\nLockSupport中的park() 和 unpark() 的作用分别是阻塞线程和解除阻塞线程。\n\n**线程等待唤醒**\n\n1. 使用Object中的wait()方法让线程等待，使用Object中的notify()方法唤醒线程\nwait和notify方法必须要在同步块或者方法里面，且成对出现使用，先wait后notify才OK\n\n2. 使用JUC包中Condition的await()方法让线程等待，使用signal()方法唤醒线程\n```java\npublic class LockSupportDemo2\n{\n    public static void main(String[] args)\n    {\n        Lock lock = new ReentrantLock();\n        Condition condition = lock.newCondition();\n\n        new Thread(() -> {\n            lock.lock();\n            try\n            {\n                System.out.println(Thread.currentThread().getName()+\"\\t\"+\"start\");\n                condition.await();\n                System.out.println(Thread.currentThread().getName()+\"\\t\"+\"被唤醒\");\n            } catch (InterruptedException e) {\n                e.printStackTrace();\n            } finally {\n                lock.unlock();\n            }\n        },\"t1\").start();\n\n        //暂停几秒钟线程\n        try { TimeUnit.SECONDS.sleep(3L); } catch (InterruptedException e) { e.printStackTrace(); }\n\n        new Thread(() -> {\n            lock.lock();\n            try\n            {\n                condition.signal();\n            } catch (Exception e) {\n                e.printStackTrace();\n            } finally {\n                lock.unlock();\n            }\n            System.out.println(Thread.currentThread().getName()+\"\\t\"+\"通知了\");\n        },\"t2\").start();\n\n    }\n}\n```\n\nlock、unlock对里面才能正确调用调用condition中线程等待和唤醒的方法，先await后signal。\n\n3. LockSupport类可以阻塞当前线程以及唤醒指定被阻塞的线程\n```java\npackage com.bilibili.juc.LockSupport;\n\nimport java.util.concurrent.TimeUnit;\nimport java.util.concurrent.atomic.AtomicInteger;\nimport java.util.concurrent.locks.Condition;\nimport java.util.concurrent.locks.Lock;\nimport java.util.concurrent.locks.LockSupport;\nimport java.util.concurrent.locks.ReentrantLock;\n\n/**\n * @auther zzyy\n * @create 2022-01-20 16:14\n */\npublic class LockSupportDemo {\n    static int x = 0;\n    static int y = 0;\n\n    public static void main(String[] args) {\n        Thread t1 = new Thread(() -> {\n            try {\n                TimeUnit.SECONDS.sleep(3);\n            } catch (InterruptedException e) {\n                e.printStackTrace();\n            }\n            System.out.println(Thread.currentThread().getName() + \"\\t ----come in\" + System.currentTimeMillis());\n            LockSupport.park();\n            System.out.println(Thread.currentThread().getName() + \"\\t ----被唤醒\" + System.currentTimeMillis());\n        }, \"t1\");\n        t1.start();\n\n        //暂停几秒钟线程\n        //try { TimeUnit.SECONDS.sleep(1); } catch (InterruptedException e) { e.printStackTrace(); }\n\n        new Thread(() -> {\n            LockSupport.unpark(t1);\n            System.out.println(Thread.currentThread().getName() + \"\\t ----发出通知\");\n        }, \"t2\").start();\n\n    }\n}\n```\n\n- 无需使用锁块(synchronized或者lock)\n- 等待唤醒顺序谁先谁后无所谓，都不会报错，正常执行\n\n\n\n# ThreadLocal\n线程变量：每个线程都有属于自己的独立变量。\n\n**原理分析**\n线程类Thread的一个对象属性`threadLocals`\n```\n//Thread类\nThreadLocal.ThreadLocalMap threadLocals = null;\n```\n实际上线程变量存储在该`threadLocals`，而`ThreadLocal`是一个提供操作该属性的中间人。\n```java\n//ThreadLocal类\npublic T get() {\n\tThread t = Thread.currentThread();\n\tThreadLocalMap map = getMap(t);\n\tif (map != null) {\n\t\tThreadLocalMap.Entry e = map.getEntry(this);\n\t\tif (e != null) {\n\t\t\t@SuppressWarnings(\"unchecked\")\n\t\t\tT result = (T)e.value;\n\t\t\treturn result;\n\t\t}\n\t}\n\treturn setInitialValue();\n}\n\npublic void set(T value) {\n\tThread t = Thread.currentThread();\n\tThreadLocalMap map = getMap(t);\n\tif (map != null)\n\t\tmap.set(this, value);\n\telse\n\t\tcreateMap(t, value);\n}\n```\n\nmap.set(this, value)\n```java\nprivate void set(ThreadLocal<?> key, Object value) {\n    Entry[] tab = table;\n    int len = tab.length;\n    int i = key.threadLocalHashCode & (len-1);\t//获取ThreadLocal的哈希码，也即在数组tab中的下标\n    \n    //从下标i向后检查\n    for (Entry e = tab[i];\n         e != null;\n         e = tab[i = nextIndex(i, len)]) {\n        ThreadLocal<?> k = e.get();\n        if (k == key) {\t//覆盖变量原有值\n            e.value = value;\n            return;\n        }\n        if (k == null) {\t//直接赋新值\n            replaceStaleEntry(key, value, i);\n            return;\n        }\n    }\n    //该下标i处还没有设置变量，直接new一个Entry对象\n    tab[i] = new Entry(key, value);\n    int sz = ++size;\n    if (!cleanSomeSlots(i, sz) && sz >= threshold)\n        rehash();\n}\n```\n\nEntry类：ThreadLocal类的静态内部类\n```java\nstatic class Entry extends WeakReference<ThreadLocal<?>> {\n        /** The value associated with this ThreadLocal. */\n        Object value;\n\n        Entry(ThreadLocal<?> k, Object v) {\n            super(k);\n            value = v;\n        }\n}\n```\n`Entry`继承了`WeakReference`，实现弱引用。\n\n**为什么要用弱引用?不用如何？**\n\n```java\npublic void function01()\n{\n    ThreadLocal tl = new ThreadLocal<Integer>();    //line1\n    tl.set(2021);                                   //line2\n    tl.get();                                       //line3\n}\n//line1新建了一个ThreadLocal对象，t1 是强引用指向这个对象；\n//line2调用set()方法后新建一个Entry，通过源码可知Entry对象里的k是弱引用指向这个对象。\n```\n\n当`function01`方法执行完毕后，栈帧销毁强引用`tl`也就没有了。但此时线程的`ThreadLocalMap`里某个`entry`的`key`引用还指向这个对象,若这个`key`引用是强引用，就会导致`key`指向的`ThreadLocal`对象及v指向的对象不能被gc回收，造成内存泄漏；若这个key引用是弱引用就大概率会减少内存泄漏的问题(还有一个key为null的雷)。使用弱引用，就可以使ThreadLocal对象在方法执行完毕后顺利被回收且Entry的key引用指向为null。\n\n此后我们调用get,set或remove方法时，就会尝试删除key为null的entry，可以释放value对象所占用的内存。\n在源码中，对`ThreadMap`进行`set`、`get`等操作时，会检查为`null`的`key`，进行垃圾回收。\n\n**弱引用就万事大吉了吗？**\n当我们为threadLocal变量赋值，实际上就是当前的Entry(threadLocal实例为key，值为value)往这个threadLocalMap中存放。Entry中的key是弱引用，当threadLocal外部强引用被置为null(tl=null),那么系统 GC 的时候，根据可达性分析，这个threadLocal实例就没有任何一条链路能够引用到它，这个ThreadLocal势必会被回收，这样一来，ThreadLocalMap中就会出现key为null的Entry，就没有办法访问这些key为null的Entry的value，如果当前线程再迟迟不结束的话，这些key为null的Entry的value就会一直存在一条强引用链：Thread Ref -> Thread -> ThreaLocalMap -> Entry -> value永远无法回收，造成内存泄漏。\n\n当然，如果当前thread运行结束，threadLocal，threadLocalMap,Entry没有引用链可达，在垃圾回收的时候都会被系统进行回收。\n\n但在实际使用中我们有时候会用线程池去维护我们的线程，比如在Executors.newFixedThreadPool()时创建线程的时候，为了复用线程是不会结束的，所以threadLocal内存泄漏就值得我们小心\n\n**补充知识点：Java中四种引用**\n\n1. 强引用（默认）\n当内存不足JVM开始垃圾回收,对于强引用的对象,就算是出现了OOM也不会对该对象进行回收,机器死了都不收。\n\n强引用是我们最常见的普通对象引用,只要还有强引用指向一个对象,就能表明对象还“活着”,垃圾收集器不会碰这种对象。在Java中最常见的就是强引用,把一个对象赋给一个引用变量这个引用变量就是一个强引用。当一个对象被强引用变量引用时,它处于可达状态,它是不可能被垃圾回收机制回收的,即使该对象以后永远都不会被用到,JVM也不会回收。因此强引用是造成Java内存泄漏的主要原因之一。\n\n对于一个普通的对象.如果没有其他的引用关系只要超过了引用的作用域或者显式地将相应(强)引用赋值为null一般认为才是可以被垃圾收集的了(当然具体回收时机还是要看垃圾收集策略).\n\n\n2. 软引用\n软引用是一种相对强引用弱化了一些的引用，需要用java.lang.ref.SoftReference类来实现，可以让对象豁免一些垃圾收集。\n\n对于只有软引用的对象来说，当系统内存充足时它 不会被回收，当系统内存不足时它会被回收。\n\n软引用通常用在对内存敏感的程序中，比如高速缓存就有用到软引用，内存够用的时候就保留，不够用就回收！\n\n3. 弱引用\n弱引用需要用java.lang.ref.WeakReference类来实现，它比软引用的生存期更短，对于只有弱引用的对象来说，只要垃圾回收机制一运行，不管JVM的内存空间是否足够，都会回收该对象占用的内存。\n\n软引用和弱引用的适用场景\n\n假如有一个应用需要读取大量的本地图片:\n- 如果每次读取图片都从硬盘读取则会严重影响性能\n- 如果一次性全部加载到内存中又可能造成内存溢出。\n\n此时使用软引用可以解决这个问题。\n设计思路是：用一个HashMap来保存图片的路径和相应图片对象关联的软引用之间的映射关系，在内存不足时，JVM会自动回收这些缓存图片对象所占用的空间，从而有效地避免了OOM的问题。\n```java\nMap<String, SoftReference<Bitmap>> imageCache = new HashMap<String, SoftReference<Bitmap>>();\n```\n\n4. 虚引用\n虚引用需要java.lang.ref.PhantomReference类来实现。\n\n顾名思义，就是形同虚设，与其他几种引用都不同，虚引用并不会决定对象的生命周期。如果一个对象仅持有虚引用，那么它就和没有任何引用一样，在任何时候都可能被垃圾回收器回收，它不能单独使用也不能通过它访问对象，虚引用必须和引用队列 (ReferenceQueue)联合使用。\n\n虚引用的主要作用是跟踪对象被垃圾回收的状态。 仅仅是提供了一种确保对象被 finalize以后，做某些事情的机制。 PhantomReference的get方法总是返回null，因此无法访问对应的引用对象。\n\n其意义在于：说明一个对象已经进入finalization阶段，可以被gc回收，用来实现比finalization机制更灵活的回收操作。\n\n换句话说，设置虚引用关联的唯一目的，就是在这个对象被收集器回收的时候收到一个系统通知或者后续添加进一步的处理\n\n**内存泄漏**\n不再会被使用的对象或者变量占用的内存不能被回收，就是内存泄露。\n\n# Lock\n**Lock和synchronized区别**\n\n- Lock接口方式需要手动进行锁的获取和释放，是显式锁；使用synchronized时，锁获取和释放是JVM自动完成的，是隐式锁\n- 使用synchronized在发生异常时，锁会自动被释放，而Lock则不会（通常会在finally块中进行锁的手动释放）\n- Lock能使等待的线程响应中断，但synchronized不行\n- Lock可以知道有无成功获取锁，synchronized不行\n- Lock可以提高多个线程进行读操作的效率，当竞争资源非常激烈时，Lock的性能要优于synchronized\n\n## AQS介绍\nAQS：AbstractQueuedSynchronizer，抽象队列同步器。\n{% asset_img 031.jpg %}\n\nAQS中的队列是CLH变体的虚拟双向队列FIFO\n（CLH : Craig.Landin and Hagersten队列，是一个单向链表）\n\n**为什么使用双向队列？**\n抢到资源的线程直接使用处理业务，则抢不到资源的必然涉及一种排队等候机制。抢占资源失败的线程继续去等待，那么就一定会有某种队列形成，这样的队列是什么数据结构呢?\n如果共享资源被占用，就需要一定的阻塞等待唤醒机制来保证锁分配。这个机制主要用的是CLH队列的变体实现的将暂时获取不到锁的线程加入到队列中，这个队列就是AQS同步队列的抽象表现。它将要请求共享资源的线程及自身的等待状态封装成队列的结点对象(Node),通过CAS、自旋以及LockSupport.park()的方式，维护state变量的状态,使并发达到同步的效果。\n{% asset_img 032.jpg %}\n\n## AQS原理\n以可重入`ReentrantLock`举例说明\n\n进入`reentrantLock.lock()`方法\n```java\nReentrantLock reentrantLock = new ReentrantLock();\nreentrantLock.lock();\n```\n\n发现调用的是`sync.lock()`\n{% asset_img 034.jpg %}\n\nlock方法的真正是由其子类`FairSync`和`NonfairSync`实现的，以下是其继承关系\n{% asset_img 035.jpg %}\n\n非公平锁`NonfairSync`和公平锁`FairSync`代码如下，可以发现非公平多了一步`if`判断\n```java\nfinal void lock() {\n\tif (compareAndSetState(0, 1))\n\t\tsetExclusiveOwnerThread(Thread.currentThread());\n \telse\n\t\tacquire(1);\n}\n```\n{% asset_img 036.jpg %}\n{% asset_img 037.jpg %}\n\n接下来以非公平锁来进行分析\n\n首先介绍队列中的节点结构\n```java\n    static final class Node {\n        /** Marker to indicate a node is waiting in shared mode */\n        static final Node SHARED = new Node();\n        /** Marker to indicate a node is waiting in exclusive mode */\n        static final Node EXCLUSIVE = null;\n        /** waitStatus value to indicate thread has cancelled */\n        /** 线程被取消了 */\n        static final int CANCELLED =  1;\n        /** waitStatus value to indicate successor's thread needs unparking */\n        /** 后续线程需要唤醒 */\n        static final int SIGNAL    = -1;\n        /** waitStatus value to indicate thread is waiting on condition */\n        /** 等待condition唤醒 */\n        static final int CONDITION = -2;\n        /** waitStatus value to indicate the next acquireShared should unconditionally propagate */\n        /** 共享式同步状态获取将会无条件的传播下去 */\n        static final int PROPAGATE = -3;\n\n        //初始为0，状态就是以上几种\n        volatile int waitStatus;\n        volatile Node prev;\n        volatile Node next;\n\n        /** The thread that enqueued this node.  Initialized on construction and nulled out after use. */\n        volatile Thread thread;\n\n        /**\n         * Link to next node waiting on condition, or the special\n         * value SHARED.  Because condition queues are accessed only\n         * when holding in exclusive mode, we just need a simple\n         * linked queue to hold nodes while they are waiting on\n         * conditions. They are then transferred to the queue to\n         * re-acquire. And because conditions can only be exclusive,\n         * we save a field by using special value to indicate shared\n         * mode.\n         */\n        Node nextWaiter;\n\n        /**\n         * Returns true if node is waiting in shared mode.\n         */\n        final boolean isShared() {\n            return nextWaiter == SHARED;\n        }\n\n        /**\n         * Returns previous node, or throws NullPointerException if null.\n         * Use when predecessor cannot be null.  The null check could\n         * be elided, but is present to help the VM.\n         *\n         * @return the predecessor of this node\n         */\n        final Node predecessor() throws NullPointerException {\n            Node p = prev;\n            if (p == null)\n                throw new NullPointerException();\n            else\n                return p;\n        }\n\n        Node() {    // Used to establish initial head or SHARED marker\n        }\n\n        Node(Thread thread, Node mode) {     // Used by addWaiter\n            this.nextWaiter = mode;\n            this.thread = thread;\n        }\n\n        Node(Thread thread, int waitStatus) { // Used by Condition\n            this.waitStatus = waitStatus;\n            this.thread = thread;\n        }\n    }\n```\n\n节点属性说明\n{% asset_img 033.jpg %}\n\nstate属性：AbstractQueuedSynchronizer#state\n- 0：表示`执行窗口`空闲，可以占用\n- 1：表示有线程在占用`执行窗口`\n- >1：如果是可重入锁，则表示重入次数\n```java\nprivate volatile int state;\n```\n\n### lock()\n非公平锁`lock`方法\n```java\nfinal void lock() {\n\tif (compareAndSetState(0, 1))\n    \tsetExclusiveOwnerThread(Thread.currentThread());\n\telse\n    \tacquire(1);\n}\n\n//compareAndSetState(0, 1)：如果state为0，则将state修改为1（即如果执行窗口空闲，则将状态修改为占用），成功返回true，失败返回false\n//setExclusiveOwnerThread(Thread.currentThread())：将当前线程设置为执行窗口独占线程\n```\n\n**情况一：执行窗口空闲，则当前线程直接占用窗口，不用进入到队列中等待**\n进入`setExclusiveOwnerThread()`方法，在这里可以知晓`执行窗口`实际上就是`AbstractOwnableSynchronizer`的`exclusiveOwnerThread`属性。\n公平锁FairSync和非公平锁NonfairSync都是其子类，继承了该属性，由于是对象属性，所以每一把锁都有一个`执行窗口`。\n\n```java\npublic abstract class AbstractOwnableSynchronizer\n    implements java.io.Serializable {\n\n    private static final long serialVersionUID = 3737899427754241961L;\n\n    protected AbstractOwnableSynchronizer() { }\n\n    private transient Thread exclusiveOwnerThread;\n\n    protected final void setExclusiveOwnerThread(Thread thread) {\n        exclusiveOwnerThread = thread;\n    }\n    \n    protected final Thread getExclusiveOwnerThread() {\n        return exclusiveOwnerThread;\n    }\n}\n```\n\n**情况二：如果执行窗口被占用，则进入`acquire(1)`，入队等待**\n```java\npublic final void acquire(int arg) {\n\tif (!tryAcquire(arg) &&\n\t\tacquireQueued(addWaiter(Node.EXCLUSIVE), arg))\n\t\tselfInterrupt();\n}\n```\n在`if`判断中，会执行`tryAcquire(arg)`再次尝试占用`执行窗口`，如果不成功则再加入到队列中。\n\n非公平锁NonfairSync重写了`AbstractQueuedSynchronizer`的`tryAcquire()`方法\n```java\nprotected final boolean tryAcquire(int acquires) {\n\treturn nonfairTryAcquire(acquires);\n}\n```\n\n调用Sync的nonfairTryAcquire(int acquires)方法\n```java\nfinal boolean nonfairTryAcquire(int acquires) {\n    final Thread current = Thread.currentThread();\n    int c = getState();\t//获得执行窗口状态\n    if (c == 0) {\t//窗口空闲，尝试占用窗口\n        if (compareAndSetState(0, acquires)) {\n            setExclusiveOwnerThread(current);\n            return true;\n        }\n    }\n    else if (current == getExclusiveOwnerThread()) {\t//窗口被占用，但是占用线程为当前线程\n        int nextc = c + acquires;\t//可重入锁的重入次数\n        if (nextc < 0) // overflow\n            throw new Error(\"Maximum lock count exceeded\");\n        setState(nextc);\n        return true;\n    }\n    return false;\t//窗口被占用，且不是当前线程\n}\n```\n\n尝试再次占用窗口失败后，执行`acquireQueued(addWaiter(Node.EXCLUSIVE), arg)`\n\n```java\nprivate Node addWaiter(Node mode) {\n    Node node = new Node(Thread.currentThread(), mode);\n    // Try the fast path of enq; backup to full enq on failure\n    Node pred = tail;\n    if (pred != null) {\t//队列尾节点不为空，则将当前线程设为尾节点\n        node.prev = pred;\n        if (compareAndSetTail(pred, node)) {\n            pred.next = node;\n            return node;\n        }\n    }\n    enq(node);\n    return node;\n}\n\n//初始化队列，并将当前线程插入到队尾（当pred为null时，只会执行一次）\nprivate Node enq(final Node node) {\n    for (;;) {\n        Node t = tail;\n        if (t == null) { // Must initialize\n            if (compareAndSetHead(new Node()))\t//尾节点为空，则初始化队列，new Node(),头节点是一个虚节点（哨兵节点）\n                tail = head;\n        } else {\t//尾节点不为空，再次尝试将当前线程设为尾节点（这一步其实在addWaiter中已经出现一次了，出现两次可能类似双重null校验）\n            node.prev = t;\n            if (compareAndSetTail(t, node)) {\n                t.next = node;\n                return t;\n            }\n        }\n\t}\n}\n\n//作用大概是检阅队列，设置节点状态\nfinal boolean acquireQueued(final Node node, int arg) {\n    boolean failed = true;\n    try {\n        boolean interrupted = false;\n        for (;;) {\n            final Node p = node.predecessor();\t//获取前节点，final修饰不可变\n            if (p == head && tryAcquire(arg)) {\t//前节点是否为头节点，true则尝试当前线程占用窗口（因为头节点为虚节点，此时队列中实际只有当前线程），当占用线程释放锁时，唤醒此线程时才会进入if代码块\n                setHead(node);\t//当前线程占用窗口后，将其设为头节点（由于节点线程已占用窗口，此头节点也可视为虚节点）\n                p.next = null; // help GC（帮助GC垃圾回收）\n                failed = false;\n                return interrupted;\n            }\n            if (shouldParkAfterFailedAcquire(p, node) &&\n                parkAndCheckInterrupt())\n                interrupted = true;\n        }\n    } finally {\n        if (failed)\t//true，需要取消节点\n            cancelAcquire(node);\n    }\n}\n```\n\n`shouldParkAfterFailedAcquire(p, node)`：修改队列中的节点及节点状态\n`parkAndCheckInterrupt()`：将当前线程挂起\n```java\n//简而言之，Node#waitStatus的值\n//0：正常同步节点的值\n//SIGNAL（-1）：表示此节点的后节点已被（或将要）被阻塞（通过`LockSupport.park()`方法），未完待续\n//CANCELLED（1）：表示此节点被取消\n//CONDITION（-2）：条件节点，目前不会作为被视作为同步节点，直到状态被改为`0`\n//PROPAGATE（-3）：传播节点\n\nprivate static boolean shouldParkAfterFailedAcquire(Node pred, Node node) {\n    int ws = pred.waitStatus;\n    if (ws == Node.SIGNAL)\n\t\t//该节点已经设置了状态，要求释放以发出信号，因此它可以安全地停放\n        return true;\n    if (ws > 0) {\n\t\t//前节点被取消，循环向前直至找到未取消的节点\n        do {\n            node.prev = pred = pred.prev;\n        } while (pred.waitStatus > 0);\n        pred.next = node;\n    } else {\n        //waitStatus 必须为 0 或 PROPAGATE\n        compareAndSetWaitStatus(pred, ws, Node.SIGNAL);\n    }\n    return false;\n}\n\nprivate final boolean parkAndCheckInterrupt() {\n    LockSupport.park(this);\n\treturn Thread.interrupted();\n}\n```\n\n以下以三个线程A、B、C具体举例说明\n\nA线程尝试获取锁时，直接占用`执行窗口`\n\nB线程尝试获取锁：A线程正在执行，窗口被占用。\n将B线程节点加入队列，队列初始化，头节点（虚节点，ws为0），B线程节点为尾节点。\n开始第一次进入`shouldParkAfterFailedAcquire`方法，前节点（即头节点）`ws`为`0`，进入`else`代码块将前节点状态设`SIGNAL`，返回`false`，`&&`右边部分此次不执行\n由于外部循环，第二次进入方法时，直接返回`true`，开始执行`&&`右边部分`parkAndCheckInterrupt()`，将当前线程B挂起\n\n线程C尝试获取锁：A线程同样正在执行，窗口被占用\n将线程C节点加入队列，线程节点C为尾节点，前节点为线程B节点。\n同线程B，开始第一次进入`shouldParkAfterFailedAcquire`方法，前节点线程B的`ws`为`0`，进入`else`代码块将前节点状态设`SIGNAL`，返回`false`，`&&`右边部分此次不执行\n由于外部循环，第二次进入方法时，直接返回`true`，开始执行`&&`右边部分`parkAndCheckInterrupt()`，将当前线程C挂起\nPS：如果前节点的`ws>0`则一直向前，直至遇到`ws<=0`的节点\n\n可见后一个线程进入队列，将前一个线程节点的`ws`设为`SIGNAL`，然后线程挂起\n\n```java\nprivate void cancelAcquire(Node node) {\n    // Ignore if node doesn't exist\n    if (node == null)\n        return;\n    node.thread = null;\n    // Skip cancelled predecessors\n    Node pred = node.prev;\n    while (pred.waitStatus > 0)\n        node.prev = pred = pred.prev;\n    // predNext is the apparent node to unsplice. CASes below will\n    // fail if not, in which case, we lost race vs another cancel\n    // or signal, so no further action is necessary.\n    Node predNext = pred.next;\n    // Can use unconditional write instead of CAS here.\n    // After this atomic step, other Nodes can skip past us.\n    // Before, we are free of interference from other threads.\n    node.waitStatus = Node.CANCELLED;\n    // If we are the tail, remove ourselves.\n    if (node == tail && compareAndSetTail(node, pred)) {\n        compareAndSetNext(pred, predNext, null);\n    } else {\n        // If successor needs signal, try to set pred's next-link\n        // so it will get one. Otherwise wake it up to propagate.\n        int ws;\n        if (pred != head &&\n            ((ws = pred.waitStatus) == Node.SIGNAL ||\n             (ws <= 0 && compareAndSetWaitStatus(pred, ws, Node.SIGNAL))) &&\n            pred.thread != null) {\n            Node next = node.next;\n            if (next != null && next.waitStatus <= 0)\n                compareAndSetNext(pred, predNext, next);\n        } else {\n            unparkSuccessor(node);\n        }\n        node.next = node; // help GC\n    }\n}\n```\n\n### unlock()\n同样以非公平锁NonfairSync举例\n\nunlock()\n```java\npublic void unlock() {\n        sync.release(1);\n    }\n```\n\nrelease()\n```java\npublic final boolean release(int arg) {\n\tif (tryRelease(arg)) {\n\t\tNode h = head;\n\t\tif (h != null && h.waitStatus != 0)\n\t\t\tunparkSuccessor(h);\n\t\treturn true;\n\t}\n\treturn false;\n}\n```\n\ntryRelease(arg)\n```java\nprotected final boolean tryRelease(int releases) {\n    int c = getState() - releases;\n    if (Thread.currentThread() != getExclusiveOwnerThread())\n        throw new IllegalMonitorStateException();\n    boolean free = false;\n    if (c == 0) {\n        free = true;\n        setExclusiveOwnerThread(null);\n    }\n    setState(c);\n    return free;\n}\n```\n\nunparkSuccessor(h)：唤醒挂起的线程。\n```java\nprivate void unparkSuccessor(Node node) {\n    int ws = node.waitStatus;\n    \n    if (ws < 0)\n        compareAndSetWaitStatus(node, ws, 0);\n\n    Node s = node.next;\n    if (s == null || s.waitStatus > 0) {\n        s = null;\n        for (Node t = tail; t != null && t != node; t = t.prev)\n            if (t.waitStatus <= 0)\n                s = t;\n    }\n    if (s != null)\n        LockSupport.unpark(s.thread);\n}\n```\n如果头节点的后节点为空或者后节点的`ws>0`，则从队列的尾节点开始向前唤醒挂起的线程，直至找到当前节点（占有窗口的头节点）后的第一个`ws<=0`的线程节点，唤醒此线程。前面介绍`lock()`部分的`parkAndCheckInterrupt()`时，线程会在此处挂起。\n\n## ReentrantRWLock读写锁\n对读写操作进行分离，分为单独的读锁和写锁。允许多个线程进行读操作，只允许一个线程进行写操作。\n\n读写锁ReentrantReadWriteLock并不是真正意义上的读写分离，它只允许读读共存，而读写和写写依然是互斥的， 大多实际场景是“读/读”线程间并不存在互斥关系，只有\"读/写\"线程或\"写/写\"线程间的操作需要互斥的。\n\n应用场景：在读多写少情况下，读写锁有较高性能体验。\n\n缺点：锁饥饿问题，大量读线程执行，造成写线程长期获取不到锁的情况。\n\n锁降级\n遵循获取写锁→再获取读锁→再释放写锁的次序，写锁能够降级成为读锁。 如果一个线程占有了写锁，在不释放写锁的情况下，它还能占有读锁，即写锁降级为读锁。\n\n写锁和读锁是互斥的（这里的互斥是指线程间的互斥）当前线程可以获取到写锁又获取到读锁（锁降级），但是获取到了读锁不能继续获取写锁。这是因为读写锁要保持写操作的可见性。因为，如果允许读锁在被获取的情况下对写锁的获取，那么正在运行的其他读线程无法感知到当前写线程的操作。\n\n因此，分析读写锁ReentrantReadWriteLock，会发现它有个潜在的问题：读锁全完，写锁有望；写锁独占，读写全堵；如果有线程正在读，写线程需要等待读线程释放锁后才能获取写锁，只有等待线程都释放了读锁，当前线程才能获取写锁，也就是写入必须等待，这是一种悲观的读锁，人家还在读着那，你先别去写，省的数据乱。\n\n分析StampedLock，会发现它改进之处在于：读的过程中也允许获取写锁介入(相当牛B，读和写两个操作也让你“共享”(注意引号))，这样会导致我们读的数据就可能不一致！所以，需要额外的方法来判断读的过程中是否有写入，这是一种乐观的读锁，O(∩_∩)O哈哈~。 显然乐观锁的并发效率更高，但一旦有小概率的写入导致读取的数据不一致，需要能检测出来，再读一遍就行。\n\nDemo\n```java\npackage com.bilibili.juc.rwlock;\n\nimport java.util.HashMap;\nimport java.util.Map;\nimport java.util.concurrent.TimeUnit;\nimport java.util.concurrent.locks.Lock;\nimport java.util.concurrent.locks.ReadWriteLock;\nimport java.util.concurrent.locks.ReentrantLock;\nimport java.util.concurrent.locks.ReentrantReadWriteLock;\n\n\n\n\nclass CoResource //资源类，模拟一个简单的缓存\n{\n    Map<String,String> map = new HashMap<>();\n    //=====ReentrantLock 等价于 =====synchronized，之前讲解过\n    Lock lock = new ReentrantLock();\n    //=====ReentrantReadWriteLock 一体两面，读写互斥，读读共享\n    ReadWriteLock rwLock = new ReentrantReadWriteLock();\n\n    public void write(String key ,String value)\n    {\n        lock.lock();\n        try\n        {\n            System.out.println(Thread.currentThread().getName()+\"\\t\"+\"正在写入\");\n            map.put(key,value);\n            //暂停毫秒\n            try { TimeUnit.MILLISECONDS.sleep(500); } catch (InterruptedException e) { e.printStackTrace(); }\n            System.out.println(Thread.currentThread().getName()+\"\\t\"+\"完成写入\");\n        }finally {\n            lock.unlock();\n        }\n    }\n\n    public void read(String key)\n    {\n        lock.lock();\n        try\n        {\n            System.out.println(Thread.currentThread().getName()+\"\\t\"+\"正在读取\");\n            String result = map.get(key);\n            //暂停200毫秒\n            try { TimeUnit.MILLISECONDS.sleep(200); } catch (InterruptedException e) { e.printStackTrace(); }\n            System.out.println(Thread.currentThread().getName()+\"\\t\"+\"完成读取\"+\"\\t\"+result);\n        }finally {\n            lock.unlock();\n        }\n    }\n\n\n}\n\n\n/**\n * @auther zzyy\n * @create 2022-04-08 18:18\n */\npublic class ReentrantLockDemo\n{\n    public static void main(String[] args)\n    {\n        CoResource coResource = new CoResource();\n\n        for (int i = 1; i <=10; i++) {\n            int finalI = i;\n            new Thread(() -> {\n                coResource.write(finalI +\"\", finalI +\"\");\n            },String.valueOf(i)).start();\n        }\n\n        for (int i = 1; i <=10; i++) {\n            int finalI = i;\n            new Thread(() -> {\n                coResource.read(finalI +\"\");\n            },String.valueOf(i)).start();\n        }\n\n    }\n}\n输出：\n1\t正在写入\n1\t完成写入\n3\t正在写入\n3\t完成写入\n4\t正在写入\n4\t完成写入\n2\t正在写入\n2\t完成写入\n5\t正在写入\n5\t完成写入\n6\t正在写入\n6\t完成写入\n7\t正在写入\n7\t完成写入\n8\t正在写入\n8\t完成写入\n9\t正在写入\n9\t完成写入\n10\t正在写入\n10\t完成写入\n1\t正在读取\n1\t完成读取\t1\n2\t正在读取\n2\t完成读取\t2\n4\t正在读取\n4\t完成读取\t4\n6\t正在读取\n6\t完成读取\t6\n5\t正在读取\n5\t完成读取\t5\n3\t正在读取\n3\t完成读取\t3\n7\t正在读取\n7\t完成读取\t7\n8\t正在读取\n8\t完成读取\t8\n9\t正在读取\n9\t完成读取\t9\n10\t正在读取\n10\t完成读取\t10\n\nProcess finished with exit code 0\n\n```\n\n## StampeLock邮戳锁\n如果解决读写锁的锁饥饿问题？\n- 使用公平锁：“公平”是以牺牲系统吞吐量为代价的。\n```java\nnew ReentrantReadWriteLock(true);\n```\n- 使用邮戳锁StampeLock\n\n邮戳锁的基本特点:\n1. 所有获取锁的方法,都返回一个邮戳(Stamp),Stamp为零表示获取失败,其余都表示成功;\n2．所有释放锁的方法,都需要一个邮戳(Stamp),这个Stamp必须是和成功获取锁时得到的Stamp一致;\n3. StampedLock是不可重入的，没有Re开头。危险(如果一个线程已经持有了写锁再去获取写锁的话就会造成死锁)\n4. StampedLock的悲观读锁和写锁都不支持条件变量(Condition),这个也需要注意。.ntes\n5. 使用StampedLock一定不要调用中断操作,即不要调用interrupt()方法\n\nStampedLock有三种访问模式:\n1. Reading(读模式悲观):功能和ReentrantReadWriteLock的读锁类似\n2. Writing(写模式悲观):功能和ReentrantReadWriteLock的写锁类似\n3. Optimistic reading(乐观读模式)∶无锁机制类似于数据库中的乐观锁.支持读写并发很乐观认为读取时没人修改假如被修改再实现升级为悲观读模式\n  - 乐观的阅读。仅当锁定当前未处于写入模式时,方法 tryOptimisticRead()才返回非零戳记。如果自获得给定标记以来没有在写入模式下获取锁定则方法validate(Jong)返回true。这种模式可以被认为是读锁的极弱版本,可以随时被作者破坏。对短的只读代码段使用乐观模式通常可以减少争用并提高吞吐量。但是,它的使用本质上是脆弱的。\n  - 乐观读取部分应该只读取字段并将它们保存在局部变量中以便以后在验证后使用。在乐观模式下读取的字段可能非常不一致因此仅在您熟悉数据表示以检查一致性和/或重复调用方法validate()例如,在首次读取对象或数组引用然后访问其中一个字段,元素或方法时,通常需要执行此类步骤。\n\nDemo\n传统版读写锁\n```java\npackage com.bilibili.juc.rwlock;\n\nimport java.util.concurrent.TimeUnit;\nimport java.util.concurrent.locks.StampedLock;\n\n/**\n * @auther zzyy\n *\n * StampedLock = ReentrantReadWriteLock + 读的过程中也允许获取写锁介入\n */\npublic class StampedLockDemo\n{\n    static int number = 37;\n    static StampedLock stampedLock = new StampedLock();\n\n    public void write()\n    {\n        long stamp = stampedLock.writeLock();\n        System.out.println(Thread.currentThread().getName()+\"\\t\"+\"写线程准备修改\");\n        try\n        {\n            number = number + 13;\n        }finally {\n            stampedLock.unlockWrite(stamp);\n        }\n        System.out.println(Thread.currentThread().getName()+\"\\t\"+\"写线程结束修改\");\n    }\n\n    //悲观读，读没有完成时候写锁无法获得锁\n    public void read()\n    {\n        long stamp = stampedLock.readLock();\n        System.out.println(Thread.currentThread().getName()+\"\\t\"+\" come in readlock code block，4 seconds continue...\");\n        for (int i = 0; i < 4; i++) {\n            //暂停几秒钟线程\n            try { TimeUnit.SECONDS.sleep(1); } catch (InterruptedException e) { e.printStackTrace(); }\n            System.out.println(Thread.currentThread().getName()+\"\\t\"+\" 正在读取中......\");\n        }\n\n        try\n        {\n            int result = number;\n            System.out.println(Thread.currentThread().getName()+\"\\t\"+\" 获得成员变量值result：\"+result);\n            System.out.println(\"读锁的时候，写锁无法介入\");\n        }finally {\n            stampedLock.unlockRead(stamp);\n        }\n    }\n\n\n    public static void main(String[] args)\n    {\n        StampedLockDemo resource = new StampedLockDemo();\n\n        //传统版\n        new Thread(() -> {\n            resource.read();\n        },\"readThread\").start();\n\n        //暂停几秒钟线程\n        try { TimeUnit.SECONDS.sleep(1); } catch (InterruptedException e) { e.printStackTrace(); }\n\n        new Thread(() -> {\n            System.out.println(Thread.currentThread().getName()+\"\\t\"+\"----come in\");\n            resource.write();\n        },\"writeThread\").start();\n\n        //暂停几秒钟线程\n        try { TimeUnit.SECONDS.sleep(4); } catch (InterruptedException e) { e.printStackTrace(); }\n\n        System.out.println(Thread.currentThread().getName()+\"\\t\"+\"number:\" +number);\n\n\n    }\n}\n\n输出：\nreadThread\t come in readlock code block，4 seconds continue...\nreadThread\t 正在读取中......\nwriteThread\t----come in\nreadThread\t 正在读取中......\nreadThread\t 正在读取中......\nreadThread\t 正在读取中......\nreadThread\t 获得成员变量值result：37\n读锁的时候，写锁无法介入\nwriteThread\t写线程准备修改\nwriteThread\t写线程结束修改\nmain\tnumber:50\n\nProcess finished with exit code 0\n\n```\n\nDmeo\n允许写线程接入\n若写线程完成修改，则此后乐观读锁升级为悲观锁\n```java\npackage com.bilibili.juc.rwlock;\n\nimport java.util.concurrent.TimeUnit;\nimport java.util.concurrent.locks.StampedLock;\n\n/**\n * @auther zzyy\n *\n * StampedLock = ReentrantReadWriteLock + 读的过程中也允许获取写锁介入\n */\npublic class StampedLockDemo\n{\n    static int number = 37;\n    static StampedLock stampedLock = new StampedLock();\n\n    public void write()\n    {\n        long stamp = stampedLock.writeLock();\n        System.out.println(Thread.currentThread().getName()+\"\\t\"+\"写线程准备修改\");\n        try\n        {\n            number = number + 13;\n        }finally {\n            stampedLock.unlockWrite(stamp);\n        }\n        System.out.println(Thread.currentThread().getName()+\"\\t\"+\"写线程结束修改\");\n    }\n\n\n\n    //乐观读，读的过程中也允许获取写锁介入\n    public void tryOptimisticRead()\n    {\n        long stamp = stampedLock.tryOptimisticRead();\n        int result = number;\n        //故意间隔4秒钟，很乐观认为读取中没有其它线程修改过number值，具体靠判断\n        System.out.println(\"4秒前stampedLock.validate方法值(true无修改，false有修改)\"+\"\\t\"+stampedLock.validate(stamp));\n        for (int i = 0; i < 4; i++) {\n            try { TimeUnit.SECONDS.sleep(1); } catch (InterruptedException e) { e.printStackTrace(); }\n            System.out.println(Thread.currentThread().getName()+\"\\t\"+\"正在读取... \"+i+\" 秒\" +\n                    \"后stampedLock.validate方法值(true无修改，false有修改)\"+\"\\t\"+stampedLock.validate(stamp));\n        }\n        if(!stampedLock.validate(stamp))\n        {\n            System.out.println(\"有人修改过------有写操作\");\n            stamp = stampedLock.readLock();//从乐观读 升级为 悲观读\n            try\n            {\n                System.out.println(\"从乐观读 升级为 悲观读\");\n                result = number;\n                System.out.println(\"重新悲观读后result：\"+result);\n            }finally {\n                stampedLock.unlockRead(stamp);\n            }\n        }\n        System.out.println(Thread.currentThread().getName()+\"\\t\"+\" finally value: \"+result);\n    }\n\n\n    public static void main(String[] args)\n    {\n        StampedLockDemo resource = new StampedLockDemo();\n\n\n        new Thread(() -> {\n            resource.tryOptimisticRead();\n        },\"readThread\").start();\n\n        //暂停2秒钟线程,读过程可以写介入，演示\n        try { TimeUnit.SECONDS.sleep(2); } catch (InterruptedException e) { e.printStackTrace(); }\n\n\n        new Thread(() -> {\n            System.out.println(Thread.currentThread().getName()+\"\\t\"+\"----come in\");\n            resource.write();\n        },\"writeThread\").start();\n\n\n    }\n}\n输出：\n4秒前stampedLock.validate方法值(true无修改，false有修改)\ttrue\nreadThread\t正在读取... 0 秒后stampedLock.validate方法值(true无修改，false有修改)\ttrue\nwriteThread\t----come in\nwriteThread\t写线程准备修改\nwriteThread\t写线程结束修改\nreadThread\t正在读取... 1 秒后stampedLock.validate方法值(true无修改，false有修改)\tfalse\nreadThread\t正在读取... 2 秒后stampedLock.validate方法值(true无修改，false有修改)\tfalse\nreadThread\t正在读取... 3 秒后stampedLock.validate方法值(true无修改，false有修改)\tfalse\n有人修改过------有写操作\n从乐观读 升级为 悲观读\n重新悲观读后result：50\nreadThread\t finally value: 50\n\nProcess finished with exit code 0\n\n```\n\n若写线程没来得及完成修改，则乐观读锁无需升级\n```java\npackage com.bilibili.juc.rwlock;\n\nimport java.util.concurrent.TimeUnit;\nimport java.util.concurrent.locks.StampedLock;\n\n/**\n * @auther zzyy\n *\n * StampedLock = ReentrantReadWriteLock + 读的过程中也允许获取写锁介入\n */\npublic class StampedLockDemo\n{\n    static int number = 37;\n    static StampedLock stampedLock = new StampedLock();\n\n    public void write()\n    {\n        long stamp = stampedLock.writeLock();\n        System.out.println(Thread.currentThread().getName()+\"\\t\"+\"写线程准备修改\");\n        try\n        {\n            number = number + 13;\n        }finally {\n            stampedLock.unlockWrite(stamp);\n        }\n        System.out.println(Thread.currentThread().getName()+\"\\t\"+\"写线程结束修改\");\n    }\n\n    //乐观读，读的过程中也允许获取写锁介入\n    public void tryOptimisticRead()\n    {\n        long stamp = stampedLock.tryOptimisticRead();\n        int result = number;\n        //故意间隔4秒钟，很乐观认为读取中没有其它线程修改过number值，具体靠判断\n        System.out.println(\"4秒前stampedLock.validate方法值(true无修改，false有修改)\"+\"\\t\"+stampedLock.validate(stamp));\n        for (int i = 0; i < 4; i++) {\n            try { TimeUnit.SECONDS.sleep(1); } catch (InterruptedException e) { e.printStackTrace(); }\n            System.out.println(Thread.currentThread().getName()+\"\\t\"+\"正在读取... \"+i+\" 秒\" +\n                    \"后stampedLock.validate方法值(true无修改，false有修改)\"+\"\\t\"+stampedLock.validate(stamp));\n        }\n        if(!stampedLock.validate(stamp))\n        {\n            System.out.println(\"有人修改过------有写操作\");\n            stamp = stampedLock.readLock();//从乐观读 升级为 悲观读\n            try\n            {\n                System.out.println(\"从乐观读 升级为 悲观读\");\n                result = number;\n                System.out.println(\"重新悲观读后result：\"+result);\n            }finally {\n                stampedLock.unlockRead(stamp);\n            }\n        }\n        System.out.println(Thread.currentThread().getName()+\"\\t\"+\" finally value: \"+result);\n    }\n\n\n    public static void main(String[] args)\n    {\n        StampedLockDemo resource = new StampedLockDemo();\n\n        new Thread(() -> {\n            resource.tryOptimisticRead();\n        },\"readThread\").start();\n\n\n        //暂停6秒钟线程，使得写线程不可介入\n        try { TimeUnit.SECONDS.sleep(6); } catch (InterruptedException e) { e.printStackTrace(); }\n\n        new Thread(() -> {\n            System.out.println(Thread.currentThread().getName()+\"\\t\"+\"----come in\");\n            resource.write();\n        },\"writeThread\").start();\n        \n        try { TimeUnit.SECONDS.sleep(4); } catch (InterruptedException e) { e.printStackTrace(); }\n        System.out.println(Thread.currentThread().getName()+\"\\t\"+\"number:\" +number);\n\n    }\n}\n\n输出：\n4秒前stampedLock.validate方法值(true无修改，false有修改)\ttrue\nreadThread\t正在读取... 0 秒后stampedLock.validate方法值(true无修改，false有修改)\ttrue\nreadThread\t正在读取... 1 秒后stampedLock.validate方法值(true无修改，false有修改)\ttrue\nreadThread\t正在读取... 2 秒后stampedLock.validate方法值(true无修改，false有修改)\ttrue\nreadThread\t正在读取... 3 秒后stampedLock.validate方法值(true无修改，false有修改)\ttrue\nreadThread\t finally value: 37\nwriteThread\t----come in\nwriteThread\t写线程准备修改\nwriteThread\t写线程结束修改\nmain\tnumber:50\n    \nProcess finished with exit code 0\n\n```\n\n## Condition\n与Lock配合实现**等待/通知**模式（生产者/消费者模式），实现线程精准唤醒。\n\nDemo\n```java\npublic class ConditionTest {\n    private final static Lock lock = new ReentrantLock(true);\n\n    private final  static Condition condition = lock.newCondition();\n\n    private static int data = 0;\n\n    private static volatile  boolean noUse = true;\n\n    public static void main(String[] args) throws InterruptedException {\n\n\n        new Thread(()->{\n            while (true){\n                buildData();\n            }\n        }).start();\n        new Thread(()->{\n            while (true){\n                useData();\n            }\n        }).start();\n    }\n\n    /**\n     * 生产数据\n     */\n    private static void buildData(){\n        try {\n            lock.lock();    //synchronized key word  #moitor enter\n            while (noUse){\n                condition.await();  // monitor.wait()\n            }\n            data++;\n            System.out.println(\"P:\" + data);\n            Thread.sleep(1000);\n            noUse = true;\n            condition.signal();  // monitor.notify()\n        } catch (InterruptedException e) {\n            e.printStackTrace();\n        } finally {\n            lock.unlock();  // synchronized  end  #moitor end\n        }\n    }\n\n\n    /**\n     * 消费数据\n     */\n    private static void useData(){\n        try {\n            lock.lock();    //synchronized key word  #moitor enter\n            while (!noUse){\n                condition.await();  // monitor.wait()\n            }\n            System.out.println(\"C:\" + data);\n            Thread.sleep(1000);\n            noUse = false;\n            condition.signal();  // monitor.notify()\n        } catch (InterruptedException e) {\n            e.printStackTrace();\n        } finally {\n            lock.unlock();  // synchronized  end  #moitor end\n        }\n    }\n}\n```\n\nDemo\n```java\nclass Data3{\n\n    private Lock lock = new ReentrantLock();\n    private Condition condition = lock.newCondition();\n    private Condition condition2 = lock.newCondition();\n    private Condition condition3 = lock.newCondition();\n    private Integer number = 1;\n\n    public void printA(){\n        lock.lock();\n        try {\n            //业务\n            while(number != 1){\n                condition.await();\n            }\n            System.out.println(Thread.currentThread().getName()+\":AAAAAAAAAAAAA\");\n            number = 2;\n            condition2.signal();\n        } catch (Exception e) {\n            e.printStackTrace();\n        }finally {\n            lock.unlock();\n        }\n    }\n\n    public void printB(){\n        lock.lock();\n        try {\n            //业务\n            while(number != 2){\n                condition2.await();\n            }\n            System.out.println(Thread.currentThread().getName()+\":BBB\");\n            number = 3;\n            condition3.signal();\n        } catch (Exception e) {\n            e.printStackTrace();\n        }finally {\n            lock.unlock();\n        }\n    }\n\n    public void printC(){\n        lock.lock();\n        try {\n            //业务\n            while(number != 3){\n                condition3.await();\n            }\n            System.out.println(Thread.currentThread().getName()+\":CCC\");\n            number = 1;\n            condition.signal();\n        } catch (Exception e) {\n            e.printStackTrace();\n        }finally {\n            lock.unlock();\n        }\n    }\n}\n```\n\n## CountDownLatch计数器\nCountDownLatch：允许count个线程阻塞在一个地方，直至这count个线程的任务都执行完毕。\n\nDemo\n我们要读取处理6个文件，这6个任务都是没有执行顺序依赖的任务，但是我们需要返回给用户的时候将这几个文件的处理的结果进行统计整理。\n为此我们定义了一个线程地和count为6的CountDownlatch对象。使用线程池处理读取任务，每一个线程处理完之后就将count-1，调用CountDownLatch对象的await()方法，直到所有文件读取完之后，才会接着执行后面的逻辑。\n\n```java\npublic class CountDownLatchExample1 {\n    // 处理文件的数量\n    private static final int threadCount = 6;\n\n    public static void main(String[] args) throws InterruptedException {\n        // 创建一个具有固定线程数量的线程池对象（推荐使用构造方法创建）\n        ExecutorService threadPool = Executors.newFixedThreadPool(10);\n        final CountDownLatch countDownLatch = new CountDownLatch(threadCount);\n        for (int i = 0; i < threadCount; i++) {\n            final int threadnum = i;\n            threadPool.execute(() -> {\n                try {\n                    //处理文件的业务操作\n                    //......\n                } catch (InterruptedException e) {\n                    e.printStackTrace();\n                } finally {\n                    //表示一个文件已经被完成\n                    countDownLatch.countDown();\n                }\n\n            });\n        }\n        countDownLatch.await();\n        threadPool.shutdown();\n        System.out.println(\"finish\");\n    }\n}\n```\n\n优化一\n```java\nCompletableFuture<Void> task1 =\n    CompletableFuture.supplyAsync(()->{\n        //自定义业务操作\n    });\n......\nCompletableFuture<Void> task6 =\n    CompletableFuture.supplyAsync(()->{\n    //自定义业务操作\n    });\n......\nCompletableFuture<Void> headerFuture=CompletableFuture.allOf(task1,.....,task6);\n\ntry {\n    headerFuture.join();\n} catch (Exception ex) {\n    //......\n}\nSystem.out.println(\"all done. \");\n```\n\n优化二\n使用集合添加任务\n```java\n//文件夹位置\nList<String> filePaths = Arrays.asList(...)\n// 异步处理所有文件\nList<CompletableFuture<String>> fileFutures = filePaths.stream()\n    .map(filePath -> doSomeThing(filePath))\n    .collect(Collectors.toList());\n// 将他们合并起来\nCompletableFuture<Void> allFutures = CompletableFuture.allOf(\n    fileFutures.toArray(new CompletableFuture[fileFutures.size()])\n);\n```\n\n**原理简介**\nCountDownLatch两个方法:\n- countDown()\n- await()\n\nCountDownLatch也是基于AQS实现的，它的实现机制很简单。\n- 在构建CountDownLatch对象时，传入的值其实就会赋值给AQS的关键变量state\n- 执行CountDownLatch的countDown方法时，其实就是利用CAS将state 减一\n- 执行await方法时，其实就是判断state是否为O，不为O则加入到阻塞队列中，将该线程阻塞掉（除了头结点)，因关头节点会一直自旋等待state为0，当state为0时，头节点把剩余的在队列中阻塞的节点也一并唤醒。\n\n\n## CyclicBarrier回环栅栏\nCyclicBarrier原理介绍\n- CyclicBarrier没有像CountDownLatch和ReentrantLock使用AQS的state变量，而是使用CyclicBarrier内部维护的内部维护count变量\n- CyclicBarrier借助ReentrantLock加上Condition实现等待唤醒的功能。\n\n在构建CyclicBarrier时，传入的值是parties变量，同时也会赋值给CyclicBarrier内部维护count变量(这是可以复用的关键)\n```java\n//parties表示屏障拦截的线程数量，当屏障撤销时，先执行barrierAction，然后在释放所有线程\npublic CyclicBarrier(int parties, Runnable barrierAction)\n//barrierAction默认为null\npublic CyclicBarrier(int parties)\n```\n\n每次调用await时，会将count-1，操作count值是直接使用ReentrantLock来保证线程安全性\n- 如果count不为0，则添加则condition队列中\n- 如果count等于0时，则把节点从condition队列添加至AQS的队列中进行全部唤醒，并且将parties的值重新赋值为count的值(实现复用)\n\nCyclicBarrier的特点：阻塞任务线程而非主线程\nCountDownLatch和CyclicBarrier都是线程同步的工具类。可以发现这两者的等待主体是不一样的\n- CountDownLatch调用await()通常是主线程/调用线程\n- CyclicBarrier调用await()是在任务线程调用的，所以CyclicBarrier中的阻塞的是任务的线程，而主线程是不受影响的\n\nDemo\n```java\n   //集齐7颗龙珠就能召唤神龙\npublic class CyclicBarrierDemo {\n    public static void main(String[] args) {\n        // public CyclicBarrier(int parties, Runnable barrierAction) {}\n        CyclicBarrier cyclicBarrier=new CyclicBarrier(7,()->{\n            System.out.println(\"召唤龙珠\");\n        });\n        for (int i = 1; i <=7; i++) {\n            final int temp=i;\n            new Thread(()->{\n                System.out.println(Thread.currentThread().getName()+\"\\t收集到了第\"+temp+\"颗龙珠\");\n                try {\n                    cyclicBarrier.await();\n                } catch (InterruptedException e) {\n                    e.printStackTrace();\n                } catch (BrokenBarrierException e) {\n                    e.printStackTrace();\n                }\n            }).start();\n        }\n\n    }\n}\n```\n\n共同抵达时的执行操作\n屏障的抵达操作:每个线程执行时，都会碰到一个屏障，直到所有线程执行结束，然后屏障便会打开，使所有线程继续往下执行。\n- CyclicBarrier支持一个可选的Runnable barrierAction命令，在一组线程中的最后一个线程到达之后，但在释放所有线程之前运行一次。\n- 若在继续所有参与线程之前更新共享状态，此屏障操作很有用。、\n\n这里介绍CyclicBarrier的两个构造函数:\n- CyclicBarrier(int parties)前者只需要声明需要拦截的线程数即可\n- CylicBarrier(int parties,Runnable barrierAction)后者还需要定义一个等待所有线程到达屏障优先执行的Runnable对象。\n\n如果一个寝室四个人约好了去球场打球，由于四个人准备工作不同，所以约好在楼下集合，并且四个人集合好之后一起出发去球场。\n```java\n    private static final ThreadPoolExecutor threadPool = new ThreadPoolExecutor(4, 10, 60, TimeUnit.SECONDS, new LinkedBlockingQueue<Runnable>());\n    //当拦截线程数达到4时，便优先执行barrierAction，然后再执行被拦截的线程。\n    private static final CyclicBarrier cb = new CyclicBarrier(4, () -> System.out.println(\"寝室四兄弟一起出发去球场\"));\n\n    private static class MyThread extends Thread {\n        private String name;\n        public MyThread(String name) {\n            this.name = name;\n        }\n\n        @Override\n        public void run() {\n            System.out.println(name + \"开始从宿舍出发\");\n            try {\n                cb.await();\n                //线程的具体业务操作\n                TimeUnit.SECONDS.sleep(1);\n                System.out.println(name + \"从楼底下出发\");\n                TimeUnit.SECONDS.sleep(1);\n                System.out.println(name + \"到达操场\");\n            } catch (Exception e) {\n                e.printStackTrace();\n            }\n        }\n    }\n\n    public static void main(String[] args) {\n        String[] str = {\"李明\", \"王强\", \"刘凯\", \"赵杰\"};\n        for (int i = 0; i < 4; i++) {\n            threadPool.execute(new MyThread(str[i]));\n        }\n        try {\n            Thread.sleep(4000);\n            System.out.println(\"四个人一起到达球场，现在开始打球\");\n        } catch (InterruptedException e) {\n            e.printStackTrace();\n        }\n        \n    }\n输出：\n王强开始从宿舍出发\n刘凯开始从宿舍出发\n李明开始从宿舍出发\n赵杰开始从宿舍出发\n寝室四兄弟一起出发去球场\n李明从楼底下出发\n刘凯从楼底下出发\n王强从楼底下出发\n赵杰从楼底下出发\n赵杰到达操场\n刘凯到达操场\n王强到达操场\n李明到达操场\n四个人一起到达球场，现在开始打球\n```\n\n屏障复用\nCyclicBarrier是可循环利用的屏障，顾名思义，这个名字也将这个类的特点给明确地表示出来了。可重复利用，说明该类创建的对象可以复用;CyclicBarrier是一个同步工具类，它允许一组线程互相等待，直到到达某个公共屏障点。与CountDownLatch不同的是该barrier在释放等待线程后可以重用，所以称它为循环(Cyclic)的屏障(Barrier)。\n现在对CyclicBarrier进行复用...又来了一拨人，看看愿不愿意一起打:\n```java\n    private static final ThreadPoolExecutor threadPool = new ThreadPoolExecutor(4, 10, 60, TimeUnit.SECONDS, new LinkedBlockingQueue<Runnable>());\n    //当拦截线程数达到4时，便优先执行barrierAction，然后再执行被拦截的线程。\n    private static final CyclicBarrier cb = new CyclicBarrier(4, () -> System.out.println(\"寝室四兄弟一起出发去球场\"));\n\n    private static class MyThread extends Thread {\n        private String name;\n        public MyThread(String name) {\n            this.name = name;\n        }\n\n        @Override\n        public void run() {\n            System.out.println(name + \"开始从宿舍出发\");\n            try {\n                cb.await();\n                TimeUnit.SECONDS.sleep(1);\n                System.out.println(name + \"从楼底下出发\");\n                TimeUnit.SECONDS.sleep(1);\n                System.out.println(name + \"到达操场\");\n            } catch (Exception e) {\n                e.printStackTrace();\n            }\n        }\n    }\n\n    public static void main(String[] args) {\n        String[] str = {\"李明\", \"王强\", \"刘凯\", \"赵杰\"};\n        for (int i = 0; i < 4; i++) {\n            threadPool.execute(new MyThread(str[i]));\n        }\n        try {\n            Thread.sleep(4000);\n            System.out.println(\"四个人一起到达球场，现在开始打球\");\n            System.out.println();\n            System.out.println(\"现在对CyclicBarrier进行复用.....\");\n            System.out.println(\"又来了一拨人，看看愿不愿意一起打：\");\n\n        } catch (InterruptedException e) {\n            e.printStackTrace();\n        }\n\n        String[] str1= {\"王二\",\"洪光\",\"雷兵\",\"赵三\"};\n        for (int i = 0; i < 4; i++) {\n            threadPool.execute(new MyThread(str1[i]));\n        }\n        try {\n            Thread.sleep(4000);\n            System.out.println(\"四个人一起到达球场，表示愿意一起打球，现在八个人开始打球\");\n        } catch (InterruptedException e) {\n            e.printStackTrace();\n        }\n\n    }\n\n李明开始从宿舍出发\n刘凯开始从宿舍出发\n王强开始从宿舍出发\n赵杰开始从宿舍出发\n寝室四兄弟一起出发去球场\n李明从楼底下出发\n赵杰从楼底下出发\n刘凯从楼底下出发\n王强从楼底下出发\n李明到达操场\n赵杰到达操场\n刘凯到达操场\n王强到达操场\n四个人一起到达球场，现在开始打球\n\n现在对CyclicBarrier进行复用…\n又来了一拨人，看看愿不愿意一起打：\n王二开始从宿舍出发\n洪光开始从宿舍出发\n赵三开始从宿舍出发\n雷兵开始从宿舍出发\n寝室四兄弟一起出发去球场\n雷兵从楼底下出发\n赵三从楼底下出发\n王二从楼底下出发\n洪光从楼底下出发\n洪光到达操场\n赵三到达操场\n王二到达操场\n雷兵到达操场\n四个人一起到达球场，表示愿意一起打球，现在八个人开始打球\n```\n\n## Semaphore\nSemaphore通常我们叫它信号量，可以用来控制同时访问特定资源的线程数量，通过协调各个线程\n以保证合理的使用资源。\n\n使用场景:\n通常用于那些资源有明确访问数量限制的场景，常用于限流。\n- 数据库连接池，同时进行连接的线程有数量限制，连接不能超过一定的数量，当连接达到了限制数量后，后面的线程只能排队等前面的线程释放了数据库连接才能获得数据库连接。\n- 停车场场景，车位数量有限，同时只能容纳多少台车，车位满了之后只有等里面的车离开停车场外面的车才可以进入。可以把它简单的理解成我们停车场入口立着的那个显示屏，每有一辆车进入停车场显尔屏就云亚尔T将示午A似，“感4停车场出去，显示屏上显示的剩余车辆就会加1，当显示屏上的剩余车位为O时，停车场入口的栏杆就不会再打开，车辆就无法进入停车场了，直到有一辆车从停车场出去为止。\n- 接口限流,应用限流,商品限流...\n\nAPI\n```java\nacquire()  \n获取一个令牌，在获取到令牌、或者被其他线程调用中断之前线程一直处于阻塞状态。\n\ntryAcquire(long timeout, TimeUnit unit)\n尝试在指定时间内获得令牌,返回获取令牌成功或失败，不阻塞线程。\n\nrelease()\n释放一个令牌，唤醒一个获取令牌不成功的阻塞线程。\n\nhasQueuedThreads()\n等待队列里是否还存在等待线程。\n\ngetQueueLength()\n获取等待队列里阻塞的线程数。\n\ndrainPermits()\n清空令牌把可用令牌数置为0，返回清空令牌的数量。\n\navailablePermits()\n返回可用的令牌数量。\n\n// .....其他的自己看源码\n```\n\nDemo\n用semaphore 实现停车场提示牌功能\n每个停车场入口都有一个提示牌，上面显示着停车场的剩余车位还有多少，当剩余车位为O时，不允许车辆进入停车场，直到停车场里面有车离开停车场，这时提示牌上会显示新的剩余车位数。\n业务场景∶\n- 停车场容纳总停车量10\n- 当一辆车进入停车场后，显示牌的剩余车位数响应的减1\n- 每有一辆车驶出停车场后，显示牌的剩余车位数响应的加1\n- 停车场剩余车位不足时，车辆只能在外面等待\n```java\npublic class TestCar {\n\n    //停车场同时容纳的车辆10\n    private  static  Semaphore semaphore=new Semaphore(10);\n\n    public static void main(String[] args) {\n\n        //模拟100辆车进入停车场\n        for(int i=0;i<100;i++){\n\n            Thread thread=new Thread(new Runnable() {\n                public void run() {\n                    try {\n                        System.out.println(\"====\"+Thread.currentThread().getName()+\"来到停车场\");\n                        if(semaphore.availablePermits()==0){\n                            System.out.println(\"车位不足，请耐心等待\");\n                        }\n                        semaphore.acquire();//获取令牌尝试进入停车场\n                        System.out.println(Thread.currentThread().getName()+\"成功进入停车场\");\n                        Thread.sleep(new Random().nextInt(10000));//模拟车辆在停车场停留的时间\n                        System.out.println(Thread.currentThread().getName()+\"驶出停车场\");\n                        semaphore.release();//释放令牌，腾出停车场车位\n                    } catch (InterruptedException e) {\n                        e.printStackTrace();\n                    }\n                }\n            },i+\"号车\");\n\n            thread.start();\n\n        }\n\n    }\n}\n```\n\nDemo\n用semaphore实现防止商品超卖\n```java\npackage com.limiting.semaphore;\n\nimport java.util.Map;\nimport java.util.concurrent.ConcurrentHashMap;\nimport java.util.concurrent.Semaphore;\nimport java.util.concurrent.TimeUnit;\n\n/**\n * 秒杀防止商品超卖现象\n */\npublic class SemaphoreCommodity {\n\n    //商品池\n  private   Map<String, Semaphore> map=new ConcurrentHashMap<>();\n\n    //初始化商品池\n    public SemaphoreCommodity() {\n        //手机10部\n        map.put(\"phone\",new Semaphore(10));\n        //电脑4台\n        map.put(\"computer\",new Semaphore(4));\n    }\n\n    /**\n     *\n     * @param name 商品名称\n     * @return 购买是否成功\n     */\n    public boolean getbuy(String name) throws Exception {\n\n        Semaphore semaphore = map.get(name);\n        while (true) {\n            int availablePermit = semaphore.availablePermits();\n            if (availablePermit==0) {\n                //商品售空\n                return  false;\n            }\n            boolean b = semaphore.tryAcquire(1, TimeUnit.SECONDS);\n            if (b) {\n                System.out.println(\"抢到商品了\");\n                ///处理逻辑\n                return  true;\n            }\n\n        }\n\n    }\n\n    public static void main(String[] args) throws Exception {\n        SemaphoreCommodity semaphoreCommodity=new SemaphoreCommodity();\n        for (int i = 0; i < 10; i++) {\n            new Thread(()->{\n                try {\n                    System.out.println(semaphoreCommodity.getbuy(\"computer\"));\n                } catch (Exception e) {\n                    e.printStackTrace();\n                }\n            }).start();\n        }\n    }\n}\n```\n\nDemo\n用semaphore 实现接口限流\n1. 切面注解SemaphoreDoc\n```java\npackage com.limiting.semaphore;\n\nimport java.lang.annotation.*;\n\n@Documented\n\n@Target({ElementType.METHOD})//作用:方法\n@Retention(RetentionPolicy.RUNTIME)\npublic @interface SemaphoreDoc {\n    String key(); //建议设置不然可能发生,不同方法重复限流现象\n    int limit() default 3;\n\n    int blockingTime() default 3;\n\n}\n```\n\n2. 切面类SemaphoreAop\n```java\npackage com.limiting.semaphore;\n\nimport org.aspectj.lang.ProceedingJoinPoint;\nimport org.aspectj.lang.annotation.Around;\nimport org.aspectj.lang.annotation.Aspect;\nimport org.aspectj.lang.annotation.Pointcut;\nimport org.aspectj.lang.reflect.MethodSignature;\nimport org.springframework.stereotype.Component;\n\n\nimport java.util.Map;\nimport java.util.concurrent.ConcurrentHashMap;\nimport java.util.concurrent.Semaphore;\nimport java.util.concurrent.TimeUnit;\n\n@Component\n@Aspect\npublic class SemaphoreAop {\n\n    //这里需要注意了，这个是将自己自定义注解作为切点的根据，路径一定要写正确了\n    @Pointcut(value = \"@annotation(com.limiting.semaphore.SemaphoreDoc)\")\n    public void semaphoreDoc() {\n\n    }\n    //限流池\n  private static  Map<String, Semaphore> map=new ConcurrentHashMap<>();\n\n\n    @Around(\"semaphoreDoc()\")\n    public Object around(ProceedingJoinPoint joinPoint) throws Throwable {\n        Object res = null;\n        MethodSignature signature = (MethodSignature)joinPoint.getSignature();\n        SemaphoreDoc annotation  = signature.getMethod().getAnnotation(SemaphoreDoc.class);\n        int blockingTime = annotation.blockingTime();\n        int limit = annotation.limit();\n        String key = annotation.key();\n\n\n        StringBuilder name = new StringBuilder(key+signature.getMethod().getName());//方法名\n        for (String parameterName : signature.getParameterNames()) {\n            name.append(parameterName);\n        }\n\n        Semaphore semaphore = map.get(name.toString());\n        if (semaphore == null) {\n            Semaphore semaphore1 = new Semaphore(limit);\n            map.put(name.toString(),semaphore1);\n            semaphore=semaphore1;\n        }\n\n        try {\n\n\n            //获取令牌\n            boolean b = semaphore.tryAcquire(blockingTime, TimeUnit.SECONDS);\n            if (b) {//如果拿到令牌了那么执行方法\n                try {\n                    res = joinPoint.proceed();\n                } catch (Throwable e) {\n                    e.printStackTrace();\n                }\n            } else {\n                //在一定时间内拿不到令牌那么就访问失败\n                throw  new Exception(\"访问超时,目前请求人数过多请稍后在试\");\n            }\n\n        } finally {\n            //释放令牌，腾出位置\n            semaphore.release();\n        }\n\n        return  res;\n    }\n\n}\n```\n\n\n# 线程池\n为什么使用线程池？\n答：减少频繁创建和销毁的时间，提升性能。\n\n使用线程池优点：\n1. 降低资源消耗。通过重复利用已创建的线程降低线程创建和销毁造成的销耗。\n2. 提高响应速度。当任务到达时，任务可以不需要等待线程创建就能立即执行。\n3. 提高线程的可管理性。线程是稀缺资源，如果无限制的创建，不仅会销耗系统资源，还会降低系统的稳定性，使用线程池可以进行统一的分配，调优和监控\n\n## 使用线程池\n### newFixedThreadPool(int)\nnewFixedThreadPool创建的线程池corePoolSize和maximumPoolSize值是相等的，它使用的是LinkedBlockingQueue执行长期任务性能好，创建一个线程池，一池有N个固定的线程，有固定线程数的线程\n```java\npublic static ExecutorService newFixedThreadPool(int nThreads) {\n    return new ThreadPoolExecutor(nThreads, nThreads,\n                                  0L, TimeUnit.MILLISECONDS,\n                                  new LinkedBlockingQueue<Runnable>());\n}\n```\n\n### newSingleThreadExecutor()\nnewSingleThreadExecutor 创建的线程池corePoolSize和maximumPoolSize值都是1，它使用的是LinkedBlockingQueue一个任务一个任务的执行，一池一线程\n```java\npublic static ExecutorService newSingleThreadExecutor() {\n    return new FinalizableDelegatedExecutorService\n        (new ThreadPoolExecutor(1, 1,\n                                0L, TimeUnit.MILLISECONDS,\n                                new LinkedBlockingQueue<Runnable>()));\n}\n```\n\n### newCachedThreadPool()\nnewCachedThreadPool创建的线程池将corePoolSize设置为0，将maximumPoolSize设置为Integer.MAX_VALUE，它使用的是SynchronousQueue，也就是说来了任务就创建线程运行，当线程空闲超过60秒，就销毁线程。\n\n执行很多短期异步任务，线程池根据需要创建新线程，但在先前构建的线程可用时将重用它们。可扩容，遇强则强\n```java\npublic static ExecutorService newCachedThreadPool() {\n    return new ThreadPoolExecutor(0, Integer.MAX_VALUE,\n                                  60L, TimeUnit.SECONDS,\n                                  new SynchronousQueue<Runnable>());\n}\n```\n\nDemo\n```java\nimport java.util.Arrays;\nimport java.util.List;\nimport java.util.concurrent.Executor;\nimport java.util.concurrent.ExecutorService;\nimport java.util.concurrent.Executors;\n\n/**\n * 线程池\n * Arrays\n * Collections\n * Executors\n */\npublic class MyThreadPoolDemo {\n\n    public static void main(String[] args) {\n        //List list = new ArrayList();\n        //List list = Arrays.asList(\"a\",\"b\");\n        //固定数的线程池，一池五线程\n\n//       ExecutorService threadPool =  Executors.newFixedThreadPool(5); //一个银行网点，5个受理业务的窗口\n//       ExecutorService threadPool =  Executors.newSingleThreadExecutor(); //一个银行网点，1个受理业务的窗口\n       ExecutorService threadPool =  Executors.newCachedThreadPool(); //一个银行网点，可扩展受理业务的窗口\n\n        //10个顾客请求\n        try {\n            for (int i = 1; i <=10; i++) {\n                threadPool.execute(()->{\n                    System.out.println(Thread.currentThread().getName()+\"\\t 办理业务\");\n                });\n            }\n        } catch (Exception e) {\n            e.printStackTrace();\n        } finally {\n            threadPool.shutdown();\n        }\n\n    }\n}\n```\n\n## 原理简介\n```java\npublic ThreadPoolExecutor(int corePoolSize,\n                          int maximumPoolSize,\n                          long keepAliveTime,\n                          TimeUnit unit,\n                          BlockingQueue<Runnable> workQueue,\n                          ThreadFactory threadFactory,\n                          RejectedExecutionHandler handler) {\n    if (corePoolSize < 0 ||\n        maximumPoolSize <= 0 ||\n        maximumPoolSize < corePoolSize ||\n        keepAliveTime < 0)\n        throw new IllegalArgumentException();\n    if (workQueue == null || threadFactory == null || handler == null)\n        throw new NullPointerException();\n    this.corePoolSize = corePoolSize;\n    this.maximumPoolSize = maximumPoolSize;\n    this.workQueue = workQueue;\n    this.keepAliveTime = unit.toNanos(keepAliveTime);\n    this.threadFactory = threadFactory;\n    this.handler = handler;\n}\n```\n\n1. **corePoolSize**：核心线程大小，当提交一个任务到线程池时，线程池会创建一个线程来执行任务，即使有其他空闲线程可以处理任务也会创新线程，等到工作的线程数大于核心线程数时就不会在创建了。如果调用了线程池的prestartAllCoreThreads方法，线程池会提前把核心线程都创造好，并启动\n2. **maximumPoolSize**：线程池允许创建的最大线程数，此值必须大于等于1。如果队列满了，并且以创建的线程数小于最大线程数，则线程池会再创建新的线程执行任务。如果我们使用了无界队列，那么所有的任务会加入队列，这个参数就没有什么效果了\n3. **keepAliveTime**：多余的空闲线程的存活时间,当前池中线程数量超过corePoolSize时，当空闲时间达到keepAliveTime时，多余线程会被销毁直到只剩下corePoolSize个线程为止，如果任务很多，并且每个任务的执行时间比较短，避免线程重复创建和回收，可以调大这个时间，提高线程的利用率\n4. **unit**：keepAliveTIme的时间单位，可以选择的单位有天、小时、分钟、毫秒、微妙、千分之一毫秒和纳秒。类型是一个枚举java.util.concurrent.TimeUnit，这个枚举也经常使用\n5. **workQueue**：任务队列，被提交但尚未被执行的任务，用于缓存待处理任务的阻塞队列\n6. **threadFactory**：表示生成线程池中工作线程的线程工厂，用于创建线程，一般默认的即可，可以通过线程工厂给每个创建出来的线程设置更有意义的名字\n7. **handler**：拒绝策略，表示当队列满了，并且工作线程大于等于线程池的最大线程数（maximumPoolSize）时如何来拒绝请求执行的runnable的策略\n\n调用线程池的execute方法处理任务，执行execute方法的过程：\n1. 判断线程池中运行的线程数是否小于corepoolsize，是：则创建新的线程来处理任务，否：执行下一步\n2. 试图将任务添加到workQueue指定的队列中，如果无法添加到队列，进入下一步\n3. 判断线程池中运行的线程数是否小于maximumPoolSize，是：则新增线程处理当前传入的任务，否：将任务传递给handler对象rejectedExecution方法处理\n```\n1. z在创建了线程池后，开始等待请求。\n2. 当调用execute()方法添加一个请求任务时，线程池会做出如下判断：\n  - 如果正在运行的线程数量小于corePoolSize，那么马上创建线程运行这个任务；\n  - 如果正在运行的线程数量大于或等于corePoolSize，那么将这个任务放入队列；\n  - 如果这个时候队列满了且正在运行的线程数量还小于maximumPoolSize，那么还是要创建非核心线程立刻运行这个任务；\n  - 如果队列满了且正在运行的线程数量大于或等于maximumPoolSize，那么线程池会启动饱和拒绝策略来执行。\n3. 当一个线程完成任务时，它会从队列中取下一个任务来执行。\n4. 当一个线程无事可做超过一定的时间（keepAliveTime）时，线程会判断：\n  - 如果当前运行的线程数大于corePoolSize，那么这个线程就被停掉。\n  - 所以线程池的所有任务完成后，它最终会收缩到corePoolSize的大小。\n```\n\n**拒绝策略**\nJDK内置拒绝策略\n- AbortPolicy(默认)：直接抛出RejectedExecutionException异常阻止系统正常运行\n- CallerRunsPolicy：“调用者运行”一种调节机制，该策略既不会抛弃任务，也不会抛出异常，而是将某些任务回退到调用者，从而降低新任务的流量。\n- DiscardOldestPolicy：抛弃队列中等待最久的任务，然后把当前任务加入队列中尝试再次提交当前任务。\n- DiscardPolicy：该策略默默地丢弃无法处理的任务，不予任何处理也不抛出异常。如果允许任务丢失，这是最好的一种策略。\n\nDemo\n```java\nimport java.util.concurrent.ArrayBlockingQueue;\nimport java.util.concurrent.Executors;\nimport java.util.concurrent.ThreadPoolExecutor;\nimport java.util.concurrent.TimeUnit;\nimport java.util.concurrent.atomic.AtomicInteger;\n\npublic class Demo5 {\n    static class Task implements Runnable {\n        String name;\n        public Task(String name) {\n            this.name = name;\n        }\n        @Override\n        public void run() {\n            System.out.println(Thread.currentThread().getName() + \"处理\" + this.name);\n            try {\n                TimeUnit.SECONDS.sleep(5);\n            } catch (InterruptedException e) {\n                e.printStackTrace();\n            }\n        }\n        @Override\n        public String toString() {\n            return \"Task{\" +\n                    \"name='\" + name + '\\'' +\n                    '}';\n        }\n    }\n    public static void main(String[] args) {\n        ThreadPoolExecutor executor = new ThreadPoolExecutor(1,\n                1,\n                60L,\n                TimeUnit.SECONDS,\n                new ArrayBlockingQueue<Runnable>(1),\n                Executors.defaultThreadFactory(),\n                (r, executors) -> {\n                    //自定义饱和策略\n                    //记录一下无法处理的任务\n                    System.out.println(\"无法处理的任务：\" + r.toString());\n                });\n        for (int i = 0; i < 5; i++) {\n            executor.execute(new Task(\"任务-\" + i));\n        }\n        executor.shutdown();\n    }\n}\n\n输出：\n无法处理的任务：Task{name='任务-2'}\n无法处理的任务：Task{name='任务-3'}\npool-1-thread-1处理任务-0\n无法处理的任务：Task{name='任务-4'}\npool-1-thread-1处理任务-1\n```\n\n**参数设置**\n合理的配置线程池，需要先分析任务的特性，可以从以下几个角度分析：\n- 任务的性质：CPU密集型任务、IO密集型任务和混合型任务\n- 任务的优先级：高、中、低\n- 任务的执行时间：长、中、短\n- 任务的依赖性：是否依赖其他的系统资源，如数据库连接\n\n性质不同任务可以用不同规模的线程池分开处理。CPU密集型任务应该尽可能小的线程，如配置cpu数量+1个线程的线程池。由于IO密集型任务并不是一直在执行任务，不能让cpu闲着，则应配置尽可能多的线程，如：CPU数量`*`2。混合型的任务，如果可以拆分，将其拆分成一个CPU密集型任务和一个IO密集型任务，只要这2个任务执行的时间相差不是太大，那么分解后执行的吞吐量将高于串行执行的吞吐量。可以通过`Runtime.getRuntime().availableProcessors()`方法获取cpu数量。优先级不同任务可以对线程池采用优先级队列来处理，让优先级高的先执行\n\n## 自定义线程池\nDemo\n```java\nimport java.util.Arrays;\nimport java.util.List;\nimport java.util.concurrent.*;\n\n/**\n * 线程池\n * Arrays\n * Collections\n * Executors\n */\npublic class MyThreadPoolDemo {\n\n    public static void main(String[] args) {\n        ExecutorService threadPool = new ThreadPoolExecutor(\n                2,\n                5,\n                2L,\n                TimeUnit.SECONDS,\n                new ArrayBlockingQueue<Runnable>(3),\n                Executors.defaultThreadFactory(),\n                //new ThreadPoolExecutor.AbortPolicy()\n                //new ThreadPoolExecutor.CallerRunsPolicy()\n                //new ThreadPoolExecutor.DiscardOldestPolicy()\n                new ThreadPoolExecutor.DiscardPolicy()\n        );\n        //10个顾客请求\n        try {\n            for (int i = 1; i <= 10; i++) {\n                threadPool.execute(() -> {\n                    System.out.println(Thread.currentThread().getName() + \"\\t 办理业务\");\n                });\n            }\n        } catch (Exception e) {\n            e.printStackTrace();\n        } finally {\n            threadPool.shutdown();\n        }\n\n    }\n\n    private static void threadPool() {\n        //List list = new ArrayList();\n        //List list = Arrays.asList(\"a\",\"b\");\n        //固定数的线程池，一池五线程\n\n//       ExecutorService threadPool =  Executors.newFixedThreadPool(5); //一个银行网点，5个受理业务的窗口\n//       ExecutorService threadPool =  Executors.newSingleThreadExecutor(); //一个银行网点，1个受理业务的窗口\n        ExecutorService threadPool = Executors.newCachedThreadPool(); //一个银行网点，可扩展受理业务的窗口\n\n        //10个顾客请求\n        try {\n            for (int i = 1; i <= 10; i++) {\n                threadPool.execute(() -> {\n                    System.out.println(Thread.currentThread().getName() + \"\\t 办理业务\");\n                });\n            }\n        } catch (Exception e) {\n            e.printStackTrace();\n        } finally {\n            threadPool.shutdown();\n        }\n    }\n}\n```\n\n## 关闭线程池\n线程池提供了2个关闭方法：shutdown和shutdownNow，当调用者两个方法之后，线程池会遍历内部的工作线程，然后调用每个工作线程的interrrupt方法给线程发送中断信号，内部如果无法响应中断信号的可能永远无法终止，所以如果内部有无线循环的，最好在循环内部检测一下线程的中断信号，合理的退出。调用者两个方法中任意一个，线程池的isShutdown方法就会返回true，当所有的任务线程都关闭之后，才表示线程池关闭成功，这时调用isTerminaed方法会返回true。\n\n调用shutdown方法之后，线程池将不再接口新任务，内部会将所有已提交的任务处理完毕，处理完毕之后，工作线程自动退出。\n\n而调用shutdownNow方法后，线程池会将还未处理的（在队里等待处理的任务）任务移除，将正在处理中的处理完毕之后，工作线程自动退出。\n\n至于调用哪个方法来关闭线程，应该由提交到线程池的任务特性决定，多数情况下调用shutdown方法来关闭线程池，如果任务不一定要执行完，则可以调用shutdownNow方法。\n\n## 阻塞队列\n- ArrayBlockingQueue：是一个基于数组结构的有界阻塞队列，此队列按照先进先出原则对元素进行排序\n- LinkedBlockingQueue：由链表结构组成的有界（但大小默认值为integer.MAX_VALUE）阻塞队列，此队列按照先进先出排序元素，吞吐量通常要高于ArrayBlockingQueue。静态工厂方法Executors.newFixedThreadPool使用了这个队列。\n- PriorityBlockingQueue：支持优先级排序的无界阻塞队列。\n- DelayQueue：使用优先级队列实现的延迟无界阻塞队列。\n- SynchronousQueue：不存储元素的阻塞队列，也即单个元素的队列,每个插入操作必须等到另外一个线程调用移除操作，否则插入操作一直处理阻塞状态，吞吐量通常要高于 LinkedBlockingQueue，静态工厂方法Executors.newCachedThreadPool使用这个队列\n- LinkedTransferQueue：由链表组成的无界阻塞队列。\n- LinkedBlockingDeque：由链表组成的双向阻塞队列。\n\n使用Executors.newCachedThreadPool()创建线程池，看一下的源码：\n```java\npublic static ExecutorService newCachedThreadPool() {\n        return new ThreadPoolExecutor(0, Integer.MAX_VALUE,\n                                      60L, TimeUnit.SECONDS,\n                                      new SynchronousQueue<Runnable>());\n}\n```\n\n可以看出，系统创建了50个线程处理任务，代码中使用了SynchronousQueue同步队列，这种队列比较特殊，放入元素必须要有另外一个线程去获取这个元素，否则放入元素会失败或者一直阻塞在那里直到有线程取走，示例中任务处理休眠了指定的时间，导致已创建的工作线程都忙于处理任务，所以新来任务之后，将任务丢入同步队列会失败，丢入队列失败之后，会尝试新建线程处理任务。使用上面的方式创建线程池需要注意，如果需要处理的任务比较耗时，会导致新来的任务都会创建新的线程进行处理，可能会导致创建非常多的线程，最终耗尽系统资源，触发OOM。\n\n**PriorityBlockingQueue优先级队列的线程池**\n```java\nimport java.util.concurrent.*;\n\npublic class Demo3 {\n    static class Task implements Runnable, Comparable<Task> {\n        private int i;\n        private String name;\n        public Task(int i, String name) {\n            this.i = i;\n            this.name = name;\n        }\n        @Override\n        public void run() {\n            System.out.println(Thread.currentThread().getName() + \"处理\" + this.name);\n        }\n        @Override\n        public int compareTo(Task o) {\n            return Integer.compare(o.i, this.i);\n        }\n    }\n    public static void main(String[] args) {\n        ExecutorService executor = new ThreadPoolExecutor(1, 1,\n                60L, TimeUnit.SECONDS,\n                new PriorityBlockingQueue());\n        for (int i = 0; i < 10; i++) {\n            String taskName = \"任务\" + i;\n            executor.execute(new Task(i, taskName));\n        }\n        for (int i = 100; i >= 90; i--) {\n            String taskName = \"任务\" + i;\n            executor.execute(new Task(i, taskName));\n        }\n        executor.shutdown();\n    }\n}\n```\n\n输出中，除了第一个任务，其他任务按照优先级高低按顺序处理。原因在于：创建线程池的时候使用了优先级队列，进入队列中的任务会进行排序，任务的先后顺序由Task中的i变量决定。向PriorityBlockingQueue加入元素的时候，内部会调用代码中Task的compareTo方法决定元素的先后顺序。\n\n## 拓展线程池\n虽然jdk提供了ThreadPoolExecutor这个高性能线程池，但是如果我们自己想在这个线程池上面做一些扩展，比如，监控每个任务执行的开始时间，结束时间，或者一些其他自定义的功能，我们应该怎么办？\n\n这个jdk已经帮我们想到了，ThreadPoolExecutor内部提供了几个方法beforeExecute、afterExecute、terminated，可以由开发人员自己去这些方法。看一下线程池内部的源码：\n\n```java\ntry {\n    beforeExecute(wt, task);//任务执行之前调用的方法\n    Throwable thrown = null;\n    try {\n        task.run();\n    } catch (RuntimeException x) {\n        thrown = x;\n        throw x;\n    } catch (Error x) {\n        thrown = x;\n        throw x;\n    } catch (Throwable x) {\n        thrown = x;\n        throw new Error(x);\n    } finally {\n        afterExecute(task, thrown);//任务执行完毕之后调用的方法\n    }\n} finally {\n    task = null;\n    w.completedTasks++;\n    w.unlock();\n}\n```\n\nbeforeExecute：任务执行之前调用的方法，有2个参数，第1个参数是执行任务的线程，第2个参数是任务\n\n```java\nprotected void beforeExecute(Thread t, Runnable r) { }\n```\n\nafterExecute：任务执行完成之后调用的方法，2个参数，第1个参数表示任务，第2个参数表示任务执行时的异常信息，如果无异常，第二个参数为null\n\n```java\nprotected void afterExecute(Runnable r, Throwable t) { }\n```\n\nterminated：线程池最终关闭之后调用的方法。所有的工作线程都退出了，最终线程池会退出，退出时调用该方法\n\n```java\nimport java.util.concurrent.ArrayBlockingQueue;\nimport java.util.concurrent.Executors;\nimport java.util.concurrent.ThreadPoolExecutor;\nimport java.util.concurrent.TimeUnit;\n\npublic class Demo6 {\n    static class Task implements Runnable {\n        String name;\n        public Task(String name) {\n            this.name = name;\n        }\n        @Override\n        public void run() {\n            System.out.println(Thread.currentThread().getName() + \"处理\" + this.name);\n            try {\n                TimeUnit.SECONDS.sleep(2);\n            } catch (InterruptedException e) {\n                e.printStackTrace();\n            }\n        }\n        @Override\n        public String toString() {\n            return \"Task{\" +\n                    \"name='\" + name + '\\'' +\n                    '}';\n        }\n    }\n    public static void main(String[] args) throws InterruptedException {\n        ThreadPoolExecutor executor = new ThreadPoolExecutor(10,\n                10,\n                60L,\n                TimeUnit.SECONDS,\n                new ArrayBlockingQueue<Runnable>(1),\n                Executors.defaultThreadFactory(),\n                (r, executors) -> {\n                    //自定义饱和策略\n                    //记录一下无法处理的任务\n                    System.out.println(\"无法处理的任务：\" + r.toString());\n                }) {\n            @Override\n            protected void beforeExecute(Thread t, Runnable r) {\n                System.out.println(System.currentTimeMillis() + \",\" + t.getName() + \",开始执行任务:\" + r.toString());\n            }\n            @Override\n            protected void afterExecute(Runnable r, Throwable t) {\n                System.out.println(System.currentTimeMillis() + \",\" + Thread.currentThread().getName() + \",任务:\" + r.toString() + \"，执行完毕!\");\n            }\n            @Override\n            protected void terminated() {\n                System.out.println(System.currentTimeMillis() + \",\" + Thread.currentThread().getName() + \"，关闭线程池!\");\n            }\n        };\n        for (int i = 0; i < 10; i++) {\n            executor.execute(new Task(\"任务-\" + i));\n        }\n        TimeUnit.SECONDS.sleep(1);\n        executor.shutdown();\n    }\n}\n```\n\n```java\n1564324574847,pool-1-thread-1,开始执行任务:Task{name='任务-0'}\n1564324574850,pool-1-thread-3,开始执行任务:Task{name='任务-2'}\npool-1-thread-3处理任务-2\n1564324574849,pool-1-thread-2,开始执行任务:Task{name='任务-1'}\npool-1-thread-2处理任务-1\n1564324574848,pool-1-thread-5,开始执行任务:Task{name='任务-4'}\npool-1-thread-5处理任务-4\n1564324574848,pool-1-thread-4,开始执行任务:Task{name='任务-3'}\npool-1-thread-4处理任务-3\n1564324574850,pool-1-thread-7,开始执行任务:Task{name='任务-6'}\npool-1-thread-7处理任务-6\n1564324574850,pool-1-thread-6,开始执行任务:Task{name='任务-5'}\n1564324574851,pool-1-thread-8,开始执行任务:Task{name='任务-7'}\npool-1-thread-8处理任务-7\npool-1-thread-1处理任务-0\npool-1-thread-6处理任务-5\n1564324574851,pool-1-thread-10,开始执行任务:Task{name='任务-9'}\npool-1-thread-10处理任务-9\n1564324574852,pool-1-thread-9,开始执行任务:Task{name='任务-8'}\npool-1-thread-9处理任务-8\n1564324576851,pool-1-thread-2,任务:Task{name='任务-1'}，执行完毕!\n1564324576851,pool-1-thread-3,任务:Task{name='任务-2'}，执行完毕!\n1564324576852,pool-1-thread-1,任务:Task{name='任务-0'}，执行完毕!\n1564324576852,pool-1-thread-4,任务:Task{name='任务-3'}，执行完毕!\n1564324576852,pool-1-thread-8,任务:Task{name='任务-7'}，执行完毕!\n1564324576852,pool-1-thread-7,任务:Task{name='任务-6'}，执行完毕!\n1564324576852,pool-1-thread-5,任务:Task{name='任务-4'}，执行完毕!\n1564324576853,pool-1-thread-6,任务:Task{name='任务-5'}，执行完毕!\n1564324576853,pool-1-thread-10,任务:Task{name='任务-9'}，执行完毕!\n1564324576853,pool-1-thread-9,任务:Task{name='任务-8'}，执行完毕!\n1564324576853,pool-1-thread-9，关闭线程池!\n```\n\n从输出结果中可以看到，每个需要执行的任务打印了3行日志，执行前由线程池的beforeExecute打印，执行时会调用任务的run方法，任务执行完毕之后，会调用线程池的afterExecute方法，从每个任务的首尾2条日志中可以看到每个任务耗时2秒左右。线程池最终关闭之后调用了terminated方法。\n\n# 原子操作类\n## 基本原子类\n- AtomicInteger：整型原子类\n- AtomicBoolean：布尔原子类\n- AtomicLong：长整型原子类  \n\n## 数组原子类\n使用原子的方式更新数组里的某个元素\n- AtomicIntegerArray：整形数组原子类\n- AtomicLongArray：长整形数组原子类\n- AtomicReferenceArray： 引用类型数组原子类\n\n## 引用原子类\n- AtomicReference：引用类型原子类\n- AtomicStampedReference：原子更新带有版本号的引用类型。该类将整数值与引用关联起来，可用于解决原子的更新数据和数据的版本号，可以解决使用CAS进行原子更新时可能出现的ABA问题\n- AtomicMarkableReference ：原子更新带有标记位的引用类型\n\n## 对象属性修改原子类\n- AtomicIntegerFieldUpdater：原子更新对象中int类型字段的值\n- AtomicLongFieldUpdater：原子更新对象中Long类型字段的值\n- AtomicReferenceFieldUpdater：原子更新引用类型字段的值\n\n## 原子操作增强原子类\n- LongAdder\n- LongAccumulator\n- DoubleAdder\n- DoubleAccumulator\n\n## 原子基本类型示例\n1. AtomicInteger保证i++在多线程情况下的安全\n```java\nclass AtomicIntegerTest {\n    private AtomicInteger atomicInteger = new AtomicInteger();\n    //使用AtomicInteger之后，不需要对该方法加锁，也可以实现线程安全。\n    public int getNumber() {\n        return count.get();\n    }\n    public void setNumber() {\n        atomicInteger.incrementAndGet();\n    }\n}\n```\n\n2. CountDownLatch保证i++在多线程情况下的安全\n```java\npackage com.bilibili.juc.atomics;\n\nimport java.util.concurrent.CountDownLatch;\nimport java.util.concurrent.TimeUnit;\nimport java.util.concurrent.atomic.AtomicInteger;\n\nclass MyNumber {\n    AtomicInteger atomicInteger = new AtomicInteger();\n\n    public void addPlusPlus() {\n        atomicInteger.getAndIncrement();\n    }\n}\n\n\n/**\n * @auther zzyy\n * @create 2022-02-25 21:59\n */\npublic class AtomicIntegerDemo {\n    public static final int SIZE = 50;\n\n    public static void main(String[] args) throws InterruptedException {\n        MyNumber myNumber = new MyNumber();\n        CountDownLatch countDownLatch = new CountDownLatch(SIZE);\n\n        for (int i = 1; i <= SIZE; i++) {\n            new Thread(() -> {\n                try {\n                    for (int j = 1; j <= 1000; j++) {\n                        myNumber.addPlusPlus();\n                    }\n                } finally {\n                    countDownLatch.countDown();\n                }\n            }, String.valueOf(i)).start();\n        }\n        \n        //暂停几秒钟线程，等待上面50个线程全部计算完成后，再去获得最终值\n        \n        //(2). 使用CountDownLatch去解决等待时间的问题\n        countDownLatch.await();\n        \n        //(1). 如果不加上下面的停顿3秒的时间,会导致还没有进行i++ 50000次main线程就已经结束了\n        //try { TimeUnit.SECONDS.sleep(2); } catch (InterruptedException e) { e.printStackTrace(); }\n        System.out.println(Thread.currentThread().getName() + \"\\t\" + \"result: \" + myNumber.atomicInteger.get());\n    }\n}\n```\n\n## 原子类型引用示例\n上面的普通原子类仅仅只能保证一个共享变量的原子操作，对于对象的原子操作有两种解决方案:\n1. 使用JDK1.5开始就提供的AtomicReference类保证对象之间的原子性，把多个变量放到一个对象里面进行CAS操作\n2. 使用锁。锁内的临界区代码可以保证只有当前线程能操作。\n\n**AtomicReference对象封装**\n```java\npackage com.bilibili.juc.cas;\n\n\nimport lombok.AllArgsConstructor;\nimport lombok.Getter;\nimport lombok.ToString;\n\nimport java.util.concurrent.atomic.AtomicReference;\n\n@Getter\n@ToString\n@AllArgsConstructor\nclass User\n{\n    String userName;\n    int    age;\n}\n\n/**\n * @auther zzyy\n * @create 2022-02-24 14:50\n */\npublic class AtomicReferenceDemo\n{\n    public static void main(String[] args)\n    {\n        AtomicReference<User> atomicReference = new AtomicReference<>();\n\n        User z3 = new User(\"z3\",22);\n        User li4 = new User(\"li4\",28);\n\n        atomicReference.set(z3);\n\n        System.out.println(atomicReference.compareAndSet(z3, li4)+\"\\t\"+atomicReference.get().toString());\n        System.out.println(atomicReference.compareAndSet(z3, li4)+\"\\t\"+atomicReference.get().toString());\n\n\n    }\n}\n```\n\n**利用AtomicReference，手写自旋锁**\n```java\n/**\n * 题目：实现一个自旋锁\n * 自旋锁好处：循环比较获取没有类似wait的阻塞。\n *\n * 通过CAS操作完成自旋锁，A线程先进来调用myLock方法自己持有锁5秒钟，B随后进来后发现\n * 当前有线程持有锁，不是null，所以只能通过自旋等待，直到A释放锁后B随后抢到。\n */\npublic class SpinLockDemo\n{\n    AtomicReference<Thread> atomicReference = new AtomicReference<>();\n\n    public void myLock()\n    {\n        Thread thread = Thread.currentThread();\n        System.out.println(Thread.currentThread().getName()+\"\\t come in\");\n        while(!atomicReference.compareAndSet(null,thread))\n        {\n\n        }\n    }\n\n    public void myUnLock()\n    {\n        Thread thread = Thread.currentThread();\n        atomicReference.compareAndSet(thread,null);\n        System.out.println(Thread.currentThread().getName()+\"\\t myUnLock over\");\n    }\n\n    public static void main(String[] args)\n    {\n        SpinLockDemo spinLockDemo = new SpinLockDemo();\n\n        new Thread(() -> {\n            spinLockDemo.myLock();\n            //暂停一会儿线程\n            try { TimeUnit.SECONDS.sleep( 5 ); } catch (InterruptedException e) { e.printStackTrace(); }\n            spinLockDemo.myUnLock();\n        },\"A\").start();\n        //暂停一会儿线程，保证A线程先于B线程启动并完成\n        try { TimeUnit.SECONDS.sleep( 1 ); } catch (InterruptedException e) { e.printStackTrace(); }\n\n        new Thread(() -> {\n            spinLockDemo.myLock();\n            spinLockDemo.myUnLock();\n        },\"B\").start();\n\n    }\n}\n```\n\nAtomicStampedReference\n\n**ABA问题**\n比如说一个线程1从内存位置V中取出A，这时候另一个线程2也从内存中取出A，并且线程2进行了一些操作将值变成了B，然后线程2又将V位置的数据变成A放回去这时候线程1进行CAS操作发现内存中仍然是A，预期OK，然后线程1操作成功\n尽管线程1的CAS操作成功，但是不代表这个过程就是没有问题的。\n\n解决CAS的ABA问题:ABA问题的解决思路是在变量前面追加上版本号时间戳戳记流水，择其一。从JDK 1.5开始，JDK的atomic包里提供了一个类AtomicstampedReference类来解决ABA[问题。\n\nABADemo\n```java\npublic class ABADemo\n{\n    static AtomicInteger atomicInteger = new AtomicInteger(100);\n    static AtomicStampedReference atomicStampedReference = new AtomicStampedReference(100,1);\n\n    public static void main(String[] args)\n    {\n        abaProblem();\n        abaResolve();\n    }\n\n    public static void abaResolve()\n    {\n        new Thread(() -> {\n            int stamp = atomicStampedReference.getStamp();\n            System.out.println(\"t3 ----第1次stamp  \"+stamp);\n            try { TimeUnit.SECONDS.sleep(1); } catch (InterruptedException e) { e.printStackTrace(); }\n            atomicStampedReference.compareAndSet(100,101,stamp,stamp+1);\n            System.out.println(\"t3 ----第2次stamp  \"+atomicStampedReference.getStamp());\n            atomicStampedReference.compareAndSet(101,100,atomicStampedReference.getStamp(),atomicStampedReference.getStamp()+1);\n            System.out.println(\"t3 ----第3次stamp  \"+atomicStampedReference.getStamp());\n        },\"t3\").start();\n\n        new Thread(() -> {\n            int stamp = atomicStampedReference.getStamp();\n            System.out.println(\"t4 ----第1次stamp  \"+stamp);\n            //暂停几秒钟线程\n            try { TimeUnit.SECONDS.sleep(3); } catch (InterruptedException e) { e.printStackTrace(); }\n            boolean result = atomicStampedReference.compareAndSet(100, 20210308, stamp, stamp + 1);\n            System.out.println(Thread.currentThread().getName()+\"\\t\"+result+\"\\t\"+atomicStampedReference.getReference());\n        },\"t4\").start();\n    }\n\n    public static void abaProblem()\n    {\n        new Thread(() -> {\n            atomicInteger.compareAndSet(100,101);\n            atomicInteger.compareAndSet(101,100);\n        },\"t1\").start();\n\n        try { TimeUnit.MILLISECONDS.sleep(200); } catch (InterruptedException e) { e.printStackTrace(); }\n\n        new Thread(() -> {\n            atomicInteger.compareAndSet(100,20210308);\n            System.out.println(atomicInteger.get());\n        },\"t2\").start();\n    }\n}\n```\n\n## 对象属性修改原子类示例\n1. 使用目的:\n以一种线程安全的方式操作非线程安全对象内的某些字段，是否可以不要锁定整个对象减少锁定的范围只关注长期、敏感性变化的某一个字段而不是整个对象以达到精确加锁+节约内存的目的\n\n2. 使用要求\n更新的对象属性必须使用public volatile修饰符\n这种原子类型，是抽象类所以每次使用都必须使用静态方法newUpdater()创建一个更新器,并且需要设置想要更新的类和属性\n\n**AtomicIntegerFieldUpdater**\n```java\npackage com.bilibili.juc.atomics;\n\n\nimport java.util.concurrent.CountDownLatch;\nimport java.util.concurrent.TimeUnit;\nimport java.util.concurrent.atomic.AtomicIntegerFieldUpdater;\n\nclass BankAccount//资源类\n{\n    String bankName = \"CCB\";\n\n    //更新的对象属性必须使用 public volatile 修饰符。\n    public volatile int money = 0;//钱数\n\n    public void add()\n    {\n        money++;\n    }\n\n    //因为对象的属性修改类型原子类都是抽象类，所以每次使用都必须\n    // 使用静态方法newUpdater()创建一个更新器，并且需要设置想要更新的类和属性。\n\n    AtomicIntegerFieldUpdater<BankAccount> fieldUpdater =\n            AtomicIntegerFieldUpdater.newUpdater(BankAccount.class,\"money\");\n\n    //不加synchronized，保证高性能原子性，局部微创小手术\n    public void transMoney(BankAccount bankAccount)\n    {\n        fieldUpdater.getAndIncrement(bankAccount);\n    }\n\n\n}\n\n/**\n * @auther zzyy\n * 以一种线程安全的方式操作非线程安全对象的某些字段。\n *\n * 需求：\n * 10个线程，\n * 每个线程转账1000，\n * 不使用synchronized,尝试使用AtomicIntegerFieldUpdater来实现。\n */\npublic class AtomicIntegerFieldUpdaterDemo\n{\n    public static void main(String[] args) throws InterruptedException\n    {\n        BankAccount bankAccount = new BankAccount();\n        CountDownLatch countDownLatch = new CountDownLatch(10);\n\n        for (int i = 1; i <=10; i++) {\n            new Thread(() -> {\n                try {\n                    for (int j = 1; j <=1000; j++) {\n                        //bankAccount.add();\n                        bankAccount.transMoney(bankAccount);\n                    }\n                } finally {\n                    countDownLatch.countDown();\n                }\n            },String.valueOf(i)).start();\n        }\n\n        countDownLatch.await();\n\n        System.out.println(Thread.currentThread().getName()+\"\\t\"+\"result: \"+bankAccount.money);\n    }\n}\n```\n\n**AtomicReferenceFieldUpdater**\n```\npackage com.bilibili.juc.atomics;\n\nimport java.util.concurrent.TimeUnit;\nimport java.util.concurrent.atomic.AtomicIntegerFieldUpdater;\nimport java.util.concurrent.atomic.AtomicReferenceFieldUpdater;\n\nclass MyVar //资源类\n{\n    public volatile Boolean isInit = Boolean.FALSE;\n\n    AtomicReferenceFieldUpdater<MyVar,Boolean> referenceFieldUpdater =\n            AtomicReferenceFieldUpdater.newUpdater(MyVar.class,Boolean.class,\"isInit\");\n\n    public void init(MyVar myVar)\n    {\n        if (referenceFieldUpdater.compareAndSet(myVar,Boolean.FALSE,Boolean.TRUE))\n        {\n            System.out.println(Thread.currentThread().getName()+\"\\t\"+\"----- start init,need 2 seconds\");\n            //暂停几秒钟线程\n            try { TimeUnit.SECONDS.sleep(3); } catch (InterruptedException e) { e.printStackTrace(); }\n            System.out.println(Thread.currentThread().getName()+\"\\t\"+\"----- over init\");\n        }else{\n            System.out.println(Thread.currentThread().getName()+\"\\t\"+\"----- 已经有线程在进行初始化工作。。。。。\");\n        }\n    }\n}\n\n/**\n * @auther zzyy\n * 需求：\n * 多线程并发调用一个类的初始化方法，如果未被初始化过，将执行初始化工作，\n * 要求只能被初始化一次，只有一个线程操作成功\n */\npublic class AtomicReferenceFieldUpdaterDemo\n{\n    public static void main(String[] args)\n    {\n        MyVar myVar = new MyVar();\n\n        for (int i = 1; i <=5; i++) {\n            new Thread(() -> {\n                myVar.init(myVar);\n            },String.valueOf(i)).start();\n        }\n    }\n}\n//打印：\nD:\\App\\java1.8\\jdk\\bin\\java.exe \"-javaagent:D:\\App\\IntelliJ IDEA 2020.3.1\\lib\\idea_rt.jar=57957:D:\\App\\IntelliJ IDEA 2020.3.1\\bin\" -Dfile.encoding=GBK -classpath ...... com.bilibili.juc.atomics.AtomicReferenceFieldUpdaterDemo\n1\t----- start init,need 2 seconds\n3\t----- 已经有线程在进行初始化工作。。。。。\n2\t----- 已经有线程在进行初始化工作。。。。。\n4\t----- 已经有线程在进行初始化工作。。。。。\n5\t----- 已经有线程在进行初始化工作。。。。。\n1\t----- over init\n\nProcess finished with exit code 0\n```\n\n## 增强原子类示例\n**为什么引入`LongAdder`?**\nAtomicLong是利用底层的CAS操作来提供并发性的，逻辑是采用自旋的方式不断更新目标值，直到更新成功，也即乐观锁的实现模式。\n在并发量比较低的情况下,线程冲突的概率比较小,自旋的次数不会很多。但是,高并发情况下,N个线程同时进行自旋操作,N-1个线程失败,导致CPU打满场景,此时AtomicLong的自旋会成为瓶颈。这就是`LongAdder`引入的初衷------解决高并发环境下AtomictLong的自旋瓶颈问题\n\n**LongAdder和LongAccumulator区别**\n- LongAdder只能用来计算加法，且从零开始计算\n- LongAccumulator提供了自定义的函数操作\n\nLongAccumulator\n```java\n//long类型的聚合器，需要传入一个long类型的二元操作，可以用来计算各种聚合操作，包括加乘等\n\nimport java.util.concurrent.atomic.LongAccumulator;\nimport java.util.concurrent.atomic.LongAdder;\nimport java.util.function.LongBinaryOperator;\n\npublic class LongAccumulatorDemo\n{\n\n    LongAdder longAdder = new LongAdder();\n    public void add_LongAdder()\n    {\n        longAdder.increment();\n    }\n\n    //LongAccumulator longAccumulator = new LongAccumulator((x, y) -> x + y,0);\n    LongAccumulator longAccumulator = new LongAccumulator(new LongBinaryOperator()\n    {\n        @Override\n        public long applyAsLong(long left, long right)\n        {\n            return left - right;\n        }\n    },777);\n\n    public void add_LongAccumulator()\n    {\n        longAccumulator.accumulate(1);\n    }\n\n    public static void main(String[] args)\n    {\n        LongAccumulatorDemo demo = new LongAccumulatorDemo();\n\n        demo.add_LongAccumulator();\n        demo.add_LongAccumulator();\n        System.out.println(demo.longAccumulator.longValue());\n    }\n}\n```\n\nLongAdder\n```java\npublic class LongAdderAPIDemo\n{\n    public static void main(String[] args)\n    {\n        LongAdder longAdder = new LongAdder();\n\n        longAdder.increment();\n        longAdder.increment();\n        longAdder.increment();\n\n        System.out.println(longAdder.longValue());\n\n        LongAccumulator longAccumulator = new LongAccumulator((x,y) -> x * y,2);\n\n        longAccumulator.accumulate(1);\n        longAccumulator.accumulate(2);\n        longAccumulator.accumulate(3);\n\n        System.out.println(longAccumulator.longValue());\n\n    }\n}\n```\n\n**LongAdder高性能对比**\n```java\nclass ClickNumberNet\n{\n    int number = 0;\n    public synchronized void clickBySync()\n    {\n        number++;\n    }\n\n    AtomicLong atomicLong = new AtomicLong(0);\n    public void clickByAtomicLong()\n    {\n        atomicLong.incrementAndGet();\n    }\n\n    LongAdder longAdder = new LongAdder();\n    public void clickByLongAdder()\n    {\n        longAdder.increment();\n    }\n\n    LongAccumulator longAccumulator = new LongAccumulator((x,y) -> x + y,0);\n    public void clickByLongAccumulator()\n    {\n        longAccumulator.accumulate(1);\n    }\n}\n\n/**\n * @auther zzyy\n * @create 2020-05-21 22:23\n * 50个线程，每个线程100W次，总点赞数出来\n */\npublic class LongAdderDemo2\n{\n    public static void main(String[] args) throws InterruptedException\n    {\n        ClickNumberNet clickNumberNet = new ClickNumberNet();\n\n        long startTime;\n        long endTime;\n        CountDownLatch countDownLatch = new CountDownLatch(50);\n        CountDownLatch countDownLatch2 = new CountDownLatch(50);\n        CountDownLatch countDownLatch3 = new CountDownLatch(50);\n        CountDownLatch countDownLatch4 = new CountDownLatch(50);\n\n\n        startTime = System.currentTimeMillis();\n        for (int i = 1; i <=50; i++) {\n            new Thread(() -> {\n                try\n                {\n                    for (int j = 1; j <=100 * 10000; j++) {\n                        clickNumberNet.clickBySync();\n                    }\n                }finally {\n                    countDownLatch.countDown();\n                }\n            },String.valueOf(i)).start();\n        }\n        countDownLatch.await();\n        endTime = System.currentTimeMillis();\n        System.out.println(\"----costTime: \"+(endTime - startTime) +\" 毫秒\"+\"\\t clickBySync result: \"+clickNumberNet.number);\n\n        startTime = System.currentTimeMillis();\n        for (int i = 1; i <=50; i++) {\n            new Thread(() -> {\n                try\n                {\n                    for (int j = 1; j <=100 * 10000; j++) {\n                        clickNumberNet.clickByAtomicLong();\n                    }\n                }finally {\n                    countDownLatch2.countDown();\n                }\n            },String.valueOf(i)).start();\n        }\n        countDownLatch2.await();\n        endTime = System.currentTimeMillis();\n        System.out.println(\"----costTime: \"+(endTime - startTime) +\" 毫秒\"+\"\\t clickByAtomicLong result: \"+clickNumberNet.atomicLong);\n\n        startTime = System.currentTimeMillis();\n        for (int i = 1; i <=50; i++) {\n            new Thread(() -> {\n                try\n                {\n                    for (int j = 1; j <=100 * 10000; j++) {\n                        clickNumberNet.clickByLongAdder();\n                    }\n                }finally {\n                    countDownLatch3.countDown();\n                }\n            },String.valueOf(i)).start();\n        }\n        countDownLatch3.await();\n        endTime = System.currentTimeMillis();\n        System.out.println(\"----costTime: \"+(endTime - startTime) +\" 毫秒\"+\"\\t clickByLongAdder result: \"+clickNumberNet.longAdder.sum());\n\n        startTime = System.currentTimeMillis();\n        for (int i = 1; i <=50; i++) {\n            new Thread(() -> {\n                try\n                {\n                    for (int j = 1; j <=100 * 10000; j++) {\n                        clickNumberNet.clickByLongAccumulator();\n                    }\n                }finally {\n                    countDownLatch4.countDown();\n                }\n            },String.valueOf(i)).start();\n        }\n        countDownLatch4.await();\n        endTime = System.currentTimeMillis();\n        System.out.println(\"----costTime: \"+(endTime - startTime) +\" 毫秒\"+\"\\t clickByLongAccumulator result: \"+clickNumberNet.longAccumulator.longValue());\n\n    }\n}\n```\n\n### LongAdder原理分析\n**继承关系**\n{% asset_img 024.png %}\n\n继承Striped64类\n\n#### Striped64全局变量分析\n```java\n\n    /** Number of CPUS, to place bound on table size \n    当前计算机CPU数量,Cell数组扩容时会使用到\n    */\n    static final int NCPU = Runtime.getRuntime().availableProcessors();\n\n    /**\n     * Table of cells. When non-null, size is a power of 2.\n     */\n    transient volatile Cell[] cells;\n\n    /**\n     * Base value, used mainly when there is no contention, but also as\n     * a fallback during table initialization races. Updated via CAS.\n     类似于AtomicLong中全局的value值。再没有竞争情况下数据直接累加到base上,或者cells扩容时,也需要将数据写入到base上\n     */\n    transient volatile long base;\n\n    /**\n     * Spinlock (locked via CAS) used when resizing and/or creating Cells.\n     初始化cells或者扩容cells需要获取锁,0表示无锁状态,1表示其他线程已经持有了锁\n     */\n    transient volatile int cellsBusy;\n```\n\n#### Striped64内部类Cell\n```java\n\n    /**\n     * Padded variant of AtomicLong supporting only raw accesses plus CAS.\n     *\n     * JVM intrinsics note: It would be possible to use a release-only\n     * form of CAS here, if it were provided.\n     */\n    @sun.misc.Contended static final class Cell {\n        volatile long value;\n        Cell(long x) { value = x; }\n        final boolean cas(long cmp, long val) {\n            return UNSAFE.compareAndSwapLong(this, valueOffset, cmp, val);\n        }\n\n        // Unsafe mechanics\n        private static final sun.misc.Unsafe UNSAFE;\n        private static final long valueOffset;\n        static {\n            try {\n                UNSAFE = sun.misc.Unsafe.getUnsafe();\n                Class<?> ak = Cell.class;\n                valueOffset = UNSAFE.objectFieldOffset\n                    (ak.getDeclaredField(\"value\"));\n            } catch (Exception e) {\n                throw new Error(e);\n            }\n        }\n    }\n```\n\n#### 分散热点技术\n{% asset_img 025.png %}\n\n**LongAdder#add**\n1. 最初无竞争时,直接通过casBase进行更新base的处理，跳过if，当casBase比较激烈，则进入if判断\n2. 调用longAccumulate:如果更新base失败后,首次新建一个Cell[]数组(默认长度是2)\n3. 调用longAccumulate:如果Cell数组当中的某一个槽位为空\n4. 调用longAccumulate:当多个线程竞争同一个cell比较激烈时,可能就要对Cell[]扩容\n{% asset_img 026.png %}\n\n```java\n    LongAdder.java\n\tpublic void add(long x) {\n\t\t//as是striped64中的cells数组\n\t\t//b是striped64中的base\n\t\t//v是当前线程hash到的cell中存储的值\n\t\t//m是cells的长度减1,hash时作为掩码使用\n\t\t//a时当前线程hash到的cell\n        Cell[] as; long b, v; int m; Cell a;\n\t\t/**\n\t\t首次首线程(as = cells) != null)一定是false,此时走casBase方法,以CAS的方式更新base值,\n\t\t且只有当cas失败时,才会走到if中\n\t\t条件1:cells不为空,说明出现过竞争,cell[]已创建\n\t\t条件2:cas操作base失败,说明其他线程先一步修改了base正在出现竞争\n\t\t*/\n        if ((as = cells) != null || !casBase(b = base, b + x)) {\n\t\t\t//true无竞争 fasle表示竞争激烈,多个线程hash到同一个cell,可能要扩容\n            boolean uncontended = true;\n\t\t\t/*\n\t\t\t条件1:cells为空,说明正在出现竞争,上面是从条件2过来的,说明!casBase(b = base, b + x))=true\n\t\t\t\t  会通过调用longAccumulate(x, null, uncontended)新建一个数组,默认长度是2\n\t\t\t条件2:默认会新建一个数组长度为2的数组,m = as.length - 1) < 0 应该不会出现,\n\t\t\t条件3:当前线程所在的cell为空,说明当前线程还没有更新过cell,应初始化一个cell。\n\t\t\t\t  a = as[getProbe() & m]) == null,如果cell为空,进行一个初始化的处理\n\t\t\t条件4:更新当前线程所在的cell失败,说明现在竞争很激烈,多个线程hash到同一个Cell,应扩容\n\t\t\t\t  (如果是cell中有一个线程操作,这个时候,通过a.cas(v = a.value, v + x)可以进行处理,返回的结果是true)\n\t\t\t**/\n            if (as == null || (m = as.length - 1) < 0 ||\n\t\t\t    //getProbe( )方法返回的时线程中的threadLocalRandomProbe字段\n\t\t\t\t//它是通过随机数生成的一个值,对于一个确定的线程这个值是固定的(除非刻意修改它)\n                (a = as[getProbe() & m]) == null ||\n                !(uncontended = a.cas(v = a.value, v + x)))\n\t\t\t\t//调用Striped64中的方法处理\n                longAccumulate(x, null, uncontended);\n        }\n```\n\n**Striped64#longAccumulate**\n```java\nfinal void longAccumulate(long x, LongBinaryOperator fn,\n\t\t\t\t\t\t  boolean wasUncontended) {\n\t//存储线程的probe值\n\tint h;\n\t//如果getProbe()方法返回0,说明随机数未初始化\n\tif ((h = getProbe()) == 0) { //这个if相当于给当前线程生成一个非0的hash值\n\t\t//使用ThreadLocalRandom为当前线程重新计算一个hash值,强制初始化\n\t\tThreadLocalRandom.current(); // force initialization\n\t\t//重新获取probe值,hash值被重置就好比一个全新的线程一样,所以设置了wasUncontended竞争状态为true\n\t\th = getProbe();\n\t\t//重新计算了当前线程的hash后认为此次不算是一次竞争,都未初始化,肯定还不存在竞争激烈\n\t\t//wasUncontended竞争状态为true\n\t\twasUncontended = true;\n\t}\n```\n{% asset_img 027.png %}\n\n**CASE2：刚刚初始化Cell[]数组（首次新建）**\n```java\n\t//CASE2:cells没有加锁且没有初始化,则尝试对它进行加锁,并初始化cells数组\n\t/*\n\tcellsBusy:初始化cells或者扩容cells需要获取锁,0表示无锁状态,1表示其他线程已经持有了锁\n\tcells == as == null  是成立的\n\tcasCellsBusy:通过CAS操作修改cellsBusy的值,CAS成功代表获取锁,\n\t返回true,第一次进来没人抢占cell单元格,肯定返回true\n\t**/\n\telse if (cellsBusy == 0 && cells == as && casCellsBusy()) { \n\t    //是否初始化的标记\n\t\tboolean init = false;\n\t\ttry {                           // Initialize table(新建cells)\n\t\t\t// 前面else if中进行了判断,这里再次判断,采用双端检索的机制\n\t\t\tif (cells == as) {\n\t\t\t\t//如果上面条件都执行成功就会执行数组的初始化及赋值操作,Cell[] rs = new Cell[2]标识数组的长度为2\n\t\t\t\tCell[] rs = new Cell[2];\n\t\t\t\t//rs[h & 1] = new Cell(x)表示创建一个新的cell元素,value是x值,默认为1\n\t\t\t\t//h & 1 类似于我们之前hashmap常用到的计算散列桶index的算法,\n\t\t\t\t//通常都是hash&(table.len-1),同hashmap一个意思\n\t\t\t\t//看这次的value是落在0还是1\n\t\t\t\trs[h & 1] = new Cell(x);\n\t\t\t\tcells = rs;\n\t\t\t\tinit = true;\n\t\t\t}\n\t\t} finally {\n\t\t\tcellsBusy = 0;\n\t\t}\n\t\tif (init)\n\t\t\tbreak;\n\t}\n```\n\n**CASE3:兜底(多个线程尝试CAS修改失败的线程会走这个分支)**\n```java\n\t//CASE3:cells正在进行初始化,则尝试直接在基数base上进行累加操作\n\t//这种情况是cell中都CAS失败了,有一个兜底的方法\n\t//该分支实现直接操作base基数,将值累加到base上,\n\t//也即其他线程正在初始化,多个线程正在更新base的值\n\telse if (casBase(v = base, ((fn == null) ? v + x :\n\t\t\t\t\t\t\t\tfn.applyAsLong(v, x))))\n\t\tbreak;     \n```\n\n**CASE1 : Cell数组不再为空且可能存在Cell数组扩容**\n```java\nfor (;;) {\n\tCell[] as; Cell a; int n; long v;\n\tif ((as = cells) != null && (n = as.length) > 0) { // CASE1:cells已经初始化了\n\t    // 当前线程的hash值运算后映射得到的Cell单元为null,说明该Cell没有被使用\n\t\tif ((a = as[(n - 1) & h]) == null) {\n\t\t\t//Cell[]数组没有正在扩容\n\t\t\tif (cellsBusy == 0) {       // Try to attach new Cell\n\t\t\t\t//先创建一个Cell\n\t\t\t\tCell r = new Cell(x);   // Optimistically create\n\t\t\t\t//尝试加锁,加锁后cellsBusy=1\n\t\t\t\tif (cellsBusy == 0 && casCellsBusy()) { \n\t\t\t\t\tboolean created = false;\n\t\t\t\t\ttry {               // Recheck under lock\n\t\t\t\t\t\tCell[] rs; int m, j; //将cell单元赋值到Cell[]数组上\n\t\t\t\t\t\t//在有锁的情况下再检测一遍之前的判断 \n\t\t\t\t\t\tif ((rs = cells) != null &&\n\t\t\t\t\t\t\t(m = rs.length) > 0 &&\n\t\t\t\t\t\t\trs[j = (m - 1) & h] == null) {\n\t\t\t\t\t\t\trs[j] = r;\n\t\t\t\t\t\t\tcreated = true;\n\t\t\t\t\t\t}\n\t\t\t\t\t} finally {\n\t\t\t\t\t\tcellsBusy = 0;//释放锁\n\t\t\t\t\t}\n\t\t\t\t\tif (created)\n\t\t\t\t\t\tbreak;\n\t\t\t\t\tcontinue;           // Slot is now non-empty\n\t\t\t\t}\n\t\t\t}\n\t\t\tcollide = false;\n\t\t}\n\t\t/**\n\t\twasUncontended表示cells初始化后,当前线程竞争修改失败\n\t\twasUncontended=false,表示竞争激烈,需要扩容,这里只是重新设置了这个值为true,\n\t\t紧接着执行advanceProbe(h)重置当前线程的hash,重新循环\n\t\t*/\n\t\telse if (!wasUncontended)       // CAS already known to fail\n\t\t\twasUncontended = true;      // Continue after rehash\n\t\t//说明当前线程对应的数组中有了数据,也重置过hash值\n\t\t//这时通过CAS操作尝试对当前数中的value值进行累加x操作,x默认为1,如果CAS成功则直接跳出循环\n\t\telse if (a.cas(v = a.value, ((fn == null) ? v + x :\n\t\t\t\t\t\t\t\t\t fn.applyAsLong(v, x))))\n\t\t\tbreak;\n\t\t//如果n大于CPU最大数量,不可扩容,并通过下面的h=advanceProbe(h)方法修改线程的probe再重新尝试\n\t\telse if (n >= NCPU || cells != as)\n\t\t\tcollide = false;    //扩容标识设置为false,标识永远不会再扩容\n\t\t//如果扩容意向collide是false则修改它为true,然后重新计算当前线程的hash值继续循环\n\t\telse if (!collide) \n\t\t\tcollide = true;\n\t\t//锁状态为0并且将锁状态修改为1(持有锁) \n\t\telse if (cellsBusy == 0 && casCellsBusy()) { \n\t\t\ttry {\n\t\t\t\tif (cells == as) {      // Expand table unless stale\n\t\t\t\t\t//按位左移1位来操作,扩容大小为之前容量的两倍\n\t\t\t\t\tCell[] rs = new Cell[n << 1];\n\t\t\t\t\tfor (int i = 0; i < n; ++i)\n\t\t\t\t\t\t//扩容后将之前数组的元素拷贝到新数组中\n\t\t\t\t\t\trs[i] = as[i];\n\t\t\t\t\tcells = rs; \n\t\t\t\t}\n\t\t\t} finally {\n\t\t\t\t//释放锁设置cellsBusy=0,设置扩容状态,然后进行循环执行\n\t\t\t\tcellsBusy = 0;\n\t\t\t}\n\t\t\tcollide = false;\n\t\t\tcontinue;                   // Retry with expanded table\n\t\t}\n\t\th = advanceProbe(h);\n\t}\n\n```\n\n**LongAdder#sum**\nLongAdder# sum()会将所有Cell数组中的value和base累加作为返回值，核心的思想就是将之前AtomicLong一个value的更新压力分散到多个value中去,从而降级更新热点\n```java\n    public long sum() {\n        Cell[] as = cells; Cell a;\n        long sum = base;\n        if (as != null) {\n            for (int i = 0; i < as.length; ++i) {\n                if ((a = as[i]) != null)\n                    sum += a.value;\n            }\n        }\n        return sum;\n    }\n```\n\n为啥高并发下sum的值不精确? sum执行时,并没有限制对base和cells的更新(一句要命的话)。所以LongAdder不是强一致性,它是最终—致性的\n- 首先最终返回的sum局部变量,初始被赋值为base,而最终返回时,很可能base已经被更新了而此时局部变量sum不会更新,造成不—致\n- 其次这里对cell的读取也无法保证是最后一次写入的值。所以,sum方法只是在没有并发的情况下,可以获得正确的结果\n\n# 参考资料\n1. JUC并发编程目录—— https://blog.csdn.net/TZ845195485/article/details/109210095\n2.  "},{"title":"Redis学习笔记","url":"/2022/08/06/redis-xue-xi-bi-ji/","content":"# 基础\n## 对象存储\n**1. String**\n- Json格式：将Java对象转换为Json格式字符串，然后再进行存储。\n\t- 优点：占用空间较小（string类型数据优化较好）\n\t- 缺点：不适合对象频繁修改的场景。需要修改时，首先从redis中获取Json字符串，然后利用工具类例如FastJson、JackJson等转换为Java对象，进行修改后再转化为Json字符串存储到redis中。\n\n- 序列化方式：将Java对象序列化后存入redis string类型中。\n\n**2. Hash**\n将Java对象的每个属性转换为Hash的每个filed，属性值转换为value。\n- 优点：可以对对象的每个属性单独操作。\n\n# 缓存\n**目的**：减少数据库的IO压力，提高响应速度。\n\n**流程**：请求数据时，首先到缓存中查找数据，若有则直接返回数据；若没有则去查询数据库，将数据返回并将数据写入缓存。\n\n**缓存淘汰**：当内存占用过多时，需要对缓存进行淘汰。\n内存淘汰和超时剔除都是由redis提供的，主动更新需要自己手动维护缓存。\n- 内存淘汰：redis自动进行，当redis内存达到咱们设定的max-memery的时候，会自动触发淘汰机制，淘汰掉一些不重要的数据(可以自己设置策略方式)\n- 超时剔除：当我们给redis设置了过期时间ttl之后，redis会将超时的数据进行删除，方便咱们继续使用缓存\n- 主动更新：手动调用方法把缓存删掉，通常用于解决缓存和数据库不一致问题\n\n**缓存更新**：若数据库中的数据发生更改时，此时缓存中的数据便和数据库不一致，需要更新缓存，与数据库进行同步。\n- Cache Aside Pattern 人工编码方式：缓存调用者在更新完数据库后再去更新缓存，也称之为双写方案\n- Read/Write Through Pattern : 由系统本身完成，数据库与缓存的问题交由系统本身去处理\n- Write Behind Caching Pattern ：调用者只操作缓存，其他线程去异步处理数据库，实现最终一致\n\n采用人工编码方式时，更新缓存有两种方式：\n* 更新缓存：每次更新数据库都更新缓存，无效写操作较多\n* 删除缓存：更新数据库时让缓存失效，查询时再更新缓存\n\n删除缓存的优点：如果数据库发生多次修改，而此期间没有数据访问请求，则缓存进行了多次的无效更新操作。相比之下，删除缓存则只有请求进入时进行更新，只进行一次更新操作。\n\n**删除缓存：是先操作数据库再删缓存，还是先删缓存再操作数据库？**\n\n- 先操作数据库再删缓存：首先**线程1**进入，删除缓存后，**线程2**进入。此时线程2查询缓存失败，操作数据库后更新缓存，然后**线程1**操作数据库，最终数据库中的数据为**线程1**的数据，缓存中为**线程2**的数据，造成不一致。\n- 先删缓存再操作数据库：首先**线程1**查询缓存，缓存失效，开始操作数据库，在**线程1**完成数据库操作后，写入缓存之前，**线程2**进入，由于此时缓存仍是失效的，开始操作数据库，然后删缓存。**线程2**删缓存后线程1执行写缓存，最终数据库中的数据为**线程2**的数据，缓存中为**线程1**的数据，造成不一致。\n\t- 此情况发生的条件是，**线程1**查缓存时缓存失效，而且由于**线程1完成操作数据库到开始写入缓存之前的间隔**远小于**线程2执行操作数据库加删缓存所需时间（操作数据库耗时较大）**。因此这种情况发生的概率远小于**先操作数据库再删缓存**。\n\t{% asset_img 003.png %}\n\n**如何保证缓存与数据库的操作的同时成功或失败？**\n\n* 单体系统，将缓存与数据库操作放在一个事务\n* 分布式系统，利用TCC等分布式事务方案\n\n## 缓存穿透\n**缓存穿透**：客户端请求的数据在缓存中和数据库中都不存在，这样缓存永远不会生效，这些请求都会打到数据库。\n\n常见的解决方案有两种：\n* 缓存空对象\n  * 优点：实现简单，维护方便\n  * 缺点：\n    * 额外的内存消耗\n    * 可能造成短期的不一致\n* 布隆过滤\n  * 优点：内存占用较少，没有多余key\n  * 缺点：\n    * 实现复杂\n    * 存在误判可能\n\n**缓存空对象思路分析：**当客户端访问不存在的数据时，先请求redis，redis中没有数据，此时会访问到数据库，但是数据库中也没有数据，这个数据穿透了缓存，直击数据库。简单的解决方案就是哪怕这个数据在数据库中也不存在，也把这个数据存入到redis中去，这样下次用户过来访问这个不存在的数据，那么在redis中也能找到这个数据就不会进入到数据库了。\n\n**布隆过滤：**布隆过滤器其实采用的是哈希思想来解决这个问题，通过一个庞大的二进制数组，走哈希思想去判断当前这个要查询的这个数据是否存在，如果布隆过滤器判断存在，则放行，这个请求会去访问redis，哪怕此时redis中的数据过期了，但是数据库中一定存在这个数据，在数据库中查询出来这个数据后，再将其放入到redis中，假设布隆过滤器判断这个数据不存在，则直接返回。这种方式优点在于节约内存空间，存在误判，误判原因在于：布隆过滤器走的是哈希思想，只要哈希思想，就可能存在哈希冲突\n{% asset_img 004.png %}\n\n缓存穿透的解决方案有哪些？\n* 缓存null值\n* 布隆过滤\n* 增强id的复杂度，避免被猜测id规律\n* 做好数据的基础格式校验\n* 加强用户权限校验\n* 做好热点参数的限流\n\n## 缓存雪崩\n**缓存雪崩**：在同一时段大量的缓存key同时失效或者Redis服务宕机，导致大量请求到达数据库，带来巨大压力。\n\n解决方案：\n* 给不同的Key的TTL添加随机值\n* 利用Redis集群提高服务的可用性\n* 给缓存业务添加降级限流策略\n* 给业务添加多级缓存\n\n## 缓存击穿\n**缓存击穿**：也称热点Key问题，就是一个被高并发访问并且缓存重建业务较复杂的key突然失效了，无数的请求访问会在瞬间给数据库带来巨大的冲击。\n\n常见的解决方案有两种：\n* 互斥锁\n* 逻辑过期\n\n**逻辑分析**：假设线程1在查询缓存之后，本来应该去查询数据库，然后把这个数据重新加载到缓存的，此时只要线程1走完这个逻辑，其他线程就都能从缓存中加载这些数据了，但是假设在线程1没有走完的时候，后续的线程2，线程3，线程4同时过来访问当前这个方法， 那么这些线程都不能从缓存中查询到数据，那么他们就会同一时刻来访问查询缓存，都没查到，接着同一时间去访问数据库，同时的去执行数据库代码，对数据库访问压力过大。\n{% asset_img 005.png %}\n\n解决方案一：使用锁来解决\n因为锁能实现互斥性。假设线程过来，只能一个人一个人的来访问数据库，从而避免对于数据库访问压力过大，但这也会影响查询的性能，因为此时会让查询的性能从并行变成了串行，我们可以采用tryLock方法 + double check来解决这样的问题。\n假设现在线程1过来访问，他查询缓存没有命中，但是此时他获得到了锁的资源，那么线程1就会一个人去执行逻辑，假设现在线程2过来，线程2在执行过程中，并没有获得到锁，那么线程2就可以进行到休眠，直到线程1把锁释放后，线程2获得到锁，然后再来执行逻辑，此时就能够从缓存中拿到数据了。\n{% asset_img 006.png %}\n\n解决方案二：逻辑过期方案\n方案分析：我们之所以会出现这个缓存击穿问题，主要原因是在于我们对key设置了过期时间，假设我们不设置过期时间，其实就不会有缓存击穿的问题，但是不设置过期时间，这样数据不就一直占用我们内存了吗，我们可以采用逻辑过期方案。\n我们把过期时间设置在 redis的value中，注意：这个过期时间并不会直接作用于redis，而是我们后续通过逻辑去处理。假设线程1去查询缓存，然后从value中判断出来当前的数据已经过期了，此时线程1去获得互斥锁，那么其他线程会进行阻塞，获得了锁的线程他会开启一个 线程去进行 以前的重构数据的逻辑，直到新开的线程完成这个逻辑后，才释放锁， 而线程1直接进行返回，假设现在线程3过来访问，由于线程线程2持有着锁，所以线程3无法获得锁，线程3也直接返回数据，只有等到新开的线程2把重建数据构建完后，其他线程才能走返回正确的数据。\n这种方案巧妙在于，异步的构建缓存，缺点在于在构建完缓存之前，返回的都是脏数据。\n{% asset_img 007.png %}\n\n**两种方案对比：**\n**互斥锁方案：**由于保证了互斥性，所以数据一致，且实现简单，因为仅仅只需要加一把锁而已，也没其他的事情需要操心，所以没有额外的内存消耗，缺点在于有锁就有死锁问题的发生，且只能串行执行性能肯定受到影响\n**逻辑过期方案：** 线程读取过程中不需要等待，性能好，有一个额外的线程持有锁去进行重构数据，但是在重构数据完成前，其他的线程只能返回之前的数据，且实现起来麻烦\n\n\n## 多级缓存\n# 锁\n## 悲观锁和乐观锁\n{% asset_img 008.png %}\n 悲观锁：可以实现对于数据的串行化执行，比如syn，和lock都是悲观锁的代表，同时，悲观锁中又可以再细分为公平锁，非公平锁，可重入锁，等等\n  乐观锁：会有一个版本号，每次操作数据会对版本号+1，再提交回数据时，会去校验是否比之前的版本大1 ，如果大1 ，则进行操作成功，这套机制的核心逻辑在于，如果在操作过程中，版本号只比原来大1 ，那么就意味着操作过程中没有人对他进行过修改，他的操作就是安全的，如果不大1，则数据被修改过，当然乐观锁还有一些变种的处理方式比如CAS（将数据本身视为版本号）\n\n## 分布式锁\n分布式锁：满足分布式系统或集群模式下多进程可见并且互斥的锁。\n{% asset_img 009.png %}\n\n**分布式锁满足特性**：\n\n- 可见性：多个线程都能看到相同的结果，注意：这个地方说的可见性并不是并发编程中指的内存可见性，只是说多个进程之间都能感知到变化的意思\n- 互斥：互斥是分布式锁的最基本的条件，使得程序串行执行\n- 高可用：程序不易崩溃，时时刻刻都保证较高的可用性\n- 高性能：由于加锁本身就让性能降低，所有对于分布式锁本身需要他就较高的加锁性能和释放锁性能\n- 安全性：安全也是程序中必不可少的一环\n\n**常见三种分布式锁**：\n\n- Mysql：mysql本身就带有锁机制，但是由于mysql性能本身一般，所以采用分布式锁的情况下，其实使用mysql作为分布式锁比较少见\n- Redis：redis作为分布式锁是非常常见的一种使用方式，现在企业级开发中基本都使用redis或者zookeeper作为分布式锁，利用setnx这个方法，如果插入key成功，则表示获得到了锁，如果有人插入成功，其他人插入失败则表示无法获得到锁，利用这套逻辑来实现分布式锁\n- Zookeeper：zookeeper也是企业级开发中较好的一个实现分布式锁的方案，由于本套视频并不讲解zookeeper的原理和分布式锁的实现，所以不过多阐述\n\n实现分布式锁时需要实现的两个基本方法：\n* 获取锁：\n  * 互斥：确保只能有一个线程获取锁\n  * 非阻塞：尝试一次，成功返回true，失败返回false\n* 释放锁：\n  * 手动释放\n  * 超时释放：获取锁时添加一个超时时间\n\n**核心思路**：\n我们利用redis 的setNx 方法，当有多个线程进入时，我们就利用该方法，第一个线程进入时，redis 中就有这个key 了，返回了1，如果结果是1，则表示他抢到了锁，那么他去执行业务，然后再删除锁，退出锁逻辑，没有抢到锁的哥们，等待一定时间后重试即可\n\n**分布式锁要点**：\n\n1. 死锁\n场景：拥有锁的线程阻塞或宕机，导致锁无法释放\n解决方案：通过对锁添加过期时间，防止出现死锁\n\n2. 误删锁\n场景：线程1在业务过程中出现阻塞，导致锁释放。线程2拿到锁，进行业务操作，但是在操作过程中线程1恢复运行，释放了线程2的锁，这便是锁误删问题。\n解决方案：在每个线程释放锁的时候，去判断一下当前这把锁是否属于自己，不属于则不进行锁的删除。\n核心逻辑：在存入锁时，放入自己线程的标识，在删除锁时，判断当前这把锁的标识是不是自己存入的，如果是，则进行删除，如果不是，则不进行删除。\n\n**代码实现**（非最终版，还未引入Lua脚本解决原子性问题）\n\n- 加锁：\n```java\nprivate static final String ID_PREFIX = UUID.randomUUID().toString(true) + \"-\";\n@Override\npublic boolean tryLock(long timeoutSec) {\n   // 获取线程标示\n   String threadId = ID_PREFIX + Thread.currentThread().getId();\n   // 获取锁\n   Boolean success = stringRedisTemplate.opsForValue()\n                .setIfAbsent(KEY_PREFIX + name, threadId, timeoutSec, TimeUnit.SECONDS);\n   return Boolean.TRUE.equals(success);\n}\n```\n- 释放锁：\n```java\npublic void unlock() {\n    // 获取线程标示\n    String threadId = ID_PREFIX + Thread.currentThread().getId();\n    // 获取锁中的标示\n    String id = stringRedisTemplate.opsForValue().get(KEY_PREFIX + name);\n    // 判断标示是否一致\n    if(threadId.equals(id)) {\n        // 释放锁\n        stringRedisTemplate.delete(KEY_PREFIX + name);\n    }\n}\n```\n\n3. 原子性问题\n场景：线程1持有锁后，在执行业务逻辑过程中，正准备删除锁，而且已经走到了条件判断的过程中，正准备删除锁，但是此时锁已经到期了，同时线程2进来并获取到锁。但线程1接着往后执行删除锁操作，相当于条件判断并没有起到作用，这就是删锁时的原子性问题。此问题是因为线程1的拿锁，比锁，删锁，实际上并不是原子性的。\n解决方案：使用Lua脚本保证拿锁、比锁、删锁是一个原子性动作。\n\n操作redis的拿锁比锁删锁的lua脚本\n```lua\n-- 这里的 KEYS[1] 就是锁的key，这里的ARGV[1] 就是当前线程标示\n-- 获取锁中的标示，判断是否与当前线程标示一致\nif (redis.call('GET', KEYS[1]) == ARGV[1]) then\n  -- 一致，则删除锁\n  return redis.call('DEL', KEYS[1])\nend\n-- 不一致，则直接返回\nreturn 0\n```\n\n释放锁（引入Lua脚本）：\n```java\nprivate static final DefaultRedisScript<Long> UNLOCK_SCRIPT;\n    static {\n        UNLOCK_SCRIPT = new DefaultRedisScript<>();\n        //加载Lua脚本文件\n        UNLOCK_SCRIPT.setLocation(new ClassPathResource(\"unlock.lua\"));\t\n        UNLOCK_SCRIPT.setResultType(Long.class);\n    }\n\npublic void unlock() {\n    // 调用lua脚本\n    stringRedisTemplate.execute(\n            UNLOCK_SCRIPT,\n            Collections.singletonList(KEY_PREFIX + name),\n            ID_PREFIX + Thread.currentThread().getId());\n}\n```\n\n4. 锁续期（见Redisson）\n5. 可重入（见Redisson）\n\n\n# Redission\nRedisson是一个在Redis的基础上实现的Java驻内存数据网格（In-Memory Data Grid）。它不仅提供了一系列的分布式的Java常用对象，还提供了许多分布式服务，其中就包含了各种分布式锁的实现。\n\n于setnx实现的分布式锁存在下面的问题：\n- **重入问题**：重入问题是指 获得锁的线程可以再次进入到相同的锁的代码块中，可重入锁的意义在于防止死锁，比如HashTable这样的代码中，他的方法都是使用synchronized修饰的，假如他在一个方法内，调用另一个方法，那么此时如果是不可重入的，不就死锁了吗？所以可重入锁他的主要意义是防止死锁，我们的synchronized和Lock锁都是可重入的。\n- **不可重试**：是指目前的分布式只能尝试一次，我们认为合理的情况是：当线程在获得锁失败后，他应该能再次尝试获得锁。\n- **超时释放：**我们在加锁时增加了过期时间，这样的我们可以防止死锁，但是如果卡顿的时间超长，虽然我们采用了lua表达式防止删锁的时候，误删别人的锁，但是毕竟没有锁住，有安全隐患\n- **主从一致性：** 如果Redis提供了主从集群，当我们向集群写数据时，主机需要异步的将数据同步给从机，而万一在同步过去之前，主机宕机了，就会出现死锁问题。\n\n## 快速入门\n1. 引入依赖\n```xml\n<dependency>\n\t<groupId>org.redisson</groupId>\n\t<artifactId>redisson</artifactId>\n\t<version>3.13.6</version>\n</dependency>\n```\n\n2. 配置客户端\n```java\n@Configuration\npublic class RedissonConfig {\n\n    @Bean\n    public RedissonClient redissonClient(){\n        // 配置\n        Config config = new Config();\n        config.useSingleServer().setAddress(\"redis://192.168.150.101:6379\")\n            .setPassword(\"123321\");\n        // 创建RedissonClient对象\n        return Redisson.create(config);\n    }\n}\n\n```\n\n3. 使用Redission的分布式锁，注入对象\n```java\n@Resource\nprivate RedissionClient redissonClient;\n```\n\n## 可重入\n在Lock锁中，是借助于底层的一个voaltile的一个state变量来记录重入的状态的，比如当前没有人持有锁，那么state=0，假如有人持有这把锁，那么state=1，如果持有这把锁的人再次持有这把锁，那么state就会+1 ，如果是对于synchronized而言，他在c语言代码中会有一个count，原理和state类似，也是重入一次就加一，释放一次就-1 ，直到减少成0 时，表示当前这把锁没有被人持有。 \n\n在redission中，我们的也支持支持可重入锁\n\n在分布式锁中，他采用hash结构用来存储锁，其中大key表示表示这把锁是否存在，用小key表示当前这把锁被哪个线程持有，所以接下来我们一起分析一下当前的这个lua表达式\n这个地方一共有3个参数\n- **KEYS[1] ： 锁名称**\n- **ARGV[1]：  锁失效时间**\n- **ARGV[2]：  id + \":\" + threadId; 锁的小key**\n\nexists: 判断数据是否存在  name：是lock是否存在,如果==0，就表示当前这把锁不存在\nredis.call('hset', KEYS[1], ARGV[2], 1);此时他就开始往redis里边去写数据 ，写成一个hash结构\nLock{\n\tid + **\":\"** + threadId :  1\n}\n如果当前这把锁存在，则第一个条件不满足，再判断\nredis.call('hexists', KEYS[1], ARGV[2]) == 1\n此时需要通过大key+小key判断当前这把锁是否是属于自己的，如果是自己的，则进行\nredis.call('hincrby', KEYS[1], ARGV[2], 1)\n将当前这个锁的value进行+1 ，redis.call('pexpire', KEYS[1], ARGV[1]); 然后再对其设置过期时间，如果以上两个条件都不满足，则表示当前这把锁抢锁失败，最后返回pttl，即为当前这把锁的失效时间\n如果小伙帮们看了前边的源码， 你会发现他会去判断当前这个方法的返回值是否为null，如果是null，则对应则前两个if对应的条件，退出抢锁逻辑，如果返回的不是null，即走了第三个分支，在源码处会进行while(true)的自旋抢锁。\n```lua\n\"if (redis.call('exists', KEYS[1]) == 0) then \" +\n                  \"redis.call('hset', KEYS[1], ARGV[2], 1); \" +\n                  \"redis.call('pexpire', KEYS[1], ARGV[1]); \" +\n                  \"return nil; \" +\n              \"end; \" +\n              \"if (redis.call('hexists', KEYS[1], ARGV[2]) == 1) then \" +\n                  \"redis.call('hincrby', KEYS[1], ARGV[2], 1); \" +\n                  \"redis.call('pexpire', KEYS[1], ARGV[1]); \" +\n                  \"return nil; \" +\n              \"end; \" +\n              \"return redis.call('pttl', KEYS[1]);\"\n```\n\n## 锁重试与WatchDog\n\n# 实践优化\n## key\n### key命名规范\n- 建议遵循：`[业务名称]:[数据名]:[id]`的层级结构\n- key的长度不建议超过44字节\n\tredis对字符串的编码方式有`int`，`embstr`，`raw`三种，key是纯数字时选择`int`编码，当`key`的长度超过44字节时会使用`raw`编码，小于44字节时会使用`embstr` 编码。\n- 避免包含特殊字符\n\n### Bigkey\n`Bigkey`：占用空间较大的`key:value`\n\n查看`key`占用空间：\n```sh\nMEMORY USAGE keyName\t#对CPU的消耗较大，不建议使用\n```\n查看字符串长度：\n```sh\nSTRLEN keyName\t#推荐使用\n```\n查看key中元素数量：\n```sh\nLLEN keyName\t#查看列表中元素数量，推荐使用\n```\n黑马推荐值：\n- 单个key的value小于10KB\n- 对于集合类型的key，建议元素数量小于1000\n\n**Bigkey问题**：\n\n- 网络阻塞：对BigKey执行读请求时，少量的QPS就可能导致带宽使用率被占满，导致Redis实例，乃至所在物理机变慢\n- Redis阻塞：对元素较多的hash、list、zset等做运算会耗时较旧，使主线程被阻塞\n- CPU压力：BigKey的数据序列化和反序列化会导致CPU的使用率飙升，影响Redis实例和本机其它应用\n\n**发现Bigkey**\n\n1. redis命令：\n```sh\nredis-cli -a 密码 --bigkeys\t#需要新开一个cmd窗口，不是在redis客户端里\n```\n\n2. scan扫描：利用scan命令，编程扫描key\n```sh\nSCAN cursor [MATCH pattern] [COUNT count]\n```\n\n参数：\n\t- cursor：游标\n\t- pattern：匹配的模式\n\t- count：指定从数据集里返回多少元素，默认值为 10\n\nscan 命令调用完后每次会返回2个元素，第一个是下一次迭代的光标，第一次光标会设置为0，当最后一次scan 返回的光标等于0时，表示整个scan遍历结束了，第二个返回的是List，一个匹配的key的数组\n\neg：\n```java\nimport com.heima.jedis.util.JedisConnectionFactory;\nimport org.junit.jupiter.api.AfterEach;\nimport org.junit.jupiter.api.BeforeEach;\nimport org.junit.jupiter.api.Test;\nimport redis.clients.jedis.Jedis;\nimport redis.clients.jedis.ScanResult;\n\nimport java.util.HashMap;\nimport java.util.List;\nimport java.util.Map;\n\npublic class JedisTest {\n    private Jedis jedis;\n\n    @BeforeEach\n    void setUp() {\n        // 1.建立连接\n        // jedis = new Jedis(\"192.168.150.101\", 6379);\n        jedis = JedisConnectionFactory.getJedis();\n        // 2.设置密码\n        jedis.auth(\"123321\");\n        // 3.选择库\n        jedis.select(0);\n    }\n\n    final static int STR_MAX_LEN = 10 * 1024;\n    final static int HASH_MAX_LEN = 500;\n\n    @Test\n    void testScan() {\n        int maxLen = 0;\n        long len = 0;\n\n        String cursor = \"0\";\n        do {\n            // 扫描并获取一部分key\n            ScanResult<String> result = jedis.scan(cursor);\n            // 记录cursor\n            cursor = result.getCursor();\n            List<String> list = result.getResult();\n            if (list == null || list.isEmpty()) {\n                break;\n            }\n            // 遍历\n            for (String key : list) {\n                // 判断key的类型\n                String type = jedis.type(key);\n                switch (type) {\n                    case \"string\":\n                        len = jedis.strlen(key);\n                        maxLen = STR_MAX_LEN;\n                        break;\n                    case \"hash\":\n                        len = jedis.hlen(key);\n                        maxLen = HASH_MAX_LEN;\n                        break;\n                    case \"list\":\n                        len = jedis.llen(key);\n                        maxLen = HASH_MAX_LEN;\n                        break;\n                    case \"set\":\n                        len = jedis.scard(key);\n                        maxLen = HASH_MAX_LEN;\n                        break;\n                    case \"zset\":\n                        len = jedis.zcard(key);\n                        maxLen = HASH_MAX_LEN;\n                        break;\n                    default:\n                        break;\n                }\n                if (len >= maxLen) {\n                    System.out.printf(\"Found big key : %s, type: %s, length or size: %d %n\", key, type, len);\n                }\n            }\n        } while (!cursor.equals(\"0\"));\n    }\n    \n    @AfterEach\n    void tearDown() {\n        if (jedis != null) {\n            jedis.close();\n        }\n    }\n\n}\n```\n\n3. 第三方工具\n利用第三方工具，如 Redis-Rdb-Tools 分析RDB快照文件，全面分析内存使用情况https://github.com/sripathikrishnan/redis-rdb-tools\n\n4. 网络监控\n- 自定义工具，监控进出Redis的网络数据，超出预警值时主动告警\n- 一般阿里云搭建的云服务器就有相关监控页面\n\n**删除Bigkey**\nBigKey内存占用较多，即便时删除这样的key也需要耗费很长时间，导致Redis主线程阻塞，引发一系列问题。\nRedis 4.0以后：提供了异步删除的命令：unlink\n\n## 合适的数据类型\neg：存储一个User对象，有三种存储方式\n**方式一：json字符串**\n| user:1 | {\"name\": \"Jack\", \"age\": 21} |\n| :----: | :-------------------------: |\n\n优点：实现简单粗暴\n缺点：数据耦合，不够灵活\n\n**方式二：字段打散**\n##### \n\n| user:1:name | Jack |\n| :---------: | :--: |\n| user:1:age  |  21  |\n\n优点：可以灵活访问对象任意字段\n缺点：占用空间大、没办法做统一控制\n\n**方式三：hash（推荐）**\n\n<table>\n\t<tr>\n\t\t<td rowspan=\"2\">user:1</td>\n        <td>name</td>\n        <td>jack</td>\n\t</tr>\n\t<tr>\n\t\t<td>age</td>\n\t\t<td>21</td>\n\t</tr>\n</table>\n\n优点：底层使用ziplist，空间占用小，可以灵活访问对象的任意字段\n缺点：代码相对复杂\n\neg：假如有hash类型的key，其中有100万对field和value，field是自增id，这个key存在什么问题？如何优化？\n<table>\n\t<tr style=\"color:red\">\n\t\t<td>key</td>\n        <td>field</td>\n        <td>value</td>\n\t</tr>\n\t<tr>\n\t\t<td rowspan=\"3\">someKey</td>\n\t\t<td>id:0</td>\n        <td>value0</td>\n\t</tr>\n    <tr>\n\t\t<td>.....</td>\n        <td>.....</td>\n\t</tr>\n    <tr>\n        <td>id:999999</td>\n        <td>value999999</td>\n    </tr>\n</table>\n\n存在的问题：hash的entry数量超过512时，会使用哈希表而不是ZipList，内存占用较多\n\nredis hash类型底层有两种编码方式：`ziplist（压缩列表）`和`hashtable（哈希表）`。\n可以通过修改配置文件来改变`ziplist`和`hashtable`的转换条件\n\n```conf\n# 配置当field-value超过512时(合起来1024),使用hashtable编码,至于为什么是1024,与ziplist有关,后面会讲述\nhash-max-ziplist-entries 512  \n# 配置当key的单个field或value长度超过64时,使用hashtable编码\nhash-max-ziplist-value 64  \n```\n\n**方案一**\n拆分为string类型\n\n<table>\n\t<tr style=\"color:red\">\n\t\t<td>key</td>\n        <td>value</td>\n\t</tr>\n\t<tr>\n\t\t<td>id:0</td>\n        <td>value0</td>\n\t</tr>\n    <tr>\n\t\t<td>.....</td>\n        <td>.....</td>\n\t</tr>\n    <tr>\n        <td>id:999999</td>\n        <td>value999999</td>\n    </tr>\n</table>\n\n存在的问题：\n- string结构底层没有太多内存优化，内存占用较多\n- 想要批量获取这些数据比较麻烦\n\n**方案二**\n拆分为小的hash，将 id / 100 作为key， 将id % 100 作为field，这样每100个元素为一个Hash\n\n<table>\n\t<tr style=\"color:red\">\n\t\t<td>key</td>\n        <td>field</td>\n        <td>value</td>\n\t</tr>\n\t<tr>\n        <td rowspan=\"3\">key:0</td>\n\t\t<td>id:00</td>\n        <td>value0</td>\n\t</tr>\n    <tr>\n\t\t<td>.....</td>\n        <td>.....</td>\n\t</tr>\n    <tr>\n        <td>id:99</td>\n        <td>value99</td>\n    </tr>\n    <tr>\n        <td rowspan=\"3\">key:1</td>\n\t\t<td>id:00</td>\n        <td>value100</td>\n\t</tr>\n    <tr>\n\t\t<td>.....</td>\n        <td>.....</td>\n\t</tr>\n    <tr>\n        <td>id:99</td>\n        <td>value199</td>\n    </tr>\n    <tr>\n    \t<td colspan=\"3\">....</td>\n    </tr>\n    <tr>\n        <td rowspan=\"3\">key:9999</td>\n\t\t<td>id:00</td>\n        <td>value999900</td>\n\t</tr>\n    <tr>\n\t\t<td>.....</td>\n        <td>.....</td>\n\t</tr>\n    <tr>\n        <td>id:99</td>\n        <td>value999999</td>\n    </tr>\n</table>\n\njava代码：\n```java\npackage com.heima.test;\n\nimport com.heima.jedis.util.JedisConnectionFactory;\nimport org.junit.jupiter.api.AfterEach;\nimport org.junit.jupiter.api.BeforeEach;\nimport org.junit.jupiter.api.Test;\nimport redis.clients.jedis.Jedis;\nimport redis.clients.jedis.Pipeline;\nimport redis.clients.jedis.ScanResult;\n\nimport java.util.HashMap;\nimport java.util.List;\nimport java.util.Map;\n\npublic class JedisTest {\n    private Jedis jedis;\n\n    @BeforeEach\n    void setUp() {\n        // 1.建立连接\n        // jedis = new Jedis(\"192.168.150.101\", 6379);\n        jedis = JedisConnectionFactory.getJedis();\n        // 2.设置密码\n        jedis.auth(\"123321\");\n        // 3.选择库\n        jedis.select(0);\n    }\n\n    @Test\n    void testSetBigKey() {\n        Map<String, String> map = new HashMap<>();\n        for (int i = 1; i <= 650; i++) {\n            map.put(\"hello_\" + i, \"world!\");\n        }\n        jedis.hmset(\"m2\", map);\n    }\n\n    //使用一个hash进行存储\n    @Test\n    void testBigHash() {\n        Map<String, String> map = new HashMap<>();\n        for (int i = 1; i <= 100000; i++) {\n            map.put(\"key_\" + i, \"value_\" + i);\n        }\n        jedis.hmset(\"test:big:hash\", map);\n    }\n\n\t//使用10000个string进行存储\n    @Test\n    void testBigString() {\n        for (int i = 1; i <= 100000; i++) {\n            jedis.set(\"test:str:key_\" + i, \"value_\" + i);\n        }\n    }\n\n\t//使用100个小hash进行存储\n    @Test\n    void testSmallHash() {\n        int hashSize = 100;\n        Map<String, String> map = new HashMap<>(hashSize);\n        for (int i = 1; i <= 100000; i++) {\n            int k = (i - 1) / hashSize;\n            int v = i % hashSize;\n            map.put(\"key_\" + v, \"value_\" + v);\n            if (v == 0) {\n                jedis.hmset(\"test:small:hash_\" + k, map);\n            }\n        }\n    }\n\n    @AfterEach\n    void tearDown() {\n        if (jedis != null) {\n            jedis.close();\n        }\n    }\n}\n```\n\n## 批处理\n### 批量插入命令\nRedis提供了很多Mxxx这样的命令，可以实现批量插入数据，例如：\n- mset\n- hmset\n\njava代码：\n```java\n@Test\nvoid testMxx() {\n    String[] arr = new String[2000];\n    int j;\n    long b = System.currentTimeMillis();\n    for (int i = 1; i <= 100000; i++) {\n        j = (i % 1000) << 1;\n        arr[j] = \"test:key_\" + i;\n        arr[j + 1] = \"value_\" + i;\n        if (j == 0) {\n            jedis.mset(arr);\n        }\n    }\n    long e = System.currentTimeMillis();\n    System.out.println(\"time: \" + (e - b));\n}\n```\n\n### 管道Pipeline\nMSET虽然可以批处理，但是却只能操作部分数据类型，因此如果有对复杂数据类型的批处理需要，建议使用Pipeline\n```java\n@Test\nvoid testPipeline() {\n    // 创建管道\n    Pipeline pipeline = jedis.pipelined();\n    long b = System.currentTimeMillis();\n    for (int i = 1; i <= 100000; i++) {\n        // 放入命令到管道\n        pipeline.set(\"test:key_\" + i, \"value_\" + i);\n        if (i % 1000 == 0) {\n            // 每放入1000条命令，批量执行\n            pipeline.sync();\n        }\n    }\n    long e = System.currentTimeMillis();\n    System.out.println(\"time: \" + (e - b));\n}\n```\n\n### 集群批处理\n如MSET或Pipeline这样的批处理需要在一次请求中携带多条命令，而此时如果Redis是一个集群，那批处理命令的多个key必须落在一个插槽中，否则就会导致执行失败。大家可以想一想这样的要求其实很难实现，因为我们在批处理时，可能一次要插入很多条数据，这些数据很有可能不会都落在相同的节点上，这就会导致报错了。\n4种解决方案\n{% asset_img 001.png %}\n第一种方案：串行执行，所以这种方式没有什么意义，当然，执行起来就很简单了，缺点就是耗时过久。\n\n第二种方案：串行slot，简单来说，就是执行前，客户端先计算一下对应的key的slot，一样slot的key就放到一个组里边，不同的，就放到不同的组里边，然后对每个组执行pipeline的批处理，他就能串行执行各个组的命令，这种做法比第一种方法耗时要少，但是缺点呢，相对来说复杂一点，所以这种方案还需要优化一下\n\n第三种方案：并行slot，相较于第二种方案，在分组完成后串行执行，第三种方案，就变成了并行执行各个命令，所以他的耗时就非常短，但是实现呢，也更加复杂。\n\n第四种：hash_tag，redis计算key的slot的时候，其实是根据key的有效部分来计算的，通过这种方式就能一次处理所有的key，这种方式耗时最短，实现也简单，但是如果通过操作key的有效部分，那么就会导致所有的key都落在一个节点上，产生数据倾斜的问题，所以我们推荐使用第三种方式。\n\n**串行化执行代码：**\n```java\npublic class JedisClusterTest {\n\n    private JedisCluster jedisCluster;\n\n    @BeforeEach\n    void setUp() {\n        // 配置连接池\n        JedisPoolConfig poolConfig = new JedisPoolConfig();\n        poolConfig.setMaxTotal(8);\n        poolConfig.setMaxIdle(8);\n        poolConfig.setMinIdle(0);\n        poolConfig.setMaxWaitMillis(1000);\n        HashSet<HostAndPort> nodes = new HashSet<>();\n        nodes.add(new HostAndPort(\"192.168.150.101\", 7001));\n        nodes.add(new HostAndPort(\"192.168.150.101\", 7002));\n        nodes.add(new HostAndPort(\"192.168.150.101\", 7003));\n        nodes.add(new HostAndPort(\"192.168.150.101\", 8001));\n        nodes.add(new HostAndPort(\"192.168.150.101\", 8002));\n        nodes.add(new HostAndPort(\"192.168.150.101\", 8003));\n        jedisCluster = new JedisCluster(nodes, poolConfig);\n    }\n\n    @Test\n    void testMSet() {\n        jedisCluster.mset(\"name\", \"Jack\", \"age\", \"21\", \"sex\", \"male\");\n\n    }\n\n    @Test\n    void testMSet2() {\n        Map<String, String> map = new HashMap<>(3);\n        map.put(\"name\", \"Jack\");\n        map.put(\"age\", \"21\");\n        map.put(\"sex\", \"Male\");\n        //对Map数据进行分组。根据相同的slot放在一个分组\n        //key就是slot，value就是一个组\n        Map<Integer, List<Map.Entry<String, String>>> result = map.entrySet()\n                .stream()\n                .collect(Collectors.groupingBy(\n                        entry -> ClusterSlotHashUtil.calculateSlot(entry.getKey()))\n                );\n        //串行的去执行mset的逻辑\n        for (List<Map.Entry<String, String>> list : result.values()) {\n            String[] arr = new String[list.size() * 2];\n            int j = 0;\n            for (int i = 0; i < list.size(); i++) {\n                j = i<<2;\n                Map.Entry<String, String> e = list.get(0);\n                arr[j] = e.getKey();\n                arr[j + 1] = e.getValue();\n            }\n            jedisCluster.mset(arr);\n        }\n    }\n\n    @AfterEach\n    void tearDown() {\n        if (jedisCluster != null) {\n            jedisCluster.close();\n        }\n    }\n}\n```\n\n**Spring集群批处理代码：**\n```java\n   @Test\n    void testMSetInCluster() {\n        Map<String, String> map = new HashMap<>(3);\n        map.put(\"name\", \"Rose\");\n        map.put(\"age\", \"21\");\n        map.put(\"sex\", \"Female\");\n        stringRedisTemplate.opsForValue().multiSet(map);\n\n\n        List<String> strings = stringRedisTemplate.opsForValue().multiGet(Arrays.asList(\"name\", \"age\", \"sex\"));\n        strings.forEach(System.out::println);\n\n    }\n```\n\n在RedisAdvancedClusterAsyncCommandsImpl中，首先根据slotHash算出来一个partitioned的map，map中的key就是slot，而他的value就是对应的对应相同slot的key对应的数据通过 `RedisFuture<String> mset = super.mset(op)`进行异步的消息发送。如下：\n```java\n@Override\npublic RedisFuture<String> mset(Map<K, V> map) {\n\n    Map<Integer, List<K>> partitioned = SlotHash.partition(codec, map.keySet());\n\n    if (partitioned.size() < 2) {\n        return super.mset(map);\n    }\n\n    Map<Integer, RedisFuture<String>> executions = new HashMap<>();\n\n    for (Map.Entry<Integer, List<K>> entry : partitioned.entrySet()) {\n\n        Map<K, V> op = new HashMap<>();\n        entry.getValue().forEach(k -> op.put(k, map.get(k)));\n\n        RedisFuture<String> mset = super.mset(op);\n        executions.put(entry.getKey(), mset);\n    }\n\n    return MultiNodeExecution.firstOfAsync(executions);\n}\n```\n\n## 持久化配置\nRedis的持久化虽然可以保证数据安全，但也会带来很多额外的开销，因此持久化请遵循下列建议：\n\n* 用来做缓存的Redis实例尽量不要开启持久化功能\n* 建议关闭RDB持久化功能，使用AOF持久化\n* 利用脚本定期在slave节点做RDB，实现数据备份\n* 设置合理的rewrite阈值，避免频繁的bgrewrite\n* 配置no-appendfsync-on-rewrite = yes，禁止在rewrite期间做aof，避免因AOF引起的阻塞\n* 部署有关建议：\n  * Redis实例的物理机要预留足够内存，应对fork和rewrite\n  * 单个Redis实例内存上限不要太大，例如4G或8G。可以加快fork的速度、减少主从同步、数据迁移压力\n  * 不要与CPU密集型应用部署在一起\n  * 不要与高硬盘负载应用一起部署。例如：数据库、消息队列\n\n## 慢查询\nRedis执行时耗时超过某个阈值的命令，称为慢查询。\n\n慢查询的危害：由于Redis是单线程的，所以当客户端发出指令后，他们都会进入到redis底层的queue来执行，如果此时有一些慢查询的数据，就会导致大量请求阻塞，从而引起报错，所以我们需要解决慢查询问题。\n\n慢查询的阈值可以通过配置指定：\n- slowlog-log-slower-than：慢查询阈值，单位是微秒。默认是10000，建议1000\n\n慢查询会被放入慢查询日志中，日志的长度有上限，可以通过配置指定：\n- slowlog-max-len：慢查询日志（本质是一个队列）的长度。默认是128，建议1000\n\n使用`config set`修改配置\n```sh\nconfig set slowlog-log-slower-than 1000\n```\n\n**查看慢查询：**\n* slowlog len：查询慢查询日志长度\n* slowlog get [n]：读取n条慢查询日志\n* slowlog reset：清空慢查询列表\n\n## 安全配置\n漏洞出现的核心的原因有以下几点：\n* Redis未设置密码\n* 利用了Redis的config set命令动态修改Redis配置\n* 使用了Root账号权限启动Redis\n\n为了避免这样的漏洞，可以采用如下几种方案：\n* Redis一定要设置密码\n* 禁止线上使用下面命令：keys、flushall、flushdb、config set等命令。可以利用rename-command禁用。\n* bind：限制网卡，禁止外网网卡访问\n* 开启防火墙\n* 不要使用Root账户启动Redis\n* 尽量不是有默认的端口\n\n## 内存划分与配置\n当Redis内存不足时，可能导致Key频繁被删除、响应时间变长、QPS不稳定等问题。当内存使用率达到90%以上时就需要我们警惕，并快速定位到内存占用的原因。\n\n**有关碎片问题分析**\nRedis底层分配并不是这个key有多大，他就会分配多大，而是有他自己的分配策略，比如8,16,20等等，假定当前key只需要10个字节，此时分配8肯定不够，那么他就会分配16个字节，多出来的6个字节就不能被使用，这就是我们常说的 碎片问题\n\n**进程内存问题分析：**\n这片内存，通常我们都可以忽略不计\n\n**缓冲区内存问题分析：**\n一般包括客户端缓冲区、AOF缓冲区、复制缓冲区等。客户端缓冲区又包括输入缓冲区和输出缓冲区两种。这部分内存占用波动较大，所以这片内存也是我们需要重点分析的内存问题。\n\n| **内存占用** | **说明**                                                     |\n| ------------ | ------------------------------------------------------------ |\n| 数据内存     | 是Redis最主要的部分，存储Redis的键值信息。主要问题是BigKey问题、内存碎片问题 |\n| 进程内存     | Redis主进程本身运⾏肯定需要占⽤内存，如代码、常量池等等；这部分内存⼤约⼏兆，在⼤多数⽣产环境中与Redis数据占⽤的内存相⽐可以忽略。 |\n| 缓冲区内存   | 一般包括客户端缓冲区、AOF缓冲区、复制缓冲区等。客户端缓冲区又包括输入缓冲区和输出缓冲区两种。这部分内存占用波动较大，不当使用BigKey，可能导致内存溢出。 |\n\n通过一些命令查看到Redis目前的内存分配状态：\n* info memory：查看内存分配的情况\n* memory xxx：查看key的主要占用情况\n\n内存缓冲区常见的有三种：\n* 复制缓冲区：主从复制的repl_backlog_buf，如果太小可能导致频繁的全量复制，影响性能。通过replbacklog-size来设置，默认1mb\n* AOF缓冲区：AOF刷盘之前的缓存区域，AOF执行rewrite的缓冲区。无法设置容量上限\n* 客户端缓冲区：分为输入缓冲区和输出缓冲区，输入缓冲区最大1G且不能设置。输出缓冲区可以设置\n\n以上复制缓冲区和AOF缓冲区 不会有问题，最关键就是客户端缓冲区的问题\n\n客户端缓冲区：指的就是我们发送命令时，客户端用来缓存命令的一个缓冲区，也就是我们向redis输入数据的输入端缓冲区和redis向客户端返回数据的响应缓存区，输入缓冲区最大1G且不能设置，所以这一块我们根本不用担心，如果超过了这个空间，redis会直接断开，因为本来此时此刻就代表着redis处理不过来了，我们需要担心的就是输出端缓冲区\n{% asset_img 002.png %}\n我们在使用redis过程中，处理大量的big value，那么会导致我们的输出结果过多，如果输出缓存区过大，会导致redis直接断开，而默认配置的情况下， 其实他是没有大小的，这就比较坑了，内存可能一下子被占满，会直接导致咱们的redis断开，所以解决方案有两个\n1、设置一个大小\n2、增加我们带宽的大小，避免我们出现大量数据从而直接超过了redis的承受能力\n\n## 集群与主从\n集群虽然具备高可用特性，能实现自动故障恢复，但是如果使用不当，也会存在一些问题：\n* 集群完整性问题\n* 集群带宽问题\n* 数据倾斜问题\n* 客户端性能问题\n* 命令的集群兼容性问题\n* lua和事务问题\n\n **问题1、在Redis的默认配置中，如果发现任意一个插槽不可用，则整个集群都会停止对外服务：** \n大家可以设想一下，如果有几个slot不能使用，那么此时整个集群都不能用了，我们在开发中，其实最重要的是可用性，所以需要把如下配置修改成no，即有slot不能使用时，我们的redis集群还是可以对外提供服务\n\n**问题2、集群带宽问题**\n集群节点之间会不断的互相Ping来确定集群中其它节点的状态。每次Ping携带的信息至少包括：\n* 插槽信息\n* 集群状态信息\n\n集群中节点越多，集群状态信息数据量也越大，10个节点的相关信息可能达到1kb，此时每次集群互通需要的带宽会非常高，这样会导致集群中大量的带宽都会被ping信息所占用，这是一个非常可怕的问题，所以我们需要去解决这样的问题\n\n**解决途径：**\n* 避免大集群，集群节点数不要太多，最好少于1000，如果业务庞大，则建立多个集群。\n* 避免在单个物理机中运行太多Redis实例\n* 配置合适的cluster-node-timeout值\n\n**问题3、命令的集群兼容性问题**\n有关这个问题咱们已经探讨过了，当我们使用批处理的命令时，redis要求我们的key必须落在相同的slot上，然后大量的key同时操作时，是无法完成的，所以客户端必须要对这样的数据进行处理，这些方案我们之前已经探讨过了，所以不再这个地方赘述了。\n\n**问题4、lua和事务的问题**\nlua和事务都是要保证原子性问题，如果你的key不在一个节点，那么是无法保证lua的执行和事务的特性的，所以在集群模式是没有办法执行lua和事务的\n\n**那我们到底是集群还是主从**\n\n单体Redis（主从Redis）已经能达到万级别的QPS，并且也具备很强的高可用特性。如果主从能满足业务需求的情况下，所以如果不是在万不得已的情况下，尽量不搭建Redis集群\n\n# 参考资料\n1. Redis数据类型及编码格式——Hash篇：https://blog.csdn.net/qq_33983753/article/details/123063712\n\n# 待办\n1. redis实战.md——全局ID\n2. redis实战.md——一人一单：事务"},{"title":"Mybatis-Plus学习笔记","url":"/2022/08/02/mybatis-plus-xue-xi-bi-ji/","content":"\n# 基本流程\n1. 引入依赖\nMybatis-Plus、数据库依赖（eg：Mysql）、Lombok（生成set、get、构造器等）\n```xml\n<dependency>\n            <groupId>org.projectlombok</groupId>\n            <artifactId>lombok</artifactId>\n</dependency>\n\n<dependency>\n            <groupId>com.baomidou</groupId>\n            <artifactId>mybatis-plus-boot-starter</artifactId>\n            <version>3.1.0</version>\n</dependency>\n\n<dependency>\n            <groupId>mysql</groupId>\n            <artifactId>mysql-connector-java</artifactId>\n</dependency>\n```\nPS：3.5.2 版本中@TableName、@MapperScan注解似乎没有了\n\n2. 构造实体类\n```java\n@Data   //get、set方法\n@TableName(\"tb_user\")\n@NoArgsConstructor  //无参构造器\n@AllArgsConstructor //有参构造器\npublic class User {\n    @TableId(\"ID\")\n    private Long id;\n    @TableField(\"USER_NAME\") private String userName; //驼峰命名,则无需注解\n    @TableField(\"PASSWORD\")\n    private String password;\n}\n```\n\n3. 编写Mapper，集成BaseMapper接口\n```java\npublic interface UserMapper extends BaseMapper<User> { }\n```\n\n4. 扫描mapper所在包\n在启动类或测试类上添加`@MapperScan(\"包名\")`"},{"title":"SpringCloud学习笔记","url":"/2022/07/15/springcloud-xue-xi-bi-ji/","content":"# EureKa\n## EureKa注册中心\n1. maven依赖\n```\n<dependency>\n\t<groupId>org.springframework.cloud</groupId>\n\t<artifactId>spring-cloud-starter-netflix-eureka-server</artifactId>\n</dependency>\n```\n2. 使用注解@EnableEureKa编写Application启动类\n3. 添加配置信息\n```\nserver:\n\tport: 10086\nspring:\n\tapplication:\n\t\tname: eurekaserver\neureka:\n\tclient:\n\t\tservice-url:\n\t\t\tdefaultZone: http://127.0.0.1:10086/eureka/\n\n```\n### EureKa服务者注册\n1. maven依赖\n```\n<dependency>\n\t<groupId>org.springframework.cloud</groupId>\n\t<artifactId>spring-cloud-starter-netflix-eureka-client</artifactId>\n</dependency>\n```\n2. 添加配置信息\n```\nserver:\n\tport: 10086\nspring:\n\tapplication:\n\t\tname: client1\neureka:\n\tclient:\n\t\tservice-url:\n\t\t\tdefaultZone: http://127.0.0.1:10086/client1/\n```\n### EureKa消费者注册\n步骤同服务者注册。但需添加http请求模块，以便于向其他微服务模块发送请求。\n```\n@Bean\n@LoadBalanced\t//一个微服务模块有多个实例时，开启负载均衡\npublic RestTemplate restTemplate(){\n\treturn new RestTemplate();\n}\n```\n发送请求时，使用注册时的服务名代替 ip 和端口，eg\n```\nString url = \"http://servicename/user/\" + order.getUserId();\n```\n## Ribbon\nEureKa的负载均衡组件。\n### 选择负载均衡策略\n方式一：手动添加负载均衡组件 IRule。这种配置方式是全局的，无论调用哪一个微服务都会采用该策略。\n```\n//选择随机策略的组件\n@Bean\npublic IRule randomRule(){\n\treturn new RandomRule();\n}\n```\n方式二：配置文件方式。该方式只对被配置的微服务生效。\n```\nuserservice:\n\tribbon:\n\t\tNFLoadBalancerRuleClassName: com.netflix.loadbalancer.RandomRule\n```\n### 加载方式\nRibbon默认采用懒加载方式，即接受到第一次请求后才开始加载。\n开启饥饿加载，即启动时加载。\n```\nribbon:\n\teager-load:\n\t\tenabled: true #开启饥饿加载\n\t\tclients: userservice #指定劝userservice这个服务饥饿加载\n```\n# Nacos\n1. 下载Nacos\n2. 项目父工程引入依赖\n```\n<dependency>\n    <groupId>com.alibaba.cloud</groupId>\n    <artifactId>spring-cloud-alibaba-dependencies</artifactId>\n    <version>2.2.5.RELEASE</version>\n    <type>pom</type>\n    <scope>import</scope>\n</dependency>\n```\n3. 微服务引入Nacos依赖\n```\n<dependency>\n    <groupId>com.alibaba.cloud</groupId>\n    <artifactId>spring-cloud-starter-alibaba-nacos-discovery</artifactId>\n</dependency>\n```\n4. 微服务配置Nacos\n```\nspring:\n\tcloud:\n\t\tnacos:\n\t\t\tserver-addr: localhost:8848\n```\nPS：微服务需要有`资源`启动后在控制台才能看到注册的微服务，`资源`是可以被访问的方法等，踩大坑！\n\n## Nacos集群\nNacos默认优先访问同一集群下的微服务，多个微服务实例间是随机访问。当本地微服务不可用时会发生跨集群访问。\n集群配置\n```\nspring:\n\tcloud:\n\t\tnacos:\n\t\t\tserver-addr: localhost:8848\n\t\t\tdiscovery:\n\t\t\t\tcluster-name: HZ #集群名称\n```\n设置负载均衡方式\n```\nuserservice:\n\tribbon:\n\t\tNFLoadBalancerRuleClassName: com.alibaba.cloud.nacos.ribbon.NacosRule\n```\n## Nacos环境隔离\n在Nacos控制台进行环境管理，不同环境下的微服务之间是相互隔离的，无法访问。\n配置临时实例为true，开启注册中心主动询问微服务实例状态，频率较高，对服务器的开销比较大。临时实例为false，微服务实例主动向注册中心发送心跳信息，频率较低，开销较小。\n与EureKa不同，如果Nacos注册中心发现有一个微服务实例不可用，则会主动向消费者推送信息，更新微服务实例列表。\n\n## Nacos配置管理\n### 远程环境配置\n1. 在Nacos控制台创建配置文件 eg：userservice-dev.yml\n2. 在微服务实例中添加bootstrap.yml文件，将需要从 application.yml 剥离的配置信息改到 bootstrap.yml ，例如Nacos地址，微服务名称等（SpringCloud负责加载 bootstrap.yml，会先于SpringBoot加载application.yml）\n3. 配置热更新\n方式一：使用 @Value 和 @RefreshScope 刷新\n方式二：使用 @ConfigurationProperties 实现\n### 远程共享配置\n多个实例间共享设置，eg：userservice.yml\n配置生效优先级：远程环境配置 > 远程共享配置 > 本地配置\n{% asset_img 001.jpg %}\n### 集群搭建\n1. 搭建MySQL集群并初始化数据库表\n2. 下载解压nacos\n3. 修改集群配置（节点信息）、数据库配置\n4. 分别启动多个nacos节点\n5. nginx反向代理\n## Feign\n较RestTemplate更为强大的http客户端。\n使用步骤：\n1. 引入 maven 依赖\n```\n<dependency>\n\t<groupId>org.springframework.cloud</groupId>\n\t<artifactId>spring-cloud-starter-openfeign</artifactId> </dependency>\n\n```\n2. 启动类添加 @EnableFeignClients 注解\n3. 编写 FeignClient 接口\n```\n@FeignClient(\"userservice\")\npublic interface UserClient {\n\t@GetMapping(\"/user/{id}\") \n\tUser findById(@PathVariable(\"id\") Long id);\n}\n```\n4. 使用 FeginClient\n### Feign日志级别\n方式一：配置文件方式\n1. 全局生效\n```\nfeign:\n\tclient:\n\t\tconfig:\n\t\t\tdefault: #对所有微服务生效\n\t\t\t\tloggerLevel: FULL #  日志级别 \n```\n2. 局部生效\n```\nfeign:\n\tclient:\n\t\tconfig:\n\t\t\tuserservice: #只对userservice生效\n\t\t\t\tloggerLevel: FULL #  日志级别 \n```\n方式二：代码方式\n```\npublic class FeignClientConfiguration {\n\t@Bean\n\tpublic Logger.Level feignLogLevel(){\n\t\treturn Logger.Level.BASIC;\n\t}\n}\n```\n1. 全局配置，则把它放到@EnableFeignClients这个注解中：\n```\n@EnableFeignClients(defaultConfiguration = FeignClientConfiguration.class)\n```\n2. 局部配置，则把它放到@FeignClient这个注解中：\n```\n@FeignClient(value = \"userservice\", configuration = FeignClientConfiguration.class) \n```\n### 设置Feign底层Http客户端\nFeign底层的客户端实现：\n    URLConnection：默认实现，不支持连接池\n    Apache HttpClient ：支持连接池\n    OKHttp：支持连接池\n配置HttpClient\n1. 引入maven依赖\n```\n<!--httpClient的依赖 -->\n<dependency>\n\t<groupId>io.github.openfeign</groupId>\n\t<artifactId>feign-httpclient</artifactId>\n</dependency>\n```\n2. 配置连接池\n```\nfeign:\n\tclient:\n\t\tconfig:\n\t\t\tdefault: # default全局的配置\n\t\t\tloggerLevel: BASIC # 日志级别，BASIC就是基本的请求和响应信息\n\thttpclient:\n\t\tenabled: true # 开启feign对HttpClient的支持\n\t\tmax-connections: 200 # 最大的连接数\n\t\tmax-connections-per-route: 50 # 每个路径的最大连接数\n```\n###  抽取FeignClient模块\nps：也可以选择继承父接口的方式。\n1. 首先创建一个module，命名为feign-api，然后引入feign的starter依赖\n2. 将order-service中编写的UserClient、User等要抽取的内容都复制到feign-api项目中\n3. 在order-service（需要使用feign-api）中引入feign-api的依赖\n4. 修改order-service，改成导入feign-api中的包\n5. 指定加载FeignClient类\n```\n//方式一\n@EnableFeignClients(basePackages = \"cn.itcast.feign.clients\")\t//扫描FeignClient所在整个模块\n//方式二\n@EnableFeignClients(clients = {UserClient.class})\t//直接指定加载FeignClient\n```\n6. 重启测试\n## 网关Gateway\n使用步骤：\n1. 创建项目，引入依赖\n```\n<!--网关依赖-->\n<dependency>\n\t<groupId>org.springframework.cloud</groupId>\n\t<artifactId>spring-cloud-starter-gateway</artifactId>\n</dependency>\n<!--nacos服务发现依赖-->\n<dependency>\n\t<groupId>com.alibaba.cloud</groupId>\n\t<artifactId>spring-cloud-starter-alibaba-nacos-discovery</artifactId> \n</dependency>\n```\n2. 编写路由配置及nacos地址\n```\nserver:\n  port: 10010 # 网关端口\nspring:\n  application:\n    name: gateway # 服务名称\n  cloud:\n    nacos:\n      server-addr: localhost:8848 # nacos地址\n    gateway:\n      routes: # 网关路由配置\n        - id: user-service # 路由id，自定义，只要唯一即可\n          # uri: http://127.0.0.1:8081 # 路由的目标地址 http就是固定地址\n          uri: lb://userservice # 路由的目标地址 lb就是负载均衡，后面跟服务名称\n          predicates: # 路由断言，也就是判断请求是否符合路由规则的条件\n            - Path=/user/** # 这个是按照路径匹配，只要以/user/开头就符合要求\n```\n### Gateway路由断言工厂\nGateway提供多种断言工厂——Route Predicate Factory，对进入的请求进行判断。\n{% asset_img 002.jpg %}\n### 路由过滤器GatewayFilter\n对进入网关的请求和微服务返回的响应做处理。\n{% asset_img 003.jpg %}\neg: 给所有进入userservice的请求添加一个请求头：Truth=itcast is freaking awesome!\n```\nspring:\n\tcloud:\n\t\tgateway:\n\t\t\troutes: # 网关路由配置\n                - id: user-service\n                  uri: lb://userservice\n                  predicates:\n                    - Path=/user/**\n                  filters: # 过滤器\n                    - AddRequestHeader=Truth, Itcast is freaking awesome! # 添加请求头\n```\n默认过滤器：对所有的路由都生效，将过滤器工厂写到default下。\n```\nspring:\n\tapplication:\n\t\tname: gateway # 服务名称\n\tcloud:\n\t\tnacos:\n\t\t\tserver-addr: localhost:8848 # nacos地址\n\t\t\tgateway:\n\t\t\t\troutes: # 网关路由配置\n                    - id: user-service \n                      uri: lb://userservice\n                      predicates:\n                        - Path=/user/**\n                    - id: order-service\n                      uri: lb://orderservice\n                      predicates:\n                        - Path=/order/**\n\t\t\t\tdefault-filters: # 默认过滤器，会对所有的路由请求都生效\t\t\t\t\t\t\t- AddRequestHeader=Truth, Itcast is freaking awesome! # 添加请求头\n```\n### 自定义全局过滤器GlobalFilter\n处理一切进入网关的请求和微服务响应，与GatewayFilter的作用一样。自定义过滤器的代码处理逻辑，需要实现GlobalFilter接口。\n```\npublic interface GlobalFilter {\n\t/**\n\t*  处理当前请求，有必要的话通过{@link GatewayFilterChain}将请求交给下一个过滤器处理\n    *\n    * @param exchange 请求上下文，里面可以获取Request、Response等信息\n    * @param chain 用来把请求委托给下一个过滤器 \n    * @return {@code Mono<Void>} 返回标示当前过滤器业务结束\n    */\n    Mono<Void> filter(ServerWebExchange exchange, GatewayFilterChain chain);\n}\n\n/**\n* 定义全局过滤器，拦截请求，判断请求的参数是否满足下面条件\n* 参数中是否有authorization\n* authorization参数值是否为admin,如果同时满足则放行，否则拦截\n*/\n@Order(-1)\t//让类实现Ordered接口，实现接口方法与使用注解效果是一样的\n@Component\npublic class AuthorizeFilter implements GlobalFilter {\n\t@Override\n\tpublic Mono<Void> filter(ServerWebExchange exchange, GatewayFilterChain chain) {\n        // 1.获取请求参数\n        MultiValueMap<String, String> params = exchange.getRequest().getQueryParams();\n        // 2.获取authorization参数\n        String auth = params.getFirst(\"authorization\");\n        // 3.校验\n        if (\"admin\".equals(auth)) {\n        // 放行\n        return chain.filter(exchange);\n        }\n        // 4.拦截\n        // 4.1.禁止访问 exchange.getResponse().setStatusCode(HttpStatus.FORBIDDEN);\n        // 4.2.结束处理\n        return exchange.getResponse().setComplete();\n\t}\n}\n```\n### 过滤器执行顺序\n1. order值越小，优先级越高\n2. 当order值一样时，顺序是defaultFilter最先，然后是局部的路由过滤器，最后是全局过滤器\n### 跨域问题\n浏览器禁止请求的发起者与服务端发生跨域ajax请求，请求被浏览器拦截的问题。\n解决方案：CORS\n```\nspring:\n\tcloud:\n\t\tgateway:\n\t\t\tglobalcors: # 全局的跨域处理\n\t\t\t\tadd-to-simple-url-handler-mapping: true # 解决options请求被拦截问题\n\t\t\t\tcorsConfigurations:\n\t\t\t\t\t'[/**]':\n\t\t\t\t\t\tallowedOrigins: # 允许哪些网站的跨域请求\n\t\t\t\t\t\t\t- \"http://localhost:8090\"\n\t\t\t\t\t\t\t- \"http://www.leyou.com\"\n\t\t\t\t\t\tallowedMethods: # 允许的跨域ajax的请求方式\n                        \t- \"GET\"           \n                        \t- \"POST\"\n                        \t- \"DELETE\"\n                        \t- \"PUT\"\n                        \t- \"OPTIONS\"\n\t\t\t\t\t\tallowedHeaders: \"*\" # 允许在请求中携带的头信息\n\t\t\t\t\t\tallowCredentials: true # 是否允许携带cookie     \t\t\t\t\t\t\tmaxAge: 360000 # 这次跨域检测的有效期\n```\n# Docker\n## 基本操作\n1. 拉取镜像\n```\ndocker pull nginx\t//不写版本号默认拉取最新版\n```\n2. 查看镜像\n```\ndocker images\n```\n3. 删除镜像\n```\ndocker rmi nginx:latest\n```\n4. 保存、导入镜像\n```\ndocker save -o [保存的目标文件名称] [镜像名称]\neg: \ndocker save -o nginx.tar nginx:latest\n```\n5. 加载镜像\n```\ndocker load -i nginx.tar\n```\n## 容器操作\n{% asset_img 004.jpg %}\n- 运行：进程正常运行\n- 暂停：进程暂停，CPU不再运行，并不释放内存\n- 停止：进程终止，回收进程占用的内存、CPU等资源\n1. 创建容器\n```\ndocker run --name containerName -p 80:80 -d nginx\nps:\ncontainName 为容器所取名称\n-p 映射端口，左侧为主机端口，右侧为容器端口\n-d 后台运行容器\nnginx 要运行的镜像名称\n```\n{% asset_img 005.jpg %}\n2. 暂停容器\n```\ndocker pause containerName\n```\n3. 容器取消暂停状态，恢复运行\n```\ndocker unpause containerName\n```\n4. 停止容器\n```\ndocker stop containerName\n```\n5. 容器取消停止，再次运行\n```\ndocker start containerName\n```\n6. 删除容器\n```\ndocker rm containerName\n```\n7. 进入容器\n```\ndocker exec -it mn bash\nps:\n-it 给当前进入的容器创建一个标准输入、输出终端，允许我们与容器交互\nmn 进入的容器的名称\nbash 进入容器后执行的命令，bash是一个linux终端交互命令\n```\n8. 查看容器日志\n```\ndocker logs\nps:\n-f 持续查看日志\n```\n9. 查看容器状态\n```\ndocker ps\nps:\n-a 查看所有容器（包括已停止）\n```\n## 数据卷\n**数据卷（volume）**是一个虚拟目录，指向宿主机文件系统中的某个目录。\n{% asset_img 006.jpg %}\n一旦完成数据卷挂载，对容器的一切操作都会作用在数据卷对应的宿主机目录了。我们操作宿主机的/var/lib/docker/volumes/html目录，就等于操作容器内的/usr/share/nginx/html目录了\n1. 创建数据卷\n```\ndocker volume create html\n```\n2. 查看所有数据卷\n```\ndocker volume ls\n```\n3. 查看数据卷详细信息\n```\ndocker volume inspect html\n```\n4. 删除数据卷\n删除未使用的数据卷\n```\ndocker volume prune \n```\n删除指定数据卷\n```\ndocker volume rm html\n```\n5. 挂载数据卷\n```\ndocker run \\\n  --name mn \\\n  -v html:/root/html \\\n  -p 8080:80 \\\n  nginx \\\nps:\n-v html:/root/htm 把html数据卷挂载到容器内的/root/html这个目录中\n```\n6. 容器直接挂载主机目录\n```\ndocker run \\\n  --name mn \\\n  -v [宿主机目录]:[容器内目录] \\\n  -p 8080:80 \\\n  nginx \\\n```\n{% asset_img 007.jpg %}\n## Dockerfile\n**Dockerfile**就是一个文本文件，其中包含一个个的**指令(Instruction)**，用指令来说明要执行什么操作来构建镜像。每一个指令都会形成一层Layer。\n{% asset_img 008.jpg %}\nDockerfile文件告诉Docker，我们的镜像的组成，需要哪些BaseImage、需要拷贝什么文件、需要安装什么依赖、启动脚本是什么，将来Docker会帮助我们构建镜像。\n{% asset_img 009.jpg %}\n### 构建镜像\n新建文件夹及准备好相关文件。\n{% asset_img 010.jpg %}\nDockerfile内容如下\n```\n# 指定基础镜像\n  FROM ubuntu:16.04\n  # 配置环境变量，JDK的安装目录\n  ENV JAVA_DIR=/usr/local\n  \n  # 拷贝jdk和java项目的包\n  COPY ./jdk8.tar.gz $JAVA_DIR/\n  COPY ./docker-demo.jar /tmp/app.jar\n  \n  # 安装JDK\n  RUN cd $JAVA_DIR \\\n   && tar -xf ./jdk8.tar.gz \\\n   && mv ./jdk1.8.0_144 ./java8\n  \n  # 配置环境变量\n  ENV JAVA_HOME=$JAVA_DIR/java8\n  ENV PATH=$PATH:$JAVA_HOME/bin\n  \n  # 暴露端口\n  EXPOSE 8090\n  # 入口，java项目的启动命令\n  ENTRYPOINT java -jar /tmp/app.jar\n```\n### 基于镜像构建镜像\n由于Docker的分层结构，因此我们可以在别人镜像的基础上制作自己的镜像。\n基于java:8-alpine镜像，将一个Java项目构建为镜像。\n- 新建一个空的目录，然后在目录中新建一个文件，命名为Dockerfile\n- 拷贝课前资料提供的docker-demo.jar到这个目录中\n- 编写Dockerfile文件：\n  - 基于java:8-alpine作为基础镜像\n  - 将app.jar拷贝到镜像中\n  - 暴露端口\n  - 编写入口ENTRYPOINT\n```\n    FROM java:8-alpine\n    COPY ./app.jar /tmp/app.jar\n    EXPOSE 8090\n    ENTRYPOINT java -jar /tmp/app.jar\n```\n## DockerCompose\nDocker Compose可以基于Compose文件帮我们快速的部署分布式应用，而无需手动一个个创建和运行容器！\n### DockerCompose下载安装\n详细见官网https://docs.docker.com/compose/\n### 部署集群案例\neg：将之前学习的cloud-demo微服务集群利用DockerCompose部署\n- 查看课前资料提供的cloud-demo文件夹，里面已经编写好了docker-compose文件\n- 修改自己的cloud-demo项目，将数据库、nacos地址都命名为docker-compose中的服务名\n- 使用maven打包工具，将项目中的每个微服务都打包为app.jar\n- 将打包好的app.jar拷贝到cloud-demo中的每一个对应的子目录中\n- 将cloud-demo上传至虚拟机，利用 docker-compose up -d 来部署\n#### 1. compose文件\n查看课前资料提供的cloud-demo文件夹，里面已经编写好了docker-compose文件，而且每个微服务都准备了一个独立的目录：\n{% asset_img 011.jpg %}\n```yaml\nversion: \"3.2\"\nservices:\n  nacos:\n    image: nacos/nacos-server\n    environment:\n      MODE: standalone\n    ports:\n      - \"8848:8848\"\n  mysql:\n    image: mysql:5.7.25\n    environment:\n      MYSQL_ROOT_PASSWORD: 123\n    volumes:\n      - \"$PWD/mysql/data:/var/lib/mysql\"\n      - \"$PWD/mysql/conf:/etc/mysql/conf.d/\"\n  userservice:\n    build: ./user-service\n  orderservice:\n    build: ./order-service\n  gateway:\n    build: ./gateway\n    ports:\n      - \"10010:10010\"\n```\n共有5个service服务：\n- `nacos`：作为注册中心和配置中心\n  - `image: nacos/nacos-server`： 基于nacos/nacos-server镜像构建\n  - `environment`：环境变量\n    - `MODE: standalone`：单点模式启动\n  - `ports`：端口映射，这里暴露了8848端口\n- `mysql`：数据库\n  - `image: mysql:5.7.25`：镜像版本是mysql:5.7.25\n  - `environment`：环境变量\n    - `MYSQL_ROOT_PASSWORD: 123`：设置数据库root账户的密码为123\n  - `volumes`：数据卷挂载，这里挂载了mysql的data、conf目录，其中有我提前准备好的数据\n- `userservice`、`orderservice`、`gateway`：都是基于Dockerfile临时构建的\nmysql目录中可已经准备好了cloud_order、cloud_user表。\n查看微服务目录，可以看到都包含Dockerfile文件：\n```dockerfile\nFROM java:8-alpine\nCOPY ./app.jar /tmp/app.jar\nENTRYPOINT java -jar /tmp/app.jar\n```\n#### 2. 修改微服务配置\n因为微服务将来要部署为docker容器，而容器之间互联不是通过IP地址，而是通过容器名。这里我们将order-service、user-service、gateway服务的mysql、nacos地址都修改为基于容器名的访问。\n```yaml\nspring:\n  datasource:\n    url: jdbc:mysql://mysql:3306/cloud_order?useSSL=false\n    username: root\n    password: 123\n    driver-class-name: com.mysql.jdbc.Driver\n  application:\n    name: orderservice\n  cloud:\n    nacos:\n      server-addr: nacos:8848 # nacos服务地址\n```\n#### 3. 打包\n接下来需要将我们的每个微服务都打包。因为之前查看到Dockerfile中的jar包名称都是app.jar，因此我们的每个微服务都需要用这个名称。可以通过修改pom.xml中的打包名称来实现，每个微服务都需要修改：\n```xml\n<build>\n  <!-- 服务打包的最终名称 -->\n  <finalName>app</finalName>\n  <plugins>\n    <plugin>\n      <groupId>org.springframework.boot</groupId>\n      <artifactId>spring-boot-maven-plugin</artifactId>\n    </plugin>\n  </plugins>\n</build>\n```\n{% asset_img 012.jpg %}\n#### 4. 拷贝jar包到部署目录\n编译打包好的app.jar文件，需要放到Dockerfile的同级目录中。注意：每个微服务的app.jar放到与服务名称对应的目录，不要搞错。\neg：order-service\n{% asset_img 013.jpg %}\n#### 5. 部署\n最后将文件整个cloud-demo文件夹上传到虚拟机中，由DockerCompose部署。可上传到任意目录。\n部署：进入cloud-demo目录，然后运行下面的命令：\n```\ndocker-compose up -d\n```\n## Docker镜像仓库\n### 简化版镜像仓库\n```\ndocker run -d \\\n    --restart=always \\\n    --name registry\t\\\n    -p 5000:5000 \\\n    -v registry-data:/var/lib/registry \\\n    registry\n```\n命令中挂载了一个数据卷registry-data到容器内的/var/lib/registry 目录，这是私有镜像库存放数据的目录。访问http://YourIp:5000/v2/_catalog 可以查看当前私有镜像服务中包含的镜像。\n\n### 图形界面镜像仓库\n使用DockerCompose部署带有图象界面的DockerRegistry，命令如下：\n```\nversion: '3.0'\nservices:\n  registry:\n    image: registry\n    volumes:\n      - ./registry-data:/var/lib/registry\n  ui:\n    image: joxit/docker-registry-ui:static\n    ports:\n      - 8080:80\n    environment:\n      - REGISTRY_TITLE=传智教育私有仓库\n      - REGISTRY_URL=http://registry:5000\n    depends_on:\n      - registry\n```\n### 配置Docker信任地址\n我们的私服采用的是http协议，默认不被Docker信任，所以需要做一个配置：\n```\n# 打开要修改的文件\nvi /etc/docker/daemon.json\n# 添加内容：\n\"insecure-registries\":[\"http://192.168.150.101:8080\"]\n# 重加载\nsystemctl daemon-reload\n# 重启docker\nsystemctl restart docker\n```\n# RabbitMQ\n## 安装部署\n详情请参考官方网站https://www.rabbitmq.com/\n### 单机部署\n方式一：镜像安装\n```\ndocker pull rabbitmq:3-management\n```\n方式二：本地文件\n下载文件后上传到虚拟机，使用以下命令加载镜像\n```\ndocker load -i mq.tar\n```\n### 运行MQ容器\n安装成功后，可使用以下命令来运行容器\n```\ndocker run \\\n -e RABBITMQ_DEFAULT_USER=itcast \\\n -e RABBITMQ_DEFAULT_PASS=123321 \\\n --name mq \\\n --hostname mq1 \\\n -p 15672:15672 \\\n -p 5672:5672 \\\n -d \\\n rabbitmq:3-management\n```\n### 集群安装\n在RabbitMQ的官方文档中，讲述了两种集群的配置方式：\n1. 普通模式：普通模式集群不进行数据同步，每个MQ都有自己的队列、数据信息（其它元数据信息如交换机等会同步）。例如我们有2个MQ：mq1，和mq2，如果你的消息在mq1，而你连接到了mq2，那么mq2会去mq1拉取消息，然后返回给你。如果mq1宕机，消息就会丢失。\n2. 镜像模式：与普通模式不同，队列会在各个mq的镜像节点之间同步，因此你连接到任何一个镜像节点，均可获取到消息。而且如果一个节点宕机，并不会导致数据丢失。不过，这种方式增加了数据同步的带宽消耗。\n详细信息请参考参考官方网站https://www.rabbitmq.com/\n## 基本介绍\nRabbitMQ角色：\n- publisher：生产者\n- consumer：消费者\n- exchange个：交换机，负责消息路由\n- queue：队列，存储消息\n- virtualHost：虚拟主机，隔离不同租户的exchange、queue、消息的隔离\nRabbitMQ基本模型：\n{% asset_img 014.jpg %}\n## 消息队列基本使用\n### 消息发送publisher\n1. 建立connection\n2. 创建channel\n3. 利用channel声明队列\n4. 利用channel向队列发送消息\neg：\n```java\npackage cn.itcast.mq.helloworld;\n\nimport com.rabbitmq.client.Channel;\nimport com.rabbitmq.client.Connection;\nimport com.rabbitmq.client.ConnectionFactory;\nimport org.junit.Test;\n\nimport java.io.IOException;\nimport java.util.concurrent.TimeoutException;\n\npublic class PublisherTest {\n    @Test\n    public void testSendMessage() throws IOException, TimeoutException {\n        // 1.建立连接\n        ConnectionFactory factory = new ConnectionFactory();\n        // 1.1.设置连接参数，分别是：主机名、端口号、vhost、用户名、密码\n        factory.setHost(\"192.168.150.101\");\n        factory.setPort(5672);\n        factory.setVirtualHost(\"/\");\n        factory.setUsername(\"itcast\");\n        factory.setPassword(\"123321\");\n        // 1.2.建立连接\n        Connection connection = factory.newConnection();\n\n        // 2.创建通道Channel\n        Channel channel = connection.createChannel();\n\n        // 3.创建队列\n        String queueName = \"simple.queue\";\n        channel.queueDeclare(queueName, false, false, false, null);\n\n        // 4.发送消息\n        String message = \"hello, rabbitmq!\";\n        channel.basicPublish(\"\", queueName, null, message.getBytes());\n        System.out.println(\"发送消息成功：【\" + message + \"】\");\n\n        // 5.关闭通道和连接\n        channel.close();\n        connection.close();\n\n    }\n}\n```\n### 消息接收consumer\n1. 建立connection\n2. 创建channel\n3. 利用channel声明队列\n4. 定义consumer的消费行为handleDelivery()\n5. 利用channel将消费者与队列绑定\neg：\n```java\n    package cn.itcast.mq.helloworld;\n\n    import com.rabbitmq.client.*;\n\n    import java.io.IOException;\n    import java.util.concurrent.TimeoutException;\n\n    public class ConsumerTest {\n\n        public static void main(String[] args) throws IOException, TimeoutException {\n            // 1.建立连接\n            ConnectionFactory factory = new ConnectionFactory();\n            // 1.1.设置连接参数，分别是：主机名、端口号、vhost、用户名、密码\n            factory.setHost(\"192.168.150.101\");\n            factory.setPort(5672);\n            factory.setVirtualHost(\"/\");\n            factory.setUsername(\"itcast\");\n            factory.setPassword(\"123321\");\n            // 1.2.建立连接\n            Connection connection = factory.newConnection();\n\n            // 2.创建通道Channel\n            Channel channel = connection.createChannel();\n\n            // 3.创建队列\n            String queueName = \"simple.queue\";\n            channel.queueDeclare(queueName, false, false, false, null);\n\n            // 4.订阅消息\n            channel.basicConsume(queueName, true, new DefaultConsumer(channel){\n                @Override\n                public void handleDelivery(String consumerTag, Envelope envelope,\n                                           AMQP.BasicProperties properties, byte[] body) throws IOException {\n                    // 5.处理消息\n                    String message = new String(body);\n                    System.out.println(\"接收到消息：【\" + message + \"】\");\n                }\n            });\n            System.out.println(\"等待接收消息。。。。\");\n        }\n    }\n```\n## SpringAMQP\nSpringAMQP是基于RabbitMQ封装的模板，利用SpringBoot对其实现了自动装配。\nSpringAMQP提供了三个功能：\n- 自动声明队列、交换机及其绑定关系\n- 基于注解的监听器模式，异步接收消息\n- 封装了RabbitTemplate工具，用于发送消息 \n### 基本使用流程\n1. 在父工程中引入spring-amqp的依赖\n```xml\n<!--AMQP依赖，包含RabbitMQ-->\n<dependency>\n    <groupId>org.springframework.boot</groupId>\n    <artifactId>spring-boot-starter-amqp</artifactId>\n</dependency>\n```\n2. 消息发送\n配置MQ信息\n```yaml\nspring:\n  rabbitmq:\n    host: 192.168.150.101 # 主机名\n    port: 5672 # 端口\n    virtual-host: / # 虚拟主机\n    username: itcast # 用户名\n    password: 123321 # 密码\n```\n使用RestTemplate实现消息发送\n```java\npackage cn.itcast.mq.spring;\n\nimport org.junit.Test;\nimport org.junit.runner.RunWith;\nimport org.springframework.amqp.rabbit.core.RabbitTemplate;\nimport org.springframework.beans.factory.annotation.Autowired;\nimport org.springframework.boot.test.context.SpringBootTest;\nimport org.springframework.test.context.junit4.SpringRunner;\n\n@RunWith(SpringRunner.class)\n@SpringBootTest\npublic class SpringAmqpTest {\n\n    @Autowired\n    private RabbitTemplate rabbitTemplate;\n\n    @Test\n    public void testSimpleQueue() {\n        // 队列名称\n        String queueName = \"simple.queue\";\n        // 消息\n        String message = \"hello, spring amqp!\";\n        // 发送消息\n        rabbitTemplate.convertAndSend(queueName, message);\n    }\n}\n```\n3. 使用RabbitTemplate消息接收\n配置MQ：\n```yaml\nspring:\n  rabbitmq:\n    host: 192.168.150.101 # 主机名\n    port: 5672 # 端口\n    virtual-host: / # 虚拟主机\n    username: itcast # 用户名\n    password: 123321 # 密码\n```\n消息接收：\n```java\npackage cn.itcast.mq.listener;\n\nimport org.springframework.amqp.rabbit.annotation.RabbitListener;\nimport org.springframework.stereotype.Component;\n\n@Component\npublic class SpringRabbitListener {\n\n    @RabbitListener(queues = \"simple.queue\")\n    public void listenSimpleQueueMessage(String msg) throws InterruptedException {\n        System.out.println(\"spring 消费者接收到消息：【\" + msg + \"】\");\n    }\n}\n```\n### WorkQueue\n也被称为（Task queues），**让多个消费者绑定到一个消息队列，共同消费队列中的消息**，能够大大提高消息处理的速度。\n#### 消息发送\n```java\n@Test\npublic void testWorkQueue() throws InterruptedException {\n    // 队列名称\n    String queueName = \"simple.queue\";\n    // 消息\n    String message = \"hello, message_\";\n    for (int i = 0; i < 50; i++) {\n        // 发送消息\n        rabbitTemplate.convertAndSend(queueName, message + i);\n        Thread.sleep(20);\n    }\n}\n```\n#### 多消费者接收消息\n```java\n@RabbitListener(queues = \"simple.queue\")\npublic void listenWorkQueue1(String msg) throws InterruptedException {\n    System.out.println(\"消费者1接收到消息：【\" + msg + \"】\" + LocalTime.now());\n    Thread.sleep(20);\n}\n\n@RabbitListener(queues = \"simple.queue\")\npublic void listenWorkQueue2(String msg) throws InterruptedException {\n    System.err.println(\"消费者2........接收到消息：【\" + msg + \"】\" + LocalTime.now());\n    Thread.sleep(200);\n}\n```\n#### 多个消费者间消息分配策略\n多个消费者之间的分配的消息默认是平均分配，与消费者处理消息的能力无关。eg：上文中的两个消费者，消费者1每20ms处理一个消息，而消费者2则每200ms处理一个消息，但是消息队列中的消息会平均分配给两个消费者，原因是RabbieMQ会预先将消息队列中的消息分配给每一个消费者，可以通过设置prefetch来控制消费者预取的消息数量。\n```yaml\nspring:\n  rabbitmq:\n    listener:\n      simple:\n        prefetch: 1 # 每次只能获取一条消息，处理完成才能获取下一个消息\n```\n### 发布订阅模式\n发布订阅模型：\n{% asset_img 015.jpg %}\n- Publisher：生产者发送的消息不再发送到队列中，而是发给交换机\n- Exchange：交换机。一方面，接收生产者发送的消息。另一方面，知道如何处理消息，例如递交给某个特别队列、递交给所有队列、或是将消息丢弃。到底如何操作，取决于Exchange的类型。Exchange有以下3种类型：\n  - Fanout：广播，将消息交给所有绑定到交换机的队列\n  - Direct：定向，把消息交给符合指定routing key 的队列\n  - Topic：通配符，把消息交给符合routing pattern（路由模式） 的队列\n- Consumer：消费者，与以前一样，订阅队列，没有变化\n- Queue：消息队列也与以前一样，接收消息、缓存消息\n\nps：\n**Exchange（交换机）只负责转发消息，不具备存储消息的能力**，因此如果没有任何队列与Exchange绑定，或者没有符合路由规则的队列，那么消息会丢失！\n#### Fanout\n生产者将消息发送给交换机，交换机会将消息发送给与之绑定的所有队列，最后订阅队列的消费者拿到消息。要点如下：\n1. 队列绑定交换机\n2. 消费者订阅队列\nps：该模式下，生产者的消息只能发送给交换机。\n##### 声明队列和交换机\n```java\npackage cn.itcast.mq.config;\n\nimport org.springframework.amqp.core.Binding;\nimport org.springframework.amqp.core.BindingBuilder;\nimport org.springframework.amqp.core.FanoutExchange;\nimport org.springframework.amqp.core.Queue;\nimport org.springframework.context.annotation.Bean;\nimport org.springframework.context.annotation.Configuration;\n\n@Configuration\npublic class FanoutConfig {\n    /**\n     * 声明交换机\n     * @return Fanout类型交换机\n     */\n    @Bean\n    public FanoutExchange fanoutExchange(){\n        return new FanoutExchange(\"itcast.fanout\");\n    }\n\n    /**\n     * 第1个队列\n     */\n    @Bean\n    public Queue fanoutQueue1(){\n        return new Queue(\"fanout.queue1\");\n    }\n\n    /**\n     * 绑定队列和交换机\n     */\n    @Bean\n    public Binding bindingQueue1(Queue fanoutQueue1, FanoutExchange fanoutExchange){\n        return BindingBuilder.bind(fanoutQueue1).to(fanoutExchange);\n    }\n\n    /**\n     * 第2个队列\n     */\n    @Bean\n    public Queue fanoutQueue2(){\n        return new Queue(\"fanout.queue2\");\n    }\n\n    /**\n     * 绑定队列和交换机\n     */\n    @Bean\n    public Binding bindingQueue2(Queue fanoutQueue2, FanoutExchange fanoutExchange){\n        return BindingBuilder.bind(fanoutQueue2).to(fanoutExchange);\n    }\n}\n```\n##### 消息发送\n```java\n@Test\npublic void testFanoutExchange() {\n    // 队列名称\n    String exchangeName = \"itcast.fanout\";\n    // 消息\n    String message = \"hello, everyone!\";\n    rabbitTemplate.convertAndSend(exchangeName, \"\", message);\n}\n```\n##### 消息接收\n```java\n@RabbitListener(queues = \"fanout.queue1\")\npublic void listenFanoutQueue1(String msg) {\n    System.out.println(\"消费者1接收到Fanout消息：【\" + msg + \"】\");\n}\n\n@RabbitListener(queues = \"fanout.queue2\")\npublic void listenFanoutQueue2(String msg) {\n    System.out.println(\"消费者2接收到Fanout消息：【\" + msg + \"】\");\n}\n```\n#### Direct\n在Fanout模式中，一条消息，会被所有订阅的队列都消费。但是，在某些场景下，我们希望不同的消息被不同的队列消费。这时就要用到Direct类型的Exchange。\n每个队列会绑定不同的关键词——bingkey，交换机发送消息时，会根据消息的key将消息发送到绑定该key的队列。\n{% asset_img 016.jpg %}\n##### 声明队列和交换机（基于注解）\n```java\n@RabbitListener(bindings = @QueueBinding(\n    value = @Queue(name = \"direct.queue1\"),\n    exchange = @Exchange(name = \"itcast.direct\", type = ExchangeTypes.DIRECT),\n    key = {\"red\", \"blue\"}\n))\npublic void listenDirectQueue1(String msg){\n    System.out.println(\"消费者接收到direct.queue1的消息：【\" + msg + \"】\");\n}\n\n@RabbitListener(bindings = @QueueBinding(\n    value = @Queue(name = \"direct.queue2\"),\n    exchange = @Exchange(name = \"itcast.direct\", type = ExchangeTypes.DIRECT),\n    key = {\"red\", \"yellow\"}\n))\npublic void listenDirectQueue2(String msg){\n    System.out.println(\"消费者接收到direct.queue2的消息：【\" + msg + \"】\");\n}\n```\n##### 发送消息\n```java\n@Test\npublic void testSendDirectExchange() {\n    // 交换机名称\n    String exchangeName = \"itcast.direct\";\n    // 消息\n    String message = \"红色警报！日本乱排核废水，导致海洋生物变异，惊现哥斯拉！\";\n    // 发送消息\n    rabbitTemplate.convertAndSend(exchangeName, \"red\", message);\n}\n```\n#### Topic\n`Topic`类型的`Exchange`与`Direct`相比，都是可以根据`RoutingKey`把消息路由到不同的队列。但是`Topic`类型`Exchange`可以让队列在绑定`Routing key` 的时候使用通配符！\nRoutingKey通配符规则：多个词之间以`.`分割。\n- `#`匹配一个或多个词\n- `*`匹配一个词\n{% asset_img 017.jpg %}\n- Queue1：绑定的是`china.#` ，因此凡是以 `china.`开头的`routing key` 都会被匹配到。包括china.news和china.weather\n- Queue2：绑定的是`#.news` ，因此凡是以 `.news`结尾的 `routing key` 都会被匹配。包括china.news和japan.news\n##### 消息发送\n```java\n/**\n     * topicExchange\n     */\n@Test\npublic void testSendTopicExchange() {\n    // 交换机名称\n    String exchangeName = \"itcast.topic\";\n    // 消息\n    String message = \"喜报！孙悟空大战哥斯拉，胜!\";\n    // 发送消息\n    rabbitTemplate.convertAndSend(exchangeName, \"china.news\", message);\n}\n```\n##### 消息接收\n```java\n@RabbitListener(bindings = @QueueBinding(\n    value = @Queue(name = \"topic.queue1\"),\n    exchange = @Exchange(name = \"itcast.topic\", type = ExchangeTypes.TOPIC),\n    key = \"china.#\"\n))\npublic void listenTopicQueue1(String msg){\n    System.out.println(\"消费者接收到topic.queue1的消息：【\" + msg + \"】\");\n}\n\n@RabbitListener(bindings = @QueueBinding(\n    value = @Queue(name = \"topic.queue2\"),\n    exchange = @Exchange(name = \"itcast.topic\", type = ExchangeTypes.TOPIC),\n    key = \"#.news\"\n))\npublic void listenTopicQueue2(String msg){\n    System.out.println(\"消费者接收到topic.queue2的消息：【\" + msg + \"】\");\n}\n```\n## 消息转换器\nSpring会把你发送的消息序列化为字节发送给MQ，接收消息的时候，还会把字节反序列化为Java对象。\n{% asset_img 018.jpg %}\n默认情况下Spring采用的序列化方式是JDK序列化，但是JDK序列化存在下列问题：\n- 数据体积过大\n- 有安全漏洞\n- 可读性差\n\n### 配置Json转换器\n1. 微服务引入依赖\n```xml\n<dependency>\n    <groupId>com.fasterxml.jackson.dataformat</groupId>\n    <artifactId>jackson-dataformat-xml</artifactId>\n    <version>2.9.10</version>\n</dependency>\n```\n2. 添加组件Bean\n```java\n//会替换Spring默认的转换器\n@Bean\npublic MessageConverter jsonMessageConverter(){\n    return new Jackson2JsonMessageConverter();\n}\n```\n\n## 消息可靠性\n消息从发送，到消费者接收，会经理多个过程，其中的每一步都可能导致消息丢失，常见的丢失原因包括：\n- 发送时丢失：\n  - 生产者发送的消息未送达exchange\n  - 消息到达exchange后未到达queue\n- MQ宕机，queue将消息丢失\n- consumer接收到消息后未消费就宕机\n\n针对这些问题，RabbitMQ分别给出了解决方案：\n- 生产者确认机制\n- mq持久化\n- 消费者确认机制\n- 失败重试机制\n\n### 生产者消息确认\nRabbitMQ提供了publisher confirm机制来避免消息发送到MQ过程中丢失。这种机制必须给每个消息指定一个唯一ID。消息发送到MQ以后，会返回一个结果给发送者，表示消息是否处理成功。返回结果有两种方式：\n- publisher-confirm，发送者确认\n  - 消息成功投递到交换机，返回ack\n  - 消息未投递到交换机，返回nack\n- publisher-return，发送者回执\n  - 消息投递到交换机了，但是没有路由到队列。返回ACK，及路由失败原因。\n\nPS：确认机制发送消息时，需要给每个消息设置一个全局唯一id，以区分不同消息，避免ack冲突\n\n1. 修改配置\n\n修改publisher服务中的application.yml文件，添加下面的内容：\n```yaml\nspring:\n  rabbitmq:\n    publisher-confirm-type: correlated\n    publisher-returns: true\n    template:\n      mandatory: true\n```\n- `publish-confirm-type`：开启publisher-confirm，这里支持两种类型：\n  - `simple`：同步等待confirm结果，直到超时\n  - `correlated`：异步回调，定义ConfirmCallback，MQ返回结果时会回调这个ConfirmCallback\n- `publish-returns`：开启publish-return功能，同样是基于callback机制，不过是定义ReturnCallback\n- `template.mandatory`：定义消息路由失败时的策略。true，则调用ReturnCallback；false：则直接丢弃消息\n\n2. 定义Return回调\n\n每个RabbitTemplate只能配置一个ReturnCallback，因此需要在项目加载时配置。修改publisher服务，添加：\n```java\npackage cn.itcast.mq.config;\n\nimport lombok.extern.slf4j.Slf4j;\nimport org.springframework.amqp.rabbit.core.RabbitTemplate;\nimport org.springframework.beans.BeansException;\nimport org.springframework.context.ApplicationContext;\nimport org.springframework.context.ApplicationContextAware;\nimport org.springframework.context.annotation.Configuration;\n\n@Slf4j\n@Configuration\npublic class CommonConfig implements ApplicationContextAware {\n    @Override\n    public void setApplicationContext(ApplicationContext applicationContext) throws BeansException {\n        // 获取RabbitTemplate\n        RabbitTemplate rabbitTemplate = applicationContext.getBean(RabbitTemplate.class);\n        // 设置ReturnCallback\n        rabbitTemplate.setReturnCallback((message, replyCode, replyText, exchange, routingKey) -> {\n            // 投递失败，记录日志\n            log.info(\"消息发送失败，应答码{}，原因{}，交换机{}，路由键{},消息{}\",\n                     replyCode, replyText, exchange, routingKey, message.toString());\n            // 如果有业务需要，可以重发消息\n        });\n    }\n}\n```\nPS：Spring容器加载成功之后会通知实现`ApplicationContextAware`接口的类，接着调用 `setApplicationContext`方法。\n\n### 定义ConfirmCallback\nConfirmCallback可以在发送消息时指定，因为每个业务处理confirm成功或失败的逻辑不一定相同。在publisher服务的cn.itcast.mq.spring.SpringAmqpTest类中，定义一个单元测试方法：\n```java\npublic void testSendMessage2SimpleQueue() throws InterruptedException {\n    // 1.消息体\n    String message = \"hello, spring amqp!\";\n    // 2.全局唯一的消息ID，需要封装到CorrelationData中\n    CorrelationData correlationData = new CorrelationData(UUID.randomUUID().toString());\n    // 3.添加callback\n    correlationData.getFuture().addCallback(\n        result -> {\n            if(result.isAck()){\n                // 3.1.ack，消息成功\n                log.debug(\"消息发送成功, ID:{}\", correlationData.getId());\n            }else{\n                // 3.2.nack，消息失败\n                log.error(\"消息发送失败, ID:{}, 原因{}\",correlationData.getId(), result.getReason());\n            }\n        },\n        ex -> log.error(\"消息发送异常, ID:{}, 原因{}\",correlationData.getId(),ex.getMessage())\n    );\n    // 4.发送消息\n    rabbitTemplate.convertAndSend(\"task.direct\", \"task\", message, correlationData);\n\n    // 休眠一会儿，等待ack回执\n    Thread.sleep(2000);\n}\n```\n\n### 消息持久化\n生产者确认可以确保消息投递到RabbitMQ的队列中，但是消息发送到RabbitMQ以后，如果突然宕机，也可能导致消息丢失。要想确保消息在RabbitMQ中安全保存，必须开启消息持久化机制。\n- 交换机持久化\n- 队列持久化\n- 消息持久化\n\n#### 交换价持久化\nRabbitMQ中交换机默认是非持久化的，mq重启后就丢失。SpringAMQP中可以通过代码指定交换机持久化：\n```java\n@Bean\npublic DirectExchange simpleExchange(){\n    // 三个参数：交换机名称、是否持久化、当没有queue与其绑定时是否自动删除\n    return new DirectExchange(\"simple.direct\", true, false);\n}\n```\n事实上，默认情况下，由SpringAMQP声明的交换机都是持久化的。\n\nPS：持久化的交换机在RabbitMQ控制台上会显示`D`标示\n\n#### 队列持久化\nRabbitMQ中队列默认是非持久化的，mq重启后就丢失。SpringAMQP中可以通过代码指定交换机持久化：\n```java\n@Bean\npublic Queue simpleQueue(){\n    // 使用QueueBuilder构建队列，durable就是持久化的\n    return QueueBuilder.durable(\"simple.queue\").build();\n}\n```\n默认情况下，由SpringAMQP声明的队列都是持久化的。\n\nPS：持久化的队列在RabbitMQ控制台会显示`D`标示\n\n#### 消息持久化\n利用SpringAMQP发送消息时，可以设置消息的属性（MessageProperties），指定delivery-mode：\n- 非持久化\n- 持久化\n\n```java\nMessage message = MessageBuilder.withBody(\"hello,ttl queue\"\n\t.getBytes(StandardCharsets.UTF_8))\n\t.setDeliveryMode (MessageDeliveryMode.PERSISTENT)\n\t.build();\n```\n默认情况下，SpringAMQP发出的任何消息都是持久化的，不用特意指定。\n\n### 消费者消息确认\nRabbitMQ是**阅后即焚**机制，RabbitMQ确认消息被消费者消费后会立刻删除。\n\nabbitMQ是通过消费者回执来确认消费者是否成功处理消息的：消费者获取消息后，应该向RabbitMQ发送ACK回执，表明自己已经处理消息。\n\neg：设想这样的场景：\n- 1）RabbitMQ投递消息给消费者\n- 2）消费者获取消息后，返回ACK给RabbitMQ\n- 3）RabbitMQ删除消息\n- 4）消费者宕机，消息尚未处理\n\n这样，消息就丢失了。因此消费者返回ACK的时机非常重要。\n\nSpringAMQP则允许配置三种确认模式：\n- manual：手动ack，需要在业务代码结束后，调用api发送ack。\n- auto：自动ack，由spring监测listener代码是否出现异常，没有异常则返回ack；抛出异常则返回nack\n- none：关闭ack，MQ假定消费者获取消息后会成功处理，因此消息投递后立即被删除\n\n#### none模式\n```yaml\nspring:\n  rabbitmq:\n    listener:\n      simple:\n        acknowledge-mode: none # 关闭ack\n```\nPS：即使消息处理中出现异常，消息任然会被删除\n\n#### auto模式\n```yaml\nspring:\n  rabbitmq:\n    listener:\n      simple:\n        acknowledge-mode: auto # 关闭ack\n```\nPS：消息处理中出现异常后，消息会被恢复为Ready状态，不会删除\n\n### 消息失败重试\n当消费者出现异常后，消息会不断requeue（重入队）到队列，再重新发送给消费者，然后再次异常，再次requeue，无限循环，导致mq的消息处理飙升，带来不必要的压力。\n解决方案：\n1. 本地重试\n\n利用Spring的retry机制，在消费者出现异常时利用本地重试，而不是无限制的requeue到mq队列。修改consumer服务的application.yml文件，添加内容：\n```yaml\nspring:\n  rabbitmq:\n    listener:\n      simple:\n        retry:\n          enabled: true # 开启消费者失败重试\n          initial-interval: 1000 # 初识的失败等待时长为1秒\n          multiplier: 1 # 失败的等待时长倍数，下次等待时长 = multiplier * last-interval\n          max-attempts: 3 # 最大重试次数\n          stateless: true # true无状态；false有状态。如果业务中包含事务，这里改为false\n```\n重启consumer服务，进行测试：\n- 在重试3次后，SpringAMQP会抛出异常AmqpRejectAndDontRequeueException，说明本地重试触发了\n- 查看RabbitMQ控制台，发现消息被删除了，说明最后SpringAMQP返回的是ack，mq删除消息了\n\n说明：\n- 开启本地重试时，消息处理过程中抛出异常，不会requeue到队列，而是在消费者本地重试\n- 重试达到最大次数后，Spring会返回ack，消息会被丢弃\n\n2. 失败策略\n\n在本地重试中，达到最大重试次数后，消息会被丢弃，这是由Spring内部机制决定的。在开启重试模式后，重试次数耗尽，如果消息依然失败，则需要有MessageRecovery接口来处理，它包含三种不同的实现：\n- RejectAndDontRequeueRecoverer：重试耗尽后，直接reject，丢弃消息。默认就是这种方式\n- ImmediateRequeueMessageRecoverer：重试耗尽后，返回nack，消息重新入队\n- RepublishMessageRecoverer：重试耗尽后，将失败消息投递到指定的交换机\n\n**RepublishMessageRecoverer**：失败后将消息投递到一个指定的，专门存放异常消息的队列，后续由人工集中处理\n1. 在consumer服务中定义处理失败消息的交换机和队列\n\n```java\n@Bean\npublic DirectExchange errorMessageExchange(){\n    return new DirectExchange(\"error.direct\");\n}\n@Bean\npublic Queue errorQueue(){\n    return new Queue(\"error.queue\", true);\n}\n@Bean\npublic Binding errorBinding(Queue errorQueue, DirectExchange errorMessageExchange){\n    return BindingBuilder.bind(errorQueue).to(errorMessageExchange).with(\"error\");\n}\n```\n\n2. 定义一个RepublishMessageRecoverer，关联队列和交换机\n\n```java\n@Bean\npublic MessageRecoverer republishMessageRecoverer(RabbitTemplate rabbitTemplate){\n    return new RepublishMessageRecoverer(rabbitTemplate, \"error.direct\", \"error\");\n}\n```\n\n## 死信交换机\n当一个队列中的消息满足下列情况之一时，可以成为死信（dead letter）：\n- 消费者使用basic.reject或 basic.nack声明消费失败，并且消息的requeue参数设置为false\n- 消息是一个过期消息，超时无人消费\n- 要投递的队列消息满了，无法投递\n\n如果这个包含死信的队列配置了`dead-letter-exchange`属性，指定了一个交换机，那么队列中的死信就会投递到这个交换机中，而这个交换机称为**死信交换机**（Dead Letter Exchange，检查DLX）。如果死信交换机也绑定了队列，则消息最终会进入这个存放死信的队列。\n\n队列将死信投递给死信交换机时，必须知道两个信息：\n- 死信交换机名称\n- 死信交换机与死信队列绑定的RoutingKey\n\n在失败重试策略中，默认的RejectAndDontRequeueRecoverer会在本地重试次数耗尽后，发送reject给RabbitMQ，消息变成死信，被丢弃。\n我们可以给simple.queue添加一个死信交换机，给死信交换机绑定一个队列。这样消息变成死信后也不会丢弃，而是最终投递到死信交换机，路由到与死信交换机绑定的队列。\n\nconsumer服务中，定义一组死信交换机、死信队列：\n```java\n// 声明普通的 simple.queue队列，并且为其指定死信交换机：dl.direct\n@Bean\npublic Queue simpleQueue2(){\n    return QueueBuilder.durable(\"simple.queue\") // 指定队列名称，并持久化\n        .deadLetterExchange(\"dl.direct\") // 指定死信交换机\n        .build();\n}\n// 声明死信交换机 dl.direct\n@Bean\npublic DirectExchange dlExchange(){\n    return new DirectExchange(\"dl.direct\", true, false);\n}\n// 声明存储死信的队列 dl.queue\n@Bean\npublic Queue dlQueue(){\n    return new Queue(\"dl.queue\", true);\n}\n// 将死信队列 与 死信交换机绑定\n@Bean\npublic Binding dlBinding(){\n    return BindingBuilder.bind(dlQueue()).to(dlExchange()).with(\"simple\");\n}\n```\n\n#### TTL\n一个队列中的消息如果超时未消费，则会变为死信，超时分为两种情况：\n- 消息所在的队列设置了超时时间\n- 消息本身设置了超时时间\n\n1. 接收超时死信的死信交换机\n\n```java\n@RabbitListener(bindings = @QueueBinding(\n    value = @Queue(name = \"dl.ttl.queue\", durable = \"true\"),\n    exchange = @Exchange(name = \"dl.ttl.direct\"),\n    key = \"ttl\"\n))\npublic void listenDlQueue(String msg){\n    log.info(\"接收到 dl.ttl.queue的延迟消息：{}\", msg);\n}\n```\n\n2. 声明一个队列，并且指定TTL \n\n队列设置超时时间，需要在声明队列时配置x-message-ttl属性：\n```java\n@Bean\npublic Queue ttlQueue(){\n    return QueueBuilder.durable(\"ttl.queue\") // 指定队列名称，并持久化\n        .ttl(10000) // 设置队列的超时时间，10秒\n        .deadLetterExchange(\"dl.ttl.direct\") // 指定死信交换机\n        .build();\n}\n```\n队列设定了死信交换机为`dl.ttl.direct`\n\n声明交换机，将ttl与交换机绑定：\n```\n@Bean\npublic DirectExchange ttlExchange(){\n    return new DirectExchange(\"ttl.direct\");\n}\n@Bean\npublic Binding ttlBinding(){\n    return BindingBuilder.bind(ttlQueue()).to(ttlExchange()).with(\"ttl\");\n}\n```\n\n3. 发送消息时，设定TTL：\n```java\n@Test\npublic void testTTLMsg() {\n    // 创建消息\n    Message message = MessageBuilder\n        .withBody(\"hello, ttl message\".getBytes(StandardCharsets.UTF_8))\n        .setExpiration(\"5000\")\n        .build();\n    // 消息ID，需要封装到CorrelationData中\n    CorrelationData correlationData = new CorrelationData(UUID.randomUUID().toString());\n    // 发送消息\n    rabbitTemplate.convertAndSend(\"ttl.direct\", \"ttl\", message, correlationData);\n    log.debug(\"发送消息成功\");\n}\n```\nPS：当队列、消息都设置了TTL时，任意一个到期就会成为死信\n\n## 延迟队列\n利用TTL结合死信交换机，我们实现了消息发出后，消费者延迟收到消息的效果。这种消息模式就称为延迟队列（Delay Queue）模式。\n\nRabbitMQ官方推出了`DelayExchange`插件，原生支持延迟队列效果，参考RabbitMQ的插件列表页面：https://www.rabbitmq.com/community-plugins.html\n\n### 安装DelayExchange\n略\n\n### DelayExchange原理\nDelayExchange需要将一个交换机声明为delayed类型。当我们发送消息到delayExchange时，流程如下：\n- 接收消息\n- 判断消息是否具备x-delay属性\n- 如果有x-delay属性，说明是延迟消息，持久化到硬盘，读取x-delay值，作为延迟时间\n- 返回routing not found结果给消息发送者\n- x-delay时间到期后，重新投递消息到指定队列\n\n### DelayExchange使用\n1. 声明DelayExchange交换机\n\n- 注解方式\n{% asset_img 076.png %}\n\n- 代码注册@Bean\n{% asset_img 077.png %}\n\n2. 发送消息，设置x-delay\n\n发送消息时，一定要携带x-delay属性，指定延迟的时间：\n{% asset_img 078.png %}\n\n## 惰性队列\nLazy Queues（惰性队列）：\n- 接收到消息后直接存入磁盘而非内存\n- 消费者要消费消息时才会从磁盘中读取并加载到内存\n- 支持数百万条的消息存储\n\n1. 基于命令行设置lazy-queue\n\n置一个队列为惰性队列，只需要在声明队列时，指定x-queue-mode属性为lazy即可。可以通过命令行将一个运行中的队列修改为惰性队列：\n```sh\nrabbitmqctl set_policy Lazy \"^lazy-queue$\" '{\"queue-mode\":\"lazy\"}' --apply-to queues  \n```\n- `rabbitmqctl` ：RabbitMQ的命令行工具\n- `set_policy` ：添加一个策略\n- `Lazy` ：策略名称，可以自定义\n- `\"^lazy-queue$\"` ：用正则表达式匹配队列的名字\n- `'{\"queue-mode\":\"lazy\"}'` ：设置队列模式为lazy模式\n- `--apply-to queues  `：策略的作用对象，是所有的队列\n\n2. 基于@Bean声明lazy-queue\n\n{% asset_img 079.png %}\n\n3. 基于@RabbitListener声明LazyQueue\n\n{% asset_img 080.png %}\n\n**小结**：\n消息堆积问题的解决方案？\n\n- 队列上绑定多个消费者，提高消费速度\n- 使用惰性队列，可以再mq中保存更多消息\n\n惰性队列的优点有哪些？\n- 基于磁盘存储，消息上限高\n- 没有间歇性的page-out，性能比较稳定\n\n惰性队列的缺点有哪些？\n- 基于磁盘存储，消息时效性会降低\n- 性能受限于磁盘的IO\n\n## MQ集群\n在RabbitMQ的官方文档中，讲述了两种集群的配置方式：\n- 普通模式：普通模式集群不进行数据同步，每个MQ都有自己的队列、数据信息（其它元数据信息如交换机等会同步）。例如我们有2个MQ：mq1，和mq2，如果你的消息在mq1，而你连接到了mq2，那么mq2会去mq1拉取消息，然后返回给你。如果mq1宕机，消息就会丢失。\n- 镜像模式：与普通模式不同，队列会在各个mq的镜像节点之间同步，因此你连接到任何一个镜像节点，均可获取到消息。而且如果一个节点宕机，并不会导致数据丢失。不过，这种方式增加了数据同步的带宽消耗。\n- 仲裁队列：仲裁队列是3.8版本以后才有的新功能，用来替代镜像队列，具备下列特征：、\n    - 与镜像队列一样，都是主从模式，支持主从数据同步\n    - 使用非常简单，没有复杂的配置\n    - 主从同步基于Raft协议，强一致\n\n### 普通模式部署\n三节点MQ集群\n| 主机名 | 控制台端口      | amqp通信端口    |\n| ------ | --------------- | --------------- |\n| mq1    | 8081 ---> 15672 | 8071 ---> 5672  |\n| mq2    | 8082 ---> 15672 | 8072 ---> 5672  |\n| mq3    | 8083 ---> 15672 | 8073  ---> 5672 |\n\n集群中的节点标示默认都是：`rabbit@[hostname]`，因此以上三个节点的名称分别为：\n\n- rabbit@mq1\n- rabbit@mq2\n- rabbit@mq3\n\n1. 获取cookie\n\n集群模式中的每个RabbitMQ 节点使用 cookie 来确定它们是否被允许相互通信。要使两个节点能够通信，它们必须具有相同的共享秘密，称为**Erlang cookie**。cookie 只是一串最多 255 个字符的字母数字字符。\n\n每个集群节点必须具有**相同的 cookie**。实例之间也需要它来相互通信。从mq容器中获取一个cookie值，作为集群的cookie。执行下面的命令便可以获取到Cookie：\n```sh\ndocker exec -it mq cat /var/lib/rabbitmq/.erlang.cookie\n```\n\n2. 配置文件\n\n新建rabbitmq.conf，内容：\n```nginx\nloopback_users.guest = false\nlisteners.tcp.default = 5672\ncluster_formation.peer_discovery_backend = rabbit_peer_discovery_classic_config\ncluster_formation.classic_config.nodes.1 = rabbit@mq1\ncluster_formation.classic_config.nodes.2 = rabbit@mq2\ncluster_formation.classic_config.nodes.3 = rabbit@mq3\n```\n\n另新建文件，记录cookie\n```sh\ncd /tmp\n# 创建cookie文件\ntouch .erlang.cookie\n# 写入cookie\necho \"FXZMCVGLBIXZCDEMMVZQ\" > .erlang.cookie\n# 修改cookie文件的权限\nchmod 600 .erlang.cookie\n```\n\n3. 准备MQ节点目录\n\n准备三个目录，mq1、mq2、mq3\n```sh\ncd /tmp\n# 创建目录\nmkdir mq1 mq2 mq3\n```\n\n拷贝rabbitmq.conf、cookie文件到mq1、mq2、mq3：\n```sh\n# 进入/tmp\ncd /tmp\n# 拷贝\ncp rabbitmq.conf mq1\ncp rabbitmq.conf mq2\ncp rabbitmq.conf mq3\ncp .erlang.cookie mq1\ncp .erlang.cookie mq2\ncp .erlang.cookie mq3\n```\n\n4. 启动集群\n\n**创建网络**\n```sh\ndocker network create mq-net\n```\n\n运行三个节点MQ容器：\n```sh\ndocker run -d --net mq-net \\\n-v ${PWD}/mq1/rabbitmq.conf:/etc/rabbitmq/rabbitmq.conf \\\n-v ${PWD}/.erlang.cookie:/var/lib/rabbitmq/.erlang.cookie \\\n-e RABBITMQ_DEFAULT_USER=itcast \\\n-e RABBITMQ_DEFAULT_PASS=123321 \\\n--name mq1 \\\n--hostname mq1 \\\n-p 8071:5672 \\\n-p 8081:15672 \\\nrabbitmq:3.8-management\n```\n```sh\ndocker run -d --net mq-net \\\n-v ${PWD}/mq2/rabbitmq.conf:/etc/rabbitmq/rabbitmq.conf \\\n-v ${PWD}/.erlang.cookie:/var/lib/rabbitmq/.erlang.cookie \\\n-e RABBITMQ_DEFAULT_USER=itcast \\\n-e RABBITMQ_DEFAULT_PASS=123321 \\\n--name mq2 \\\n--hostname mq2 \\\n-p 8072:5672 \\\n-p 8082:15672 \\\nrabbitmq:3.8-management\n```\n```sh\ndocker run -d --net mq-net \\\n-v ${PWD}/mq3/rabbitmq.conf:/etc/rabbitmq/rabbitmq.conf \\\n-v ${PWD}/.erlang.cookie:/var/lib/rabbitmq/.erlang.cookie \\\n-e RABBITMQ_DEFAULT_USER=itcast \\\n-e RABBITMQ_DEFAULT_PASS=123321 \\\n--name mq3 \\\n--hostname mq3 \\\n-p 8073:5672 \\\n-p 8083:15672 \\\nrabbitmq:3.8-management\n```\n\n### 镜像模式部署\n镜像模式下，创建队列的节点被称为该队列的**主节点**，队列还会拷贝到集群中的其它节点，为该队列的**镜像**节点。\n\n不同队列可以在集群中的任意节点上创建，因此不同队列的主节点可以不同。甚至，**一个队列的主节点可能是另一个队列的镜像节点**。\n\n用户发送给队列的一切请求，例如发送消息、消息回执默认都会在主节点完成，如果是从节点接收到请求，也会路由到主节点去完成。**镜像节点仅仅起到备份数据作用**。\n\n当主节点接收到消费者的ACK时，所有镜像都会删除节点中的数据。\n\n小结：\n- 镜像队列结构是一主多从（从就是镜像）\n- 所有操作都是主节点完成，然后同步给镜像节点\n- 主宕机后，镜像节点会替代成新的主（如果在主从同步完成前，主就已经宕机，可能出现数据丢失）\n- 不具备负载均衡功能，因为所有操作都会有主节点完成（但是不同队列，其主节点可以不同，可以利用这个提高吞吐量）\n\n镜像模式的配置有3种模式：\n| ha-mode         | ha-params         | 效果                                                         |\n| :-------------- | :---------------- | :----------------------------------------------------------- |\n| 准确模式exactly | 队列的副本量count | 集群中队列副本（主服务器和镜像服务器之和）的数量。count如果为1意味着单个副本：即队列主节点。count值为2表示2个副本：1个队列主和1个队列镜像。换句话说：count = 镜像数量 + 1。如果群集中的节点数少于count，则该队列将镜像到所有节点。如果有集群总数大于count+1，并且包含镜像的节点出现故障，则将在另一个节点上创建一个新的镜像。 |\n| all             | (none)            | 队列在群集中的所有节点之间进行镜像。队列将镜像到任何新加入的节点。镜像到所有节点将对所有群集节点施加额外的压力，包括网络I / O，磁盘I / O和磁盘空间使用情况。推荐使用exactly，设置副本数为（N / 2 +1）。 |\n| nodes           | *node names*      | 指定队列创建到哪些节点，如果指定的节点全部不存在，则会出现异常。如果指定的节点在集群中存在，但是暂时不可用，会创建节点到当前客户端连接到的节点。 |\n\n以rabbitmqctl命令作为案例来讲解配置语法：\n1. exactly模式\n\n```sh\nrabbitmqctl set_policy ha-two \"^two\\.\" '{\"ha-mode\":\"exactly\",\"ha-params\":2,\"ha-sync-mode\":\"automatic\"}'\n```\n- `rabbitmqctl set_policy`：固定写法\n- `ha-two`：策略名称，自定义\n- `\"^two\\.\"`：匹配队列的正则表达式，符合命名规则的队列才生效，这里是任何以`two.`开头的队列名称\n- `'{\"ha-mode\":\"exactly\",\"ha-params\":2,\"ha-sync-mode\":\"automatic\"}'`: 策略内容\n  - `\"ha-mode\":\"exactly\"`：策略模式，此处是exactly模式，指定副本数量\n  - `\"ha-params\":2`：策略参数，这里是2，就是副本数量为2，1主1镜像\n  - `\"ha-sync-mode\":\"automatic\"`：同步策略，默认是manual，即新加入的镜像节点不会同步旧的消息。如果设置为automatic，则新加入的镜像节点会把主节点中所有消息都同步，会带来额外的网络开销\n\n2. all模式\n\n```sh\nrabbitmqctl set_policy ha-all \"^all\\.\" '{\"ha-mode\":\"all\"}'\n```\n- `ha-all`：策略名称，自定义\n- `\"^all\\.\"`：匹配所有以`all.`开头的队列名\n- `'{\"ha-mode\":\"all\"}'`：策略内容\n  - `\"ha-mode\":\"all\"`：策略模式，此处是all模式，即所有节点都会称为镜像节点\n\n3. nodes模式\n\n```sh\nrabbitmqctl set_policy ha-nodes \"^nodes\\.\" '{\"ha-mode\":\"nodes\",\"ha-params\":[\"rabbit@nodeA\", \"rabbit@nodeB\"]}'\n```\n- `rabbitmqctl set_policy`：固定写法\n- `ha-nodes`：策略名称，自定义\n- `\"^nodes\\.\"`：匹配队列的正则表达式，符合命名规则的队列才生效，这里是任何以`nodes.`开头的队列名称\n- `'{\"ha-mode\":\"nodes\",\"ha-params\":[\"rabbit@nodeA\", \"rabbit@nodeB\"]}'`: 策略内容\n  - `\"ha-mode\":\"nodes\"`：策略模式，此处是nodes模式\n  - `\"ha-params\":[\"rabbit@mq1\", \"rabbit@mq2\"]`：策略参数，这里指定副本所在节点名称\n\n### 仲裁队列部署\n在任意RabbitMQ控制台添加一个队列，选择队列类型为Quorum类型。仲裁队列默认的镜像数为5。如果你的集群有7个节点，那么镜像数肯定是5；而我们集群只有3个节点，因此镜像数量就是3。\n\nJava中创建仲裁队列：\n```java\n@Bean\npublic Queue quorumQueue() {\n    return QueueBuilder\n        .durable(\"quorum.queue\") // 持久化\n        .quorum() // 仲裁队列\n        .build();\n}\n```\n\n### SpringAMQP连接集群\n```yaml\nspring:\n  rabbitmq:\n    addresses: 192.168.150.105:8071, 192.168.150.105:8072, 192.168.150.105:8073\n    username: itcast\n    password: 123321\n    virtual-host: /\n```\n\n### 集群扩容\n略。\n\n# ElasticSearch\n一个开源的分布式搜索引擎，可以用来实现搜索、日志统计、分析、系统监控等功能。\n## 安装部署\n因为我们还需要部署kibana容器，因此需要让es和kibana容器互联。这里先创建一个网络：\n```sh\ndocker network create es-net\n```\n### ES\n安装方式一：从DockerHub中pull到虚拟机\n安装方式二：下载好文件上传到虚拟机，然后加载文件\n```sh\n# 导入数据\ndocker load -i es.tar\n```\n运行ES容器：\n```sh\ndocker run -d \\\n\t--name es \\\n    -e \"ES_JAVA_OPTS=-Xms512m -Xmx512m\" \\\n    -e \"discovery.type=single-node\" \\\n    -v es-data:/usr/share/elasticsearch/data \\\n    -v es-plugins:/usr/share/elasticsearch/plugins \\\n    --privileged \\\n    --network es-net \\\n    -p 9200:9200 \\\n    -p 9300:9300 \\\nelasticsearch:7.12.1\n```\n命令解释：\n\n- `-e \"cluster.name=es-docker-cluster\"`：设置集群名称\n- `-e \"http.host=0.0.0.0\"`：监听的地址，可以外网访问\n- `-e \"ES_JAVA_OPTS=-Xms512m -Xmx512m\"`：内存大小\n- `-e \"discovery.type=single-node\"`：非集群模式\n- `-v es-data:/usr/share/elasticsearch/data`：挂载逻辑卷，绑定es的数据目录\n- `-v es-logs:/usr/share/elasticsearch/logs`：挂载逻辑卷，绑定es的日志目录\n- `-v es-plugins:/usr/share/elasticsearch/plugins`：挂载逻辑卷，绑定es的插件目录\n- `--privileged`：授予逻辑卷访问权\n- `--network es-net` ：加入一个名为es-net的网络中\n- `-p 9200:9200`：端口映射配置\n\n在浏览器中输入：http://192.168.150.101:9200 即可看到elasticsearch的响应结果(192.168.150.101为虚拟机ip)：\n{% asset_img 023.jpg %}\n### kibana\nkibana提供了一个elasticsearch的可视化界面，可以运行DSL语句，而且具有自动补全功能，方便学习ES。\nkibana安装同ES。\n运行kibana容器：\n```sh\ndocker run -d \\\n--name kibana \\\n-e ELASTICSEARCH_HOSTS=http://es:9200 \\\n--network=es-net \\\n-p 5601:5601  \\\nkibana:7.12.1\n```\n- `--network es-net` ：加入一个名为es-net的网络中，与elasticsearch在同一个网络中\n- `-e ELASTICSEARCH_HOSTS=http://es:9200\"`：设置elasticsearch的地址，因为kibana已经与elasticsearch在一个网络，因此可以用容器名直接访问elasticsearch\n- `-p 5601:5601`：端口映射配置\n\n查看kibana日志，出现以下结果则kibana运行成功\n```sh\ndocker logs -f kibana\n```\n{% asset_img 024.jpg %}\n## ES基础\n### 倒排索引\n重要概念：\n- 文档（document）：用来搜索的数据，每一条数据就是一个文档。例如一个网页、一个商品信息\n- 词条（term）：对文档数据或用户搜索数据，利用某种算法分词，得到的具备含义的词语就是词条。例如：我是中国人，就可以分为：我、是、中国人、中国、国人这样的几个词条\n\n倒排索引是相对正向索引而言的。传统的正向索引在面对模糊查询时，通常需要逐行扫描数据判断是否符合查询条件，效率不高。\n创建倒排索引流程如下：\n- 将每一个文档的数据利用算法分词，得到一个个词条\n- 创建表，每行数据包括词条、词条所在文档id、位置等信息\n- 因为词条唯一性，可以给词条创建索引，例如hash表结构索引\n{% asset_img 019.jpg %}\n\n搜索流程如下：\n- 用户输入条件`\"华为手机\"`进行搜索\n- 对用户输入内容**分词**，得到词条：`华为`、`手机`。\n- 拿着词条在倒排索引中查找，可以得到包含词条的文档id：1、2、3。\n- 拿着文档id到正向索引中查找具体文档。\n{% asset_img 020.jpg %}\n\n### 文档和字段\nelasticsearch是面向**文档（Document）**存储的，可以是数据库中的一条商品数据，一个订单信息。文档数据会被序列化为json格式后存储在elasticsearch中。Json文档中往往包含很多的**字段（Field）**，类似于数据库中的列。\n{% asset_img 021.jpg %}\n### 索引和映射\n**索引（Index）**，就是相同类型的文档的集合。\n{% asset_img 022.jpg %}\n索引库中有**映射（mapping）**，是索引中文档的字段约束信息，类似表的结构约束。\n常见mapping属性：\n\n- type：字段数据类型，常见的简单类型有：\n  - 字符串：text（可分词的文本）、keyword（精确值，例如：品牌、国家、ip地址）\n  - 数值：long、integer、short、byte、double、float、\n  - 布尔：boolean\n  - 日期：date\n  - 对象：object\n  - 地址（地理坐标，包含经纬度）：geo_point\n- index：是否创建索引，默认为true\n- analyzer：使用哪种分词器\n- properties：该字段的子字段\n\neg:\n```json\n{\n    \"age\": 21,\n    \"weight\": 52.1,\n    \"isMarried\": false,\n    \"info\": \"黑马程序员Java讲师\",\n    \"email\": \"zy@itcast.cn\",\n    \"score\": [99.1, 99.5, 98.9],\n    \"name\": {\n        \"firstName\": \"云\",\n        \"lastName\": \"赵\"\n    }\n}\n```\n对应的每个字段映射（mapping）：\n- age：类型为 integer；参与搜索，因此需要index为true；无需分词器\n- weight：类型为float；参与搜索，因此需要index为true；无需分词器\n- isMarried：类型为boolean；参与搜索，因此需要index为true；无需分词器\n- info：类型为字符串，需要分词，因此是text；参与搜索，因此需要index为true；分词器可以用ik_smart\n- email：类型为字符串，但是不需要分词，因此是keyword；不参与搜索，因此需要index为false；无需分词器\n- score：虽然是数组，但是我们只看元素的类型，类型为float；参与搜索，因此需要index为true；无需分词器\n- name：类型为object，需要定义多个子属性\n  - name.firstName；类型为字符串，但是不需要分词，因此是keyword；参与搜索，因此需要index为true；无需分词器\n  - name.lastName；类型为字符串，但是不需要分词，因此是keyword；参与搜索，因此需要index为true；无需分词器\n\n### ES与Mysql概念对比\n| ES | Mysql | 说明|\n| :-- | :-- | :--|\n| Table | Index | 索引(index)，就是文档的集合，类似数据库的表(table)           |\n| Row | Document | 文档（Document），就是一条条的数据，类似数据库中的行（Row），文档都是JSON格式 |\n| Column | Field | 字段（Field），就是JSON文档中的字段，类似数据库中的列（Column） |\n| Schema | Mapping | Mapping（映射）是索引中文档的约束，例如字段类型约束。类似数据库的表结构（Schema） |\n| SQL | DSL | DSL是elasticsearch提供的JSON风格的请求语句，用来操作elasticsearch，实现CRUD |\n### ik分词器\n#### 安装配置ik分词器\n方式一：在线安装\n```sh\n# 进入容器内部\ndocker exec -it elasticsearch /bin/bash\n\n# 在线下载并安装\n./bin/elasticsearch-plugin  install https://github.com/medcl/elasticsearch-analysis-ik/releases/download/v7.12.1/elasticsearch-analysis-ik-7.12.1.zip\n\n#退出\nexit\n#重启容器\ndocker restart elasticsearch\n```\n方式二：离线安装ik插件\n1. 查看ES数据卷目录\n```sh\ndocker volume inspect es-plugins\n```\n结果如下：\n```json\n[\n    {\n        \"CreatedAt\": \"2022-05-06T10:06:34+08:00\",\n        \"Driver\": \"local\",\n        \"Labels\": null,\n        \"Mountpoint\": \"/var/lib/docker/volumes/es-plugins/_data\",\n        \"Name\": \"es-plugins\",\n        \"Options\": null,\n        \"Scope\": \"local\"\n    }\n]\n```\n说明plugins目录被挂载到了：`/var/lib/docker/volumes/es-plugins/_data `目录\n2. 将ik分词器文件上传到`/var/lib/docker/volumes/es-plugins/_data `\n3. 重启ES\n```sh\ndocker restart es\n```\n#### 分词模式\n- ik_smart：最少切分\n- ik_max_word：最细切分\n\n```json\nGET /_analyze\n{\n  \"analyzer\": \"ik_max_word\",\n  \"text\": \"黑马程序员学习java太棒了\"\n}\n```\n结果如下\n```json\n{\n  \"tokens\" : [\n    {\n      \"token\" : \"黑马\",\n      \"start_offset\" : 0,\n      \"end_offset\" : 2,\n      \"type\" : \"CN_WORD\",\n      \"position\" : 0\n    },\n    {\n      \"token\" : \"程序员\",\n      \"start_offset\" : 2,\n      \"end_offset\" : 5,\n      \"type\" : \"CN_WORD\",\n      \"position\" : 1\n    },\n    {\n      \"token\" : \"程序\",\n      \"start_offset\" : 2,\n      \"end_offset\" : 4,\n      \"type\" : \"CN_WORD\",\n      \"position\" : 2\n    },\n    {\n      \"token\" : \"员\",\n      \"start_offset\" : 4,\n      \"end_offset\" : 5,\n      \"type\" : \"CN_CHAR\",\n      \"position\" : 3\n    },\n    {\n      \"token\" : \"学习\",\n      \"start_offset\" : 5,\n      \"end_offset\" : 7,\n      \"type\" : \"CN_WORD\",\n      \"position\" : 4\n    },\n    {\n      \"token\" : \"java\",\n      \"start_offset\" : 7,\n      \"end_offset\" : 11,\n      \"type\" : \"ENGLISH\",\n      \"position\" : 5\n    },\n    {\n      \"token\" : \"太棒了\",\n      \"start_offset\" : 11,\n      \"end_offset\" : 14,\n      \"type\" : \"CN_WORD\",\n      \"position\" : 6\n    },\n    {\n      \"token\" : \"太棒\",\n      \"start_offset\" : 11,\n      \"end_offset\" : 13,\n      \"type\" : \"CN_WORD\",\n      \"position\" : 7\n    },\n    {\n      \"token\" : \"了\",\n      \"start_offset\" : 13,\n      \"end_offset\" : 14,\n      \"type\" : \"CN_CHAR\",\n      \"position\" : 8\n    }\n  ]\n}\n```\n#### 拓展词词典\n1. 进入ikbana的config目录，修改IKAnalyzer.cfg.xml文件，添加\n```xml\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<!DOCTYPE properties SYSTEM \"http://java.sun.com/dtd/properties.dtd\">\n<properties>\n        <comment>IK Analyzer 扩展配置</comment>\n        <!--用户可以在这里配置自己的扩展字典 *** 添加扩展词典-->\n        <entry key=\"ext_dict\">ext.dic</entry>\n</properties>\n```\n2. 在config目录下新建 ext.dic文件\n```\n拿来吧你\n永远的神\n```\n3. 重启ES\n```sh\ndocker restart es\n\n# 查看 日志\ndocker logs -f elasticsearch\n```\n#### 停用词词典\n1. 在IKAnalyzer.cfg.xml文件添加如下内容：\n```xml\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<!DOCTYPE properties SYSTEM \"http://java.sun.com/dtd/properties.dtd\">\n<properties>\n        <comment>IK Analyzer 扩展配置</comment>\n        <!--用户可以在这里配置自己的扩展字典-->\n        <entry key=\"ext_dict\">ext.dic</entry>\n         <!--用户可以在这里配置自己的扩展停止词字典  *** 添加停用词词典-->\n        <entry key=\"ext_stopwords\">stopword.dic</entry>\n</properties>\n```\n2. 在stopword.dic文件中添加停用词\n```\n黄赌毒\n```\n3. 重启ES\n```sh\n# 重启服务\ndocker restart elasticsearch\ndocker restart kibana\n\n# 查看 日志\ndocker logs -f elasticsearch\n```\n## DSL\n### 索引库操作\n#### 创建索引库和映射\n- 请求方式：PUT\n- 请求路径：/索引库名，可以自定义\n- 请求参数：mapping映射\n\n格式：\n```jason\nPUT /索引库名称\n{\n  \"mappings\": {\n    \"properties\": {\n      \"字段名\":{\n        \"type\": \"text\",\n        \"analyzer\": \"ik_smart\"\n      },\n      \"字段名2\":{\n        \"type\": \"keyword\",\n        \"index\": \"false\"\n      },\n      \"字段名3\":{\n        \"properties\": {\n          \"子字段\": {\n            \"type\": \"keyword\"\n          }\n        }\n      },\n      // ...略\n    }\n  }\n}\n```\neg：\n```json\nPUT /heima\n{\n  \"mappings\": {\n    \"properties\": {\n      \"info\":{\n        \"type\": \"text\",\n        \"analyzer\": \"ik_smart\"\n      },\n      \"email\":{\n        \"type\": \"keyword\",\n        \"index\": \"falsae\"\n      },\n      \"name\":{\n        \"properties\": {\n          \"firstName\": {\n            \"type\": \"keyword\"\n          }\n        }\n      },\n      // ... 略\n    }\n  }\n}\n```\n#### 查询索引库\n- 请求方式：GET\n- 请求路径：/索引库名\n- 请求参数：无\n\n格式：\n```\nGET /索引库名\n```\n#### 修改索引库\n倒排索引一旦数据结构改变，需要重新创建倒排索引。因此ES索引库**一旦创建，无法修改mapping**。虽然无法修改，但是ES允许添加新的字段到mapping中，因为不会对倒排索引产生影响。\n```json\nPUT /索引库名/_mapping\n{\n  \"properties\": {\n    \"新字段名\":{\n      \"type\": \"integer\"\n    }\n  }\n}\n```\n#### 删除索引库\n- 请求方式：DELETE\n- 请求路径：/索引库名\n- 请求参数：无\n\n格式：\n```\nDELETE /索引库名\n```\n### 文档操作\n#### 新增文档\n格式：\n```json\nPOST /索引库名/_doc/文档id\n{\n    \"字段1\": \"值1\",\n    \"字段2\": \"值2\",\n    \"字段3\": {\n        \"子属性1\": \"值3\",\n        \"子属性2\": \"值4\"\n    },\n    // ...\n}\n```\neg：\n```json\nPOST /heima/_doc/1\n{\n    \"info\": \"黑马程序员Java讲师\",\n    \"email\": \"zy@itcast.cn\",\n    \"name\": {\n        \"firstName\": \"云\",\n        \"lastName\": \"赵\"\n    }\n}\n```\n#### 查询文档\n格式：\n```json\nGET /{索引库名称}/_doc/{id}\n```\n#### 删除文档\n格式：\n```json\nDELETE /{索引库名}/_doc/id值\n```\n#### 修改文档\n全量修改：直接覆盖原有文档（如果文档不存在则会新建文档）\n格式：\n```json\nPUT /{索引库名}/_doc/文档id\n{\n    \"字段1\": \"值1\",\n    \"字段2\": \"值2\",\n    // ... 略\n}\n```\n增量修改：修改文档中的部分字段\n```json\nPOST /{索引库名}/_update/文档id\n{\n    \"doc\": {\n         \"字段名\": \"新的值\",\n    }\n}\n```\n### 查询文档\n**ES copy_to**参数：将多个字段合并为一个字段进行查询，可以避免由于多字段查询时的效率低问题。在创建映射时可以设置该属性，但是该字段仅在查询时起作用，并不会直接作为数据存在ES中。\nPS：搜索字段越多，对查询性能影响越大，因此建议采用copy_to，然后单字段查询的方式。\n\n常见的查询类型包括：\n\n- 查询所有：查询出所有数据，一般测试用。例如：match_all\n\n- 全文检索（full text）查询：利用分词器对用户输入内容分词，然后去倒排索引库中匹配。例如：\n  - match_query\n  - multi_match_query\n- 精确查询：根据精确词条值查找数据，一般是查找keyword、数值、日期、boolean等类型字段。例如：\n  - ids\n  - range\n  - term\n- 地理（geo）查询：根据经纬度查询。例如：\n  - geo_distance\n  - geo_bounding_box\n- 复合（compound）查询：复合查询可以将上述各种查询条件组合起来，合并查询条件。例如：\n  - bool\n  - function_score\n\n基本语法：\n```json\nGET /indexName/_search\n{\n  \"query\": {\n    \"查询类型\": {\n      \"查询条件\": \"条件值\"\n    }\n  }\n}\n```\neg：查询所有\n```json\n// 查询所有\nGET /indexName/_search\n{\n  \"query\": {\n    \"match_all\": {\n    }\n  }\n}\n```\n#### 全文检索查询\n参与搜索的字段也必须是可分词的text类型的字段\n- match查询：单字段查询\n- multi_match查询：多字段查询，任意一个字段符合条件就算符合查询条件\n\nmatch查询格式：\n```json\nGET /indexName/_search\n{\n  \"query\": {\n    \"match\": {\n      \"FIELD\": \"TEXT\"\n    }\n  }\n}\n```\nmulit_match查询格式：\n```json\nGET /indexName/_search\n{\n  \"query\": {\n    \"multi_match\": {\n      \"query\": \"TEXT\",\n      \"fields\": [\"FIELD1\", \" FIELD12\"]\n    }\n  }\n}\n```\n#### 精准查询\n一般是查找keyword、数值、日期、boolean等类型字段。所以**不会**对搜索条件分词。\n- term：根据词条精确值查询\n- range：根据值的范围查询\n\nterm查询：\n```json\n// term查询\nGET /indexName/_search\n{\n  \"query\": {\n    \"term\": {\n      \"FIELD\": {\n        \"value\": \"VALUE\"\n      }\n    }\n  }\n}\n```\nrange查询：\n```json\n// range查询\nGET /indexName/_search\n{\n  \"query\": {\n    \"range\": {\n      \"FIELD\": {\n        \"gte\": 10, // 这里的gte代表大于等于，gt则代表大于\n        \"lte\": 20 // lte代表小于等于，lt则代表小于\n      }\n    }\n  }\n}\n```\n#### 地理坐标查询\n1. 矩形范围查询\n```json\n// geo_bounding_box查询\nGET /indexName/_search\n{\n  \"query\": {\n    \"geo_bounding_box\": {\n      \"FIELD\": {\n        \"top_left\": { // 左上点\n          \"lat\": 31.1,\n          \"lon\": 121.5\n        },\n        \"bottom_right\": { // 右下点\n          \"lat\": 30.9,\n          \"lon\": 121.7\n        }\n      }\n    }\n  }\n}\n```\n2. 距离查询\n也称附近查询\n```json\n// geo_distance 查询\nGET /indexName/_search\n{\n  \"query\": {\n    \"geo_distance\": {\n      \"distance\": \"15km\", // 半径\n      \"FIELD\": \"31.21,121.5\" // 圆心\n    }\n  }\n}\n```\n#### 复合查询\n##### 相关性算分\n当我们利用match查询时，文档结果会根据与搜索词条的关联度打分（_score），返回结果时按照分值降序排列。ES会根据词条和文档的相关度做打分，算法由两种：\n- TF-IDF算法\n- BM25算法，elasticsearch5.1版本后采用的算法\n{% asset_img 027.jpg %}\n{% asset_img 028.jpg %}\n\nTF-IDF算法有一各缺陷，就是词条频率越高，文档得分也会越高，单个词条对文档影响较大。而BM25则会让单个词条的算分有一个上限，曲线更加平滑。\n{% asset_img 029.jpg %}\n##### 算分函数查询\n通过控制算分函数调整最终的查询相关性得分。\n**function score**\n{% asset_img 030.jpg %}\nfunction score 查询中包含四部分内容：\n- 原始查询条件：query部分，基于这个条件搜索文档，并且基于BM25算法给文档打分，原始算分（query score)\n- 过滤条件：filter部分，符合该条件的文档才会重新算分\n- 算分函数：符合filter条件的文档要根据这个函数做运算，得到的**函数算分**（function score），有四种函数\n  - weight：函数结果是常量\n  - field_value_factor：以文档中的某个字段值作为函数结果\n  - random_score：以随机数作为函数结果\n  - script_score：自定义算分函数算法\n- 运算模式：算分函数的结果、原始查询的相关性算分，两者之间的运算方式，包括：\n  - multiply：相乘\n  - replace：用function score替换query score\n  - 其它，例如：sum、avg、max、min\n\nfunction score的运行流程如下：\n- 根据原始条件查询搜索文档，并且计算相关性算分，称为原始算分（query score）\n- 根据过滤条件，过滤文档\n- 符合过滤条件的文档，基于算分函数运算，得到函数算分（function score）\n- 将原始算分（query score）和函数算分（function score）基于运算模式做运算，得到最终结果，作为相关性算分。\n\neg：使“如家”这个品牌的酒店排名靠前一些\n```json\nGET /hotel/_search\n{\n  \"query\": {\n    \"function_score\": {\n      \"query\": {  .... }, // 原始查询，可以是任意条件\n      \"functions\": [ // 算分函数\n        {\n          \"filter\": { // 满足的条件，品牌必须是如家\n            \"term\": {\n              \"brand\": \"如家\"\n            }\n          },\n          \"weight\": 2 // 算分权重为2\n        }\n      ],\n      \"boost_mode\": \"sum\" // 加权模式，求和\n    }\n  }\n}\n```\n#### 布尔查询\n布尔查询是一个或多个查询子句的组合，每一个子句就是一个**子查询**。子查询的组合方式有：\n- must：必须匹配每个子查询，类似“与”\n- should：选择性匹配子查询，类似“或”\n- must_not：必须不匹配，**不参与算分**，类似“非”\n- filter：必须匹配，**不参与算分**\n\nPS：需要注意的是，搜索时，参与**打分的字段越多，查询的性能也越差**。因此这种多条件查询时，建议：\n- 搜索框的关键字搜索，是全文检索查询，使用must查询，参与算分\n- 其它过滤条件，采用filter查询。不参与算分\n\neg：\n```json\nGET /hotel/_search\n{\n  \"query\": {\n    \"bool\": {\n      \"must\": [\n        {\"term\": {\"city\": \"上海\" }}\n      ],\n      \"should\": [\n        {\"term\": {\"brand\": \"皇冠假日\" }},\n        {\"term\": {\"brand\": \"华美达\" }}\n      ],\n      \"must_not\": [\n        { \"range\": { \"price\": { \"lte\": 500 } }}\n      ],\n      \"filter\": [\n        { \"range\": {\"score\": { \"gte\": 45 } }}\n      ]\n    }\n  }\n}\n```\n#### 搜索结果\n##### 排序\nES默认根据相关度算分（_score）排序，但是也支持自定义方式对搜索排序。可以排序字段类型有：keyword类型、数值类型、地理坐标类型、日期类型等。\n1. 普通字段排序\n\nkeyword、数值、日期类型排序的语法基本一致。\n```json\nGET /indexName/_search\n{\n  \"query\": {\n    \"match_all\": {}\n  },\n  \"sort\": [\n    {\n      \"FIELD\": \"desc\"  // 排序字段、排序方式ASC、DESC\n    }\n  ]\n}\n```\nPS：排序条件是一个数组，也就是可以写多个排序条件。按照声明的顺序，当第一个条件相等时，再按照第二个条件排序，以此类推。\n2. 地理坐标排序\n```json\nGET /indexName/_search\n{\n  \"query\": {\n    \"match_all\": {}\n  },\n  \"sort\": [\n    {\n      \"_geo_distance\" : {\n          \"FIELD\" : \"纬度，经度\", // 文档中geo_point类型的字段名、目标坐标点\n          \"order\" : \"asc\", // 排序方式\n          \"unit\" : \"km\" // 排序的距离单位\n      }\n    }\n  ]\n}\n```\n- 指定一个坐标，作为目标点\n- 计算每一个文档中，指定字段（必须是geo_point类型）的坐标 到目标点的距离是多少\n- 根据距离排序\n\n##### 分页\nES默认情况下只返回top10的数据。查询更多数据可以通过修改from、size参数来控制要返回的分页结果：\n- from：从第几个文档开始\n- size：总共查询几个文档\n\n###### 基本分页\n```json\nGET /hotel/_search\n{\n  \"query\": {\n    \"match_all\": {}\n  },\n  \"from\": 0, // 分页开始的位置，默认为0\n  \"size\": 10, // 期望获取的文档总数\n  \"sort\": [\n    {\"price\": \"asc\"}\n  ]\n}\n```\n###### 深度分页\n1. 单点ES分页过程\n    例如查询990~1000的数据，ES会将查询排序0~1000条数据，然后截取990~1000的10条数据。\n2. 集群模式分页\n    集群模式下有N个ES节点，查询990~1000的数据，此时要对每个ES节点进行990~1000的数据查询过程，最后将所有节点的数据（注意是每个节点的0~1000数据，而不是每个节点的990~1000数据）进行汇总排序，最终得到正确的990~1000的数据。\n    可见，集群模式下ES的数据查询的消耗是十分巨大的，会对内存和CPU造成巨大压力，因此ES禁止form+size超过10000的查询请求。\n    针对深度分页问题，ES提供两种解决方案：\n    - search after：分页时需要排序，原理是从上一次的排序值开始，查询下一页数据。官方推荐使用的方式。\n    - 原理将排序后的文档id形成快照，保存在内存。官方已经不推荐使用。\n\n##### 高亮\n搜索结果中的高亮显示:\n- 给文档中的所有关键字都添加一个标签，例如`<em>`标签\n- 页面给`<em>`标签编写CSS样式\n\n高亮语法:\n```json\nGET /hotel/_search\n{\n  \"query\": {\n    \"match\": {\n      \"FIELD\": \"TEXT\" // 查询条件，高亮一定要使用全文检索查询\n    }\n  },\n  \"highlight\": {\n    \"fields\": { // 指定要高亮的字段\n      \"FIELD\": {\n        \"pre_tags\": \"<em>\",  // 用来标记高亮字段的前置标签\n        \"post_tags\": \"</em>\" // 用来标记高亮字段的后置标签\n      }\n    }\n  }\n}\n```\nPS:\n- 高亮是对关键字高亮，因此**搜索条件必须带有关键字**，而不能是范围这样的查询。\n- 默认情况下，**高亮的字段，必须与搜索指定的字段一致**，否则无法高亮\n- 如果要对非搜索字段高亮，则需要添加一个属性：required_field_match=false\n\n### 数据聚合\n根据文档的属性值对文档进行分组。\n三类聚合：\n\n- **桶（Bucket）**聚合：用来对文档做分组\n  - TermAggregation：按照文档字段值分组，例如按照品牌值分组、按照国家分组\n  - Date Histogram：按照日期阶梯分组，例如一周为一组，或者一月为一组\n- **度量（Metric）**聚合：用以计算一些值，比如：最大值、最小值、平均值等\n  - Avg：求平均值\n  - Max：求最大值\n  - Min：求最小值\n  - Stats：同时求max、min、avg、sum等\n- **管道（pipeline）**聚合：其它聚合的结果为基础做聚合\n\nPS：参加聚合的字段必须是keyword、日期、数值、布尔类型\n#### Bucket聚合\n```json\nGET /hotel/_search\n{\n  \"size\": 0,  // 设置size为0，结果中不包含文档，只包含聚合结果\n  \"aggs\": { // 定义聚合\n    \"brandAgg\": { //给聚合起个名字\n      \"terms\": { // 聚合的类型，按照品牌值聚合，所以选择term\n        \"field\": \"brand\", // 参与聚合的字段\n        \"size\": 20 // 希望获取的聚合结果数量\n      }\n    }\n  }\n}\n```\n\n聚合结果排序：Bucket聚合会统计Bucket内的文档数量记为_count，并且按照_count降序排序。可以指定order属性，自定义聚合的排序方式：\n```json\nGET /hotel/_search\n{\n  \"size\": 0, \n  \"aggs\": {\n    \"brandAgg\": {\n      \"terms\": {\n        \"field\": \"brand\",\n        \"order\": {\n          \"_count\": \"asc\" // 按照_count升序排列\n        },\n        \"size\": 20\n      }\n    }\n  }\n}\n```\n\n限定聚合范围：限定要聚合的文档范围，只要添加query条件即可。\n```json\nGET /hotel/_search\n{\n  \"query\": {\n    \"range\": {\n      \"price\": {\n        \"lte\": 200 // 只对200元以下的文档聚合\n      }\n    }\n  }, \n  \"size\": 0, \n  \"aggs\": {\n    \"brandAgg\": {\n      \"terms\": {\n        \"field\": \"brand\",\n        \"size\": 20\n      }\n    }\n  }\n}\n```\n#### Metric聚合语法\n```json\nGET /hotel/_search\n{\n  \"size\": 0, \n  \"aggs\": {\n    \"brandAgg\": { \n      \"terms\": { \n        \"field\": \"brand\", \n        \"size\": 20\n      },\n      \"aggs\": { // 是brands聚合的子聚合，也就是分组后对每组分别计算\n        \"score_stats\": { // 聚合名称\n          \"stats\": { // 聚合类型，这里stats可以计算min、max、avg等\n            \"field\": \"score\" // 聚合字段，这里是score\n          }\n        }\n      }\n    }\n  }\n}\n```\n\n## 自定义分词器\n默认的拼音分词器会将每个汉字单独分为拼音，而我们希望的是每个词条形成一组拼音，需要对拼音分词器做个性化定制，形成自定义分词器。\nelasticsearch中分词器（analyzer）的组成包含三部分：\n- character filters：在tokenizer之前对文本进行处理。例如删除字符、替换字符\n- tokenizer：将文本按照一定的规则切割成词条（term）。例如keyword，就是不分词；还有ik_smart\n- tokenizer filter：将tokenizer输出的词条做进一步处理。例如大小写转换、同义词处理、拼音处理等\n### 拼音分词器\n拼音分词插件，地址：https://github.com/medcl/elasticsearch-analysis-pinyin\n安装同IK分词器\n安装后测试：\n```json\nPOST /_analyze\n{\n  \"text\": \"如家酒店还不错\",\n  \"analyzer\": \"pinyin\"\n}\n```\n### 声明自定义分词器\n```json\nPUT /test\n{\n  \"settings\": {\n    \"analysis\": {\n      \"analyzer\": { // 自定义分词器\n        \"my_analyzer\": {  // 分词器名称\n          \"tokenizer\": \"ik_max_word\",\n          \"filter\": \"py\"\n        }\n      },\n      \"filter\": { // 自定义tokenizer filter\n        \"py\": { // 过滤器名称\n          \"type\": \"pinyin\", // 过滤器类型，这里是pinyin\n\t\t  \"keep_full_pinyin\": false,\n          \"keep_joined_full_pinyin\": true,\n          \"keep_original\": true,\n          \"limit_first_letter_length\": 16,\n          \"remove_duplicated_term\": true,\n          \"none_chinese_pinyin_tokenize\": false\n        }\n      }\n    }\n  },\n  \"mappings\": {\n    \"properties\": {\n      \"name\": {\n        \"type\": \"text\",\n        \"analyzer\": \"my_analyzer\",\n        \"search_analyzer\": \"ik_smart\"\n      }\n    }\n  }\n}\n```\n### 自动补全查询\nelasticsearch提供了**Completion Suggester**查询来实现自动补全功能。这个查询会匹配以用户输入内容开头的词条并返回。为了提高补全查询的效率，对于文档中字段的类型有一些约束：\n- 参与补全查询的字段必须是completion类型。\n- 字段的内容一般是用来补全的多个词条形成的数组。\n\neg：\n1. 创建索引库\n```json\n// 创建索引库\nPUT test\n{\n  \"mappings\": {\n    \"properties\": {\n      \"title\":{\n        \"type\": \"completion\"\n      }\n    }\n  }\n}\n```\n2. 插入数据\n```json\n// 示例数据\nPOST test/_doc\n{\n  \"title\": [\"Sony\", \"WH-1000XM3\"]\n}\nPOST test/_doc\n{\n  \"title\": [\"SK-II\", \"PITERA\"]\n}\nPOST test/_doc\n{\n  \"title\": [\"Nintendo\", \"switch\"]\n}\n```\n3. 测试自动补全\n```json\n// 自动补全查询\nGET /test/_search\n{\n  \"suggest\": {\n    \"title_suggest\": {\n      \"text\": \"s\", // 关键字\n      \"completion\": {\n        \"field\": \"title\", // 补全查询的字段\n        \"skip_duplicates\": true, // 跳过重复的\n        \"size\": 10 // 获取前10条结果\n      }\n    }\n  }\n}\n```\n\n## RestAPI\n操作ES的客户端，官方文档：https://www.elastic.co/guide/en/elasticsearch/client/index.html\n### 准备工作\n1. 引入ES RestHighLevelClient依赖\n```xml\n<dependency>\n    <groupId>org.elasticsearch.client</groupId>\n    <artifactId>elasticsearch-rest-high-level-client</artifactId>\n</dependency>\n```\n2. 覆盖SpringBoot的默认版本\n```xml\n<properties>\n    <java.version>1.8</java.version>\n    <elasticsearch.version>7.12.1</elasticsearch.version>\n</properties>\n```\n3. 初始化RestHighLevelClient\n```java\nRestHighLevelClient client = new RestHighLevelClient(RestClient.builder(\n        HttpHost.create(\"http://192.168.150.101:9200\")\n));\n```\n单元测试类\n```java\npackage cn.itcast.hotel;\n\nimport org.apache.http.HttpHost;\nimport org.elasticsearch.client.RestHighLevelClient;\nimport org.junit.jupiter.api.AfterEach;\nimport org.junit.jupiter.api.BeforeEach;\nimport org.junit.jupiter.api.Test;\n\nimport java.io.IOException;\n\npublic class HotelIndexTest {\n    private RestHighLevelClient client;\n\n    @BeforeEach\n    void setUp() {\n        this.client = new RestHighLevelClient(RestClient.builder(\n                HttpHost.create(\"http://192.168.150.101:9200\")\n        ));\n    }\n\n    @AfterEach\n    void tearDown() throws IOException {\n        this.client.close();\n    }\n}\n```\n### 操作索引库\n#### 创建索引库\n使用Java代码操作ES时，操作步骤可以仿照DSL语句来编写代码，逻辑会比较清晰\n{% asset_img 025.jpg %}\n准备DSL语句\n\n```java\npackage cn.itcast.hotel.constants;\n\npublic class HotelConstants {\n    public static final String MAPPING_TEMPLATE = \"{\\n\" +\n            \"  \\\"mappings\\\": {\\n\" +\n            \"    \\\"properties\\\": {\\n\" +\n            \"      \\\"id\\\": {\\n\" +\n            \"        \\\"type\\\": \\\"keyword\\\"\\n\" +\n            \"      },\\n\" +\n            \"      \\\"name\\\":{\\n\" +\n            \"        \\\"type\\\": \\\"text\\\",\\n\" +\n            \"        \\\"analyzer\\\": \\\"ik_max_word\\\",\\n\" +\n            \"        \\\"copy_to\\\": \\\"all\\\"\\n\" +\n            \"      },\\n\" +\n            \"      \\\"address\\\":{\\n\" +\n            \"        \\\"type\\\": \\\"keyword\\\",\\n\" +\n            \"        \\\"index\\\": false\\n\" +\n            \"      },\\n\" +\n            \"      \\\"price\\\":{\\n\" +\n            \"        \\\"type\\\": \\\"integer\\\"\\n\" +\n            \"      },\\n\" +\n            \"      \\\"score\\\":{\\n\" +\n            \"        \\\"type\\\": \\\"integer\\\"\\n\" +\n            \"      },\\n\" +\n            \"      \\\"brand\\\":{\\n\" +\n            \"        \\\"type\\\": \\\"keyword\\\",\\n\" +\n            \"        \\\"copy_to\\\": \\\"all\\\"\\n\" +\n            \"      },\\n\" +\n            \"      \\\"city\\\":{\\n\" +\n            \"        \\\"type\\\": \\\"keyword\\\",\\n\" +\n            \"        \\\"copy_to\\\": \\\"all\\\"\\n\" +\n            \"      },\\n\" +\n            \"      \\\"starName\\\":{\\n\" +\n            \"        \\\"type\\\": \\\"keyword\\\"\\n\" +\n            \"      },\\n\" +\n            \"      \\\"business\\\":{\\n\" +\n            \"        \\\"type\\\": \\\"keyword\\\"\\n\" +\n            \"      },\\n\" +\n            \"      \\\"location\\\":{\\n\" +\n            \"        \\\"type\\\": \\\"geo_point\\\"\\n\" +\n            \"      },\\n\" +\n            \"      \\\"pic\\\":{\\n\" +\n            \"        \\\"type\\\": \\\"keyword\\\",\\n\" +\n            \"        \\\"index\\\": false\\n\" +\n            \"      },\\n\" +\n            \"      \\\"all\\\":{\\n\" +\n            \"        \\\"type\\\": \\\"text\\\",\\n\" +\n            \"        \\\"analyzer\\\": \\\"ik_max_word\\\"\\n\" +\n            \"      }\\n\" +\n            \"    }\\n\" +\n            \"  }\\n\" +\n            \"}\";\n}\n```\n向ES发送请求创建索引库\n```java\n@Test\nvoid createHotelIndex() throws IOException {\n    // 1.创建Request对象\n    CreateIndexRequest request = new CreateIndexRequest(\"hotel\");\n    // 2.准备请求的参数：DSL语句\n    request.source(MAPPING_TEMPLATE, XContentType.JSON);\n    // 3.发送请求\n    client.indices().create(request, RequestOptions.DEFAULT);\n}\n```\n- 创建Request对象。因为是创建索引库的操作，因此Request是CreateIndexRequest。\n- 添加请求参数，其实就是DSL的JSON参数部分。因为json字符串很长，这里是定义了静态字符串常量MAPPING_TEMPLATE，让代码看起来更加优雅。\n- 发送请求，client.indices()方法的返回值是IndicesClient类型，封装了所有与索引库操作有关的方法。\n\n#### 删除索引库\n- 创建Request对象。这次是DeleteIndexRequest对象\n- 准备参数。这里是无参\n- 发送请求。改用delete方法\n\n```java\n@Test\nvoid testDeleteHotelIndex() throws IOException {\n    // 1.创建Request对象\n    DeleteIndexRequest request = new DeleteIndexRequest(\"hotel\");\n    // 2.发送请求\n    client.indices().delete(request, RequestOptions.DEFAULT);\n}\n```\n#### 查询索引库是否存在\n- 创建Request对象。这次是GetIndexRequest对象\n- 准备参数。这里是无参\n- 发送请求。改用exists方法\n\n```java\n@Test\nvoid testExistsHotelIndex() throws IOException {\n    // 1.创建Request对象\n    GetIndexRequest request = new GetIndexRequest(\"hotel\");\n    // 2.发送请求\n    boolean exists = client.indices().exists(request, RequestOptions.DEFAULT);\n    // 3.输出\n    System.err.println(exists ? \"索引库已经存在！\" : \"索引库不存在！\");\n}\n```\n#### 总结\nJava操作索引库的基本步骤：\n- 初始化RestHighLevelClient\n- 创建XxxIndexRequest。XXX是Create、Get、Delete\n- 准备DSL（ Create时需要，其它是无参）\n- 发送请求。调用RestHighLevelClient#indices().xxx()方法，xxx是create、exists、delete\n\n### 操作文档\n#### 索引库实体类\n```java\npackage cn.itcast.hotel.pojo;\n\nimport lombok.Data;\nimport lombok.NoArgsConstructor;\n\n@Data\n@NoArgsConstructor\npublic class HotelDoc {\n    private Long id;\n    private String name;\n    private String address;\n    private Integer price;\n    private Integer score;\n    private String brand;\n    private String city;\n    private String starName;\n    private String business;\n    private String location;\t//对应ES中的坐标类型，geo_point\n    private String pic;\n\n    public HotelDoc(Hotel hotel) {\n        this.id = hotel.getId();\n        this.name = hotel.getName();\n        this.address = hotel.getAddress();\n        this.price = hotel.getPrice();\n        this.score = hotel.getScore();\n        this.brand = hotel.getBrand();\n        this.city = hotel.getCity();\n        this.starName = hotel.getStarName();\n        this.business = hotel.getBusiness();\n        this.location = hotel.getLatitude() + \", \" + hotel.getLongitude();\n        this.pic = hotel.getPic();\n    }\n}\n```\n#### 新增文档\n{% asset_img 026.jpg %}\n- 创建Request对象\n- 准备请求参数，也就是DSL中的JSON文档\n- 发送请求\n\n从数据库中查询数据，再将数据转换成JSON文档存储在ES中\n- 根据id查询酒店数据Hotel\n- 将Hotel封装为HotelDoc\n- 将HotelDoc序列化为JSON\n- 创建IndexRequest，指定索引库名和id\n- 准备请求参数，也就是JSON文档\n- 发送请求\n\n```java\n@Test\nvoid testAddDocument() throws IOException {\n    // 1.根据id查询酒店数据\n    Hotel hotel = hotelService.getById(61083L);\n    // 2.转换为文档类型\n    HotelDoc hotelDoc = new HotelDoc(hotel);\n    // 3.将HotelDoc转json\n    String json = JSON.toJSONString(hotelDoc);\n\n    // 1.准备Request对象\n    IndexRequest request = new IndexRequest(\"hotel\").id(hotelDoc.getId().toString());\n    // 2.准备Json文档\n    request.source(json, XContentType.JSON);\n    // 3.发送请求\n    client.index(request, RequestOptions.DEFAULT);\n}\n```\n#### 查询文档\n- 准备Request对象。这次是查询，所以是GetRequest\n- 发送请求，得到结果。因为是查询，这里调用client.get()方法\n- 解析结果，就是对JSON做反序列化\n\n```java\n@Test\nvoid testGetDocumentById() throws IOException {\n    // 1.准备Request\n    GetRequest request = new GetRequest(\"hotel\", \"61082\");\n    // 2.发送请求，得到响应\n    GetResponse response = client.get(request, RequestOptions.DEFAULT);\n    // 3.解析响应结果\n    String json = response.getSourceAsString();\n\n    HotelDoc hotelDoc = JSON.parseObject(json, HotelDoc.class);\n    System.out.println(hotelDoc);\n}\n```\n#### 删除文档\n- 准备Request对象，因为是删除，这次是DeleteRequest对象。要指定索引库名和id\n- 准备参数，无参\n- 发送请求。因为是删除，所以是client.delete()方法\n\n```java\n@Test\nvoid testDeleteDocument() throws IOException {\n    // 1.准备Request\n    DeleteRequest request = new DeleteRequest(\"hotel\", \"61083\");\n    // 2.发送请求\n    client.delete(request, RequestOptions.DEFAULT);\n}\n```\n#### 修改文档\n在RestClient的API中，全量修改与新增的API完全一致，判断依据是ID：\n- 如果新增时，ID已经存在，则修改\n- 如果新增时，ID不存在，则新增\n\n以下是增量修改代码\n```java\n@Test\nvoid testUpdateDocument() throws IOException {\n    // 1.准备Request\n    UpdateRequest request = new UpdateRequest(\"hotel\", \"61083\");\n    // 2.准备请求参数\n    request.doc(\n        \"price\", \"952\",\n        \"starName\", \"四钻\"\n    );\n    // 3.发送请求\n    client.update(request, RequestOptions.DEFAULT);\n}\n```\n#### 总结\n文档操作的基本步骤：\n- 初始化RestHighLevelClient\n- 创建XxxRequest。XXX是Index、Get、Update、Delete、Bulk\n- 准备参数（Index、Update、Bulk时需要）\n- 发送请求。调用RestHighLevelClient#.xxx()方法，xxx是index、get、update、delete、bulk\n- 解析结果（Get时需要）\n\n### 查询文档\n基本步骤:\n- 准备Request对象\n- 准备请求参数\n- 发起请求\n- 解析响应\n\n#### match_all查询\n```java\n@Test\nvoid testMatchAll() throws IOException {\n    // 1.准备Request\n    SearchRequest request = new SearchRequest(\"hotel\");\n    // 2.准备DSL\n    request.source()\n        .query(QueryBuilders.matchAllQuery());\n    // 3.发送请求\n    SearchResponse response = client.search(request, RequestOptions.DEFAULT);\n\n    // 4.解析响应\n    handleResponse(response);\n}\n\nprivate void handleResponse(SearchResponse response) {\n    // 4.解析响应\n    SearchHits searchHits = response.getHits();\n    // 4.1.获取总条数\n    long total = searchHits.getTotalHits().value;\n    System.out.println(\"共搜索到\" + total + \"条数据\");\n    // 4.2.文档数组\n    SearchHit[] hits = searchHits.getHits();\n    // 4.3.遍历\n    for (SearchHit hit : hits) {\n        // 获取文档source\n        String json = hit.getSourceAsString();\n        // 反序列化\n        HotelDoc hotelDoc = JSON.parseObject(json, HotelDoc.class);\n        System.out.println(\"hotelDoc = \" + hotelDoc);\n    }\n}\n```\n1. 创建SearchRequest对象\n2. 准备Request.source()，也就是DSL。\n   - QueryBuilders来构建查询条件\n   - 传入Request.source() 的 query() 方法\n3. 发送请求，得到结果\n4. 解析结果（参考JSON结果，从外到内，逐层解析）\n\nAPI:\n- request.soure()，包含了查询、分页、排序高亮等功能\n- QueryBuilders，包含match、term、function_score、bool等各种查询\n\n{% asset_img 031.jpg %}\n解析响应：逐层解析JSON字符串，流程如下：\n- `SearchHits`：通过response.getHits()获取，就是JSON中的最外层的hits，代表命中的结果\n  - `SearchHits#getTotalHits().value`：获取总条数信息\n  - `SearchHits#getHits()`：获取SearchHit数组，也就是文档数组\n    - `SearchHit#getSourceAsString()`：获取文档结果中的_source，也就是原始的json文档数据\n\n#### match查询\n```java\n@Test\nvoid testMatch() throws IOException {\n    // 1.准备Request\n    SearchRequest request = new SearchRequest(\"hotel\");\n    // 2.准备DSL\n    request.source()\n        .query(QueryBuilders.matchQuery(\"all\", \"如家\"));\n    // 3.发送请求\n    SearchResponse response = client.search(request, RequestOptions.DEFAULT);\n    // 4.解析响应\n    handleResponse(response);\n}\n```\n#### 精确查询\n查询流程同上，差异是使用到的API：\n- QueryBuilders.termQuery()\n- QueryBuilders.rangeQuery().gte().lte()\n\n#### 布尔查询\n```java\n@Test\nvoid testBool() throws IOException {\n    // 1.准备Request\n    SearchRequest request = new SearchRequest(\"hotel\");\n    // 2.准备DSL\n    // 2.1.准备BooleanQuery\n    BoolQueryBuilder boolQuery = QueryBuilders.boolQuery();\n    // 2.2.添加term\n    boolQuery.must(QueryBuilders.termQuery(\"city\", \"杭州\"));\n    // 2.3.添加range\n    boolQuery.filter(QueryBuilders.rangeQuery(\"price\").lte(250));\n\n    request.source().query(boolQuery);\n    // 3.发送请求\n    SearchResponse response = client.search(request, RequestOptions.DEFAULT);\n    // 4.解析响应\n    handleResponse(response);\n\n}\n```\n#### 排序、分页、高亮\n1. 排序分页\n```java\n@Test\nvoid testPageAndSort() throws IOException {\n    // 页码，每页大小\n    int page = 1, size = 5;\n\n    // 1.准备Request\n    SearchRequest request = new SearchRequest(\"hotel\");\n    // 2.准备DSL\n    // 2.1.query\n    request.source().query(QueryBuilders.matchAllQuery());\n    // 2.2.排序 sort\n    request.source().sort(\"price\", SortOrder.ASC);\n    // 2.3.分页 from、size\n    request.source().from((page - 1) * size).size(5);\n    // 3.发送请求\n    SearchResponse response = client.search(request, RequestOptions.DEFAULT);\n    // 4.解析响应\n    handleResponse(response);\n\n}\n```\n2. 高亮\n```java\nprivate void handleResponse(SearchResponse response) {\n    // 4.解析响应\n    SearchHits searchHits = response.getHits();\n    // 4.1.获取总条数\n    long total = searchHits.getTotalHits().value;\n    System.out.println(\"共搜索到\" + total + \"条数据\");\n    // 4.2.文档数组\n    SearchHit[] hits = searchHits.getHits();\n    // 4.3.遍历\n    for (SearchHit hit : hits) {\n        // 获取文档source\n        String json = hit.getSourceAsString();\n        // 反序列化\n        HotelDoc hotelDoc = JSON.parseObject(json, HotelDoc.class);\n        // 获取高亮结果\n        Map<String, HighlightField> highlightFields = hit.getHighlightFields();\n        if (!CollectionUtils.isEmpty(highlightFields)) {\n            // 根据字段名获取高亮结果\n            HighlightField highlightField = highlightFields.get(\"name\");\n            if (highlightField != null) {\n                // 获取高亮值\n                String name = highlightField.getFragments()[0].string();\n                // 覆盖非高亮结果\n                hotelDoc.setName(name);\n            }\n        }\n        System.out.println(\"hotelDoc = \" + hotelDoc);\n    }\n}\n```\n- 第一步：从结果中获取source。hit.getSourceAsString()，这部分是非高亮结果，json字符串。还需要反序列为HotelDoc对象\n- 第二步：获取高亮结果。hit.getHighlightFields()，返回值是一个Map，key是高亮字段名称，值是HighlightField对象，代表高亮值\n- 第三步：从map中根据高亮字段名称，获取高亮字段值对象HighlightField\n- 第四步：从HighlightField中获取Fragments，并且转为字符串。这部分就是真正的高亮字符串了\n- 第五步：用高亮的结果替换HotelDoc中的非高亮结果\n\n### 数据聚合\n请求API：\n{% asset_img 032.jpg %}\n返回结果解析：\n{% asset_img 033.jpg %}\n\n## 数据同步\n数据库中的数据和ES中的数据保持一致。\n- 同步调用：依次更新数据库和ES，实现简单，但是业务会耗时较长，业务耦合度高。\n- 异步调用：数据库写入完成后使用异步消息队列来通知ES更新数据，响应时间短，但实现复杂，而且依赖消息队列的可靠性。\n- 监听binlog：Mysql主从模式下，主服务器会将数据操作记录到binlog中，通过binlog实现主从数据库的数据一致，因此我们可以通过监听binlog的方式来实现Mysql和ES的数据一致。\n\n## ES集群\n### 部署集群\n使用虚拟机利用docker模拟ES集群，docker-compose文件如下：\n```sh\nversion: '2.2'\nservices:\n  es01:\n    image: elasticsearch:7.12.1\n    container_name: es01\n    environment:\n      - node.name=es01\n      - cluster.name=es-docker-cluster\n      - discovery.seed_hosts=es02,es03\n      - cluster.initial_master_nodes=es01,es02,es03\n      - \"ES_JAVA_OPTS=-Xms512m -Xmx512m\"\n    volumes:\n      - data01:/usr/share/elasticsearch/data\n    ports:\n      - 9200:9200\n    networks:\n      - elastic\n  es02:\n    image: elasticsearch:7.12.1\n    container_name: es02\n    environment:\n      - node.name=es02\n      - cluster.name=es-docker-cluster\n      - discovery.seed_hosts=es01,es03\n      - cluster.initial_master_nodes=es01,es02,es03\n      - \"ES_JAVA_OPTS=-Xms512m -Xmx512m\"\n    volumes:\n      - data02:/usr/share/elasticsearch/data\n    ports:\n      - 9201:9200\n    networks:\n      - elastic\n  es03:\n    image: elasticsearch:7.12.1\n    container_name: es03\n    environment:\n      - node.name=es03\n      - cluster.name=es-docker-cluster\n      - discovery.seed_hosts=es01,es02\n      - cluster.initial_master_nodes=es01,es02,es03\n      - \"ES_JAVA_OPTS=-Xms512m -Xmx512m\"\n    volumes:\n      - data03:/usr/share/elasticsearch/data\n    networks:\n      - elastic\n    ports:\n      - 9202:9200\nvolumes:\n  data01:\n    driver: local\n  data02:\n    driver: local\n  data03:\n    driver: local\n\nnetworks:\n  elastic:\n    driver: bridge\n```\n1. 修改linux系统权限，修改 /etc/sysctl.conf 文件，添加：\n```sh\nvm.max_map_count=262144\n```\n2. 执行命令，使配置生效\n```sh\nsysctl -p\n```\n3. 重启ES集群\n```sh\ndocker-compose up -d\n```\n\n### 集群监控\n推荐使用cerebro来监控es集群状态，官方网址：https://github.com/lmenezes/cerebro\n安装成功后，进入bin目录双击 cerebro.bat 文件启动cerebro，访问 http://localhost:9000 进入控制台\n\n### 集群脑裂问题\n集群ES节点的职责划分：\n{% asset_img 034.jpg %}\n默认情况下，集群中的任何一个节点都同时具备上述四种角色。将集群职责分离有利于提高集群工作效率：\n- master节点：对CPU要求高，但是内存要求第\n- data节点：对CPU和内存要求都高\n- coordinating节点：对网络带宽、CPU要求高\n\n典型集群职责划分：\n{% asset_img 035.jpg %}\n\n#### 脑裂问题\n当ES集群中主节点和其他节点失联（主节点并未宕机），导致从节点中选出一个新的主节点，旧主节点恢复连接后，集群便会出现两个主节点，造成集群数据不一致（旧主节点自成集群，新主节点和其他节点构成新集群）。\n解决方案：要求选票超过 ( eligible节点数量 + 1 ）/ 2 才能当选为主，因此eligible节点数量最好是奇数。对应配置项是discovery.zen.minimum_master_nodes，在es7.0以后，已经成为默认配置，因此一般不会发生脑裂问题。\neg：3个节点形成的集群，选票必须超过 （3 + 1） / 2 ，也就是2票。node3得到node2和node3的选票，当选为主。node1只有自己1票，没有当选。集群中依然只有1个主节点，没有出现脑裂。\n\n### 集群分布式存储\n#### 分片Shard和副本Replicas\nES提供了把 Index（索引）拆分到多个 Shard（分片）中的能力。在创建索引时，可以定义 Shard的数量。每个 Shard 本身就是一个全功能的和独立的 “Index（索引）”，Shard可以存储在集群中的任何节点上。ES会通过hash算法来计算文档应该存储到哪个分片：\n{%asset_img 036.jpg %}\n- _routing默认是文档的id\n- 算法与分片数量有关，因此索引库一旦创建，分片数量不能修改！\n\n在网络/云环境中可能随时会故障，为了数据的安全性和可靠性，ES 可以让您设置一个或多个索引的 Shard 副本到所谓的副本分片，或者副本中去。\n- 在 shard/node 故障的情况下提供了高可用性。为了达到这个目的，需要注意的是在原始的/主 Shard 被复制时副本的 Shard 不会被分配到相同的节点上。\n- 它可以让你水平扩展搜索量/吞吐量，因为搜索可以在所有的副本上并行执行。\n\n每个索引可以被拆分成多个分片，一个索引可以设置 0 个（没有副本）或多个副本。开启副本后，每个索引将有主分片（被复制的原始分片）和副本分片（主分片的副本）。分片和副本的数量在索引被创建时都能够被指定。在创建索引后，您也可以在任何时候动态的改变副本的数量，但是不能够改变分片数量。\n默认情况下，Elasticsearch 中的每个索引分配了 5 个主分片和 1 个副本，这也就意味着如果您的集群至少有两个节点的话，您的索引将会有 5 个主分片和另外 5 个副本分片（1 个完整的副本），每个索引共计 10 个分片。\n\n#### 新增文档流程\n{% asset_img 037.jpg %}\n- 新增一个id=1的文档\n- 对id做hash运算，假如得到的是2，则应该存储到shard-2\n- shard-2的主分片在node3节点，将数据路由到node3\n- 保存文档\n- 同步给shard-2的副本replica-2，在node2节点\n- 返回结果给coordinating-node节点\n\n#### 查询文档流程\n{% asset_img 038.jpg %}\n- scatter phase：分散阶段，coordinating node会把请求分发到每一个分片\n- gather phase：聚集阶段，coordinating node汇总data node的搜索结果，并处理为最终结果集返回给用户\n\n### 集群故障转移\n集群的master节点会监控集群中的节点状态，如果发现有节点宕机，会立即将宕机节点的分片数据迁移到其它节点，确保数据安全，这个叫做故障转移。\n1. ode1是主节点，其它两个节点是从节点。\n{% asset_img 039.jpg %}\n2. 突然node1发生了故障\n{% asset_img 040.jpg %}\n3. 宕机后的第一件事，需要重新选主，例如选中了node2：\n{% asset_img 041.jpg %}\n4.node2成为主节点后会检测集群监控状态，发现：shard-1、shard-0没有副本节点。因此需要将node1上的数据迁移到node2、node3： \n{% asset_img 042.jpg %}\n\n# 微服务保护\nSentinel是阿里巴巴开源的一款微服务流量控制组件。官网地址：https://sentinelguard.io/zh-cn/index.html\n## 初识sentinel\n1. 下载安装Sentinel\n2. 运行\n```sh\njava -jar sentinel-dashboard-1.8.1.jar\n```\n如果要修改Sentinel的默认端口、账户、密码，可以通过下列配置：\n\n| **配置项**                       | **默认值** | **说明**   |\n| -------------------------------- | ---------- | ---------- |\n| server.port                      | 8080       | 服务端口   |\n| sentinel.dashboard.auth.username | sentinel   | 默认用户名 |\n| sentinel.dashboard.auth.password | sentinel   | 默认密码   |\n\n例如，修改端口：\n```sh\njava -Dserver.port=8090 -jar sentinel-dashboard-1.8.1.jar\n```\n3. Sentinel控制台，访问http://localhost:8080 ，输入账号和密码，默认都是：sentinel\n\n### 微服务整合Sentinel\n1. 引入sentinel依赖\n```xml\n<!--sentinel-->\n<dependency>\n    <groupId>com.alibaba.cloud</groupId> \n    <artifactId>spring-cloud-starter-alibaba-sentinel</artifactId>\n</dependency>\n```\n2. 配置控制台，修改application.yaml文件，添加：\n```yaml\nserver:\n  port: 8088\nspring:\n  cloud: \n    sentinel:\n      transport:\n        dashboard: localhost:8080\n```\n3. 访问order-service的任意端点，触发sentinel的监控。访问sentinel的控制台，查看效果\n\n### 雪崩问题\n一个微服务发生故障，导致依赖于该微服务的整个服务链发生故障，甚至发生级联故障造成大范围内的微服务不可用，即微服务的雪崩问题。\n几种解决方案：\n- 超时处理：设定超时时间，请求超过一定时间没有响应就返回错误信息，不会无休止等待\n- 仓壁模式：可以限定每个业务能使用的线程数，避免耗尽整个tomcat的资源，因此也叫线程隔离\n- 断路器：由断路器统计业务执行的异常比例，如果超出阈值则会**熔断**该业务，拦截访问该业务的一切请求。\n- 流量控制：限制业务访问的QPS，避免服务因流量的突增而故障。\n\n小结：\n- **限流**是对服务的保护，避免因瞬间高并发流量而导致服务故障，进而避免雪崩。是一种**预防**措施。\n- **超时处理、线程隔离、降级熔断**是在部分服务故障时，将故障控制在一定范围，避免雪崩。是一种**补救**措施。\n\n## 流量控制\n### 簇点链路\n当请求进入微服务时，首先会访问DispatcherServlet，然后进入Controller、Service、Mapper，这样的一个调用链就叫做**簇点链路**。簇点链路中被监控的每一个接口就是一个**资源**。\n默认情况下sentinel会监控SpringMVC的每一个端点（Endpoint，也就是controller中的方法），因此SpringMVC的每一个端点（Endpoint）就是调用链路中的一个资源。\n### 流控模式\n- 直接：统计当前资源的请求，触发阈值时对当前资源直接限流，也是默认的模式\n- 关联：统计与当前资源相关的另一个资源，触发阈值时，对当前资源限流\n- 链路：统计从指定链路访问到本资源的请求，触发阈值时，对指定链路限流\n\n### 流控效果\n流控效果是指请求达到流控阈值时应该采取的措施，包括三种：\n- 快速失败：达到阈值后，新的请求会被立即拒绝并抛出FlowException异常。是默认的处理方式。\n- warm up：预热模式，对超出阈值的请求同样是拒绝并抛出异常。但这种模式阈值会动态变化，从一个较小值逐渐增加到最大阈值。\n- 排队等待：让所有的请求按照先后次序排队执行，两个请求的间隔不能小于指定时长\n\n### 热点参数限流\n限流是统计访问某个资源的所有请求，判断是否超过QPS阈值。而热点参数限流是**分别统计参数值相同的请求**，判断是否超过QPS阈值。\nPS：热点参数限流对默认的SpringMVC资源无效，需要利用@SentinelResource注解标记资源\n\n## 隔离、降级\n限流是一种预防措施，虽然可以尽量避免因高并发而引起的服务故障，但服务还会因为其它原因而故障。要将这些故障控制在一定范围，避免雪崩，就要靠**线程隔离**（舱壁模式）和**熔断降级**\n不管是线程隔离还是熔断降级，都是对**客户端**（调用方）的保护。需要在**调用方** 发起远程调用时做线程隔离、或者服务熔断。我们的微服务远程调用都是基于Feign来完成的，因此我们需要将Feign与Sentinel整合，在Feign里面实现线程隔离和服务熔断。\n### FeignClient整合Sentinel\n1. 修改配置，开启sentinel功能\n修改OrderService的application.yml文件，开启Feign的Sentinel功能：\n```yml\nfeign:\n  sentinel:\n    enabled: true # 开启feign对sentinel的支持\n```\n2. 编写失败降级逻辑\n业务失败后，不能直接报错，而应该返回用户一个友好提示或者默认结果，这个就是失败降级逻辑。给FeignClient编写失败后的降级逻辑：\n- 方式一：FallbackClass，无法对远程调用的异常做处理\n- 方式二：FallbackFactory，可以对远程调用的异常做处理（推荐使用）\n\neg：降级逻辑实现方式二\n1. 自定义类实现FallbackFactory\n```java\npackage cn.itcast.feign.clients.fallback;\n\nimport cn.itcast.feign.clients.UserClient;\nimport cn.itcast.feign.pojo.User;\nimport feign.hystrix.FallbackFactory;\nimport lombok.extern.slf4j.Slf4j;\n\n@Slf4j\npublic class UserClientFallbackFactory implements FallbackFactory<UserClient> {\n    @Override\n    public UserClient create(Throwable throwable) {\n        return new UserClient() {\n            @Override\n            public User findById(Long id) {\n                log.error(\"查询用户异常\", throwable);\n                return new User();\n            }\n        };\n    }\n}\n```\n2. 将自定义类UserClientFallbackFactory注册为一个Bean\n```java\n@Bean\npublic UserClientFallbackFactory userClientFallbackFactory(){\n    return new UserClientFallbackFactory();\n}\n```\n3. 在UserClient接口中使用UserClientFallbackFactory\n```java\nimport cn.itcast.feign.clients.fallback.UserClientFallbackFactory;\nimport cn.itcast.feign.pojo.User;\nimport org.springframework.cloud.openfeign.FeignClient;\nimport org.springframework.web.bind.annotation.GetMapping;\nimport org.springframework.web.bind.annotation.PathVariable;\n\n@FeignClient(value = \"userservice\", fallbackFactory = UserClientFallbackFactory.class)\npublic interface UserClient {\n\n    @GetMapping(\"/user/{id}\")\n    User findById(@PathVariable(\"id\") Long id);\n}\n```\n\n### 线程隔离（舱壁模式）\n线程隔离有两种方式实现：\n- 线程池隔离：给每个服务调用业务分配一个线程池，利用线程池本身实现隔离效果\n- 信号量隔离（Sentinel默认采用）：不创建线程池，而是计数器模式，记录业务使用的线程数量，达到信号量上限时，禁止新的请求\n\n### 熔断降级\n**断路器**统计服务调用的异常比例、慢请求比例，如果超出阈值则会**熔断**该服务。即拦截访问该服务的一切请求；而当服务恢复时，断路器会放行访问该服务的请求。断路器控制熔断和放行是通过状态机来完成的：\n{% asset_img 043.jpg %}\n\n状态机包括三个状态：\n- closed：关闭状态，断路器放行所有请求，并开始统计异常比例、慢请求比例。超过阈值则切换到open状态\n- open：打开状态，服务调用被**熔断**，访问被熔断服务的请求会被拒绝，快速失败，直接走降级逻辑。Open状态5秒后会进入half-open状态\n- half-open：半开状态，放行一次请求，根据执行结果来判断接下来的操作。\n  - 请求成功：则切换到closed状态\n  - 请求失败：则切换到open状态\n\n断路器熔断策略有三种：\n- 慢调用：业务的响应时长（RT）大于指定时长的请求认定为慢调用请求。在指定时间内，如果请求数量超过设定的最小数量，慢调用比例大于设定的阈值，则触发熔断\n- 异常比例：统计指定时间内的调用，如果调用次数超过指定请求数，并且出现异常的比例达到设定的比例阈值，则触发熔断\n- 异常数：统计指定时间内的调用，如果调用次数超过指定请求数，并且出现异常超过指定异常数达，则触发熔断\n\n## 授权规则\n### 授权规则\n授权规则可以对调用方的来源做控制，有白名单和黑名单两种方式。\n- 白名单：来源（origin）在白名单内的调用者允许访问\n- 黑名单：来源（origin）在黑名单内的调用者不允许访问\n{% asset_img 044.jpg %}\n\n通过**流控应用**选项来指定调用方，sentiel通过获取Request请求头中的**origin**字段来获取调用方的名称。\n#### 获取origin\nSentinel是通过RequestOriginParser这个接口的parseOrigin来获取请求的来源的。默认情况下，sentinel不管请求者从哪里来，返回值永远是default。\n```java\npublic interface RequestOriginParser {\n    /**\n     * 从请求request对象中获取origin，获取方式自定义\n     */\n    String parseOrigin(HttpServletRequest request);\n}\n```\n因此，我们需要自定义这个接口的实现，让**不同的请求，返回不同的origin**\neg：order-service服务中，定义一个RequestOriginParser的实现类\n```java\npackage cn.itcast.order.sentinel;\n\nimport com.alibaba.csp.sentinel.adapter.spring.webmvc.callback.RequestOriginParser;\nimport org.springframework.stereotype.Component;\nimport org.springframework.util.StringUtils;\n\nimport javax.servlet.http.HttpServletRequest;\n\n@Component\npublic class HeaderOriginParser implements RequestOriginParser {\n    @Override\n    public String parseOrigin(HttpServletRequest request) {\n        // 1.获取请求头\n        String origin = request.getHeader(\"origin\");\n        // 2.非空判断\n        if (StringUtils.isEmpty(origin)) {\n            origin = \"blank\";\n        }\n        return origin;\n    }\n}\n```\n#### 请求附带origin请求头\n获取origin的方式是从reques-header中获取origin值，我们需要让**所有从gateway路由到微服务的请求都带上origin头**。\n利用GatewayFilter——AddRequestHeaderGatewayFilter。修改gateway服务中的application.yml，添加一个defaultFilter：\n```yml\nspring:\n  cloud:\n    gateway:\n      default-filters:\n        - AddRequestHeader=origin,gateway\n      routes:\n       # ...略\n```\n#### 配置授权规则\n{% asset_img 045.jpg %}\n跳过网关，访问order-service服务，结果如下：\n{% asset_img 046.jpg %}:\n通过gateway网关访问，结果如下：\n{% asset_img 047.jpg %}\n\n### 自定义异常\n默认情况下，发生限流、降级、授权拦截时，都会抛出异常到调用方。异常结果都是flow limmiting（限流）。这样不够友好，无法得知是限流还是降级还是授权拦截。\n\n```java\npublic interface BlockExceptionHandler {\n    /**\n     * 处理请求被限流、降级、授权拦截时抛出的异常：BlockException\n     */\n    void handle(HttpServletRequest request, HttpServletResponse response, BlockException e) throws Exception;\n}\n```\n- BlockException e：被sentinel拦截时抛出的异常，子类如下\n\n| **异常**             | **说明**           |\n| -------------------- | ------------------ |\n| FlowException        | 限流异常           |\n| ParamFlowException   | 热点参数限流的异常 |\n| DegradeException     | 降级异常           |\n| AuthorityException   | 授权规则异常       |\n| SystemBlockException | 系统规则异常       |\n\n自定义异常处理类：\n```java\npackage cn.itcast.order.sentinel;\n\nimport com.alibaba.csp.sentinel.adapter.spring.webmvc.callback.BlockExceptionHandler;\nimport com.alibaba.csp.sentinel.slots.block.BlockException;\nimport com.alibaba.csp.sentinel.slots.block.authority.AuthorityException;\nimport com.alibaba.csp.sentinel.slots.block.degrade.DegradeException;\nimport com.alibaba.csp.sentinel.slots.block.flow.FlowException;\nimport com.alibaba.csp.sentinel.slots.block.flow.param.ParamFlowException;\nimport org.springframework.stereotype.Component;\n\nimport javax.servlet.http.HttpServletRequest;\nimport javax.servlet.http.HttpServletResponse;\n\n@Component\npublic class SentinelExceptionHandler implements BlockExceptionHandler {\n    @Override\n    public void handle(HttpServletRequest request, HttpServletResponse response, BlockException e) throws Exception {\n        String msg = \"未知异常\";\n        int status = 429;\n\n        if (e instanceof FlowException) {\n            msg = \"请求被限流了\";\n        } else if (e instanceof ParamFlowException) {\n            msg = \"请求被热点参数限流\";\n        } else if (e instanceof DegradeException) {\n            msg = \"请求被降级了\";\n        } else if (e instanceof AuthorityException) {\n            msg = \"没有权限访问\";\n            status = 401;\n        }\n\n        response.setContentType(\"application/json;charset=utf-8\");\n        response.setStatus(status);\n        response.getWriter().println(\"{\\\"msg\\\": \" + msg + \", \\\"status\\\": \" + status + \"}\");\n    }\n}\n```\n\n## 规则持久化\nsentinel的所有规则都是内存存储，重启后所有规则都会丢失。在生产环境下，必须确保这些规则的持久化，避免丢失。\n规则是否能持久化，取决于规则管理模式，sentinel支持三种规则管理模式：\n- 原始模式：Sentinel的默认模式，将规则保存在内存，重启服务会丢失。\n- pull模式：控制台将配置的规则推送到Sentinel客户端，而客户端会将配置规则保存在本地文件或数据库中。以后会定时去本地文件或数据库中查询，更新本地规则\n{% asset_img 048.jpg %}\n- push模式：控制台将配置规则推送到远程配置中心，例如Nacos。Sentinel客户端监听Nacos，获取配置变更的推送消息，完成本地配置更新\n{% asset_img 049.jpg %}\n\n配置方法参见官网：https://sentinelguard.io/zh-cn/docs/dynamic-rule-configuration.html\n\n# 分布式事务\n在分布式系统下，一个业务跨越多个服务或数据源，每个服务都是一个分支事务，要保证所有分支事务最终状态一致，这样的事务就是分布式事务。\n## CAP定理\n加州大学的计算机科学家 Eric Brewer 提出，分布式系统有三个指标：\n- Consistency（一致性）\n- Availability（可用性）\n- Partition tolerance （分区容错性）\n{% asset_img 050.jpg %}\n\nCAP定理：分布式系统，不可能同时满足三个指标\n- 一致性：用户访问分布式系统中的任意节点，得到的数据必须一致\n- 可用性：用户访问集群中的任意健康节点，必须能得到响应，而不是超时或拒绝\n- 分区容错性：\n\t- 分区：因为网络故障或其它原因导致分布式系统中的部分节点与其它节点失去连接，形成独立分区。\n\t- 容错：在集群出现分区时，整个系统也要持续对外提供服务\n\n在分布式系统中，系统间的网络不能100%保证健康，一定会有故障的时候，而服务有必须对外保证服务。因此Partition Tolerance（分区容错性）是不可或缺的。\n- 如果此时要保证**一致性**，就必须等待网络恢复，完成数据同步后，整个集群才对外提供服务，服务处于阻塞状态，不可用\n- 如果此时要保证**可用性**，就不能等待网络恢复，那node01、node02与node03之间就会出现数据不一致\n\n## BASE理论\nBASE理论是对CAP的一种解决思路，包含三个思想：\n- **Basically Available** **（基本可用）**：分布式系统在出现故障时，允许损失部分可用性，即保证核心可用。\n- **Soft State（软状态）：**在一定时间内，允许出现中间状态，比如临时的不一致状态。\n- **Eventually Consistent（最终一致性）**：虽然无法保证强一致性，但是在软状态结束后，最终达到数据一致。\n\n### 分布式事务解决思路\n分布式事务最大的问题是各个子事务的一致性问题，因此可以借鉴CAP定理和BASE理论，有两种解决思路：\n- AP模式：各子事务分别执行和提交，允许出现结果不一致，然后采用弥补措施恢复数据即可，实现最终一致\n- CP模式：各个子事务执行后互相等待，同时提交，同时回滚，达成强一致。但事务等待过程中，处于弱可用状态\n\n## Seata\nSeata是 2019 年 1 月份蚂蚁金服和阿里巴巴共同开源的分布式事务解决方案。致力于提供高性能和简单易用的分布式事务服务，为用户打造一站式的分布式解决方案。官网地址：http://seata.io/ 。\nSeata事务管理中有三个重要的角色：\n- **TC (Transaction Coordinator) -** **事务协调者：**维护全局和分支事务的状态，协调全局事务提交或回滚。\n- **TM (Transaction Manager) -** **事务管理器：**定义全局事务的范围、开始全局事务、提交或回滚全局事务。\n- **RM (Resource Manager) -** **资源管理器：**管理分支事务处理的资源，与TC交谈以注册分支事务和报告分支事务的状态，并驱动分支事务提交或回滚。\n{% asset_img 051.jpg %}\n\nSeata基于上述架构提供了四种不同的分布式事务解决方案：\n- XA模式：强一致性分阶段事务模式，牺牲了一定的可用性，无业务侵入\n- TCC模式：最终一致的分阶段事务模式，有业务侵入\n- AT模式：最终一致的分阶段事务模式，无业务侵入，也是Seata的默认模式\n- SAGA模式：长事务模式，有业务侵入\n\nPS：无论哪种方案，都离不开事务的协调者TC。\n\n### Seata tc-server 部署\n#### 1. 下载安装seata-server\n访问官网：http://seata.io/ ，下载安装解压压缩包\n#### 2. 修改conf目录下registry.conf文件\n```properties\nregistry {\n  # tc服务的注册中心类，这里选择nacos，也可以是eureka、zookeeper等\n  type = \"nacos\"\n\n  nacos {\n    # seata tc 服务注册到 nacos的服务名称，可以自定义\n    application = \"seata-tc-server\"\n    serverAddr = \"127.0.0.1:8848\"\n    group = \"DEFAULT_GROUP\"\n    namespace = \"\"\n    cluster = \"SH\"\n    username = \"nacos\"\n    password = \"nacos\"\n  }\n}\n\nconfig {\n  # 读取tc服务端的配置文件的方式，这里是从nacos配置中心读取，这样如果tc是集群，可以共享配置\n  type = \"nacos\"\n  # 配置nacos地址等信息\n  nacos {\n    serverAddr = \"127.0.0.1:8848\"\n    namespace = \"\"\n    group = \"SEATA_GROUP\"\n    username = \"nacos\"\n    password = \"nacos\"\n    dataId = \"seataServer.properties\"\n  }\n}\n```\n#### 3. nacos添加配置信息\n让tc服务的集群可以共享配置，我们选择了nacos作为统一配置中心。因此服务端配置文件seataServer.properties文件需要在nacos中配好。\n```properties\n# 数据存储方式，db代表数据库\nstore.mode=db\nstore.db.datasource=druid\nstore.db.dbType=mysql\nstore.db.driverClassName=com.mysql.jdbc.Driver\nstore.db.url=jdbc:mysql://127.0.0.1:3306/seata?useUnicode=true&rewriteBatchedStatements=true\nstore.db.user=root\nstore.db.password=123\nstore.db.minConn=5\nstore.db.maxConn=30\nstore.db.globalTable=global_table\nstore.db.branchTable=branch_table\nstore.db.queryLimit=100\nstore.db.lockTable=lock_table\nstore.db.maxWait=5000\n# 事务、日志等配置\nserver.recovery.committingRetryPeriod=1000\nserver.recovery.asynCommittingRetryPeriod=1000\nserver.recovery.rollbackingRetryPeriod=1000\nserver.recovery.timeoutRetryPeriod=1000\nserver.maxCommitRetryTimeout=-1\nserver.maxRollbackRetryTimeout=-1\nserver.rollbackRetryTimeoutUnlockEnable=false\nserver.undo.logSaveDays=7\nserver.undo.logDeletePeriod=86400000\n\n# 客户端与服务端传输方式\ntransport.serialization=seata\ntransport.compressor=none\n# 关闭metrics功能，提高性能\nmetrics.enabled=false\nmetrics.registryType=compact\nmetrics.exporterList=prometheus\nmetrics.exporterPrometheusPort=9898\n```\nPS：注意修改数据库地址、用户名、密码\n#### 5. 创建数据库表\ntc服务在管理分布式事务时，需要记录事务相关数据到数据库中，需要提前创建表。\n新建seata数据库，运行sql语句\n```sql\nSET NAMES utf8mb4;\nSET FOREIGN_KEY_CHECKS = 0;\n\n-- ----------------------------\n-- 分支事务表\n-- ----------------------------\nDROP TABLE IF EXISTS `branch_table`;\nCREATE TABLE `branch_table`  (\n  `branch_id` bigint(20) NOT NULL,\n  `xid` varchar(128) CHARACTER SET utf8 COLLATE utf8_general_ci NOT NULL,\n  `transaction_id` bigint(20) NULL DEFAULT NULL,\n  `resource_group_id` varchar(32) CHARACTER SET utf8 COLLATE utf8_general_ci NULL DEFAULT NULL,\n  `resource_id` varchar(256) CHARACTER SET utf8 COLLATE utf8_general_ci NULL DEFAULT NULL,\n  `branch_type` varchar(8) CHARACTER SET utf8 COLLATE utf8_general_ci NULL DEFAULT NULL,\n  `status` tinyint(4) NULL DEFAULT NULL,\n  `client_id` varchar(64) CHARACTER SET utf8 COLLATE utf8_general_ci NULL DEFAULT NULL,\n  `application_data` varchar(2000) CHARACTER SET utf8 COLLATE utf8_general_ci NULL DEFAULT NULL,\n  `gmt_create` datetime(6) NULL DEFAULT NULL,\n  `gmt_modified` datetime(6) NULL DEFAULT NULL,\n  PRIMARY KEY (`branch_id`) USING BTREE,\n  INDEX `idx_xid`(`xid`) USING BTREE\n) ENGINE = InnoDB CHARACTER SET = utf8 COLLATE = utf8_general_ci ROW_FORMAT = Compact;\n\n-- ----------------------------\n-- 全局事务表\n-- ----------------------------\nDROP TABLE IF EXISTS `global_table`;\nCREATE TABLE `global_table`  (\n  `xid` varchar(128) CHARACTER SET utf8 COLLATE utf8_general_ci NOT NULL,\n  `transaction_id` bigint(20) NULL DEFAULT NULL,\n  `status` tinyint(4) NOT NULL,\n  `application_id` varchar(32) CHARACTER SET utf8 COLLATE utf8_general_ci NULL DEFAULT NULL,\n  `transaction_service_group` varchar(32) CHARACTER SET utf8 COLLATE utf8_general_ci NULL DEFAULT NULL,\n  `transaction_name` varchar(128) CHARACTER SET utf8 COLLATE utf8_general_ci NULL DEFAULT NULL,\n  `timeout` int(11) NULL DEFAULT NULL,\n  `begin_time` bigint(20) NULL DEFAULT NULL,\n  `application_data` varchar(2000) CHARACTER SET utf8 COLLATE utf8_general_ci NULL DEFAULT NULL,\n  `gmt_create` datetime NULL DEFAULT NULL,\n  `gmt_modified` datetime NULL DEFAULT NULL,\n  PRIMARY KEY (`xid`) USING BTREE,\n  INDEX `idx_gmt_modified_status`(`gmt_modified`, `status`) USING BTREE,\n  INDEX `idx_transaction_id`(`transaction_id`) USING BTREE\n) ENGINE = InnoDB CHARACTER SET = utf8 COLLATE = utf8_general_ci ROW_FORMAT = Compact;\n\nSET FOREIGN_KEY_CHECKS = 1;\n```\n#### 6. 启动TC服务\n运行bin目录下seata-server.bat。打开浏览器，访问nacos地址：http://localhost:8848 ，进入服务列表页面，可以看到seata-tc-server的信息\n\n### 微服务集成Seata\n1. 引入Seata依赖\n```xml\n<dependency>\n    <groupId>com.alibaba.cloud</groupId>\n    <artifactId>spring-cloud-starter-alibaba-seata</artifactId>\n    <exclusions>\n        <!--版本较低，1.3.0，因此排除-->\n        <exclusion>\n            <artifactId>seata-spring-boot-starter</artifactId>\n            <groupId>io.seata</groupId>\n        </exclusion>\n    </exclusions>\n</dependency>\n<!--seata starter 采用1.4.2版本-->\n<dependency>\n    <groupId>io.seata</groupId>\n    <artifactId>seata-spring-boot-starter</artifactId>\n    <version>${seata.version}</version>\n</dependency>\n```\n2. 修改配置文件\n```yaml\nseata:\n  registry: # TC服务注册中心的配置，微服务根据这些信息去注册中心获取tc服务地址\n    # 参考tc服务自己的registry.conf中的配置\n    type: nacos\n    nacos: # tc\n      server-addr: 127.0.0.1:8848\n      namespace: \"\"\n      group: DEFAULT_GROUP\n      application: seata-tc-server # tc服务在nacos中的服务名称\n      cluster: SH\n  tx-service-group: seata-demo # 事务组，根据这个获取tc服务的cluster名称\n  service:\n    vgroup-mapping: # 事务组与TC服务cluster的映射关系\n      seata-demo: SH\n```\n微服务如何根据这些配置寻找TC的地址呢？注册到Nacos中的微服务，确定一个具体实例需要四个信息：\n- namespace：命名空间\n- group：分组\n- application：服务名\n- cluster：集群名\n\n以上四个信息，在刚才的yaml文件中都能找到：\n{% asset_img 053.jpg %}\n\nnamespace为空，就是默认的public。结合起来，TC服务的信息就是：public@DEFAULT_GROUP@seata-tc-server@SH，这样就能确定TC服务集群了。然后就可以去Nacos拉取对应的实例信息了。\n\n### Seata分布式事务解决方案\n#### XA模式\nXA是规范，目前主流数据库都实现了这种规范，实现的原理都是基于两阶段提交。\n正常情况：\n{% asset_img 054.jpg %}\n异常情况：\n{% asset_img 055.jpg %}\n\n一阶段：\n- 事务协调者通知每个事物参与者执行本地事务\n- 本地事务执行完成后报告事务执行状态给事务协调者，此时事务不提交，继续持有数据库锁\n\n二阶段：\n- 事务协调者基于一阶段的报告来判断下一步操作\n  - 如果一阶段都成功，则通知所有事务参与者，提交事务\n  - 如果一阶段任意一个参与者失败，则通知所有事务参与者回滚事务\n\n**XA模式优缺点**\n优点：\n- 事务的强一致性，满足ACID原则。\n- 常用数据库都支持，实现简单，并且没有代码侵入\n\n缺点：\n- 因为一阶段需要锁定数据库资源，等待二阶段结束才释放，性能较差\n- 依赖关系型数据库实现事务\n\n**Seata XA**模型：Seata对原始的XA模式做了简单的封装和改造，以适应自己的事务模型\n{% asset_img 056.jpg %}\n\nRM一阶段的工作：\n- 注册分支事务到TC\n- 执行分支业务sql但不提交\n- 报告执行状态到TC\n\nTC二阶段的工作：\n- TC检测各分支事务执行状态\n  a.如果都成功，通知所有RM提交事务\n  b.如果有失败，通知所有RM回滚事务\n\nRM二阶段的工作：\n- 接收TC指令，提交或回滚事务\n\n**Seata实现XA模式**：\n\n- 修改application.yml文件（每个参与事务的微服务），开启XA模式\n```yaml\nseata:\n  data-source-proxy-mode: XA\n```\n- 给发起全局事务的入口方法添加@GlobalTransactional注解\n- 重启服务并测试\n\n#### AT模式\n**Seata AT模型**：\n{% asset_img 057.jpg %}\n\n阶段一RM的工作：\n- 注册分支事务\n- 记录undo-log（数据快照）\n- 执行业务sql并提交\n- 报告事务状态\n\n阶段二提交时RM的工作：\n- 删除undo-log即可\n\n阶段二回滚时RM的工作：\n- 根据undo-log恢复数据到更新前\n\n简述**AT与XA的区别**\n- XA模式一阶段不提交事务，锁定资源；AT模式一阶段直接提交，不锁定资源。\n- XA模式依赖数据库机制实现回滚；AT模式利用数据快照实现数据回滚。\n- XA模式强一致；AT模式最终一致\n\n##### 脏写问题\n在多线程并发访问AT模式的分布式事务时，有可能出现脏写问题，如图：\n{% asset_img 058.jpg %}\n解决思路就是引入了全局锁的概念。在释放DB锁之前，先拿到全局锁。避免同一时刻有另外一个事务来操作当前数据。\n{% asset_img 059.jpg %}\n\n**实现AT模式**\n1. 导入数据库表，记录全局锁\n```sql\n/*\n Navicat Premium Data Transfer\n\n Source Server         : local\n Source Server Type    : MySQL\n Source Server Version : 50622\n Source Host           : localhost:3306\n Source Schema         : seata_demo\n\n Target Server Type    : MySQL\n Target Server Version : 50622\n File Encoding         : 65001\n\n Date: 20/06/2021 12:39:03\n*/\n\nSET NAMES utf8mb4;\nSET FOREIGN_KEY_CHECKS = 0;\n\n-- ----------------------------\n-- Table structure for undo_log\n-- ----------------------------\nDROP TABLE IF EXISTS `undo_log`;\nCREATE TABLE `undo_log`  (\n  `branch_id` bigint(20) NOT NULL COMMENT 'branch transaction id',\n  `xid` varchar(100) CHARACTER SET utf8 COLLATE utf8_general_ci NOT NULL COMMENT 'global transaction id',\n  `context` varchar(128) CHARACTER SET utf8 COLLATE utf8_general_ci NOT NULL COMMENT 'undo_log context,such as serialization',\n  `rollback_info` longblob NOT NULL COMMENT 'rollback info',\n  `log_status` int(11) NOT NULL COMMENT '0:normal status,1:defense status',\n  `log_created` datetime(6) NOT NULL COMMENT 'create datetime',\n  `log_modified` datetime(6) NOT NULL COMMENT 'modify datetime',\n  UNIQUE INDEX `ux_undo_log`(`xid`, `branch_id`) USING BTREE\n) ENGINE = InnoDB CHARACTER SET = utf8 COLLATE = utf8_general_ci COMMENT = 'AT transaction mode undo table' ROW_FORMAT = Compact;\n\n-- ----------------------------\n-- Records of undo_log\n-- ----------------------------\n\n\n\n-- ----------------------------\n-- Table structure for lock_table\n-- ----------------------------\nDROP TABLE IF EXISTS `lock_table`;\nCREATE TABLE `lock_table`  (\n  `row_key` varchar(128) CHARACTER SET utf8 COLLATE utf8_general_ci NOT NULL,\n  `xid` varchar(96) CHARACTER SET utf8 COLLATE utf8_general_ci NULL DEFAULT NULL,\n  `transaction_id` bigint(20) NULL DEFAULT NULL,\n  `branch_id` bigint(20) NOT NULL,\n  `resource_id` varchar(256) CHARACTER SET utf8 COLLATE utf8_general_ci NULL DEFAULT NULL,\n  `table_name` varchar(32) CHARACTER SET utf8 COLLATE utf8_general_ci NULL DEFAULT NULL,\n  `pk` varchar(36) CHARACTER SET utf8 COLLATE utf8_general_ci NULL DEFAULT NULL,\n  `gmt_create` datetime NULL DEFAULT NULL,\n  `gmt_modified` datetime NULL DEFAULT NULL,\n  PRIMARY KEY (`row_key`) USING BTREE,\n  INDEX `idx_branch_id`(`branch_id`) USING BTREE\n) ENGINE = InnoDB CHARACTER SET = utf8 COLLATE = utf8_general_ci ROW_FORMAT = Compact;\n\n\nSET FOREIGN_KEY_CHECKS = 1;\n```\n2. 修改application.yml文件，将事务模式修改为AT模式\n```yaml\nseata:\n  data-source-proxy-mode: AT # 默认就是AT\n```\n3. 重启服务并测试\n\n**AT模式优缺点**\n优点：\n- 一阶段完成直接提交事务，释放数据库资源，性能比较好\n- 利用全局锁实现读写隔离\n- 没有代码侵入，框架自动完成回滚和提交\n\n缺点：\n- 两阶段之间属于软状态，属于最终一致\n- 框架的快照功能会影响性能，但比XA模式要好很多\n\n#### TCC模式\nTCC模式通过**补偿操作**来实现数据恢复，依靠人工编码来实现。需实现三个方法：\n- Try：资源的检测和预留； \n- Confirm：完成资源操作业务；要求 Try 成功 Confirm 一定要能成功。\n- Cancel：预留资源释放，可以理解为try的反向操作。\n\n##### 案例分析\n一个扣减用户余额的业务。假设账户A原来余额是100，需要余额扣减30元。\n- **阶段一（ Try ）**：检查余额是否充足，如果充足则冻结金额增加30元，可用余额扣除30。此时，总金额 = 冻结金额 + 可用金额，数量依然是100不变。事务直接提交无需等待其它事务。\n- **阶段二（Confirm)**：假如要提交（Confirm），则冻结金额扣减30。确认可以提交，因为之前可用金额已经扣减过了，这里只要清除冻结金额。此时，总金额 = 冻结金额 + 可用金额 = 0 + 70  = 70元。\n- **阶段三(Canncel)**：如果要回滚（Cancel），则冻结金额扣减30，可用余额增加30。\n\n**TCC模型图**和AT模式几乎相同，只是数据回滚不是依赖数据快照而是通过人工编码实现。\n{% asset_img 060.jpg %}\n\n**TCC模式优缺点**\n优点：\n- 一阶段完成直接提交事务，释放数据库资源，性能好\n- 相比AT模型，无需生成快照，无需使用全局锁，性能最强\n- 不依赖数据库事务，而是依赖补偿操作，可以用于非事务型数据库\n\n缺点：\n- 有代码侵入，需要人为编写try、Confirm和Cancel接口，太麻烦\n- 软状态，事务是最终一致\n- 需要考虑Confirm和Cancel的失败情况，做好幂等处理\n\n##### 事务悬挂和空回滚\n1. 空回滚\n当某分支事务的try阶段**阻塞**时，可能导致全局事务超时而触发二阶段的cancel操作。在未执行try操作时先执行了cancel操作，这时cancel不能做回滚，就是**空回滚**。\n{% asset_img 061.jpg %}\n**执行cancel操作时，应当判断try是否已经执行，如果尚未执行，则应该空回滚。**\n2. 事务悬挂\n对于已经空回滚的业务，之前被阻塞的try操作恢复，继续执行try，就永远不可能confirm或cancel ，事务一直处于中间状态，这就是**业务（事务）悬挂**。\n**执行try操作时，应当判断cancel是否已经执行过了，如果已经执行，应当阻止空回滚后的try操作，避免悬挂**\n\n##### TCC模式实现\n**解决空回滚和业务悬挂问题，必须要记录当前事务状态，是在try、还是cancel**\n###### 1. 案例分析\n定义数据表\n```sql\nCREATE TABLE `account_freeze_tbl` (\n  `xid` varchar(128) NOT NULL,\n  `user_id` varchar(255) DEFAULT NULL COMMENT '用户id',\n  `freeze_money` int(11) unsigned DEFAULT '0' COMMENT '冻结金额',\n  `state` int(1) DEFAULT NULL COMMENT '事务状态，0:try，1:confirm，2:cancel',\n  PRIMARY KEY (`xid`) USING BTREE\n) ENGINE=InnoDB DEFAULT CHARSET=utf8 ROW_FORMAT=COMPACT;\n```\n- xid：是全局事务id\n- freeze_money：用来记录用户冻结金额\n- state：用来记录事务状态\n\n那么业务该怎么做呢？\n- Try业务：\n  - 记录冻结金额和事务状态到account_freeze表\n  - 扣减account表可用金额\n- Confirm业务\n  - 根据xid删除account_freeze表的冻结记录\n- Cancel业务\n  - 修改account_freeze表，冻结金额为0，state为2\n  - 修改account表，恢复可用金额\n- 如何判断是否空回滚？\n  - cancel业务中，根据xid查询account_freeze，如果为null则说明try还没做，需要空回滚\n- 如何避免业务悬挂？\n  - try业务中，根据xid查询account_freeze ，如果已经存在则证明Cancel已经执行，拒绝执行try业务\n\n###### 2. 声明TCC接口\nTCC的Try、Confirm、Cancel方法都需要在接口中基于注解来声明。\n新建一个接口，声明TCC三个接口：\n```java\npackage cn.itcast.account.service;\n\nimport io.seata.rm.tcc.api.BusinessActionContext;\nimport io.seata.rm.tcc.api.BusinessActionContextParameter;\nimport io.seata.rm.tcc.api.LocalTCC;\nimport io.seata.rm.tcc.api.TwoPhaseBusinessAction;\n\n@LocalTCC\npublic interface AccountTCCService {\n\n    @TwoPhaseBusinessAction(name = \"deduct\", commitMethod = \"confirm\", rollbackMethod = \"cancel\")\n    void deduct(@BusinessActionContextParameter(paramName = \"userId\") String userId,\n                @BusinessActionContextParameter(paramName = \"money\")int money);\n\n    boolean confirm(BusinessActionContext ctx);\n\n    boolean cancel(BusinessActionContext ctx);\n}\n```\n\n###### 3. 编写实现类\n新建一个类，实现TCC业务：\n```java\npackage cn.itcast.account.service.impl;\n\nimport cn.itcast.account.entity.AccountFreeze;\nimport cn.itcast.account.mapper.AccountFreezeMapper;\nimport cn.itcast.account.mapper.AccountMapper;\nimport cn.itcast.account.service.AccountTCCService;\nimport io.seata.core.context.RootContext;\nimport io.seata.rm.tcc.api.BusinessActionContext;\nimport lombok.extern.slf4j.Slf4j;\nimport org.springframework.beans.factory.annotation.Autowired;\nimport org.springframework.stereotype.Service;\nimport org.springframework.transaction.annotation.Transactional;\n\n@Service\n@Slf4j\npublic class AccountTCCServiceImpl implements AccountTCCService {\n\n    @Autowired\n    private AccountMapper accountMapper;\n    @Autowired\n    private AccountFreezeMapper freezeMapper;\n\n    @Override\n    @Transactional\n    public void deduct(String userId, int money) {\n        // 0.获取事务id\n        String xid = RootContext.getXID();\n        // 1.扣减可用余额\n        accountMapper.deduct(userId, money);\n        // 2.记录冻结金额，事务状态\n        AccountFreeze freeze = new AccountFreeze();\n        freeze.setUserId(userId);\n        freeze.setFreezeMoney(money);\n        freeze.setState(AccountFreeze.State.TRY);\n        freeze.setXid(xid);\n        freezeMapper.insert(freeze);\n    }\n\n    @Override\n    public boolean confirm(BusinessActionContext ctx) {\n        // 1.获取事务id\n        String xid = ctx.getXid();\n        // 2.根据id删除冻结记录\n        int count = freezeMapper.deleteById(xid);\n        return count == 1;\n    }\n\n    @Override\n    public boolean cancel(BusinessActionContext ctx) {\n        // 0.查询冻结记录\n        String xid = ctx.getXid();\n        AccountFreeze freeze = freezeMapper.selectById(xid);\n\n        // 1.恢复可用余额\n        accountMapper.refund(freeze.getUserId(), freeze.getFreezeMoney());\n        // 2.将冻结金额清零，状态改为CANCEL\n        freeze.setFreezeMoney(0);\n        freeze.setState(AccountFreeze.State.CANCEL);\n        int count = freezeMapper.updateById(freeze);\n        return count == 1;\n    }\n}\n```\n\n#### SAGA模式\nSeata官网对于Saga的指南：https://seata.io/zh-cn/docs/user/saga.html\n\n**原理**：\n在 Saga 模式下，分布式事务内有多个参与者，每一个参与者都是一个冲正补偿服务，需要用户根据业务场景实现其正向操作和逆向回滚操作。分布式事务执行过程中，依次执行各参与者的正向操作，如果所有正向操作均执行成功，那么分布式事务提交。如果任何一个正向操作执行失败，那么分布式事务会去退回去执行前面各参与者的逆向回滚操作，回滚已提交的参与者，使分布式事务回到初始状态。\n\nSaga分为两个阶段：\n- 一阶段：直接提交本地事务\n- 二阶段：成功则什么都不做；失败则通过编写补偿业务来回滚\n\n**SAGA优缺点**\n优点：\n- 事务参与者可以基于事件驱动实现异步调用，吞吐高\n- 一阶段直接提交事务，无锁，性能好\n- 不用编写TCC中的三个阶段，实现简单\n\n缺点：\n- 软状态持续时间不确定，时效性差\n- 没有锁，没有事务隔离，会有脏写\n\n#### 四种模式对比\n从以下几个方面来对比四种实现：\n- 一致性：能否保证事务的一致性？强一致还是最终一致？\n- 隔离性：事务之间的隔离性如何？\n- 代码侵入：是否需要对业务代码改造？\n- 性能：有无性能损耗？\n- 场景：常见的业务场景\n{% asset_img 062.jpg %}\n\n### TC服务的高可用和异地容灾\n微服务基于事务组（tx-service-group)与TC集群的映射关系，来查找当前应该使用哪个TC集群。当SH集群故障时，只需要将vgroup-mapping中的映射关系改成HZ。则所有微服务就会切换到HZ的TC集群了。\n#### 模拟异地容灾的TC集群\n计划启动两台seata的tc服务节点：\n| 节点名称 | ip地址    | 端口号 | 集群名称 |\n| -------- | --------- | ------ | -------- |\n| seata    | 127.0.0.1 | 8091   | SH       |\n| seata2   | 127.0.0.1 | 8092   | HZ       |\n\n前面我们已经启动了一台seata服务，端口是8091，集群名为SH。现在，将seata目录复制一份，起名为seata2，修改seata2/conf/registry.conf内容如下：\n```properties\nregistry {\n  # tc服务的注册中心类，这里选择nacos，也可以是eureka、zookeeper等\n  type = \"nacos\"\n\n  nacos {\n    # seata tc 服务注册到 nacos的服务名称，可以自定义\n    application = \"seata-tc-server\"\n    serverAddr = \"127.0.0.1:8848\"\n    group = \"DEFAULT_GROUP\"\n    namespace = \"\"\n    cluster = \"HZ\"\n    username = \"nacos\"\n    password = \"nacos\"\n  }\n}\n\nconfig {\n  # 读取tc服务端的配置文件的方式，这里是从nacos配置中心读取，这样如果tc是集群，可以共享配置\n  type = \"nacos\"\n  # 配置nacos地址等信息\n  nacos {\n    serverAddr = \"127.0.0.1:8848\"\n    namespace = \"\"\n    group = \"SEATA_GROUP\"\n    username = \"nacos\"\n    password = \"nacos\"\n    dataId = \"seataServer.properties\"\n  }\n}\n```\n进入seata2/bin目录，然后运行命令：\n```sh\nseata-server.bat -p 8092\n```\n打开nacos控制台，查看服务列表，点进详情查看：\n{% asset_img 052.jpg %}\n\n#### 将事务组映射配置到nacos\n需要将tx-service-group与cluster的映射关系都配置到nacos配置中心，新建一个配置：\n```properties\n# 事务组映射关系\nservice.vgroupMapping.seata-demo=SH\n\nservice.enableDegrade=false\nservice.disableGlobalTransaction=false\n# 与TC服务的通信配置\ntransport.type=TCP\ntransport.server=NIO\ntransport.heartbeat=true\ntransport.enableClientBatchSendRequest=false\ntransport.threadFactory.bossThreadPrefix=NettyBoss\ntransport.threadFactory.workerThreadPrefix=NettyServerNIOWorker\ntransport.threadFactory.serverExecutorThreadPrefix=NettyServerBizHandler\ntransport.threadFactory.shareBossWorker=false\ntransport.threadFactory.clientSelectorThreadPrefix=NettyClientSelector\ntransport.threadFactory.clientSelectorThreadSize=1\ntransport.threadFactory.clientWorkerThreadPrefix=NettyClientWorkerThread\ntransport.threadFactory.bossThreadSize=1\ntransport.threadFactory.workerThreadSize=default\ntransport.shutdown.wait=3\n# RM配置\nclient.rm.asyncCommitBufferLimit=10000\nclient.rm.lock.retryInterval=10\nclient.rm.lock.retryTimes=30\nclient.rm.lock.retryPolicyBranchRollbackOnConflict=true\nclient.rm.reportRetryCount=5\nclient.rm.tableMetaCheckEnable=false\nclient.rm.tableMetaCheckerInterval=60000\nclient.rm.sqlParserType=druid\nclient.rm.reportSuccessEnable=false\nclient.rm.sagaBranchRegisterEnable=false\n# TM配置\nclient.tm.commitRetryCount=5\nclient.tm.rollbackRetryCount=5\nclient.tm.defaultGlobalTransactionTimeout=60000\nclient.tm.degradeCheck=false\nclient.tm.degradeCheckAllowTimes=10\nclient.tm.degradeCheckPeriod=2000\n\n# undo日志配置\nclient.undo.dataValidation=true\nclient.undo.logSerialization=jackson\nclient.undo.onlyCareUpdateColumns=true\nclient.undo.logTable=undo_log\nclient.undo.compress.enable=true\nclient.undo.compress.type=zip\nclient.undo.compress.threshold=64k\nclient.log.exceptionRate=100\n```\n\n#### 微服务读取nacos配置\n修改每一个微服务的application.yml文件，让微服务读取nacos中的client.properties文件：\n```yaml\nseata:\n  config:\n    type: nacos\n    nacos:\n      server-addr: 127.0.0.1:8848\n      username: nacos\n      password: nacos\n      group: SEATA_GROUP\n      data-id: client.properties\n```\n重启微服务，现在微服务到底是连接tc的SH集群，还是tc的HZ集群，都统一由nacos的client.properties来决定了。\n\n# 分布式缓存\n参考Redis学习笔记。\n\n# 多级缓存\n多级缓存就是充分利用请求处理的每个环节，分别添加缓存，减轻Tomcat压力，提升服务性能：\n- 浏览器访问静态资源时，优先读取浏览器本地缓存\n- 访问非静态资源（ajax查询数据）时，访问服务端\n- 请求到达Nginx后，优先读取Nginx本地缓存\n- 如果Nginx本地缓存未命中，则去直接查询Redis（不经过Tomcat）\n- 如果Redis查询未命中，则查询Tomcat\n- 请求进入Tomcat后，优先查询JVM进程缓存\n- 如果JVM进程缓存未命中，则查询数据库\n{% asset_img 063.jpg %}\n\n在多级缓存架构中，Nginx内部需要编写本地缓存查询、Redis查询、Tomcat查询的业务逻辑，因此nginx服务不再是一个**反向代理服务器**，而是一个编写**业务的Web服务器了**。因此这样的业务Nginx服务也需要搭建集群来提高并发，再有专门的nginx服务来做反向代理，Tomcat服务将来也会部署为集群模式\n{% asset_img 064.jpg %}\n\n多级缓存的关键有两个：\n- 一个是在nginx中编写业务，实现nginx本地缓存、Redis、Tomcat的查询\n- 另一个就是在Tomcat中实现JVM进程缓存\n\n\n## JVM进程缓存\n### Caffeine\n**Caffeine**是一个基于Java8开发的，提供了近乎最佳命中率的高性能的本地缓存库。目前Spring内部的缓存使用的就是Caffeine。GitHub地址：https://github.com/ben-manes/caffeine\n\n缓存使用基本流程：\n\n```java\n@Test\nvoid testBasicOps() {\n    // 构建cache对象\n    Cache<String, String> cache = Caffeine.newBuilder().build();\n\n    // 存数据\n    cache.put(\"gf\", \"迪丽热巴\");\n\n    // 取数据\n    String gf = cache.getIfPresent(\"gf\");\n    System.out.println(\"gf = \" + gf);\n\n    // 取数据，包含两个参数：\n    // 参数一：缓存的key\n    // 参数二：Lambda表达式，表达式参数就是缓存的key，方法体是查询数据库的逻辑\n    // 优先根据key查询JVM缓存，如果未命中，则执行参数二的Lambda表达式\n    String defaultGF = cache.get(\"defaultGF\", key -> {\n        // 根据key去数据库查询数据\n        return \"柳岩\";\n    });\n    System.out.println(\"defaultGF = \" + defaultGF);\n}\n```\n\nCaffeine缓存驱逐策略：\n- **基于容量**：设置缓存的数量上限\n```java\n// 创建缓存对象\nCache<String, String> cache = Caffeine.newBuilder()\n    .maximumSize(1) // 设置缓存大小上限为 1\n    .build();\n```\n- **基于时间**：设置缓存的有效时间\n```java\n// 创建缓存对象\nCache<String, String> cache = Caffeine.newBuilder()\n    // 设置缓存有效期为 10 秒，从最后一次写入开始计时 \n    .expireAfterWrite(Duration.ofSeconds(10)) \n    .build();\n```\n- **基于引用**：设置缓存为软引用或弱引用，利用GC来回收缓存数据。性能较差，不建议使用\n\nPS：在默认情况下，当一个缓存元素过期的时候，Caffeine不会自动立即将其清理和驱逐。而是在一次读或写操作后，或者在空闲时间完成对失效数据的驱逐。\n\n### 缓存实现示例\neg：利用Caffeine实现下列需求：\n- 给根据id查询商品的业务添加缓存，缓存未命中时查询数据库\n- 给根据id查询商品库存的业务添加缓存，缓存未命中时查询数据库\n- 缓存初始大小为100\n- 缓存上限为10000\n\n1. 定义两个Caffeine的缓存对象，分别保存商品、库存的缓存数据\n```java\npackage com.heima.item.config;\n\nimport com.github.benmanes.caffeine.cache.Cache;\nimport com.github.benmanes.caffeine.cache.Caffeine;\nimport com.heima.item.pojo.Item;\nimport com.heima.item.pojo.ItemStock;\nimport org.springframework.context.annotation.Bean;\nimport org.springframework.context.annotation.Configuration;\n\n@Configuration\npublic class CaffeineConfig {\n\n    @Bean\n    public Cache<Long, Item> itemCache(){\n        return Caffeine.newBuilder()\n                .initialCapacity(100)\n                .maximumSize(10_000)\n                .build();\n    }\n\n    @Bean\n    public Cache<Long, ItemStock> stockCache(){\n        return Caffeine.newBuilder()\n                .initialCapacity(100)\n                .maximumSize(10_000)\n                .build();\n    }\n}\n```\n2. 修改item-service的ItemController类，添加缓存逻辑\n```java\n@RestController\n@RequestMapping(\"item\")\npublic class ItemController {\n\n    @Autowired\n    private IItemService itemService;\n    @Autowired\n    private IItemStockService stockService;\n\n    @Autowired\n    private Cache<Long, Item> itemCache;\n    @Autowired\n    private Cache<Long, ItemStock> stockCache;\n    \n    // ...其它略\n    \n    @GetMapping(\"/{id}\")\n    public Item findById(@PathVariable(\"id\") Long id) {\n        return itemCache.get(id, key -> itemService.query()\n                .ne(\"status\", 3).eq(\"id\", key)\n                .one()\n        );\n    }\n\n    @GetMapping(\"/stock/{id}\")\n    public ItemStock findStockById(@PathVariable(\"id\") Long id) {\n        return stockCache.get(id, key -> stockService.getById(key));\n    }\n}\n```\n\n## OpenRestry\n### 快速入门Lua\nLua 是一种轻量小巧的脚本语言，用标准C语言编写并以源代码形式开放， 其设计目的是为了嵌入应用程序中，从而为应用程序提供灵活的扩展和定制功能。官网：https://www.lua.org/\n\n为什么学习Lua？\n因为对Nginx进行编程需要使用Lua（Nginx本身也是C语言开发，允许基于Lua做拓展），因此要实现Nginx缓存必须了解Lua\n\n#### HellodWorld\n1. 新建 hello.lua 文件\n2. 添加Lua语句\n```lua\nprint(\"Hello World!\")  \n```\n3. 运行\n```sh\nlua hello.lua\n```\n\n#### 变量、循环\nLua中支持的常见数据类型包括：\n{% asset_img 065.png%}\n\nPS：Lua提供了type()函数来判断一个变量的数据类型\n\n**声明变量**：\nLua声明变量的时候无需指定数据类型，而是用local来声明变量为局部变量\n```lua\n-- 声明字符串，可以用单引号或双引号，\nlocal str = 'hello'\n-- 字符串拼接可以使用 ..\nlocal str2 = 'hello' .. 'world'\n-- 声明数字\nlocal num = 21\n-- 声明布尔类型\nlocal flag = true\n```\nLua中的table类型既可以作为数组，又可以作为map。数组就是特殊的table，key是数组角标而已：\n```lua\n-- 声明数组 ，key为角标的 table\nlocal arr = {'java', 'python', 'lua'}\n-- 声明table，类似java的map\nlocal map =  {name='Jack', age=21}\n\n-- 访问数组，lua数组的角标从1开始\nprint(arr[1])\n\n-- 访问table,可以用key来访问\nprint(map['name'])\nprint(map.name)\n```\n\n**循环**：\n```lua\n-- 声明数组 key为索引的 table\nlocal arr = {'java', 'python', 'lua'}\n-- 遍历数组\nfor index,value in ipairs(arr) do\n    print(index, value) \nend\n\n-- 声明map，也就是table\nlocal map = {name='Jack', age=21}\n-- 遍历table\nfor key,value in pairs(map) do\n   print(key, value) \nend\n```\n\n#### 条件控制、函数\n**函数**：\n定义函数\n```lua\nfunction 函数名( argument1, argument2..., argumentn)\n    -- 函数体\n    return 返回值\nend\n```\n条件控制\n```lua\nif(布尔表达式)\nthen\n   --[ 布尔表达式为 true 时执行该语句块 --]\nelse\n   --[ 布尔表达式为 false 时执行该语句块 --]\nend\n```\nPS：与java不同，布尔表达式中的逻辑运算是基于英文单词\n{% asset_img 066.png %}\n\n### 安装OpenRestry\nOpenResty® 是一个基于 Nginx的高性能 Web 平台，用于方便地搭建能够处理超高并发、扩展性极高的动态 Web 应用、Web 服务和动态网关：\n- 具备Nginx的完整功能\n- 基于Lua语言进行扩展，集成了大量精良的 Lua 库、第三方模块\n- 允许使用Lua**自定义业务逻辑**、**自定义库**\n\n1. 安装开发库\n```sh\nyum install -y pcre-devel openssl-devel gcc --skip-broken\n```\n2. 安装OpenResty\n（CentOS）添加 `openresty` 仓库，可以便于未来安装或更新软件包（通过 `yum check-update` 命令）\n```sh\nyum-config-manager --add-repo https://openresty.org/package/centos/openresty.repo\n```\n如果提示说命令不存在，则运行：\n```sh\nyum install -y yum-utils \n```\n3. 安装OpenResty\n```sh\nyum install -y openresty\n```\n4. 安装opm工具\nopm是OpenResty的一个管理工具，可以帮助我们安装一个第三方的Lua模块\n```sh\nyum install -y openresty-opm\n```\n5. 目录结构\n默认情况下，OpenResty安装的目录是：/usr/local/openresty。OpenResty就是在Nginx基础上集成了一些Lua模块。\n6. 配置nginx的环境变量\n- 打开配置文件\n```sh\nvi /etc/profile\n```\n- 添加内容（NGINX_HOME：后面是OpenResty安装目录下的nginx的目录）\n```sh\nexport NGINX_HOME=/usr/local/openresty/nginx\nexport PATH=${NGINX_HOME}/sbin:$PATH\n```\n- 配置生效\n```sh\nsource /etc/profile\n```\n7. 启动运行\n```sh\n# 启动nginx\nnginx\n# 重新加载配置\nnginx -s reload\n# 停止\nnginx -s stop\n```\n**备注**：\n加载OpenResty的lua模块：\n\n```nginx\n#lua 模块\nlua_package_path \"/usr/local/openresty/lualib/?.lua;;\";\n#c模块     \nlua_package_cpath \"/usr/local/openresty/lualib/?.so;;\";  \n```\ncommon.lua\n```lua\n-- 封装函数，发送http请求，并解析响应\nlocal function read_http(path, params)\n    local resp = ngx.location.capture(path,{\n        method = ngx.HTTP_GET,\n        args = params,\n    })\n    if not resp then\n        -- 记录错误信息，返回404\n        ngx.log(ngx.ERR, \"http not found, path: \", path , \", args: \", args)\n        ngx.exit(404)\n    end\n    return resp.body\nend\n-- 将方法导出\nlocal _M = {  \n    read_http = read_http\n}  \nreturn _M\n```\n释放Redis连接API：\n```lua\n-- 关闭redis连接的工具方法，其实是放入连接池\nlocal function close_redis(red)\n    local pool_max_idle_time = 10000 -- 连接的空闲时间，单位是毫秒\n    local pool_size = 100 --连接池大小\n    local ok, err = red:set_keepalive(pool_max_idle_time, pool_size)\n    if not ok then\n        ngx.log(ngx.ERR, \"放入redis连接池失败: \", err)\n    end\nend\n```\n读取Redis数据的API：\n```lua\n-- 查询redis的方法 ip和port是redis地址，key是查询的key\nlocal function read_redis(ip, port, key)\n    -- 获取一个连接\n    local ok, err = red:connect(ip, port)\n    if not ok then\n        ngx.log(ngx.ERR, \"连接redis失败 : \", err)\n        return nil\n    end\n    -- 查询redis\n    local resp, err = red:get(key)\n    -- 查询失败处理\n    if not resp then\n        ngx.log(ngx.ERR, \"查询Redis失败: \", err, \", key = \" , key)\n    end\n    --得到的数据为空处理\n    if resp == ngx.null then\n        resp = nil\n        ngx.log(ngx.ERR, \"查询Redis数据为空, key = \", key)\n    end\n    close_redis(red)\n    return resp\nend\n```\n开启共享词典：\n```nginx\n# 共享字典，也就是本地缓存，名称叫做：item_cache，大小150m\nlua_shared_dict item_cache 150m; \n```\n\n### 监听请求\n我们希望达到的多级缓存架构如图：\n{% asset_img 067.png %}\n- windows上的nginx用来做反向代理服务，将前端的查询商品的ajax请求代理到OpenResty集群\n- OpenResty集群用来编写多级缓存业务\n\n**反向代理流程**:\n1. 浏览器发送请求,请求被nginx拦截\n2. nginx将请求代理到OpenResty集群\n{% asset_img 068.png %}\n\n#### 1. 添加OpenResty对Lua模块的加载\n修改`/usr/local/openresty/nginx/conf/nginx.conf`文件，在其中的http下面，添加下面代码：\n```nginx\n#lua 模块\nlua_package_path \"/usr/local/openresty/lualib/?.lua;;\";\n#c模块     \nlua_package_cpath \"/usr/local/openresty/lualib/?.so;;\";  \n```\n\n#### 2. 监听路径，配置响应文件\n修改`/usr/local/openresty/nginx/conf/nginx.conf`文件，在nginx.conf的server下面，添加对/api/item这个路径的监听：\n```nginx\nlocation  /api/item {\n    # 默认的响应类型\n    default_type application/json;\n    # 响应结果由lua/item.lua文件来决定\n    content_by_lua_file lua/item.lua;\n}\n```\n类似于SpringMVC中的`@GetMapping(\"/api/item\")`路径映射。而`content_by_lua_file lua/item.lua`则相当于调用item.lua这个文件，执行其中的业务，把结果返回给用户，相当于java中调用service。\n\n#### 3. 编写Lua文件\n1. 在`/usr/loca/openresty/nginx`目录创建文件夹`lua`并在目录`lua`下新建`item.lua`文件\n2. 在`item.lua`中编写业务逻辑\n```lua\nngx.say('{\"id\":10001,\"name\":\"SALSA AIR\",\"title\":\"RIMOWA 21寸托运箱拉杆箱 SALSA AIR系列果绿色 820.70.36.4\",\"price\":17900,\"image\":\"https://m.360buyimg.com/mobilecms/s720x720_jfs/t6934/364/1195375010/84676/e9f2c55f/597ece38N0ddcbc77.jpg!q70.jpg.webp\",\"category\":\"拉杆箱\",\"brand\":\"RIMOWA\",\"spec\":\"\",\"status\":1,\"createTime\":\"2019-04-30T16:00:00.000+00:00\",\"updateTime\":\"2019-04-30T16:00:00.000+00:00\",\"stock\":2999,\"sold\":31290}')\n```\nPS：这里返回的是假数据\n3. 重新加载配置\n```sh\nnginx -s reload\n```\n#### 请求参数处理\n1. 获取请求参数API\nOpenResty中提供了一些API用来获取不同类型的前端请求参数：\n{% asset_img 069.png %}\n2. 获取请求参数\neg：获取 http://localhost/api/item/1001 的`id`=1001\n参数以路径占位符方式传递的，则利用正则表达式匹配的方式来获取。\n```nginx\nlocation ~ /api/item/(\\d+) {\n    # 默认的响应类型\n    default_type application/json;\n    # 响应结果由lua/item.lua文件来决定\n    content_by_lua_file lua/item.lua;\n}\n```\n修改`lua`文件获取id并拼接到结果中返回：\n```nginx\n-- 获取商品id\nlocal id = ngx.var[1]\n-- 拼接并返回\nngx.say('{\"id\":' .. id .. ',\"name\":\"SALSA AIR\",\"title\":\"RIMOWA 21寸托运箱拉杆箱 SALSA AIR系列果绿色 820.70.36.4\",\"price\":17900,\"image\":\"https://m.360buyimg.com/mobilecms/s720x720_jfs/t6934/364/1195375010/84676/e9f2c55f/597ece38N0ddcbc77.jpg!q70.jpg.webp\",\"category\":\"拉杆箱\",\"brand\":\"RIMOWA\",\"spec\":\"\",\"status\":1,\"createTime\":\"2019-04-30T16:00:00.000+00:00\",\"updateTime\":\"2019-04-30T16:00:00.000+00:00\",\"stock\":2999,\"sold\":31290}')\n```\n\n#### 查询Tomcat\n此时环境是OpenResty是在虚拟机，Tomcat是在Windows。\n{% asset_img 070.png %}\n关于OpenResty和Tomcat之间的访问问题有以下参考：\n- 教程视频中使用的是虚拟机，虚拟机ip和主机ip有对应关系（虎哥说的），关闭防火墙，即可完成连接\n- 弹幕说，用云服务的阿里云服务器的话，把课件中的项目放到阿里云运行，然后配置nginx代理地址之间转发到阿里云的地址即可\n- 弹幕说，用云服务器的话可以搜一下如何配置内网穿透\n- 弹幕说，服务器的话用公网ip就可以\n\n**发送请求API**\n```nginx\nlocal resp = ngx.location.capture(\"/path\",{\n    method = ngx.HTTP_GET,   -- 请求方式\n    args = {a=1,b=2},  -- get方式传参数\n})\n```\n返回的响应内容包括：\n- resp.status：响应状态码\n- resp.header：响应头，是一个table\n- resp.body：响应体，就是响应数据\n\n这里的path是路径，并不包含IP和端口，这个请求会被nginx内部的server监听并处理。我们希望这个请求发送到Tomcat服务器，所以还需要编写一个server来对这个路径做反向代理：\n```nginx\n location /path {\n     # 这里是windows电脑的ip和Java服务端口，需要确保windows防火墙处于关闭状态\n     proxy_pass http://192.168.150.1:8081; \n }\n```\n\n#### 封装http工具\n封装一个发送Http请求的工具，基于ngx.location.capture来实现查询tomcat\n\n1. 添加反向代理，到windows的Java服务。\n\n因为item-service中接口都是/item开头，所以监听/item路径代理到windows上的tomcat服务，添加一个location：\n```nginx\nlocation /item {\n    proxy_pass http://192.168.150.1:8081;\n}\n```\n以后调用`ngx.location.capture(\"/item\")`，就会发送请求到windows的tomcat服务。\n\n2. 封装工具类\n\nOpenResty启动时会加载以下两个目录中的工具文件：\n{% asset_img 072.png %}\n所以，自定义的http工具也需要放到这个目录下，新建common.lua文件：\n```lua\n-- 封装函数，发送http请求，并解析响应\nlocal function read_http(path, params)\n    local resp = ngx.location.capture(path,{\n        method = ngx.HTTP_GET,\n        args = params,\n    })\n    if not resp then\n        -- 记录错误信息，返回404\n        ngx.log(ngx.ERR, \"http请求查询失败, path: \", path , \", args: \", args)\n        ngx.exit(404)\n    end\n    return resp.body\nend\n-- 将方法导出\nlocal _M = {  \n    read_http = read_http\n}  \nreturn _M\n```\n这个工具将read_http函数封装到_M这个table类型的变量中，并且返回，这类似于导出。使用的时候，可以利用`require('common')`来导入该函数库，这里的common是函数库的文件名。\n\n3. 实现商品查询\n\n修改`/usr/local/openresty/lua/item.lua`文件，利用刚刚封装的函数库实现对tomcat的查询：\n```lua\n-- 引入自定义common工具模块，返回值是common中返回的 _M\nlocal common = require(\"common\")\n-- 从 common中获取read_http这个函数\nlocal read_http = common.read_http\n-- 获取路径参数\nlocal id = ngx.var[1]\n-- 根据id查询商品\nlocal itemJSON = read_http(\"/item/\".. id, nil)\n-- 根据id查询商品库存\nlocal itemStockJSON = read_http(\"/item/stock/\".. id, nil)\n```\n\n### 序列化、反序列化\nOpenResty提供cjson模块用来处理JSON的序列化和反序列化，官方地址： https://github.com/openresty/lua-cjson/\n1. 引入cjson模块\n\n```lua\nlocal cjson = require \"cjson\"\n```\n\n2. 序列化\n\n```lua\nlocal obj = {\n    name = 'jack',\n    age = 21\n}\n-- 把 table 序列化为 json\nlocal json = cjson.encode(obj)\n```\n\n3. 反序列化\n\n```lua\nlocal json = '{\"name\": \"jack\", \"age\": 21}'\n-- 反序列化 json为 table\nlocal obj = cjson.decode(json);\nprint(obj.name)\n```\n\n修改之前的item.lua中的业务，添加json处理功能：\n```lua\n-- 导入common函数库\nlocal common = require('common')\nlocal read_http = common.read_http\n-- 导入cjson库\nlocal cjson = require('cjson')\n\n-- 获取路径参数\nlocal id = ngx.var[1]\n-- 根据id查询商品\nlocal itemJSON = read_http(\"/item/\".. id, nil)\n-- 根据id查询商品库存\nlocal itemStockJSON = read_http(\"/item/stock/\".. id, nil)\n\n-- JSON转化为lua的table\nlocal item = cjson.decode(itemJSON)\nlocal stock = cjson.decode(stockJSON)\n\n-- 组合数据\nitem.stock = stock.stock\nitem.sold = stock.sold\n\n-- 把item序列化为json 返回结果\nngx.say(cjson.encode(item))\n```\n\n### 基于ID负载均衡\n以上示例代码中，tomcat均是单机部署。而实际开发中，tomcat一定是集群模式，因此OpenResty需要对tomcat集群做负载均衡。\n\n默认的负载均衡规则是轮询模式，当查询/item/10001时：\n- 第一次会访问8081端口的tomcat服务，在该服务内部就形成了JVM进程缓存\n- 第二次会访问8082端口的tomcat服务，该服务内部没有JVM缓存（因为JVM缓存无法共享），会查询数据库\n- ...\n\n因为轮询，第一次查询8081形成的JVM缓存并未生效，直到下一次再次访问到8081时才可以生效，显得JVM进程缓存并没有多大意义，这种负载均衡的效率很低。\n\n**Hash负载均衡**\nnginx提供了基于请求路径做负载均衡的算法，根据请求路径做hash运算根据运算结果决定访问哪个服务，实现负载均衡。\n只要id不变，每次hash运算结果也不会变，那就可以保证同一个商品，一直访问同一个tomcat服务，确保JVM缓存生效。\n\n1. 配置Tomcat集群\n\n```nginx\nupstream tomcat-cluster {\n    hash $request_uri;\n    server 192.168.150.1:8081;\n    server 192.168.150.1:8082;\n}\n```\n\n2. 修改对tomcat服务的反向代理，目标指向tomcat集群：\n\n```nginx\nlocation /item {\n    proxy_pass http://tomcat-cluster;\n}\n```\n\n3. 重新加载OpenResty\n\n```nginx\nnginx -s reload\n```\n\n## Redis缓存预热\nRedis缓存会面临冷启动问题：\n**冷启动**：服务刚刚启动时，Redis中并没有缓存，如果所有商品数据都在第一次查询时添加缓存，可能会给数据库带来较大压力。\n**缓存预热**：在实际开发中，我们可以利用大数据统计用户访问的热点数据，在项目启动时将这些热点数据提前查询并保存到Redis中。\n\n1. 安装Redis\n2. 微服务引入Redis依赖\n3. 配置Redis\n4. 编写初始化类\n\n缓存预热需要在项目启动时完成，并且必须是拿到RedisTemplate之后。利用InitializingBean接口来实现，因为InitializingBean可以在对象被Spring创建并且成员变量全部注入后执行。\n```java\npackage com.heima.item.config;\n\nimport com.fasterxml.jackson.core.JsonProcessingException;\nimport com.fasterxml.jackson.databind.ObjectMapper;\nimport com.heima.item.pojo.Item;\nimport com.heima.item.pojo.ItemStock;\nimport com.heima.item.service.IItemService;\nimport com.heima.item.service.IItemStockService;\nimport org.springframework.beans.factory.InitializingBean;\nimport org.springframework.beans.factory.annotation.Autowired;\nimport org.springframework.data.redis.core.StringRedisTemplate;\nimport org.springframework.stereotype.Component;\n\nimport java.util.List;\n\n@Component\npublic class RedisHandler implements InitializingBean {\n\n    @Autowired\n    private StringRedisTemplate redisTemplate;\n\n    @Autowired\n    private IItemService itemService;\n    @Autowired\n    private IItemStockService stockService;\n\n    private static final ObjectMapper MAPPER = new ObjectMapper();\n\n    @Override\n    public void afterPropertiesSet() throws Exception {\n        // 初始化缓存\n        // 1.查询商品信息\n        List<Item> itemList = itemService.list();\n        // 2.放入缓存\n        for (Item item : itemList) {\n            // 2.1.item序列化为JSON\n            String json = MAPPER.writeValueAsString(item);\n            // 2.2.存入redis\n            redisTemplate.opsForValue().set(\"item:id:\" + item.getId(), json);\n        }\n\n        // 3.查询商品库存信息\n        List<ItemStock> stockList = stockService.list();\n        // 4.放入缓存\n        for (ItemStock stock : stockList) {\n            // 2.1.item序列化为JSON\n            String json = MAPPER.writeValueAsString(stock);\n            // 2.2.存入redis\n            redisTemplate.opsForValue().set(\"item:stock:id:\" + stock.getId(), json);\n        }\n    }\n}\n```\n\n### OpenResty查询Redis\n当请求进入OpenResty之后：\n- 优先查询Redis缓存\n- 如果Redis缓存未命中，再查询Tomcat\n\n### 封装Redis工具\nOpenResty提供了操作Redis的模块，引入该模块就使用。但是为了方便，我们将Redis操作封装到之前的common.lua工具库中。\n修改上文中的`/usr/local/openresty/lualib/common.lua`文件：\n```lua\n-- 导入redis\nlocal redis = require('resty.redis')\n-- 初始化redis\nlocal red = redis:new()\nred:set_timeouts(1000, 1000, 1000)\n\n-- 关闭redis连接的工具方法，其实是放入连接池\nlocal function close_redis(red)\n    local pool_max_idle_time = 10000 -- 连接的空闲时间，单位是毫秒\n    local pool_size = 100 --连接池大小\n    local ok, err = red:set_keepalive(pool_max_idle_time, pool_size)\n    if not ok then\n        ngx.log(ngx.ERR, \"放入redis连接池失败: \", err)\n    end\nend\n\n-- 查询redis的方法 ip和port是redis地址，key是查询的key\nlocal function read_redis(ip, port, key)\n    -- 获取一个连接\n    local ok, err = red:connect(ip, port)\n    if not ok then\n        ngx.log(ngx.ERR, \"连接redis失败 : \", err)\n        return nil\n    end\n    -- 查询redis\n    local resp, err = red:get(key)\n    -- 查询失败处理\n    if not resp then\n        ngx.log(ngx.ERR, \"查询Redis失败: \", err, \", key = \" , key)\n    end\n    --得到的数据为空处理\n    if resp == ngx.null then\n        resp = nil\n        ngx.log(ngx.ERR, \"查询Redis数据为空, key = \", key)\n    end\n    close_redis(red)\n    return resp\nend\n\n-- 封装函数，发送http请求，并解析响应\nlocal function read_http(path, params)\n    local resp = ngx.location.capture(path,{\n        method = ngx.HTTP_GET,\n        args = params,\n    })\n    if not resp then\n        -- 记录错误信息，返回404\n        ngx.log(ngx.ERR, \"http查询失败, path: \", path , \", args: \", args)\n        ngx.exit(404)\n    end\n    return resp.body\nend\n-- 将方法导出\nlocal _M = {  \n    read_http = read_http,\n    read_redis = read_redis\n}  \nreturn _M\n```\n\n#### 实现Redis查询\neg：\n- 根据id查询Redis\n- 如果查询失败则继续查询Tomcat\n- 将查询结果返回\n\n```lua\n-- 导入common函数库\nlocal common = require('common')\nlocal read_http = common.read_http\nlocal read_redis = common.read_redis\n-- 导入cjson库\nlocal cjson = require('cjson')\n\n-- 封装查询函数\nfunction read_data(key, path, params)\n    -- 查询本地缓存\n    local val = read_redis(\"127.0.0.1\", 6379, key)\n    -- 判断查询结果\n    if not val then\n        ngx.log(ngx.ERR, \"redis查询失败，尝试查询http， key: \", key)\n        -- redis查询失败，去查询http\n        val = read_http(path, params)\n    end\n    -- 返回数据\n    return val\nend\n\n-- 获取路径参数\nlocal id = ngx.var[1]\n\n-- 查询商品信息\nlocal itemJSON = read_data(\"item:id:\" .. id,  \"/item/\" .. id, nil)\n-- 查询库存信息\nlocal stockJSON = read_data(\"item:stock:id:\" .. id, \"/item/stock/\" .. id, nil)\n\n-- JSON转化为lua的table\nlocal item = cjson.decode(itemJSON)\nlocal stock = cjson.decode(stockJSON)\n-- 组合数据\nitem.stock = stock.stock\nitem.sold = stock.sold\n\n-- 把item序列化为json 返回结果\nngx.say(cjson.encode(item))\n```\n\n## Nginx本地缓存\nOpenResty为Nginx提供了**shard dict**的功能，可以在nginx的多个worker之间共享数据，实现缓存功能。\n1. 开启共享字典，在nginx.conf的http下添加配置\n\n```nginx\n # 共享字典，也就是本地缓存，名称叫做：item_cache，大小150m\n lua_shared_dict item_cache 150m; \n```\n\n2. 操作共享词典\n\n```nginx\n-- 获取本地缓存对象\nlocal item_cache = ngx.shared.item_cache\n-- 存储, 指定key、value、过期时间，单位s，默认为0代表永不过期\nitem_cache:set('key', 'value', 1000)\n-- 读取\nlocal val = item_cache:get('key')\n```\n\n3. 本地缓存查询\n\n修改`/usr/local/openresty/lua/item.lua`文件:\n- 修改read_data查询函数，添加本地缓存逻辑\n- 修改item.lua中查询商品和库存的业务，实现最新的read_data函数\n\t- 多了缓存时间参数，过期后nginx缓存会自动删除，下次访问即可更新缓存。\n\t品基本信息设置超时时间为30分钟，库存为1分钟。\n\n因为库存更新频率较高，如果缓存时间过长，可能与数据库差异较大。\n```lua\n-- 导入common函数库\nlocal common = require('common')\nlocal read_http = common.read_http\nlocal read_redis = common.read_redis\n-- 导入cjson库\nlocal cjson = require('cjson')\n-- 导入共享词典，本地缓存\nlocal item_cache = ngx.shared.item_cache\n\n-- 封装查询函数\nfunction read_data(key, expire, path, params)\n    -- 查询本地缓存\n    local val = item_cache:get(key)\n    if not val then\n        ngx.log(ngx.ERR, \"本地缓存查询失败，尝试查询Redis， key: \", key)\n        -- 查询redis\n        val = read_redis(\"127.0.0.1\", 6379, key)\n        -- 判断查询结果\n        if not val then\n            ngx.log(ngx.ERR, \"redis查询失败，尝试查询http， key: \", key)\n            -- redis查询失败，去查询http\n            val = read_http(path, params)\n        end\n    end\n    -- 查询成功，把数据写入本地缓存\n    item_cache:set(key, val, expire)\n    -- 返回数据\n    return val\nend\n\n-- 获取路径参数\nlocal id = ngx.var[1]\n\n-- 查询商品信息\nlocal itemJSON = read_data(\"item:id:\" .. id, 1800,  \"/item/\" .. id, nil)\n-- 查询库存信息\nlocal stockJSON = read_data(\"item:stock:id:\" .. id, 60, \"/item/stock/\" .. id, nil)\n\n-- JSON转化为lua的table\nlocal item = cjson.decode(itemJSON)\nlocal stock = cjson.decode(stockJSON)\n-- 组合数据\nitem.stock = stock.stock\nitem.sold = stock.sold\n\n-- 把item序列化为json 返回结果\nngx.say(cjson.encode(item))\n```\n\n## 缓存同步\n缓存同步策略：\n**设置有效期**：给缓存设置有效期，到期后自动删除。再次查询时更新\n- 优势：简单、方便\n- 缺点：时效性差，缓存过期之前可能不一致\n- 场景：更新频率较低，时效性要求低的业务\n\n**同步双写**：在修改数据库的同时，直接修改缓存\n- 优势：时效性强，缓存与数据库强一致\n- 缺点：有代码侵入，耦合度高；\n- 场景：对一致性、时效性要求较高的缓存数据\n\n**异步通知：**修改数据库时发送事件通知，相关服务监听到通知后修改缓存数据\n- 优势：低耦合，可以同时通知多个缓存服务\n- 缺点：时效性一般，可能存在中间不一致状态\n- 场景：时效性要求一般，有多个服务需要同步\n\n异步实现可以基于MQ或者Canal：\n- 基于MQ的异步通知\n{% asset_img 073.png %}\n- 商品服务完成对数据的修改后，只需要发送一条消息到MQ中。\n- 缓存服务监听MQ消息，然后完成对缓存的更新\n\n依然有少量的代码侵入。\n\n- 基于Canal的通知\n{% asset_img 074.png %}\n- 商品服务完成商品修改后，业务直接结束，没有任何代码侵入\n- Canal监听MySQL变化，当发现变化后，立即通知缓存服务\n- 缓存服务接收到canal通知，更新缓存\n\n代码零侵入\n\n### Canal\nCanal是阿里巴巴旗下的一款开源项目，基于Java开发。基于数据库增量日志解析，提供增量数据订阅&消费。GitHub的地址：https://github.com/alibaba/canal\n\nCanal是基于mysql的主从同步来实现的，MySQL主从同步的原理如下：\n{% asset_img 075.png %}\n- MySQL master 将数据变更写入二进制日志( binary log），其中记录的数据叫做binary log events\n- MySQL slave 将 master 的 binary log events拷贝到它的中继日志(relay log)\n- MySQL slave 重放 relay log 中事件，将数据变更反映它自己的数据\n\nCanal就是把自己伪装成MySQL的一个slave节点，从而监听master的binary log变化。再把得到的变化信息通知给Canal的客户端，进而完成对其它数据库的同步。\n\n#### 安装配置Canal\nCanal是基于MySQL的主从同步功能，因此必须先开启MySQL的主从功能\n1. 开启binlog\n\n打开mysql容器挂载的日志文件，添加：\n```ini\nlog-bin=/var/lib/mysql/mysql-bin\nbinlog-do-db=heima\n```\n- `log-bin=/var/lib/mysql/mysql-bin`：设置binary log文件的存放地址和文件名，叫做mysql-bin\n- `binlog-do-db=heima`：指定对哪个database记录binary log events，这里记录heima这个库\n\n最终效果：\n```ini\n[mysqld]\nskip-name-resolve\ncharacter_set_server=utf8\ndatadir=/var/lib/mysql\nserver-id=1000\nlog-bin=/var/lib/mysql/mysql-bin\nbinlog-do-db=heima\n```\n\n2. 设置用户权限\n\n添加一个仅用于数据同步的账户，出于安全考虑，这里仅提供对heima这个库的操作权限\n```sql\ncreate user canal@'%' IDENTIFIED by 'canal';\nGRANT SELECT, REPLICATION SLAVE, REPLICATION CLIENT,SUPER ON *.* TO 'canal'@'%' identified by 'canal';\nFLUSH PRIVILEGES;\n```\n重启Mysql\n```sh\ndocker restart mysql\n```\n\n安装过程略。\n安装好之后，运行容器：\n```sh\ndocker run -p 11111:11111 --name canal \\\n-e canal.destinations=heima \\\n-e canal.instance.master.address=mysql:3306  \\\n-e canal.instance.dbUsername=canal  \\\n-e canal.instance.dbPassword=canal  \\\n-e canal.instance.connectionCharset=UTF-8 \\\n-e canal.instance.tsdb.enable=true \\\n-e canal.instance.gtidon=false  \\\n-e canal.instance.filter.regex=heima\\\\..* \\\n--network heima \\\n-d canal/canal-server:v1.1.5\n```\n- `-p 11111:11111`：这是canal的默认监听端口\n- `-e canal.instance.master.address=mysql:3306`：数据库地址和端口，如果不知道mysql容器地址，可以通过`docker inspect 容器id`来查看\n- `-e canal.instance.dbUsername=canal`：数据库用户名\n- `-e canal.instance.dbPassword=canal` ：数据库密码\n- `-e canal.instance.filter.regex=`：要监听的表名称\n\n表名称监听支持的语法：\n```\nmysql 数据解析关注的表，Perl正则表达式.\n多个正则之间以逗号(,)分隔，转义符需要双斜杠(\\\\) \n常见例子：\n1.  所有表：.*   or  .*\\\\..*\n2.  canal schema下所有表： canal\\\\..*\n3.  canal下的以canal打头的表：canal\\\\.canal.*\n4.  canal schema下的一张表：canal.test1\n5.  多个规则组合使用然后以逗号隔开：canal\\\\..*,mysql.test1,mysql.test2 \n```\n\n#### 监听Canal\n当Canal监听到binlog变化时，会通知Canal的客户端。用Canal提供的Java客户端，监听Canal通知消息。当收到变化的消息时，完成对缓存的更新。\n\n这里我们会使用GitHub上的第三方开源的canal-starter客户端，https://github.com/NormanGyllenhaal/canal-client 与SpringBoot完美整合，自动装配，比官方客户端要简单好用很多。\n\n1. 引入依赖\n\n```\n<dependency>\n    <groupId>top.javatool</groupId>\n    <artifactId>canal-spring-boot-starter</artifactId>\n    <version>1.2.1-RELEASE</version>\n</dependency>\n```\n\n2. 编写配置\n\n```yaml\ncanal:\n  destination: heima # canal的集群名字，要与安装canal时设置的名称一致\n  server: 192.168.150.101:11111 # canal服务地址\n```\n\n3. 修改实体类\n\n```java\npackage com.heima.item.pojo;\n\nimport com.baomidou.mybatisplus.annotation.IdType;\nimport com.baomidou.mybatisplus.annotation.TableField;\nimport com.baomidou.mybatisplus.annotation.TableId;\nimport com.baomidou.mybatisplus.annotation.TableName;\nimport lombok.Data;\nimport org.springframework.data.annotation.Id;\nimport org.springframework.data.annotation.Transient;\n\nimport javax.persistence.Column;\nimport java.util.Date;\n\n@Data\n@TableName(\"tb_item\")\npublic class Item {\n    @TableId(type = IdType.AUTO)\n    @Id\n    private Long id;//商品id\n    @Column(name = \"name\")\n    private String name;//商品名称\n    private String title;//商品标题\n    private Long price;//价格（分）\n    private String image;//商品图片\n    private String category;//分类名称\n    private String brand;//品牌名称\n    private String spec;//规格\n    private Integer status;//商品状态 1-正常，2-下架\n    private Date createTime;//创建时间\n    private Date updateTime;//更新时间\n    @TableField(exist = false)\n    @Transient\n    private Integer stock;\n    @TableField(exist = false)\n    @Transient\n    private Integer sold;\n}\n```\n\n4. 编写监听器\n\n通过实现`EntryHandler<T>`接口编写监听器，监听Canal消息。注意两点：\n- 实现类通过`@CanalTable(\"tb_item\")`指定监听的表信息\n- EntryHandler的泛型是与表对应的实体类\n\n```java\npackage com.heima.item.canal;\n\nimport com.github.benmanes.caffeine.cache.Cache;\nimport com.heima.item.config.RedisHandler;\nimport com.heima.item.pojo.Item;\nimport org.springframework.beans.factory.annotation.Autowired;\nimport org.springframework.stereotype.Component;\nimport top.javatool.canal.client.annotation.CanalTable;\nimport top.javatool.canal.client.handler.EntryHandler;\n\n@CanalTable(\"tb_item\")\n@Component\npublic class ItemHandler implements EntryHandler<Item> {\n\n    @Autowired\n    private RedisHandler redisHandler;\n    @Autowired\n    private Cache<Long, Item> itemCache;\n\n    @Override\n    public void insert(Item item) {\n        // 写数据到JVM进程缓存\n        itemCache.put(item.getId(), item);\n        // 写数据到redis\n        redisHandler.saveItem(item);\n    }\n\n    @Override\n    public void update(Item before, Item after) {\n        // 写数据到JVM进程缓存\n        itemCache.put(after.getId(), after);\n        // 写数据到redis\n        redisHandler.saveItem(after);\n    }\n\n    @Override\n    public void delete(Item item) {\n        // 删除数据到JVM进程缓存\n        itemCache.invalidate(item.getId());\n        // 删除数据到redis\n        redisHandler.deleteItemById(item.getId());\n    }\n}\n```\n在这里对Redis的操作都封装到了RedisHandler这个对象中，是我们之前做缓存预热时编写的一个类，内容如下：\n```java\npackage com.heima.item.config;\n\nimport com.fasterxml.jackson.core.JsonProcessingException;\nimport com.fasterxml.jackson.databind.ObjectMapper;\nimport com.heima.item.pojo.Item;\nimport com.heima.item.pojo.ItemStock;\nimport com.heima.item.service.IItemService;\nimport com.heima.item.service.IItemStockService;\nimport org.springframework.beans.factory.InitializingBean;\nimport org.springframework.beans.factory.annotation.Autowired;\nimport org.springframework.data.redis.core.StringRedisTemplate;\nimport org.springframework.stereotype.Component;\n\nimport java.util.List;\n\n@Component\npublic class RedisHandler implements InitializingBean {\n\n    @Autowired\n    private StringRedisTemplate redisTemplate;\n\n    @Autowired\n    private IItemService itemService;\n    @Autowired\n    private IItemStockService stockService;\n\n    private static final ObjectMapper MAPPER = new ObjectMapper();\n\n    @Override\n    public void afterPropertiesSet() throws Exception {\n        // 初始化缓存\n        // 1.查询商品信息\n        List<Item> itemList = itemService.list();\n        // 2.放入缓存\n        for (Item item : itemList) {\n            // 2.1.item序列化为JSON\n            String json = MAPPER.writeValueAsString(item);\n            // 2.2.存入redis\n            redisTemplate.opsForValue().set(\"item:id:\" + item.getId(), json);\n        }\n\n        // 3.查询商品库存信息\n        List<ItemStock> stockList = stockService.list();\n        // 4.放入缓存\n        for (ItemStock stock : stockList) {\n            // 2.1.item序列化为JSON\n            String json = MAPPER.writeValueAsString(stock);\n            // 2.2.存入redis\n            redisTemplate.opsForValue().set(\"item:stock:id:\" + stock.getId(), json);\n        }\n    }\n\n    public void saveItem(Item item) {\n        try {\n            String json = MAPPER.writeValueAsString(item);\n            redisTemplate.opsForValue().set(\"item:id:\" + item.getId(), json);\n        } catch (JsonProcessingException e) {\n            throw new RuntimeException(e);\n        }\n    }\n\n    public void deleteItemById(Long id) {\n        redisTemplate.delete(\"item:id:\" + id);\n    }\n}\n```","tags":["SpringClound"]},{"title":"nginx初试","url":"/2022/04/06/nginx-chu-shi/","content":"\nLinux安装nginx，安装路径为 /usr/local/nginx 。启动及其他命令须在 sbin 目录下进行。\n常用命令\n```\n启动nginx\t\t./nginx\t\t\n停止nginx\t\t./nginx\t-s stop\t\n重新加载nginx  ./nginx -s reload\n```\n\n### 反向代理\n概念：客户端发送的请求经过中间件，然后派发到不同服务器的过程即为反向代理。\n正向代理代理的是客户端，特点是用户明确知道实际访问的服务器。\n反向代理代理的是服务器，特点是用户不知道实际要访问的服务器，服务器对用户来说是隐藏的，用户知道的是中间件。\n\n#### 反向代理单个节点\nnginx.con配置\n```\nserver {\n\tlisten\t\"访问端口\";\n\tserver_name:\t\"访问ip\";\n\tlocation / {\n\t\troot\thtml;\n\t\tindex\tindex.html index.html;\n\t\tproxy_name\t\"被代理的服务器ip:port\";\n\t}\n}\n```\n#### 反向代理两个节点\nnginx.conf配置\n```\nserver {\n\tlisten\t\"访问端口\";\n\tserver\t\"访问ip\";\n\t\n\tlocation ~ /edu/ {\n\t\tproxy_pass\thttp://op:port;\n\t}\n\t\n\tlocation ~ /vod/ {\n\t\tproxy_pass\thttp://ip:port;\n\t}\n}\n```\n/edu/ 是正则表达式，nginx会根据客户端的访问路径，将请求派发到与正则表达式匹配的服务器。\n\n### 负载均衡\n概念：将请求派发到不同服务器上，减轻服务器的负担，提高系统的可用性和可靠性。\n#### 默认轮询\nnginx.conf配置\n```\nupstream myServer{\n\tserver\tip:port;\n\tserver\tip:port;\n}\n\nserver{\n\tlisten\tport;\n\tserver_name\t\tip;\n    \n    location{\n    \tproxy_pass\thttp://myServer;\n    \t\n    \troot\thtml;\n    \tindex\tindex.html\tindex.html;\n    }\n}\n```\n#### 分配权重\nnginx.conf配置\n```\nupstream myServer{\n\tserver\tip:port\t\tweight=10;\n\tserver\tip:port\t\tweight=5;\t\n}\n\nserver{\n\tlisten\tport;\n\tserver_name\t\tip;\n    \n    location{\n    \tproxy_pass\thttp://myServer;\n    \t\n    \troot\thtml;\n    \tindex\tindex.html\tindex.html;\n    }\n}\n```\nweight的值越大，请求被派发到该服务器的几率越大。\n#### ip_hash\nnginx.conf配置\n```\nupstream myServer{\n\tip_hash;\n\tserver\tip:port;\n\tserver\tip:port;\n}\n\nserver{\n\tlisten\tport;\n\tserver_name\t\tip;\n    \n    location{\n    \tproxy_pass\thttp://myServer;\n    \t\n    \troot\thtml;\n    \tindex\tindex.html\tindex.html;\n    }\n}\n```\nnginx根据客户端的ip的hash值进行派发请求，此方法可以解决session问题。\n#### fair\nnginx.conf配置\n```\nupstream myServer{\n\tfair;\n\tserver\tip:port;\n\tserver\tip:port;\n}\n\nserver{\n\tlisten\tport;\n\tserver_name\t\tip;\n    \n    location{\n    \tproxy_pass\thttp://myServer;\n    \t\n    \troot\thtml;\n    \tindex\tindex.html\tindex.html;\n    }\n}\n```\nnginx根据服务器的响应时间来分配请求，响应时间越短越优先分配。\n### 动静分离\n看尚硅谷的nginx视频，感觉这部分讲的不是很好，和一般的反向代理差不多，但还是记录一下。\n本次测试是把静态资源放在nginx所在的主机下，在/myData/img 和 /myData/html 目录下放置静态资源。\nnginx.conf配置\n```\nserver{\n\tlisten\tport;\n\tserver_name\t\tip;\n    \n    location{\n    \tproxy_pass\thttp://myServer;\n    \t\n    \troot\thtml;\n    \tindex\tindex.html\tindex.html;\n    }\n    \n    #添加规则\n    location /html/ {\n        root    /myData/;\n    }\n    location /img/ {\n \t\troot    /myData/;\n \t\t#访问/img/会把该目录下的资源列出来\n\t\tautoindex       on;\n    }\n}\n```\n","categories":["nginx"]},{"title":"问题踩坑汇总","url":"/2022/03/17/wen-ti-cai-keng-hui-zong/","content":"## 请路径参数获取问题\n使用ajax发送请求，在请求路径中拼接了一个参数 calledName ，在后台 controller 方法中使用 request.getAttribute(\"calledName\") 获取 calledName ，结果为 null 。换一种方法使用 @RequestParam 注解却能获取到 calledName 的值。\n原因尚未知，在以后的开发中尽量使用 @RequestParam 注解获取参数值。\n请求路径中拼接参数的方式，GET 和 POST 都可以使用。\n\n## ajax回调函数的返回数据data\n使用 $.ajax() 方式发送 ajax 请求，其中 datatype 的值设为 json，发现最终回调函数不能正常使用，将 datatype 这一参数设置不写，（后台 controller 方法注解是有 @RequestBody 的），回调函数能够正常使用。\n\n## 集合遍历中修改\n**方式一： for(int i = 0; i < length; i++)**\n如果能够使用这该方式遍历集合，则可以在遍历中修改\n\n**方式二：增强 for 循环，for(Integer i : list)**\n如果使用该方式遍历，则不可以在遍历中修改！！！\n原因：在迭代器的底层源码中，使用该方式会产生下标索引不一致的问题，会报错。\n\n**方式三：使用迭代器，Iterator**\n可以使用迭代器方式遍历集合，遍历中可以删除\n```java\nfor(Iterator it = set.iterator();it.hasNext();){\n\tObject obj = it.next();\n\tit.remove();//删除迭代出来的元素\n}\n```\n\n## char[] 比较是否相等\n```java\nchar[] c1 = {'a', 'b'};\nchar[] c2 = {'a', 'b'};\nSystem.out.println(c1.equals(c2)); //输出为 false\nArrays.equals(c1, c2); //输出为 true\n```\n不能使用 **c1.equals(c2)**，可以借助**Arrays.equals()方法**\n\n## 复制数组的一部分\n可以借助工具类**Arrays**\n```java\nArrays.copyOfRange(is, from, to); //不包含to\n```\n\n## 拼接String集合\n```java\nLinkedList<String> track = new LinkedList<>();\nString res = String.join(\" \", track);\t//将track中的字符串以“ ”连接\n```\n\n# Maven pom爆红\n\n## 1.1 maven坐标正确\n\n这种情况可能是maven或IDEA自身的问题，这里给出一种解决方案。\n\n1. 首先到maven中央仓库手动下载所需要的jar包\n2. 将下载的jar包导入到maven本地仓库\n   在jar包所在目录下打开cmd控制台，执行：\n\n```sh\nmvn install:install-file -Dfile=jar包名称（带后缀） -DgroupId=jar包groupId -DartifactId=jar包artifactId -Dversion=jar包版本号 -Dpackaging=jar\n```\n\n3. 修改IDEA maven设置\n   {% asset_img 001.jpg %}\n   勾选圈出的选项，确定。之后重启IDEA，pom文件不再爆红。\n\n# 参考帖子\n\n1. https://www.cnblogs.com/think-world/p/12229763.html\n2. https://blog.csdn.net/qq_43242707/article/details/115277308"},{"title":"Java学习笔记","url":"/2022/03/10/java-xue-xi-bi-ji/","content":"实体类的属性名称不能和数据库的保留字相同，否则会导致数据表创建错误。\nMysql保留字有：\n\tcall\n\t\n# 反射与注解\n### 注解Annotation\n作用：注释和解释（狂神说的，很喜欢，简洁）。被人用来注释代码，并交给JVM去解释执行。\n\n定义：\n```\n@Target({ElementType.TYPE})\n@Retention(RetentionPolicy.RUNTIME)\n@interface MyAnnotation{\n    public String value();\n}\n```\n以上就简单自定义了一个注解。在定义注解的时候可以使用其他注解。\n\n元注解：用来注解注解的注解。\n四个元注解：\n```\n@Target 确定注解可以使用的地方，如类、接口、方法等\n@Retention 可以理解为注解的\"生命周期\"\n@Documented 此注解会被javadoc工具提取成文档\n@Inherited 允许子类继承父类中的注解\n```\n\n### 反射Reflection\n个人理解：通过Class类去操纵对象的过程就称为反射。\n代码示例：\n```\n\n```\n\n# 重载与重写\n### 重载\n描述：一个类中，同一个方法名，有用多个参数类型或数量不同的方法实现，则称之为方法重载。\n代码示例：\n```\npublic class A{\n\tpublic void methodA(){};\n\tpublic void methodA(int a){};\n    public void methodA(String str){};\n}\n```\n\n### 继承\n定义：\n```\npublic class B extends A{\n\t\n}\n```\n类B继承了类A，B拥有A的所有方法（构造方法除外）和属性。类B可以对父类A的方法进行重写，还可以声明父类A没有的属性。\n构造方法：当父类有多个构造方法时，子类必须声明一个参数列表（可以是无参类型）和父类相同的构造方法，并在方法体的第一行调用父类的其中一个构造方法。\n注意，当父类只有默认无参构造方法时，子类的默认无参构造方法中默认调用了父类的无参构造方法。\n当以一个类声明了构造方法，默认的无参构造方法便不存在了。\n代码示例：\n```\n示例一：\npublic class Father {\n    public Father(){\n        System.out.println(\"Father\");\n    }\n\n    public Father(String name, String age){\n        System.out.println(name + age);\n    }\n}\n\nclass Son extends Father{\n\n    public Son(String name) {\n        super();\n    }\n}\n\n示例二：\npublic class Father {\n    public Father(){\n        System.out.println(\"Father\");\n    }\n\n    public Father(String name, String age){\n        System.out.println(name + age);\n    }\n}\n\nclass Son extends Father{\n\t//有默认的无参构造器，而且会默认调用父类的无参构造器\n\t\n\tpublic static void main(String[] args){\n\t\tnew Son();\n\t}\n}\n输出：Father\n\n示例三：\npublic class Father {\n    public Father(String name){\n        System.out.println(name);\n    }\n\n    public Father(String name, String age){\n        System.out.println(name + age);\n    }\n}\n\nclass Son extends Father{\n\tpublic Son(String name){\n\t\tsuper(name + \"age\");\n\t}\n}\n```\n\n### 重写\n描述：子类继承父类，并对继承的父类方法进行重新实现的过程，称之为方法重写。\n\n\n代码示例\n```\npublic class Father{\n\tpublic String method1(){\n\t\treturn \"father\";\n\t}\n}\n\npublic class Son extends Father{\n\tpublic String method1(){\n\t\treturn \"son\"\n\t}\n}\n```\n\n### 向上转型与向下转型\n\n#### 向上转型\n描述：把子类的对象实例赋值给父类的引用。\n代码示例：\n```\npublic class Father{\n\tpublic void method1(){\n\t\tSystem.out.println(\"father\");\n\t}\n}\n\npublic class B extends Father{\n\tpublic void method1(){\n\t\tSystem.out.println(\"son\");\n\t}\n\t\n\tpublic static void main(String[] args){\n\t\tFather f = new Son();\t//向上转型,将子类实例赋值给父类引用。可以理解为把子类对象向上转换成父类对象。 \n\t\tf.method1();\t//输出结果为\"son\",而不是\"father\"\n\t}\n}\n```\n通过向上转型的获得的对象引用，在调用方法时，只能调用父类中已有的方法，但执行的方法体是子类的方法。\n\n易混淆情况：\n```\npublic class Father{\n\tpublic void method1(){\n\t\tSystem.out.println(\"father\");\n\t}\n\t\n\tpublic void method2(){\n\t\tSystem.out.println(\"father.method2\");\n\t}\n}\n\npublic class B extends Father{\n\tpublic void method1(){\n\t\tSystem.out.println(\"son\");\n\t}\n\t\n\tpublic static void main(String[] args){\n\t\tFather f = new Son();\t//向上转型,将子类实例赋值给父类引用。可以理解为把子类对象向上转换成父类对象。 \n\t\tf.method2();\t//输出结果为\"father.method2\",method2()方法没有被子类B重写，是从父类A中继承过来的，也是类B的方法不要理解为method2不是B的方法。\n\t}\n}\n```\n\n代码示例：\n```\npublic class Father {\n    public String method1(){\n        return \"father\";\n    }\n}\nclass Son extends Father{\n    public String method1(){\n        return \"son\";\n    }\n\n    public String method2(){\n        return \"Son.method2\";\n    }\n\n    public static void main(String[] args){\n        Father f = new Son();\n        //System.out.println(f.method2());\t该行会提示报错，因为f此时是Father类型，没有method2()方法\n        System.out.println(((Son)f).method2());\t//此时再使用向下转型，便不会报错。输出结果为\"Son.method2\"\n    }\n}\n```\n\n#### 向上转型经典例题\n```\nclass A {\n    public String show(D obj) {\n        return (\"A and D\");\n    }\n\n    public String show(A obj) {\n        return (\"A and A\");\n    }\n\n}\n\nclass B extends A{\n    public String show(B obj){\n        return (\"B and B\");\n    }\n\n    public String show(A obj){\n        return (\"B and A\");\n    }\n}\n\nclass C extends B{\n\n}\n\nclass D extends B{\n\n}\n\npublic class Demo {\n    public static void main(String[] args) {\n        A a1 = new A();\n        A a2 = new B();\n        B b = new B();\n        C c = new C();\n        D d = new D();\n\n        System.out.println(\"1--\" + a1.show(b));\n        System.out.println(\"2--\" + a1.show(c));\n        System.out.println(\"3--\" + a1.show(d));\n        System.out.println(\"4--\" + a2.show(b));\n        System.out.println(\"5--\" + a2.show(c));\n        System.out.println(\"6--\" + a2.show(d));\n        System.out.println(\"7--\" + b.show(b));\n        System.out.println(\"8--\" + b.show(c));\n        System.out.println(\"9--\" + b.show(d));\n    }\n}\n//结果：\n//1--A and A\n//2--A and A\n//3--A and D\n//4--B and A\n//5--B and A\n//6--A and D\n//7--B and B\n//8--B and B\n//9--A and D\n\n//能看懂这个结果么？先自分析一下。\n```\n这个例子是非常复杂的啦，要想完全理解后面几个输出结果还要知道一条重要知识：\n```\n继承链中对象方法的调用的优先级：this.show(O)、super.show(O)、this.show((super)O)、super.show((super)O)\n(其实按照我前面的理解，感觉这一条原则不要也行，因为子类没有重写的方法是默认继承自父类的，验证了一下例题也没问题)\n```\n对于输出4，a2.show(b))的输出结果是\"B and A\"。对象a2是A类型，但是指向B类型实例，为向上转型。a2可执行的方法名为类A中的方法，public String show(D obj)和public String show(A obj)；\n```\n继承链第一步：this.show(O)显然不行，因为对象b是B类型，可执行方法中没有符合要求的。\n继承链第二步：super.show(O)，显然没有符合要求的。\n继承链第三步：this.show((super)O)，即shou((A) b)，执行类B中的方法show(A obj)，输出\"B and A\"\n```\n对于输出5，分析同输出4，略。\n对于输出6，a2.show(d))的输出结果为\"A and D\"，也很好理解。\n```\n继承链第一步：this.show(O)显然可以，因为类B继承了类A的public String show(D obj)方法，\n```\n\n\n\n[参考博文](https://blog.csdn.net/qq_31655965/article/details/54746235)","categories":["mysql","Java"]},{"title":"SpringBoot源码笔记","url":"/2022/01/19/springboot-yuan-ma-bi-ji/","content":"### 静态资源\n\n#### 默认路径\n项目资源文件夹resources下：/META-INF/resources/、/resources/、/static/、/public/ 共四个路径。即使是使用了thymeleaf模板的情况下，放在以上路径下的静态资源仍然可以被访问，而且在这些路径下的html页面中使用thymeleaf语法同样有效。（thymeleaf似乎值对拦截再templates路径下的资源访问进行拦截设置）\n源码探究：\n\n```java\npackage org.springframework.boot.autoconfigure.web;\n@ConfigurationProperties(\"spring.web\")\npublic class WebProperties {\n\tpublic static class Resources {\n\t\tprivate static final String[] CLASSPATH_RESOURCE_LOCATIONS = { \"classpath:/META-INF/resources/\",\"classpath:/resources/\", \"classpath:/static/\", \"classpath:/public/\" };\n\t}\n}\n```\n##### 自定义资源路径\n注解@ConfigurationProperties(\"spring.web\")，WebProperties类下的属性和配置文件进行了绑定，在配置文件application.properties中即可自定义静态资源访问路径。\n```\n##由于CLASSPATH_RESOURCE_LOCATIONS被final修饰，所以不能修改\n##类属性和配置文件的对应规则：spring.web为注解设置前缀，resource对应内部类Resources的类名，static-locations对应类属性staticLocations\nspring.web.resources.static-locations = 自定义资源路径\n```\n源码探究：\n```java\npackage org.springframework.boot.autoconfigure.web;\n@ConfigurationProperties(\"spring.web\")\npublic class WebProperties {\n\tpublic static class Resources {\n\t\tprivate static final String[] CLASSPATH_RESOURCE_LOCATIONS = { \"classpath:/META-INF/resources/\",\"classpath:/resources/\", \"classpath:/static/\", \"classpath:/public/\" };\n\t\tprivate String[] staticLocations = CLASSPATH_RESOURCE_LOCATIONS;\n\t}\n}\n```\n\n#### 资源访问前缀\n默认访问前缀：/\n源码探究：\n\n```java\n@ConfigurationProperties(prefix = \"spring.mvc\")\npublic class WebMvcProperties {\n\tpublic static class Servlet {\n\t\t/**\n\t\t * Path of the dispatcher servlet. Setting a custom value for this property is not\n\t\t * compatible with the PathPatternParser matching strategy.\n\t\t */\n\t\tprivate String path = \"/\";\n\t}\n}\n```\n自定义访问前缀：\n```\nspring.web.servlet.path = 自定义前缀（注意要“/”结尾）\n```\n\n\n### web请求处理过程\n\n所有web请求都会进入到 org.springframework.web.servlet 包下的 DispatcherServlet 类的 doDispatch(HttpServletRequest request, HttpServletResponse response) 方法中\n```java\nprotected void doDispatch(HttpServletRequest request, HttpServletResponse response) throws Exception {\n\tHttpServletRequest processedRequest = request;\n\tHandlerExecutionChain mappedHandler = null;\t\n    boolean multipartRequestParsed = false;\n\n\tWebAsyncManager asyncManager = WebAsyncUtils.getAsyncManager(request);\n\t\n\ttry {\t\t\tModelAndView mv = null;\n\t\tException dispatchException = null;\n\n\t\ttry {\n\t\t\tprocessedRequest = checkMultipart(request);\n\t\t\tmultipartRequestParsed = (processedRequest != request);\n\n\t\t\t// Determine handler for the current request.\n\t\t\t//***获取映射处理器，进入该方法可以看到所有的请求路径映射***\n\t\t\tmappedHandler = getHandler(processedRequest);\n\t\t\tif (mappedHandler == null) {\n\t\t\t\tnoHandlerFound(processedRequest, response);\n\t\t\t\treturn;\n\t\t\t}\n\n\t\t\t// Determine handler adapter for the current request.\n\t\t\tHandlerAdapter ha = getHandlerAdapter(mappedHandler.getHandler());\n\n\t\t\t// Process last-modified header, if supported by the handler.\n\t\t\tString method = request.getMethod();\n\t\t\tboolean isGet = HttpMethod.GET.matches(method);\n\t\t\tif (isGet || HttpMethod.HEAD.matches(method)) {\n\t\t\t\tlong lastModified = ha.getLastModified(request, mappedHandler.getHandler());\n\t\t\t\tif (new ServletWebRequest(request, response).checkNotModified(lastModified) && isGet) {\n\t\t\t\t\treturn;\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tif (!mappedHandler.applyPreHandle(processedRequest, response)) {\n\t\t\t\treturn;\n\t\t\t}\n\n\t\t\t//***（1）***\n             //***真正要开始处理请求映射的方法***\n\t\t\t// Actually invoke the handler.\n\t\t\tmv = ha.handle(processedRequest, response, mappedHandler.getHandler());\n\n\t\t\tif (asyncManager.isConcurrentHandlingStarted()) {\n\t\t\t\treturn;\n\t\t\t}\n\n\t\t\tapplyDefaultViewName(processedRequest, mv);\n\t\t\tmappedHandler.applyPostHandle(processedRequest, response, mv);\n\t\t}\n\t\tcatch (Exception ex) {\n\t\t\tdispatchException = ex;\n\t\t}\n\t\tcatch (Throwable err) {\n\t\t\t// As of 4.3, we're processing Errors thrown from handler methods as well,\n\t\t\t// making them available for @ExceptionHandler methods and other scenarios.\n\t\t\tdispatchException = new NestedServletException(\"Handler dispatch failed\", err);\n\t\t}\n\t\tprocessDispatchResult(processedRequest, response, mappedHandler, mv, dispatchException);\n\t}\n\tcatch (Exception ex) {\n\t\ttriggerAfterCompletion(processedRequest, response, mappedHandler, ex);\n\t}\n\tcatch (Throwable err) {\n\t\ttriggerAfterCompletion(processedRequest, response, mappedHandler,\n\t\t\tnew NestedServletException(\"Handler processing failed\", err));\n\t}\n\tfinally {\n\t\tif (asyncManager.isConcurrentHandlingStarted()) {\n\t\t\t// Instead of postHandle and afterCompletion\n\t\t\tif (mappedHandler != null) {\t\t\t\tmappedHandler.applyAfterConcurrentHandlingStarted(processedRequest, response);\n\t\t\t}\n\t\t}\n\t\telse {\n\t\t\t// Clean up any resources used by a multipart request.\n\t\t\tif (multipartRequestParsed) {\n\t\t\t\tcleanupMultipart(processedRequest);\n\t\t\t}\n\t\t}\n\t}\n}\n```\n\n执行 mappedHandler = getHandler(processedRequest) ，进入到 getHandler() 方法\n```java\nprotected HandlerExecutionChain getHandler(HttpServletRequest request) throws Exception {\n\tif (this.handlerMappings != null) {\n\t\t//***mapping中包含了所有的请求路径，和请求路径映射的方法。\n\t\tfor (HandlerMapping mapping : this.handlerMappings) {\n\t\t\tHandlerExecutionChain handler = mapping.getHandler(request);\n\t\t\tif (handler != null) {\n\t\t\t\treturn handler;\n\t\t\t}\n\t\t}\n\t}\n\treturn null;\n}\n```\nthis.handlerMappings:\n\t{% asset_img 003.png %}\nmapping:\n\t包含了所有请求路径和请求路径的映射方法\n\t{% asset_img 005.png %}\n\t{% asset_img 004.png %}\n\n执行 mv = ha.handle(processedRequest, response, mappedHandler.getHandler()) 时，会进入到 AbstractHandlerMethodAdapter 类的 handle(HttpServletRequest request, HttpServletResponse response, Object handler) 方法中（共有四个HandleMethodAdapter， 分别是...）。\n\n```java\npublic final ModelAndView handle(HttpServletRequest request, HttpServletResponse response, Object handler)\n\t\t\tthrows Exception {\n\t\treturn handleInternal(request, response, (HandlerMethod) handler);\n\t}\n```\n接着进入到 RequestMappingHandlerAdapter 类的 handleInternal(HttpServletRequest request,\nHttpServletResponse response, HandlerMethod handlerMethod) 方法\n```java\nprotected ModelAndView handleInternal(HttpServletRequest request,\n\t\t\tHttpServletResponse response, HandlerMethod handlerMethod) throws Exception {\n\n\tModelAndView mav;\n\tcheckRequest(request);\n\n\t// Execute invokeHandlerMethod in synchronized block if required.\n\tif (this.synchronizeOnSession) {\n\t\tHttpSession session = request.getSession(false);\n\t\tif (session != null) {\n\t\t\tObject mutex = WebUtils.getSessionMutex(session);\n\t\t\tsynchronized (mutex) {\n\t\t\t\tmav = invokeHandlerMethod(request, response, handlerMethod);\n\t\t\t}\n\t\t}\n\t\telse {\n\t\t\t// No HttpSession available -> no mutex necessary\n\t\t\tmav = invokeHandlerMethod(request, response, handlerMethod);\n\t\t}\n\t}\n\telse {\n         //***(2)***\n         //***开始进入请求方法执行流程***\n\t\t// No synchronization on session demanded at all...\n\t\tmav = invokeHandlerMethod(request, response, handlerMethod);\n\t}\n\t\tif (!response.containsHeader(HEADER_CACHE_CONTROL)) {\n\t\tif (getSessionAttributesHandler(handlerMethod).hasSessionAttributes()) {\n\t\t\tapplyCacheSeconds(response, this.cacheSecondsForSessionAttributeHandlers);\n\t\t}\n\t\telse {\n\t\t\tprepareResponse(response);\n\t\t}\n\t}\n\treturn mav;\n}\n```\n\n执行 mav = invokeHandlerMethod(request, response, handlerMethod) 进入到同类中的 invokeHandlerMethod(HttpServletRequest request,HttpServletResponse response, HandlerMethod handlerMethod) 方法。\n```java\nprotected ModelAndView invokeHandlerMethod(HttpServletRequest request,\n\t\tHttpServletResponse response, HandlerMethod handlerMethod) throws Exception {\n\tServletWebRequest webRequest = new ServletWebRequest(request, response);\n\ttry {\n\t\tWebDataBinderFactory binderFactory = getDataBinderFactory(handlerMethod);\n\t\tModelFactory modelFactory = getModelFactory(handlerMethod, binderFactory);\n\t\tServletInvocableHandlerMethod invocableMethod = createInvocableHandlerMethod(handlerMethod);\n\t\tif (this.argumentResolvers != null) {\t\t\t\t\t\t  \n//***设置请求方法的参数解析器***\ninvocableMethod.setHandlerMethodArgumentResolvers(this.argumentResolvers);\n\t\t}\n\t\tif (this.returnValueHandlers != null) {\n//***设置请求方法的返回值处理器***\ninvocableMethod.setHandlerMethodReturnValueHandlers(this.returnValueHandlers);\n\t\t}\n\t\tinvocableMethod.setDataBinderFactory(binderFactory);\n\t\tinvocableMethod.setParameterNameDiscoverer(this.parameterNameDiscoverer);\n\t\tModelAndViewContainer mavContainer = new ModelAndViewContainer();\n\t\tmavContainer.addAllAttributes(RequestContextUtils.getInputFlashMap(request));\n\t\tmodelFactory.initModel(webRequest, mavContainer, invocableMethod);\n\t\tmavContainer.setIgnoreDefaultModelOnRedirect(this.ignoreDefaultModelOnRedirect);\n\t\tAsyncWebRequest asyncWebRequest = WebAsyncUtils.createAsyncWebRequest(request, response);\n\t\tasyncWebRequest.setTimeout(this.asyncRequestTimeout);\n\t\tWebAsyncManager asyncManager = WebAsyncUtils.getAsyncManager(request);\n\t\tasyncManager.setTaskExecutor(this.taskExecutor);\n\t\tasyncManager.setAsyncWebRequest(asyncWebRequest);\n\t\tasyncManager.registerCallableInterceptors(this.callableInterceptors);\n\t\tasyncManager.registerDeferredResultInterceptors(this.deferredResultInterceptors);\n\t\tif (asyncManager.hasConcurrentResult()) {\n\t\t\tObject result = asyncManager.getConcurrentResult();\n\t\t\tmavContainer = (ModelAndViewContainer) asyncManager.getConcurrentResultContext()[0];\n\t\t\tasyncManager.clearConcurrentResult();\n\t\t\tLogFormatUtils.traceDebug(logger, traceOn -> {\n\t\t\t\tString formatted = LogFormatUtils.formatValue(result, !traceOn);\n\t\t\t\treturn \"Resume with async result [\" + formatted + \"]\";\n\t\t\t});\n\t\t\tinvocableMethod = invocableMethod.wrapConcurrentResult(result);\n\t\t}\n        //***(3)***\n        //***开始处理请求方法的参数、试图等\n\t\tinvocableMethod.invokeAndHandle(webRequest, mavContainer);\n\t\tif (asyncManager.isConcurrentHandlingStarted()) {\n\t\t\treturn null;\n\t\t}\n\t\treturn getModelAndView(mavContainer, modelFactory, webRequest);\n\t}\n\tfinally {\n\t\twebRequest.requestCompleted();\n}\n```\n请求方法参数解析器 ：{% asset_img 001.png %}\n请求方法返回值处理器：{% asset_img 002.png %}\n\n执行 invocableMethod.invokeAndHandle(webRequest, mavContainer)，进入到 ServletInvocableHandlerMethod 类下的 invokeAndHandle(ServletWebRequest webRequest, ModelAndViewContainer mavContainer,Object... providedArgs) 方法。\n```java\npublic void invokeAndHandle(ServletWebRequest webRequest, ModelAndViewContainer mavContainer,\n\t\tObject... providedArgs) throws Exception {\n    //***(4)***\n    //***对请求方法选择支持的参数类型解析器（可能不准确）***\n\tObject returnValue = invokeForRequest(webRequest, mavContainer, providedArgs);\n\tsetResponseStatus(webRequest);\n\tif (returnValue == null) {\n\t\tif (isRequestNotModified(webRequest) || getResponseStatus() != null || mavContainer.isRequestHandled()) {\n\t\t\tdisableContentCachingIfNecessary(webRequest);\n\t\t\tmavContainer.setRequestHandled(true);\n\t\t\treturn;\n\t\t}\n\t}\n\telse if (StringUtils.hasText(getResponseStatusReason())) {\n\t\tmavContainer.setRequestHandled(true);\n\t\treturn;\n\t}\n\tmavContainer.setRequestHandled(false);\n\tAssert.state(this.returnValueHandlers != null, \"No return value handlers\");\n\ttry {\n\t\tthis.returnValueHandlers.handleReturnValue(\n\t\t\t\treturnValue, getReturnValueType(returnValue), mavContainer, webRequest);\n\t}\n\tcatch (Exception ex) {\n\t\tif (logger.isTraceEnabled()) {\n\t\t\tlogger.trace(formatErrorForReturnValue(returnValue), ex);\n\t\t}\n\t\tthrow ex;\n\t}\n}\n```\n\n执行 Object returnValue = invokeForRequest(webRequest, mavContainer, providedArgs) ，进入 InvocableHandlerMethod 类下的 invokeForRequest(NativeWebRequest request, @Nullable ModelAndViewContainer mavContainer,Object... providedArgs) 方法。\n```java\npublic Object invokeForRequest(NativeWebRequest request, @Nullable ModelAndViewContainer mavContainer,\n\t\tObject... providedArgs) throws Exception {\n\t//***(5)***\n\tObject[] args = getMethodArgumentValues(request, mavContainer, providedArgs);\n\tif (logger.isTraceEnabled()) {\n\t\tlogger.trace(\"Arguments: \" + Arrays.toString(args));\n\t}\n\treturn doInvoke(args);\n}\n```\n\n执行 Object[] args = getMethodArgumentValues(request, mavContainer, providedArgs) ，进入到同类下的 getMethodArgumentValues(NativeWebRequest request, @Nullable ModelAndViewContainer mavContainer,Object... providedArgs) 方法。\n```java\nprotected Object[] getMethodArgumentValues(NativeWebRequest request, @Nullable ModelAndViewContainer mavContainer,\n\t\tObject... providedArgs) throws Exception {\n\tMethodParameter[] parameters = getMethodParameters();\n\tif (ObjectUtils.isEmpty(parameters)) {\n\t\treturn EMPTY_ARGS;\n\t}\n\t\n\t//***(6)***\n\t//***开始遍历请求方法的参数列表,按照参数列表的数量创建一个对象数组args，args中的的每个元素后来都会转化为对应的参数列表中的对象类型***\n\tObject[] args = new Object[parameters.length];\n\tfor (int i = 0; i < parameters.length; i++) {\n\t\tMethodParameter parameter = parameters[i];\n\t\tparameter.initParameterNameDiscovery(this.parameterNameDiscoverer);\n\t\targs[i] = findProvidedArgument(parameter, providedArgs);\n\t\tif (args[i] != null) {\n\t\t\tcontinue;\n\t\t}\n\t\t//***(7)***\n\t\t//判断resolvers中是否有支持当前参数的resolver\n\t\tif (!this.resolvers.supportsParameter(parameter)) {\n\t\t\tthrow new IllegalStateException(formatArgumentError(parameter, \"No suitable resolver\"));\n\t\t}\n\t\ttry {\n\t\t\t//***(8)***\n\t\t\t//***获取参数类型的对象数组***\n\t\t\targs[i] = this.resolvers.resolveArgument(parameter, mavContainer, request, this.dataBinderFactory);\n\t\t}\n\t\tcatch (Exception ex) {\n\t\t\t// Leave stack trace for later, exception may actually be resolved and handled...\n\t\t\tif (logger.isDebugEnabled()) {\n\t\t\t\tString exMsg = ex.getMessage();\n\t\t\t\tif (exMsg != null && !exMsg.contains(parameter.getExecutable().toGenericString())) {\n\t\t\t\t\tlogger.debug(formatArgumentError(parameter, exMsg));\n\t\t\t\t}\n\t\t\t}\n\t\t\tthrow ex;\n\t\t}\n\t}\n\treturn args;\n}\n```\n\n执行 args[i] = this.resolvers.resolveArgument(parameter, mavContainer, request, this.dataBinderFactory) \n```java\npublic Object resolveArgument(MethodParameter parameter, @Nullable ModelAndViewContainer mavContainer,\n\t\tNativeWebRequest webRequest, @Nullable WebDataBinderFactory binderFactory) throws Exception {\n\t//***(9)***\n\t//***获取参数解析器***\n\tHandlerMethodArgumentResolver resolver = getArgumentResolver(parameter);\n\tif (resolver == null) {\n\t\tthrow new IllegalArgumentException(\"Unsupported parameter type [\" +\n\t\t\t\tparameter.getParameterType().getName() + \"]. supportsParameter should be called first.\");\n\t}\n\t\n\t//***这一部像是递归，还没搞懂该行的作用***\n\treturn resolver.resolveArgument(parameter, mavContainer, webRequest, binderFactory);\n}\n```\n\n执行 HandlerMethodArgumentResolver resolver = getArgumentResolver(parameter) \n```java\nprivate HandlerMethodArgumentResolver getArgumentResolver(MethodParameter parameter) {\n\tHandlerMethodArgumentResolver result = this.argumentResolverCache.get(parameter);\n\tif (result == null) {\n\t\t//***(10)***\n\t\t//***遍历所有的参数类型解析器，找到支持该参数的解析器***\n\t\tfor (HandlerMethodArgumentResolver resolver : this.argumentResolvers) {\n\t\t\tif (resolver.supportsParameter(parameter)) {\n\t\t\t\tresult = resolver;\n\t\t\t\tthis.argumentResolverCache.put(parameter, result);\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t}\n\treturn result;\n}\n```\n\n\n### 内容协商机制\n内容协商：协商浏览器能接受的数据类型和服务端能生产的数据类型（数据类型值的是数据的格式，例如XML和JSON等）\n在SpringBoot中，内容协商流程发生在返回值处理器中。\n请求的响应过程中，会得到支持请求路径映射的方法返回值的返回值处理器HandlerMethodReturnValueHandler ，接着进入到 HandlerMethodReturnValueHandler 具体实现类中，执行 handleReturnValue() 方法。以 RequestResponseBodyMethodProcessor 为例。\n```java\npublic void handleReturnValue(@Nullable Object returnValue, MethodParameter returnType,\n\t\t\tModelAndViewContainer mavContainer, NativeWebRequest webRequest)\n\t\t\tthrows IOException, HttpMediaTypeNotAcceptableException, HttpMessageNotWritableException {\n\n\t\tmavContainer.setRequestHandled(true);\n\t\tServletServerHttpRequest inputMessage = createInputMessage(webRequest);\n\t\tServletServerHttpResponse outputMessage = createOutputMessage(webRequest);\n\n\t\t// Try even with null return value. ResponseBodyAdvice could get involved.\n\t\twriteWithMessageConverters(returnValue, returnType, inputMessage, outputMessage);\n\t}\n```\n进入 writeWithMessageConverters(returnValue, returnType, inputMessage, outputMessage) \n```java\nprotected <T> void writeWithMessageConverters(@Nullable T value, MethodParameter returnType,\n\t\t\tServletServerHttpRequest inputMessage, ServletServerHttpResponse outputMessage)\n\t\t\tthrows IOException, HttpMediaTypeNotAcceptableException, HttpMessageNotWritableException {\n\n\t\tObject body;\n\t\tClass<?> valueType;\n\t\tType targetType;\n\n\t\tif (value instanceof CharSequence) {\n\t\t\tbody = value.toString();\n\t\t\tvalueType = String.class;\n\t\t\ttargetType = String.class;\n\t\t}\n\t\telse {\n\t\t\tbody = value;\n\t\t\tvalueType = getReturnValueType(body, returnType);\n\t\t\ttargetType = GenericTypeResolver.resolveType(getGenericType(returnType), returnType.getContainingClass());\n\t\t}\n\n\t\tif (isResourceType(value, returnType)) {\n\t\t\toutputMessage.getHeaders().set(HttpHeaders.ACCEPT_RANGES, \"bytes\");\n\t\t\tif (value != null && inputMessage.getHeaders().getFirst(HttpHeaders.RANGE) != null &&\n\t\t\t\t\toutputMessage.getServletResponse().getStatus() == 200) {\n\t\t\t\tResource resource = (Resource) value;\n\t\t\t\ttry {\n\t\t\t\t\tList<HttpRange> httpRanges = inputMessage.getHeaders().getRange();\n\t\t\t\t\toutputMessage.getServletResponse().setStatus(HttpStatus.PARTIAL_CONTENT.value());\n\t\t\t\t\tbody = HttpRange.toResourceRegions(httpRanges, resource);\n\t\t\t\t\tvalueType = body.getClass();\n\t\t\t\t\ttargetType = RESOURCE_REGION_LIST_TYPE;\n\t\t\t\t}\n\t\t\t\tcatch (IllegalArgumentException ex) {\n\t\t\t\t\toutputMessage.getHeaders().set(HttpHeaders.CONTENT_RANGE, \"bytes */\" + resource.contentLength());\n\t\t\t\t\toutputMessage.getServletResponse().setStatus(HttpStatus.REQUESTED_RANGE_NOT_SATISFIABLE.value());\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\tMediaType selectedMediaType = null;\n\t\tMediaType contentType = outputMessage.getHeaders().getContentType();\n\t\tboolean isContentTypePreset = contentType != null && contentType.isConcrete();\n\t\tif (isContentTypePreset) {\n\t\t\tif (logger.isDebugEnabled()) {\n\t\t\t\tlogger.debug(\"Found 'Content-Type:\" + contentType + \"' in response\");\n\t\t\t}\n\t\t\tselectedMediaType = contentType;\n\t\t}\n\t\telse {\n\t\t\tHttpServletRequest request = inputMessage.getServletRequest();\n\t\t\tList<MediaType> acceptableTypes;\n\t\t\ttry {\n\t\t\t\t//***得到浏览器可接受的媒体类型***\n\t\t\t\t//***进入getAcceptableMediaTypes方法，可获取使用哪种内容协商策略ContentNegotiationStrategy***\n\t\t\t\tacceptableTypes = getAcceptableMediaTypes(request);\n\t\t\t}\n\t\t\tcatch (HttpMediaTypeNotAcceptableException ex) {\n\t\t\t\tint series = outputMessage.getServletResponse().getStatus() / 100;\n\t\t\t\tif (body == null || series == 4 || series == 5) {\n\t\t\t\t\tif (logger.isDebugEnabled()) {\n\t\t\t\t\t\tlogger.debug(\"Ignoring error response content (if any). \" + ex);\n\t\t\t\t\t}\n\t\t\t\t\treturn;\n\t\t\t\t}\n\t\t\t\tthrow ex;\n\t\t\t}\n\t\t\t\n\t\t\t//***得到服务端可生产的媒体类型***\n\t\t\tList<MediaType> producibleTypes = getProducibleMediaTypes(request, valueType, targetType);\n\n\t\t\tif (body != null && producibleTypes.isEmpty()) {\n\t\t\t\tthrow new HttpMessageNotWritableException(\n\t\t\t\t\t\t\"No converter found for return value of type: \" + valueType);\n\t\t\t}\n\t\t\t\n\t\t\t//***遍历两种媒体类型，得到双方可以匹配的媒体类型***\n\t\t\tList<MediaType> mediaTypesToUse = new ArrayList<>();\n\t\t\tfor (MediaType requestedType : acceptableTypes) {\n\t\t\t\tfor (MediaType producibleType : producibleTypes) {\n\t\t\t\t\tif (requestedType.isCompatibleWith(producibleType)) {\n\t\t\t\t\t\tmediaTypesToUse.add(getMostSpecificMediaType(requestedType, producibleType));\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t\tif (mediaTypesToUse.isEmpty()) {\n\t\t\t\tif (body != null) {\n\t\t\t\t\tthrow new HttpMediaTypeNotAcceptableException(producibleTypes);\n\t\t\t\t}\n\t\t\t\tif (logger.isDebugEnabled()) {\n\t\t\t\t\tlogger.debug(\"No match for \" + acceptableTypes + \", supported: \" + producibleTypes);\n\t\t\t\t}\n\t\t\t\treturn;\n\t\t\t}\n\t\t\t\n\t\t\t//***按照权重等规则进行排序***\n\t\t\tMediaType.sortBySpecificityAndQuality(mediaTypesToUse);\n\n\t\t\t//***确定最佳匹配的媒体类型***\n\t\t\tfor (MediaType mediaType : mediaTypesToUse) {\n\t\t\t\tif (mediaType.isConcrete()) {\n\t\t\t\t\tselectedMediaType = mediaType;\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t\telse if (mediaType.isPresentIn(ALL_APPLICATION_MEDIA_TYPES)) {\n\t\t\t\t\tselectedMediaType = MediaType.APPLICATION_OCTET_STREAM;\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tif (logger.isDebugEnabled()) {\n\t\t\t\tlogger.debug(\"Using '\" + selectedMediaType + \"', given \" +\n\t\t\t\t\t\tacceptableTypes + \" and supported \" + producibleTypes);\n\t\t\t}\n\t\t}\n\n\t\tif (selectedMediaType != null) {\n\t\t\tselectedMediaType = selectedMediaType.removeQualityValue();\n\t\t\t//***根据最终匹配的媒体类型，遍历寻找支持的消息转换器Converter\n\t\t\tfor (HttpMessageConverter<?> converter : this.messageConverters) {\n\t\t\t\tGenericHttpMessageConverter genericConverter = (converter instanceof GenericHttpMessageConverter ?\n\t\t\t\t\t\t(GenericHttpMessageConverter<?>) converter : null);\n\t\t\t\tif (genericConverter != null ?\n\t\t\t\t\t\t((GenericHttpMessageConverter) converter).canWrite(targetType, valueType, selectedMediaType) :\n\t\t\t\t\t\tconverter.canWrite(valueType, selectedMediaType)) {\n\t\t\t\t\tbody = getAdvice().beforeBodyWrite(body, returnType, selectedMediaType,\n\t\t\t\t\t\t\t(Class<? extends HttpMessageConverter<?>>) converter.getClass(),\n\t\t\t\t\t\t\tinputMessage, outputMessage);\n\t\t\t\t\tif (body != null) {\n\t\t\t\t\t\tObject theBody = body;\n\t\t\t\t\t\tLogFormatUtils.traceDebug(logger, traceOn ->\n\t\t\t\t\t\t\t\t\"Writing [\" + LogFormatUtils.formatValue(theBody, !traceOn) + \"]\");\n\t\t\t\t\t\taddContentDispositionHeader(inputMessage, outputMessage);\n\t\t\t\t\t\tif (genericConverter != null) {\n\t\t\t\t\t\t//***执行消息转换器的 write 方法***\n\t\t\t\t\t\t\tgenericConverter.write(body, targetType, selectedMediaType, outputMessage);\n\t\t\t\t\t\t}\n\t\t\t\t\t\telse {\n\t\t\t\t\t\t//***执行消息转换器的 write 方法***\n\t\t\t\t\t\t\t((HttpMessageConverter) converter).write(body, selectedMediaType, outputMessage);\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\telse {\n\t\t\t\t\t\tif (logger.isDebugEnabled()) {\n\t\t\t\t\t\t\tlogger.debug(\"Nothing to write: null body\");\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\treturn;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\tif (body != null) {\n\t\t\tSet<MediaType> producibleMediaTypes =\n\t\t\t\t\t(Set<MediaType>) inputMessage.getServletRequest()\n\t\t\t\t\t\t\t.getAttribute(HandlerMapping.PRODUCIBLE_MEDIA_TYPES_ATTRIBUTE);\n\n\t\t\tif (isContentTypePreset || !CollectionUtils.isEmpty(producibleMediaTypes)) {\n\t\t\t\tthrow new HttpMessageNotWritableException(\n\t\t\t\t\t\t\"No converter for [\" + valueType + \"] with preset Content-Type '\" + contentType + \"'\");\n\t\t\t}\n\t\t\tthrow new HttpMediaTypeNotAcceptableException(getSupportedMediaTypes(body.getClass()));\n\t\t}\n\t}\n```\nacceptableTypes = getAcceptableMediaTypes(request) ，确定内容协商策略，进而根据策略获取浏览器可接受的媒体类型\n```java\nprivate List<MediaType> getAcceptableMediaTypes(HttpServletRequest request)\n\t\t\tthrows HttpMediaTypeNotAcceptableException {\n\n\t\treturn this.contentNegotiationManager.resolveMediaTypes(new ServletWebRequest(request));\n\t}\n```\n```java\npublic List<MediaType> resolveMediaTypes(NativeWebRequest request) throws HttpMediaTypeNotAcceptableException {\n\t\tfor (ContentNegotiationStrategy strategy : this.strategies) {\n\t\t\tList<MediaType> mediaTypes = strategy.resolveMediaTypes(request);\n\t\t\tif (mediaTypes.equals(MEDIA_TYPE_ALL_LIST)) {\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t\treturn mediaTypes;\n\t\t}\n\t\treturn MEDIA_TYPE_ALL_LIST;\n\t}\n```\n此时只有一种默认的协商策略，基于request请求头的协商策略：HeaderContentNegotiationStrategy。也可以添加其他的内容协商策略，如在配置文件中开启基于请求参数的协商策略，也可以自定义协商策略。\n{% asset_img 007.png %}\n\n消息转换器Converter：{% asset_img 006.png %}\n\n开启支持XML格式数据：导入依赖\n```\n<dependency>\n            <groupId>com.fasterxml.jackson.dataformat</groupId>\n            <artifactId>jackson-dataformat-xml</artifactId>\n</dependency>\n```\n\n开启基于请求参数的内容协商策略，配置文件中配置相应属性值。此时发送的请求中要附带一个 format 的字段，例如 http://localhost:8080/test/person?format=json 和http://localhost:8080/test/person?format=xml\n```\nspring.contentnegotiation.favor-parameter=true\n```\n\n自定义内容协商策略\n\n\n\n"},{"title":"SpringBoot-JPA","url":"/2021/12/04/springboot-jpa/","content":"### pom依赖配置\n#### jpa本身配置\n```\n<dependency>\n\t<groupId>org.springframework.boot</groupId>\n\t<artifactId>spring-boot-starter-data-jpa</artifactId>\n</dependency>\n```\n#### 引入驱动依赖（mysql数据库操作必配）\n```\n<dependency>\n\t<groupId>mysql</groupId>\n\t<artifactId>mysql-connector-java</artifactId>\n</dependency>\n```\n\n#### mysql数据库链接\n```\n#数据库连接\nspring.datasource.url=jdbc:mysql://127.0.0.1:3306/admin?characterEncoding=UTF-8\nspring.datasource.username=用户名\nspring.datasource.password=用户密码\n#mysql驱动\nspring.datasource.driver-class-name=com.mysql.cj.jdbc.Driver\n```\n\n### 使用步骤\n#### 一、创建实体类\n实体类标注注解：@Entity、@Table。注意导入的包为：javax.persistence.*\n```java\n@Entity\n@Table(name = \"user\")\npublic class User {\n\n    @Id\n    @GeneratedValue(strategy = GenerationType.IDENTITY)\n    @Column\n    int id;\n\n    @Column\n    String userName;\n\n    @Column\n    String name;\n\n    @Column\n    String headImg;\n\n    //性别\n    @Column\n    String gender;\n\n    @Column\n    String phone;\n\n    @Column\n    String email;\n\n    String password;\n\n    public void setId(int id) {\n        this.id = id;\n    }\n\n    public int getId() {\n        return id;\n    }\n\n    public void setUserName(String userName) {\n        this.userName = userName;\n    }\n\n    public String getUserName() {\n        return userName;\n    }\n\n    public void setName(String name) {\n        this.name = name;\n    }\n\n    public String getName() {\n        return name;\n    }\n\n    public void setHeadImg(String headImg) {\n        this.headImg = headImg;\n    }\n\n    public String getHeadImg() {\n        return headImg;\n    }\n\n    public void setGender(String gender) {\n        this.gender = gender;\n    }\n\n    public String getGender() {\n        return gender;\n    }\n\n    public void setPhone(String phone) {\n        this.phone = phone;\n    }\n\n    public String getPhone() {\n        return phone;\n    }\n\n    public void setEmail(String email) {\n        this.email = email;\n    }\n\n    public String getEmail() {\n        return email;\n    }\n\n    public void setPassword(String password) {\n        this.password = password;\n    }\n\n    public String getPassword() {\n        return password;\n    }\n}\n```\nJPA默认的字段命名规则是驼峰转换，eg：UserName --> user_name。\n\n#### JPA配置修改\n```\n#设置自动更新表结构\nspring.jpa.properties.hibernate.hbm2ddl.auto=update\nspring.jpa.properties.hibernate.dialect=org.hibernate.dialect.MySQL5InnoDBDialect\n#在控制台显示sql语句\nspring.jpa.show-sql= true\n```\n\n#### 二、继承JpaRepository接口\n```java\n//User对应要操作的数据表实体类，Integer是int类型的封装类，固定不变\npublic interface UserDAO extends JpaRepository<User, Integer> {}\n```\n\n#### 三、使用接口类进行CRUD操作\n当UserDAO继承了JpaRepository后，可以在其它类中注入UserDAO，使用UserDAO进行简单的crud操作。在类UserService标注注解@Service的作用是，向容器中添加该类的组件，之后可以在其它地方使用注解@Autowired注入该类对象。\n```java\n@Service\npublic class UserService {\n    @Autowired\n    UserDAO userDAO;\n\n    public void add(User user){\n        userDAO.save(user);\n    } \n}\n```\nJPA注入：\n\t使用注解@Autowired。\n\t内部使用了@Autowired的类，在外面不能使用new创建该类对象，而是使用@Autowired注入对象，否则会导致JPA注入失败，报空指针异常。\n\teg：UserController类中使用了new UserService创建对象，导致UserService类中UserDAO注入失败，userDAO为null\n\n```\n@Controller\npublic class UserController {\n    @RequestMapping(\"/hello\")\n    @ResponseBody\n    public void hi(){\n        new UserService().add(new User());\n    }\n}\n```\n\n正确用法是使用@Autowired注入UserService对象，如下所示\n```\n@Controller\npublic class UserController {\n\n    @Autowired\n    UserService userService;\n\n    @RequestMapping(\"/hello\")\n    @ResponseBody\n    public void hi(){\n        userService.add(new User());\n    }\n}\n```","tags":["JPA"],"categories":["mysql","SpringBoot"]},{"title":"SpringBoot-方法参数","url":"/2021/12/02/springboot-fang-fa-can-shu/","content":"### 方法参数封装\n","categories":["SpringBoot"]},{"title":"Mysql学习笔记","url":"/2021/11/26/mysql-xue-xi-bi-ji/","content":"\n# SQL语法\n## 基本规范\n**书写规范：**\n- SQL 可以写在一行或者多行。为了提高可读性，各子句分行写，必要时使用缩进\n- 每条命令以 ; 或 \\g 或 \\G 结束\n- 关键字不能被缩写也不能分行\n- 关于标点符号\n  - 必须保证所有的()、单引号、双引号是成对结束的\n  - 必须使用英文状态下的半角输入方式\n  - 字符串型和日期时间类型的数据可以使用单引号（' '）表示\n  - 列的别名，尽量使用双引号（\" \"），而且不建议省略as\n\n**大小写：**\n- **MySQL 在 Windows 环境下是大小写不敏感的**\n- **MySQL 在 Linux 环境下是大小写敏感的**\n- 数据库名、表名、表的别名、变量名是严格区分大小写的\n- 关键字、函数名、列名(或字段名)、列的别名(字段的别名) 是忽略大小写的\n\n**推荐采用统一的书写规范：**\n- 数据库名、表名、表别名、字段名、字段别名等都小写\n- SQL 关键字、函数名、绑定变量等都大写\n\n**注释：**\n```mysql\n单行注释：#注释文字(MySQL特有的方式)\n单行注释：-- 注释文字(--后面必须包含一个空格。)\n多行注释：/* 注释文字  */\n```\n\n**数据导入：**\nMysql命令行客户端使用`source`命令\n```mysql\nmysql> source d:\\mysqldb.sql\n```\n\n**查看表结构**\n```mysql\nDESCRIBE employees;\n# 或\nDESC employees;\n```\n\n## SELECT语法基础\n1. SELECT\n```mysql\nSELECT 1; #没有任何子句\nSELECT 9/2; #没有任何子句\n```\n\n2. SELECT ... FROM\n```mysql\nSELECT   表列名\nFROM     要选择的表\n\n#选择特定列\nSELECT department_id, location_id\nFROM   departments;\n\n#选择表的全部列\nSELECT *\nFROM   departments;\n```\n> 一般情况下，除非需要使用表中所有的字段数据，最好不要使用通配符`*`\n> 使用通配符虽然可以节省输入查询语句的时间，但是获取不需要的列数据通常会降低查询和所使用的应用程序的效率\n> 在生产环境下，不推荐你直接使用`SELECT *`进行查询\n\n**列的别名**\n语法：紧跟列名，也可以**在列名和别名之间加入关键字AS，别名使用双引号**，以便在别名中包含空格或特殊的字符并区分大小写。AS 可以省略\n```mysql\nSELECT last_name AS name, commission_pct comm\nFROM   employees;\n  \nSELECT last_name \"Name\", salary*12 \"Annual Salary\"\nFROM   employees;\n```\n\n**去除重复行**\n```\nSELECT DISTINCT department_id\nFROM   employees;\n```\n\n`DISTINCT`其实是对后面所有列名的组合进行去重，当`DISTINCT`后面有多个列名时，`DISTINCT`需要放在最前面\n```mysql\nSELECT DISTINCT department_id,salary \nFROM employees;\n```\n\n**空值null**\n所有运算符或列值遇到null值，运算的结果都为null\n\n**着重号**\n表中的字段、表名等如果有和Mysql保留字、数据库系统或常用方法冲突时，需在SQL语句中使用一对``（着重号）引起来\n```mysql\nSELECT * FROM `ORDER`;\n```\n\n**查询常数**\n`SELECT`查询还可以对常数进行查询。在 SELECT 查询结果中增加一列固定的常数列。这列的取值是我们指定的，而不是从数据表中动态取出的。\n\nSQL 中的 SELECT 语法的确提供了这个功能，一般来说我们只从一个表中查询数据，通常不需要增加一个固定的常数列，但如果我们想整合不同的数据源，用常数列作为这个表的标记，就需要查询常数。\n比如说，我们想对 employees 数据表中的员工姓名进行查询，同时增加一列字段`corporation`，这个字段固定值为“尚硅谷”，可以这样写：\n```mysql\nSELECT '尚硅谷' as corporation, last_name FROM employees;\n```\n\n**过滤数据——WHERE**\n- 使用WHERE 子句，将不满足条件的行过滤掉\n- **WHERE子句紧随 FROM子句**\n```mysql\nSELECT 字段1,字段2\nFROM 表名\nWHERE 过滤条件\n\n# 举例\nSELECT employee_id, last_name, job_id, department_id\nFROM   employees\nWHERE  department_id = 90 ;\n```\n\n## 运算符\n### 算术运算符\n算术运算符主要用于数学运算，其可以连接运算符前后的两个数值或表达式。\n![img-001](./Mysql学习笔记/001.png)\n\n1. 加减法运算符\n```mysql\nmysql> SELECT 100, 100 + 0, 100 - 0, 100 + 50, 100 + 50 -30, 100 + 35.5, 100 - 35.5 FROM dual;\n+-----+---------+---------+----------+--------------+------------+------------+\n| 100 | 100 + 0 | 100 - 0 | 100 + 50 | 100 + 50 -30 | 100 + 35.5 | 100 - 35.5 |\n+-----+---------+---------+----------+--------------+------------+------------+\n| 100 |     100 |     100 |      150 |          120 |      135.5 |       64.5 |\n+-----+---------+---------+----------+--------------+------------+------------+\n1 row in set (0.00 sec)\n```\n> - 一个整数类型的值对整数进行加法和减法操作，结果还是一个整数；\n> - 一个整数类型的值对浮点数进行加法和减法操作，结果是一个浮点数；\n> - 加法和减法的优先级相同，进行先加后减操作与进行先减后加操作的结果是一样的；\n> - 在Java中，+的左右两边如果有字符串，那么表示字符串的拼接。但是在MySQL中+只表示数值相加。如果遇到非数值类型，先尝试转成数值，如果转失败，就按0计算。（补充：MySQL中字符串拼接要使用字符串函数CONCAT()实现）\n\n2. 乘除法运算符\n```mysql\nmysql> SELECT 100, 100 * 1, 100 * 1.0, 100 / 1.0, 100 / 2,100 + 2 * 5 / 2,100 /3, 100 DIV 0 FROM dual;\n+-----+---------+-----------+-----------+---------+-----------------+---------+-----------+\n| 100 | 100 * 1 | 100 * 1.0 | 100 / 1.0 | 100 / 2 | 100 + 2 * 5 / 2 | 100 /3  | 100 DIV 0 |\n+-----+---------+-----------+-----------+---------+-----------------+---------+-----------+\n| 100 |     100 |     100.0 |  100.0000 | 50.0000 |        105.0000 | 33.3333 |      NULL |\n+-----+---------+-----------+-----------+---------+-----------------+---------+-----------+\n1 row in set (0.00 sec)\n```\n> - 一个数乘以整数1和除以整数1后仍得原数；\n> - 一个数乘以浮点数1和除以浮点数1后变成浮点数，数值与原数相等；\n> - 一个数除以整数后，不管是否能除尽，结果都为一个浮点数；\n> - 一个数除以另一个数，除不尽时，结果为一个浮点数，并保留到小数点后4位；\n> - 乘法和除法的优先级相同，进行先乘后除操作与先除后乘操作，得出的结果相同。\n> - 在数学运算中，0不能用作除数，在MySQL中，一个数除以0为NULL。\n\n**求模（求余）运算符**\n```mysql\nmysql> SELECT 12 % 3, 12 MOD 5 FROM dual;\n+--------+----------+\n| 12 % 3 | 12 MOD 5 |\n+--------+----------+\n|      0 |        2 |\n+--------+----------+\n1 row in set (0.00 sec)\n```\n\n### 比较运算符\n**等号运算符**\n- 等号运算符（=）判断等号两边的值、字符串或表达式是否相等，如果相等则返回1，不相等则返回0\n- 在使用等号运算符时，遵循如下规则：\n  - 如果等号两边的值、字符串或表达式都为字符串，则MySQL会按照字符串进行比较，其比较的是每个字符串中字符的ANSI编码是否相等。\n  - 如果等号两边的值都是整数，则MySQL会按照整数来比较两个值的大小。\n  - 如果等号两边的值一个是整数，另一个是字符串，则MySQL会将字符串转化为数字进行比较。\n  - 如果等号两边的值、字符串或表达式中有一个为NULL，则比较结果为NULL。\n- 对比：SQL中赋值符号使用 := \n\n```mysql\nmysql> SELECT 1 = 1, 1 = '1', 1 = 0, 'a' = 'a', (5 + 3) = (2 + 6), '' = NULL , NULL = NULL; \n+-------+---------+-------+-----------+-------------------+-----------+-------------+\n| 1 = 1 | 1 = '1' | 1 = 0 | 'a' = 'a' | (5 + 3) = (2 + 6) | '' = NULL | NULL = NULL |\n+-------+---------+-------+-----------+-------------------+-----------+-------------+\n|    1  |     1   |   0   |      1    |             1     |    NULL   |        NULL  |\n+-------+---------+-------+-----------+-------------------+-----------+-------------+\n1 row in set (0.00 sec)\n\nmysql> SELECT 1 = 2, 0 = 'abc', 1 = 'abc' FROM dual;\n+-------+-----------+-----------+\n| 1 = 2 | 0 = 'abc' | 1 = 'abc' |\n+-------+-----------+-----------+\n|     0 |         1 |         0 |\n+-------+-----------+-----------+\n1 row in set, 2 warnings (0.00 sec)\n```\n\n**安全等与运算符**\n安全等于运算符（<=>）与等于运算符（=）的作用是相似的，`唯一的区别`是‘<=>’可以用来对NULL进行判断。在两个操作数均为NULL时，其返回值为1，而不为NULL；当一个操作数为NULL时，其返回值为0，而不为NULL。\n```mysql\nmysql> SELECT 1 <=> '1', 1 <=> 0, 'a' <=> 'a', (5 + 3) <=> (2 + 6), '' <=> NULL,NULL <=> NULL FROM dual;\n+-----------+---------+-------------+---------------------+-------------+---------------+\n| 1 <=> '1' | 1 <=> 0 | 'a' <=> 'a' | (5 + 3) <=> (2 + 6) | '' <=> NULL | NULL <=> NULL |\n+-----------+---------+-------------+---------------------+-------------+---------------+\n|         1 |       0 |           1 |                   1 |           0 |             1 |\n+-----------+---------+-------------+---------------------+-------------+---------------+\n1 row in set (0.00 sec)\n```\n\n**不等于运算符**\n不等于运算符（<>和!=）用于判断两边的数字、字符串或者表达式的值是否不相等，如果不相等则返回1，相等则返回0。不等于运算符不能判断NULL值。如果两边的值有任意一个为NULL，或两边都为NULL，则结果为NULL。\n```mysql\nmysql> SELECT 1 <> 1, 1 != 2, 'a' != 'b', (3+4) <> (2+6), 'a' != NULL, NULL <> NULL; \n+--------+--------+------------+----------------+-------------+--------------+\n| 1 <> 1 | 1 != 2 | 'a' != 'b' | (3+4) <> (2+6) | 'a' != NULL | NULL <> NULL |\n+--------+--------+------------+----------------+-------------+--------------+\n|      0 |   1    |       1    |            1   |     NULL    |         NULL |\n+--------+--------+------------+----------------+-------------+--------------+\n1 row in set (0.00 sec)\n```\n\n**空值运算符**\n空运算符（IS NULL或者ISNULL）判断一个值是否为NULL，如果为NULL则返回1，否则返回0。\n\n**非空运算符**\n非空运算符（IS NOT NULL）判断一个值是否不为NULL，如果不为NULL则返回1，否则返回0。\n\n**最小值运算符**\n语法格式为：LEAST(值1，值2，...，值n)\n```mysql\nmysql> SELECT LEAST (1,0,2), LEAST('b','a','c'), LEAST(1,NULL,2);\n+---------------+--------------------+-----------------+\n| LEAST (1,0,2) | LEAST('b','a','c') | LEAST(1,NULL,2) |\n+---------------+--------------------+-----------------+\n|       0       |        a           |      NULL       |\n+---------------+--------------------+-----------------+\n1 row in set (0.00 sec)\n```\n当参数是整数或者浮点数时，LEAST将返回其中最小的值；当参数为字符串时，返回字母表中顺序最靠前的字符；当比较值列表中有NULL时，不能判断大小，返回值为NULL。\n\n**最大值运算符**\n语法格式为：GREATEST(值1，值2，...，值n)\n```mysql\nmysql> SELECT GREATEST(1,0,2), GREATEST('b','a','c'), GREATEST(1,NULL,2);\n+-----------------+-----------------------+--------------------+\n| GREATEST(1,0,2) | GREATEST('b','a','c') | GREATEST(1,NULL,2) |\n+-----------------+-----------------------+--------------------+\n|               2 | c                     |               NULL |\n+-----------------+-----------------------+--------------------+\n1 row in set (0.00 sec)\n```\n当参数中是整数或者浮点数时，GREATEST将返回其中最大的值；当参数为字符串时，返回字母表中顺序最靠后的字符；当比较值列表中有NULL时，不能判断大小，返回值为NULL。\n\n**BETWEEN AND运算符**\n使用的格式通常为SELECT D FROM TABLE WHERE C BETWEEN A AND B，注意A必须小于B！\n```mysql\nmysql> SELECT 1 BETWEEN 0 AND 1, 10 BETWEEN 11 AND 12, 'b' BETWEEN 'a' AND 'c';\n+-------------------+----------------------+-------------------------+\n| 1 BETWEEN 0 AND 1 | 10 BETWEEN 11 AND 12 | 'b' BETWEEN 'a' AND 'c' |\n+-------------------+----------------------+-------------------------+\n|                 1 |                    0 |                       1 |\n+-------------------+----------------------+-------------------------+\n1 row in set (0.00 sec)\n```\n\n**IN运算符**\nIN运算符用于判断给定的值是否是IN列表中的一个值，如果是则返回1，否则返回0。如果给定的值为NULL，或者IN列表中存在NULL，则结果为NULL。\n```mysql\nmysql> SELECT 'a' IN ('a','b','c'), 1 IN (2,3), NULL IN ('a','b'), 'a' IN ('a', NULL);\n+----------------------+------------+-------------------+--------------------+\n| 'a' IN ('a','b','c') | 1 IN (2,3) | NULL IN ('a','b') | 'a' IN ('a', NULL) |\n+----------------------+------------+-------------------+--------------------+\n|            1         |        0   |         NULL      |         1          |\n+----------------------+------------+-------------------+--------------------+\n1 row in set (0.00 sec)\n```\n\n**NOT IN运算符**\nNOT IN运算符用于判断给定的值是否不是IN列表中的一个值，如果不是IN列表中的一个值，则返回1，否则返回0。\n```mysql\nmysql> SELECT 'a' NOT IN ('a','b','c'), 1 NOT IN (2,3);\n+--------------------------+----------------+\n| 'a' NOT IN ('a','b','c') | 1 NOT IN (2,3) |\n+--------------------------+----------------+\n|                 0        |            1   |\n+--------------------------+----------------+\n1 row in set (0.00 sec)\n```\n\n**LIKE运算符**\nLIKE运算符主要用来匹配字符串，通常用于模糊匹配，如果满足条件则返回1，否则返回0。如果给定的值或者匹配条件为NULL，则返回结果为NULL。\n```mysql\n# 通配符\n# “%”：匹配0个或多个字符。\n# “_”：只能匹配一个字符。\n\nSELECT\tfirst_name\nFROM \temployees\nWHERE\tfirst_name LIKE 'S%';\n```\n\n**ESCAPE**\nESCAPE 关键字的主要作用就是指定一个字符替代“\\”的作用。查询条件中所有通过ESCAPE指代的字符均会替代“\\”的作用。\n```mysql\n# MySQL中，转义字符以“\\”开头\n\n### 查询名字中带明字的用户\nSELECT * FROM user WHERE name LIKE CONCAT(\"%\", \"明\", \"%\")\n\n### 查询名字带有%字符的用户\nSELECT * FROM user WHERE name LIKE CONCAT(\"%\", \"\\%\", \"%\")\n\n# 使用ESCAPE代替转义字符 \\\n### 查询名字带有“%”字符的用户\nSELECT * FROM user WHERE name LIKE CONCAT(\"%\", \"$%\", \"%\") ESCAPE \"$\"\n\n### 查询名字带有“_”字符的用户\nSELECT * FROM user WHERE name LIKE CONCAT(\"%\", \"a_\", \"%\") ESCAPE \"a\"\n```\n\n**REGEXP运算符**\nREGEXP运算符用来匹配字符串，语法格式为：`expr REGEXP 匹配条件`。如果expr满足匹配条件，返回1；如果不满足，则返回0。若expr或匹配条件任意一个为NULL，则结果为NULL。\n\nREGEXP运算符在进行匹配时，常用的有下面几种通配符：\n```\n（1）‘^’匹配以该字符后面的字符开头的字符串。\n（2）‘$’匹配以该字符前面的字符结尾的字符串。\n（3）‘.’匹配任何一个单字符。\n（4）“[...]”匹配在方括号内的任何字符。例如，“[abc]”匹配“a”或“b”或“c”。为了命名字符的范围，使用一个‘-’。“[a-z]”匹配任何字母，而“[0-9]”匹配任何数字。\n（5）‘*’匹配零个或多个在它前面的字符。例如，“x*”匹配任何数量的‘x’字符，“[0-9]*”匹配任何数量的数字，而“*”匹配任何数量的任何字符。\n```\n\n```mysql\nmysql> SELECT 'shkstart' REGEXP '^s', 'shkstart' REGEXP 't$', 'shkstart' REGEXP 'hk';\n+------------------------+------------------------+-------------------------+\n| 'shkstart' REGEXP '^s' | 'shkstart' REGEXP 't$' | 'shkstart' REGEXP 'hk'  |\n+------------------------+------------------------+-------------------------+\n|                      1 |                      1 |                       1 |\n+------------------------+------------------------+-------------------------+\n1 row in set (0.01 sec)\n\nmysql> SELECT 'atguigu' REGEXP 'gu.gu', 'atguigu' REGEXP '[ab]';\n+--------------------------+-------------------------+\n| 'atguigu' REGEXP 'gu.gu' | 'atguigu' REGEXP '[ab]' |\n+--------------------------+-------------------------+\n|                        1 |                       1 |\n+--------------------------+-------------------------+\n1 row in set (0.00 sec)\n```\n\n**图示总览**\n![img-002](./Mysql学习笔记/002.png)\n![img-003](./Mysql学习笔记/003.png)\n\n### 逻辑运算符\n逻辑运算符主要用来判断表达式的真假，在MySQL中，逻辑运算符的返回结果为1、0或者NULL。\n![img-004](./Mysql学习笔记/004.png)\n\n**逻辑与运算符**\n逻辑与（AND或&&）运算符是当给定的所有值均为非0值，并且都不为NULL时，返回1；当给定的一个值或者多个值为0时则返回0；否则返回NULL。\n\n**逻辑或运算符**\n逻辑或（OR或||）运算符是当给定的值都不为NULL，并且任何一个值为非0值时，则返回1，否则返回0；当一个值为NULL，并且另一个值为非0值时，返回1，否则返回NULL；当两个值都为NULL时，返回NULL。\n>OR可以和AND一起使用，但是在使用时要注意两者的优先级，由于AND的优先级高于OR，因此先对AND两边的操作数进行操作，再与OR中的操作数结合。\n\n**逻辑非运算符**\n逻辑非（NOT或!）运算符表示当给定的值为0时返回1；当给定的值为非0值时返回0；当给定的值为NULL时，返回NULL。\n\n**逻辑异或运算符**\n逻辑或（OR或||）运算符是当给定的值都不为NULL，并且任何一个值为非0值时，则返回1，否则返回0；当一个值为NULL，并且另一个值为非0值时，返回1，否则返回NULL；当两个值都为NULL时，返回NULL。\n\n### 位运算符\n位运算符是在二进制数上进行计算的运算符。位运算符会先将操作数变成二进制数，然后进行位运算，最后将计算结果从二进制变回十进制数。\n![img-005](./Mysql学习笔记/005.png)\n\n### 运算符优先级\n![img-006](./Mysql学习笔记/006.png)\n![img-007](./Mysql学习笔记/007.png)\n\n## 正则表达式\nMySQL中使用REGEXP关键字指定正则表达式的字符匹配模式。下表列出了REGEXP操作符中常用字符匹配列表。\n![img-008](./Mysql学习笔记/008.png)\n\n**1. 查询以特定字符或字符串开头的记录**\n字符‘^’匹配以特定字符或者字符串开头的文本。\n\n在fruits表中，查询f_name字段以字母‘b’开头的记录，SQL语句如下：\n\n```mysql\nmysql> SELECT * FROM fruits WHERE f_name REGEXP '^b';\n```\n\n**2. 查询以特定字符或字符串结尾的记录**\n字符‘$’匹配以特定字符或者字符串结尾的文本。\n\n在fruits表中，查询f_name字段以字母‘y’结尾的记录，SQL语句如下：\n\n```mysql\nmysql> SELECT * FROM fruits WHERE f_name REGEXP 'y$';\n```\n\n**3. 用符号\".\"来替代字符串中的任意一个字符**\n字符‘.’匹配任意一个字符。\n在fruits表中，查询f_name字段值包含字母‘a’与‘g’且两个字母之间只有一个字母的记录，SQL语句如下：\n\n```mysql\nmysql> SELECT * FROM fruits WHERE f_name REGEXP 'a.g';\n```\n\n**4. 使用\"*\"和\"+\"来匹配多个字符**\n星号‘*’匹配前面的字符任意多次，包括0次。加号‘+’匹配前面的字符至少一次。\n\n在fruits表中，查询f_name字段值以字母‘b’开头且‘b’后面出现字母‘a’的记录，SQL语句如下：\n\n```mysql\nmysql> SELECT * FROM fruits WHERE f_name REGEXP '^ba*';\n```\n\n在fruits表中，查询f_name字段值以字母‘b’开头且‘b’后面出现字母‘a’至少一次的记录，SQL语句如下：\n\n```mysql\nmysql> SELECT * FROM fruits WHERE f_name REGEXP '^ba+';\n```\n\n**5. 匹配指定字符串**\n正则表达式可以匹配指定字符串，只要这个字符串在查询文本中即可，如要匹配多个字符串，多个字符串之间使用分隔符‘|’隔开。\n\n在fruits表中，查询f_name字段值包含字符串“on”的记录，SQL语句如下：\n\n```mysql\nmysql> SELECT * FROM fruits WHERE f_name REGEXP 'on';\n```\n\n在fruits表中，查询f_name字段值包含字符串“on”或者“ap”的记录，SQL语句如下：\n\n```mysql\nmysql> SELECT * FROM fruits WHERE f_name REGEXP 'on|ap';\n```\n\n之前介绍过，LIKE运算符也可以匹配指定的字符串，但与REGEXP不同，LIKE匹配的字符串如果在文本中间出现，则找不到它，相应的行也不会返回。REGEXP在文本内进行匹配，如果被匹配的字符串在文本中出现，REGEXP将会找到它，相应的行也会被返回。对比结果如下所示。\n\n在fruits表中，使用LIKE运算符查询f_name字段值为“on”的记录，SQL语句如下：\n\n```mysql\nmysql> SELECT * FROM fruits WHERE f_name like 'on';\nEmpty set(0.00 sec)\n```\n\n**6. 匹配指定字符中的任意一个**\n方括号“[]”指定一个字符集合，只匹配其中任何一个字符，即为所查找的文本。\n\n在fruits表中，查找f_name字段中包含字母‘o’或者‘t’的记录，SQL语句如下：\n\n```mysql\nmysql> SELECT * FROM fruits WHERE f_name REGEXP '[ot]';\n```\n\n在fruits表中，查询s_id字段中包含4、5或者6的记录，SQL语句如下：\n\n```mysql\nmysql> SELECT * FROM fruits WHERE s_id REGEXP '[456]';\n```\n\n**7. 匹配指定字符以外的字符**\n`“[^字符集合]”`匹配不在指定集合中的任何字符。\n\n在fruits表中，查询f_id字段中包含字母a~e和数字1~2以外字符的记录，SQL语句如下：\n\n```mysql\nmysql> SELECT * FROM fruits WHERE f_id REGEXP '[^a-e1-2]';\n```\n\n**8. 使用{n,}或者{n,m}来指定字符串连续出现的次数**\n“字符串{n,}”表示至少匹配n次前面的字符；“字符串{n,m}”表示匹配前面的字符串不少于n次，不多于m次。例如，a{2,}表示字母a连续出现至少2次，也可以大于2次；a{2,4}表示字母a连续出现最少2次，最多不能超过4次。\n\n在fruits表中，查询f_name字段值出现字母‘x’至少2次的记录，SQL语句如下：\n\n```mysql\nmysql> SELECT * FROM fruits WHERE f_name REGEXP 'x{2,}';\n```\n\n在fruits表中，查询f_name字段值出现字符串“ba”最少1次、最多3次的记录，SQL语句如下：\n\n```mysql\nmysql> SELECT * FROM fruits WHERE f_name REGEXP 'ba{1,3}';\n```\n\n## 排序\n- 使用 ORDER BY 子句排序\n  - **ASC（ascend）: 升序**\n  - **DESC（descend）:降序**\n- **ORDER BY 子句在SELECT语句的结尾**\n\n**单列排序**\n```mysql\nSELECT   last_name, job_id, department_id, hire_date\nFROM     employees\nORDER BY hire_date ;\n\n# 降序\nSELECT   last_name, job_id, department_id, hire_date\nFROM     employees\nORDER BY hire_date DESC ;\n```\n\n**多列排序**\n多列排序，实际上是先按第一个排序条件进行排序，如果结果相同再按第二个排序条件进行比较，以此类推。\n```mysql\nSELECT last_name, department_id, salary\nFROM   employees\nORDER BY department_id, salary DESC;\n```\n![img-009](./Mysql学习笔记/009.png)\n\n## 分页\nMySQL中使用**LIMIT**实现分页\n```mysql\nLIMIT [位置偏移量,] 行数\n```\n“位置偏移量”指示MySQL从哪一行开始显示，是一个可选参数，不指定会从表中的第一条记录开始（第一条记录的位置偏移量是0，第二条记录的位置偏移量是1，以此类推）；第二个参数“行数”指示返回的记录条数。\n```mysql\n--前10条记录：\nSELECT * FROM 表名 LIMIT 0,10;\n或者\nSELECT * FROM 表名 LIMIT 10;\n\n--第11至20条记录：\nSELECT * FROM 表名 LIMIT 10,10;\n\n--第21至30条记录： \nSELECT * FROM 表名 LIMIT 20,10;\n```\n\n分页显示公式：**（当前页数-1）每页条数，每页条数**\n```mysql\nSELECT * FROM table \nLIMIT(PageNo - 1)*PageSize,PageSize;\n```\nPS：LIMIT 子句必须放在整个SELECT语句的最后！\n\n## 多表查询\n多表查询，也称为关联查询，指两个或更多个表一起完成查询操作。\n\n前提条件：这些一起查询的表之间是有关系的（一对一、一对多），它们之间一定是有关联字段，关联字段可能建立了外键，也可能没有建立外键。比如：员工表和部门表，这两个表依靠“部门编号”进行关联。\n\n### 错误案例\n![img-010](./Mysql学习笔记/010.png)\n\n从多个表中获取数据：\n\n![img-011](./Mysql学习笔记/011.png)\n\n```mysql\n#案例：查询员工的姓名及部门名称\nSELECT last_name, department_name\nFROM employees, departments;\n```\n查询结果：\n```\n+-----------+----------------------+\n| last_name | department_name      |\n+-----------+----------------------+\n| King      | Administration       |\n| King      | Marketing            |\n| King      | Purchasing           |\n| King      | Human Resources      |\n| King      | Shipping             |\n| King      | IT                   |\n| King      | Public Relations     |\n| King      | Sales                |\n| King      | Executive            |\n| King      | Finance              |\n| King      | Accounting           |\n| King      | Treasury             |\n...\n| Gietz     | IT Support           |\n| Gietz     | NOC                  |\n| Gietz     | IT Helpdesk          |\n| Gietz     | Government Sales     |\n| Gietz     | Retail Sales         |\n| Gietz     | Recruiting           |\n| Gietz     | Payroll              |\n+-----------+----------------------+\n2889 rows in set (0.01 sec)\n```\n\n错误分析：\n上面的SQL语句的查询结果将每一个员工和每一个部门都进行了匹配，出现了一个员工隶属所有部门的情况，查询结果的数量为员工表和部门表的记录数量乘积。\n\n### 案例分析\n- 笛卡儿积错误产生条件：\n  - 省略多个表的连接条件（关联条件）\n  - 连接条件（关联条件）无效\n  - 所有表中的所有行相互连接\n- 避免笛卡儿积，**在WHERE 加入有效的连接条件**\n```mysql\nSELECT\ttable1.column, table2.column\nFROM\ttable1, table2\nWHERE\ttable1.column1 = table2.column2;  #连接条件\n```\n- 上述错误案例的正确写法：\n```mysql\n#案例：查询员工的姓名及其部门名称\nSELECT last_name, department_name\nFROM employees, departments\nWHERE employees.department_id = departments.department_id;\n```\n- 在多个表中存在相同列名时，在列名前加上表名前缀\n\n### 多表查询分类及拓展\n**分类1：等值链接 vs 非等值连接**\n等值连接\n```mysql\nSELECT employees.employee_id, employees.last_name, \n       employees.department_id, departments.department_id,\n       departments.location_id\nFROM   employees, departments\nWHERE  employees.department_id = departments.department_id;\n```\n\n非等值连接\n```mysql\nSELECT e.last_name, e.salary, j.grade_level\nFROM   employees e, job_grades j\nWHERE  e.salary BETWEEN j.lowest_sal AND j.highest_sal;\n```\n\n**分类2：自连接 vs 非自连接**\n\n![img-012](./Mysql学习笔记/012.png)\n\n当table1和table2本质上是同一张表，只是用取别名的方式虚拟成两张表以代表不同的意义，此时的多表查询类型为自连接。然后两个表可以再进行内连接，外连接等查询。\n```mysql\nSELECT CONCAT(worker.last_name ,' works for ' \n       , manager.last_name)\nFROM   employees worker, employees manager\nWHERE  worker.manager_id = manager.employee_id ;\n```\n\n**分类3：内连接 vs外连接**\n\n![img-013](./Mysql学习笔记/013.png)\n\n- 内连接: 合并具有同一列的两个以上的表的行, **结果集中不包含一个表与另一个表不匹配的行**\n- 外连接: 两个表在连接过程中除了返回满足连接条件的行以外**还返回左（或右）表中不满足条件的行** **，这种连接称为左（或右） 外连接**。没有匹配的行时, 结果表中相应的列为空(NULL)\n  - 如果是左外连接，则连接条件中左边的表也称为`主表`，右边的表称为`从表`\n  - 如果是右外连接，则连接条件中右边的表也称为`主表`，左边的表称为`从表`\n\n**拓展**\n拓展1：多个连接条件时使用**AND**操作符\n拓展2：使用表名前缀区分重复的列名\n```mysql\nSELECT employees.last_name, departments.department_name,employees.department_id\nFROM employees, departments\nWHERE employees.department_id = departments.department_id;\n```\n拓展3：使用表别名简化查询，提高查询效率\n```mysql\nSELECT e.employee_id, e.last_name, e.department_id,\n       d.department_id, d.location_id\nFROM   employees e , departments d\nWHERE  e.department_id = d.department_id;\n```\n> 需要注意的是，如果我们使用了表的别名，在查询字段中、过滤条件中就只能使用别名进行代替，不能使用原有的表名，否则就会报错。\n\n> `阿里开发规范`：\n>\n> 【`强制`】对于数据库中表记录的查询和变更，只要涉及多个表，都需要在列名前加表的别名（或 表名）进行限定。 \n>\n> `说明`：对多表进行查询记录、更新记录、删除记录时，如果对操作列没有限定表的别名（或表名），并且操作列在多个表中存在时，就会抛异常。 \n>\n> `正例`：select t1.name from table_first as t1 , table_second as t2 where t1.id=t2.id; \n>\n> `反例`：在某业务中，由于多表关联查询语句没有加表的别名（或表名）的限制，正常运行两年后，最近在 某个表中增加一个同名字段，在预发布环境做数据库变更后，线上查询语句出现出 1052 异常：Column  'name' in field list is ambiguous。\n\n拓展4：连接n个表，至少需要n-1个连接条件\n\n### SQL99语法实现多表查询\n- 使用JOIN...ON子句创建连接的语法结构：\n```mysql\nSELECT table1.column, table2.column,table3.column\nFROM table1\n    JOIN table2 ON table1 和 table2 的连接条件\n    \tJOIN table3 ON table2 和 table3 的连接条件\n```\n\n嵌套逻辑类似 FOR 循环：\n```mysql\nfor t1 in table1:\n    for t2 in table2:\n       if condition1:\n           for t3 in table3:\n              if condition2:\n                  output t1 + t2 + t3\n```\n\nSQL99 采用的这种嵌套结构非常清爽、层次性更强、可读性更强，即使再多的表进行连接也都清晰\n\n- 语法说明：\n  - **可以使用 ON 子句指定额外的连接条件**\n  - 这个连接条件是与其它条件分开的\n  - **ON 子句使语句具有更高的易读性**\n  - 关键字 JOIN、INNER JOIN、CROSS JOIN 的含义是一样的，都表示内连接\n\n#### 内连接(INNER JOIN)的实现\n```mysql\nSELECT 字段列表\nFROM A表 INNER JOIN B表\nON 关联条件\nWHERE 等其他子句;\n```\n\n#### 外连接(OUTER JOIN)的实现\n##### 左外连接LEFT OUTER JOIN\n```mysql\n#实现查询结果是A\nSELECT 字段列表\nFROM A表 LEFT JOIN B表\nON 关联条件\nWHERE 等其他子句;\n```\n##### 右外连接REIGHT OUTER JOIN\n```mysql\n#实现查询结果是B\nSELECT 字段列表\nFROM A表 RIGHT JOIN B表\nON 关联条件\nWHERE 等其他子句;\n```\n\n##### 满外连接FULL OUTER JOIN\n- 满外连接的结果 = 左右表匹配的数据 + 左表没有匹配到的数据 + 右表没有匹配到的数据。\n- SQL99是支持满外连接的。使用FULL JOIN 或 FULL OUTER JOIN来实现。\n- 需要注意的是，MySQL不支持FULL JOIN，但是可以用 LEFT JOIN **UNION** RIGHT join代替\n\n##### UNION的使用\n**合并查询结果**\n利用UNION关键字，可以给出多条SELECT语句，并将它们的结果组合成单个结果集。合并时，两个表对应的列数和数据类型必须相同，并且相互对应。各个SELECT语句之间使用UNION或UNION ALL关键字分隔。\n\n语法格式：\n```mysql\nSELECT column,... FROM table1\nUNION [ALL]\nSELECT column,... FROM table2\n```\n\n**UNION操作符**\n\n![img 014](./Mysql学习笔记/014.png)\n\n返回两个查询的结果集的并集，去除重复记录\n\n**UNION ALL操作符**\n\n![img 015](./Mysql学习笔记/015.png)\n\n返回两个查询的结果集的并集，不去除重复记录\n\n> 执行UNION ALL所需要的资源比UNION语句少，如果名曲知道合并数据的结果不存在重复数据，或者不需要去除重复的数据，则尽量使用UNION ALL语句，提高数据查询的效率\n\n举例1：查询部门编号>90或邮箱包含a的员工信息\n```mysql\n#方式1\nSELECT * FROM employees WHERE email LIKE '%a%' OR department_id>90;\n```\n```mysql\n#方式2\nSELECT * FROM employees WHERE email LIKE '%a%'\nUNION\nSELECT * FROM employees WHERE department_id>90;\n```\n\n举例2：查询中国用户中男性的信息及美国用户中男性的用户信息\n```mysql\nSELECT id, cname FROM t_chinamale WHERE csex='男'\nUNION ALL\nSELECT id, tname FROM t_usmale WHERE tGender='male';\n```\n\n##### 7种SQL JOINS的实现\n![img 016](./Mysql学习笔记/016.png)\n\n```mysql\n#中图：内连接 A∩B\nSELECT employee_id,last_name,department_name\nFROM employees e JOIN departments d\nON e.`department_id` = d.`department_id`;\n```\n\n```mysql\n#左上图：左外连接\nSELECT employee_id,last_name,department_name\nFROM employees e LEFT JOIN departments d\nON e.`department_id` = d.`department_id`;\n```\n\n```mysql\n#右上图：右外连接\nSELECT employee_id,last_name,department_name\nFROM employees e RIGHT JOIN departments d\nON e.`department_id` = d.`department_id`;\n```\n\n```mysql\n#左中图：A - A∩B\nSELECT employee_id,last_name,department_name\nFROM employees e LEFT JOIN departments d\nON e.`department_id` = d.`department_id`\nWHERE d.`department_id` IS NULL\n```\n\n```mysql\n#右中图：B-A∩B\nSELECT employee_id,last_name,department_name\nFROM employees e RIGHT JOIN departments d\nON e.`department_id` = d.`department_id`\nWHERE e.`department_id` IS NULL\n```\n\n```mysql\n#左下图：满外连接\n#左中图 + 右上图  A∪B\nSELECT employee_id,last_name,department_name\nFROM employees e LEFT JOIN departments d\nON e.`department_id` = d.`department_id`\nWHERE d.`department_id` IS NULL\nUNION ALL  #没有去重操作，效率高\nSELECT employee_id,last_name,department_name\nFROM employees e RIGHT JOIN departments d\nON e.`department_id` = d.`department_id`;\n```\n\n```mysql\n#右下图\n#左中图 + 右中图  A ∪B- A∩B 或者 (A -  A∩B) ∪ （B - A∩B）\nSELECT employee_id,last_name,department_name\nFROM employees e LEFT JOIN departments d\nON e.`department_id` = d.`department_id`\nWHERE d.`department_id` IS NULL\nUNION ALL\nSELECT employee_id,last_name,department_name\nFROM employees e RIGHT JOIN departments d\nON e.`department_id` = d.`department_id`\nWHERE e.`department_id` IS NULL\n```\n\n**小结**\n- 左中图\n\n```mysql\n#实现A -  A∩B\nselect 字段列表\nfrom A表 left join B表\non 关联条件\nwhere 从表关联字段 is null and 等其他子句;\n```\n\n- 右中图\n\n```mysql\n#实现B -  A∩B\nselect 字段列表\nfrom A表 right join B表\non 关联条件\nwhere 从表关联字段 is null and 等其他子句;\n```\n\n- 左下图\n\n```mysql\n#实现查询结果是A∪B\n#用左外的A，union 右外的B\nselect 字段列表\nfrom A表 left join B表\non 关联条件\nwhere 等其他子句\n\nunion \n\nselect 字段列表\nfrom A表 right join B表\non 关联条件\nwhere 等其他子句;\n```\n\n- 右下图\n\n```mysql\n#实现A∪B -  A∩B  或   (A -  A∩B) ∪ （B - A∩B）\n#使用左外的 (A -  A∩B)  union 右外的（B - A∩B）\nselect 字段列表\nfrom A表 left join B表\non 关联条件\nwhere 从表关联字段 is null and 等其他子句\n\nunion\n\nselect 字段列表\nfrom A表 right join B表\non 关联条件\nwhere 从表关联字段 is null and 等其他子句\n```\n\n#### SQL99新特性\n##### 自然连接\nSQL99 在 SQL92 的基础上提供了一些特殊语法，比如 `NATURAL JOIN` 用来表示自然连接。我们可以把自然连接理解为 SQL92 中的等值连接。它会帮你自动查询两张连接表中`所有相同的字段`，然后进行`等值连接`。\n\n在SQL92标准中：\n```mysql\nSELECT employee_id,last_name,department_name\nFROM employees e JOIN departments d\nON e.`department_id` = d.`department_id`\nAND e.`manager_id` = d.`manager_id`;\n```\n\n在 SQL99 中你可以写成：\n```mysql\nSELECT employee_id,last_name,department_name\nFROM employees e NATURAL JOIN departments d;\n```\n\n##### USING连接\n当我们进行连接的时候，SQL99还支持使用 USING 指定数据表里的`同名字段`进行等值连接。但是只能配合JOIN一起使用。比如：\n\n```mysql\nSELECT employee_id,last_name,department_name\nFROM employees e JOIN departments d\nUSING (department_id);\n```\n\n你能看出与自然连接 NATURAL JOIN 不同的是，USING 指定了具体的相同的字段名称，你需要在 USING 的括号 () 中填入要指定的同名字段。同时使用 `JOIN...USING` 可以简化 JOIN ON 的等值连接。它与下面的 SQL 查询结果是相同的：\n\n```mysql\nSELECT employee_id,last_name,department_name\nFROM employees e ,departments d\nWHERE e.department_id = d.department_id;\n```\n\n**小结**\n表连接的约束条件可以有三种方式：WHERE, ON, USING\n\n- WHERE：适用于所有关联查询\n- ON：只能和JOIN一起使用，只能写关联条件。虽然关联条件可以并到WHERE中和其他条件一起写，但分开写可读性更好\n- USING：只能和JOIN一起使用，而且要求**两个**关联字段在关联表中名称一致，而且只能表示关联字段值相等\n\n```mysql\n#关联条件\n#把关联条件写在where后面\nSELECT last_name,department_name \nFROM employees,departments \nWHERE employees.department_id = departments.department_id;\n\n#把关联条件写在on后面，只能和JOIN一起使用\nSELECT last_name,department_name \nFROM employees INNER JOIN departments \nON employees.department_id = departments.department_id;\n\nSELECT last_name,department_name \nFROM employees CROSS JOIN departments \nON employees.department_id = departments.department_id;\n\nSELECT last_name,department_name  \nFROM employees JOIN departments \nON employees.department_id = departments.department_id;\n\n#把关联字段写在using()中，只能和JOIN一起使用\n#而且两个表中的关联字段必须名称相同，而且只能表示=\n#查询员工姓名与基本工资\nSELECT last_name,job_title\nFROM employees INNER JOIN jobs USING(job_id);\n\n#n张表关联，需要n-1个关联条件\n#查询员工姓名，基本工资，部门名称\nSELECT last_name,job_title,department_name FROM employees,departments,jobs \nWHERE employees.department_id = departments.department_id \nAND employees.job_id = jobs.job_id;\n\nSELECT last_name,job_title,department_name \nFROM employees INNER JOIN departments INNER JOIN jobs \nON employees.department_id = departments.department_id \nAND employees.job_id = jobs.job_id;\n```\n\n注意：我们要控制**连接表的数量**。多表连接就相当嵌套for循环一样，非常消耗资源，会让SQL的查询性能下降得很严重，因此不要连接不要的表。\n>【强制】超过三个表禁止 join。需要 join 的字段，数据类型保持绝对一致；多表关联查询时， 保证被关联的字段需要有索引。 \n> 说明：即使双表 join 也要注意表索引、SQL 性能。\n> 来源：阿里巴巴《Java开发手册》\n\n## 函数\nMySQL提供了丰富的内置函数，这些函数使得数据的维护与管理更加方便，能够更好地提供数据的分析与统计功能，在一定程度上提高了开发人员进行数据分析与统计的效率。\n\nMySQL提供的内置函数从`实现的功能角度`可以分为数值函数、字符串函数、日期和时间函数、流程控制函数、加密与解密函数、获取MySQL信息函数、聚合函数等。这里，我将这些丰富的内置函数再分为两类：`单行函数`、`聚合函数（或分组函数）`。\n\n![img 017](./Mysql学习笔记/017.png)\n\n### 单行函数\n- 操作数据对象\n- 接受参数返回一个结果\n- **只对一行进行变换**\n- **每行返回一个结果**\n- 可以嵌套\n- 参数可以是一列或一个值\n\n#### 数值函数\n**基本函数**\n| 函数                | 用法                                                         |\n| ------------------- | ------------------------------------------------------------ |\n| ABS(x)              | 返回x的绝对值                                                |\n| SIGN(X)             | 返回X的符号。正数返回1，负数返回-1，0返回0                   |\n| PI()                | 返回圆周率的值                                               |\n| CEIL(x)，CEILING(x) | 返回大于或等于某个值的最小整数                               |\n| FLOOR(x)            | 返回小于或等于某个值的最大整数                               |\n| LEAST(e1,e2,e3…)    | 返回列表中的最小值                                           |\n| GREATEST(e1,e2,e3…) | 返回列表中的最大值                                           |\n| MOD(x,y)            | 返回X除以Y后的余数                                           |\n| RAND()              | 返回0~1的随机值                                              |\n| RAND(x)             | 返回0~1的随机值，其中x的值用作种子值，相同的X值会产生相同的随机数 |\n| ROUND(x)            | 返回一个对x的值进行四舍五入后，最接近于X的整数               |\n| ROUND(x,y)          | 返回一个对x的值进行四舍五入后最接近X的值，并保留到小数点后面Y位 |\n| TRUNCATE(x,y)       | 返回数字x截断为y位小数的结果                                 |\n| SQRT(x)             | 返回x的平方根。当X的值为负数时，返回NULL                     |\n\n**角度与弧度互换函数**\n| 函数       | 用法                                  |\n| ---------- | ------------------------------------- |\n| RADIANS(x) | 将角度转化为弧度，其中，参数x为角度值 |\n| DEGREES(x) | 将弧度转化为角度，其中，参数x为弧度值 |\n\n**三角函数**\n| 函数       | 用法                                                         |\n| ---------- | ------------------------------------------------------------ |\n| SIN(x)     | 返回x的正弦值，其中，参数x为弧度值                           |\n| ASIN(x)    | 返回x的反正弦值，即获取正弦为x的值。如果x的值不在-1到1之间，则返回NULL |\n| COS(x)     | 返回x的余弦值，其中，参数x为弧度值                           |\n| ACOS(x)    | 返回x的反余弦值，即获取余弦为x的值。如果x的值不在-1到1之间，则返回NULL |\n| TAN(x)     | 返回x的正切值，其中，参数x为弧度值                           |\n| ATAN(x)    | 返回x的反正切值，即返回正切值为x的值                         |\n| ATAN2(m,n) | 返回两个参数的反正切值                                       |\n| COT(x)     | 返回x的余切值，其中，X为弧度值                               |\n\n**指数与对数**\n| 函数                 | 用法                                                 |\n| -------------------- | ---------------------------------------------------- |\n| POW(x,y)，POWER(X,Y) | 返回x的y次方                                         |\n| EXP(X)               | 返回e的X次方，其中e是一个常数，2.718281828459045     |\n| LN(X)，LOG(X)        | 返回以e为底的X的对数，当X <= 0 时，返回的结果为NULL  |\n| LOG10(X)             | 返回以10为底的X的对数，当X <= 0 时，返回的结果为NULL |\n| LOG2(X)              | 返回以2为底的X的对数，当X <= 0 时，返回NULL        |\n\n**进制转换**\n| 函数                 | 用法                                                 |\n| -------------------- | ---------------------------------------------------- |\n| POW(x,y)，POWER(X,Y) | 返回x的y次方                                         |\n| EXP(X)               | 返回e的X次方，其中e是一个常数，2.718281828459045     |\n| LN(X)，LOG(X)        | 返回以e为底的X的对数，当X <= 0 时，返回的结果为NULL  |\n| LOG10(X)             | 返回以10为底的X的对数，当X <= 0 时，返回的结果为NULL |\n| LOG2(X)              | 返回以2为底的X的对数，当X <= 0 时，返回NULL        |\n\n**字符串函数**\n| 函数                              | 用法                                                         |\n| --------------------------------- | ------------------------------------------------------------ |\n| ASCII(S)                          | 返回字符串S中的第一个字符的ASCII码值                         |\n| CHAR_LENGTH(s)                    | 返回字符串s的字符数。作用与CHARACTER_LENGTH(s)相同           |\n| LENGTH(s)                         | 返回字符串s的字节数，和字符集有关                            |\n| CONCAT(s1,s2,......,sn)           | 连接s1,s2,......,sn为一个字符串                              |\n| CONCAT_WS(x, s1,s2,......,sn)     | 同CONCAT(s1,s2,...)函数，但是每个字符串之间要加上x           |\n| INSERT(str, idx, len, replacestr) | 将字符串str从第idx位置开始，len个字符长的子串替换为字符串replacestr |\n| REPLACE(str, a, b)                | 用字符串b替换字符串str中所有出现的字符串a                    |\n| UPPER(s) 或 UCASE(s)              | 将字符串s的所有字母转成大写字母                              |\n| LOWER(s)  或LCASE(s)              | 将字符串s的所有字母转成小写字母                              |\n| LEFT(str,n)                       | 返回字符串str最左边的n个字符                                 |\n| RIGHT(str,n)                      | 返回字符串str最右边的n个字符                                 |\n| LPAD(str, len, pad)               | 用字符串pad对str最左边进行填充，直到str的长度为len个字符     |\n| RPAD(str ,len, pad)               | 用字符串pad对str最右边进行填充，直到str的长度为len个字符     |\n| LTRIM(s)                          | 去掉字符串s左侧的空格                                        |\n| RTRIM(s)                          | 去掉字符串s右侧的空格                                        |\n| TRIM(s)                           | 去掉字符串s开始与结尾的空格                                  |\n| TRIM(s1 FROM s)                   | 去掉字符串s开始与结尾的s1                                    |\n| TRIM(LEADING s1 FROM s)           | 去掉字符串s开始处的s1                                        |\n| TRIM(TRAILING s1 FROM s)          | 去掉字符串s结尾处的s1                                        |\n| REPEAT(str, n)                    | 返回str重复n次的结果                                         |\n| SPACE(n)                          | 返回n个空格                                                  |\n| STRCMP(s1,s2)                     | 比较字符串s1,s2的ASCII码值的大小                             |\n| SUBSTR(s,index,len)               | 返回从字符串s的index位置其len个字符，作用与SUBSTRING(s,n,len)、MID(s,n,len)相同 |\n| LOCATE(substr,str)                | 返回字符串substr在字符串str中首次出现的位置，作用于POSITION(substr IN str)、INSTR(str,substr)相同。未找到，返回0 |\n| ELT(m,s1,s2,…,sn)                 | 返回指定位置的字符串，如果m=1，则返回s1，如果m=2，则返回s2，如果m=n，则返回sn |\n| FIELD(s,s1,s2,…,sn)               | 返回字符串s在字符串列表中第一次出现的位置                    |\n| FIND_IN_SET(s1,s2)                | 返回字符串s1在字符串s2中出现的位置。其中，字符串s2是一个以逗号分隔的字符串 |\n| REVERSE(s)                        | 返回s反转后的字符串                                          |\n| NULLIF(value1,value2)             | 比较两个字符串，如果value1与value2相等，则返回NULL，否则返回value1 |\n\n> 注意：MySQL中，字符串的位置是从1开始的。\n\n**日期时间函数**\n| 函数                                                         | 用法                           |\n| ------------------------------------------------------------ | ------------------------------ |\n| **CURDATE()** ，CURRENT_DATE()   | 返回当前日期，只包含年、月、日   |\n| **CURTIME()** ， CURRENT_TIME()    | 返回当前时间，只包含时、分、秒 |\n| **NOW()** / SYSDATE() / CURRENT_TIMESTAMP() / LOCALTIME() / LOCALTIMESTAMP() | 返回当前系统日期和时间         |\n| UTC_DATE()             | 返回UTC（世界标准时间）日期    |\n| UTC_TIME()             | 返回UTC（世界标准时间）时间    |\n| UNIX_TIMESTAMP()         | 以UNIX时间戳的形式返回当前时间。SELECT UNIX_TIMESTAMP() ->1634348884 |\n| UNIX_TIMESTAMP(date)     | 将时间date以UNIX时间戳的形式返回          |\n| FROM_UNIXTIME(timestamp) | 将UNIX时间戳的时间转换为普通格式的时间      |\n| YEAR(date) / MONTH(date) / DAY(date)     | 返回具体的日期值         |\n| HOUR(time) / MINUTE(time) / SECOND(time) | 返回具体的时间值   |\n| MONTHNAME(date)                          | 返回月份：January，...      |\n| DAYNAME(date)            | 返回星期几：MONDAY，TUESDAY.....SUNDAY       |\n| WEEKDAY(date)         | 返回周几，注意，周1是0，周2是1，。。。周日是6   |\n| QUARTER(date)                | 返回日期对应的季度，范围为1～4           |\n| WEEK(date) ， WEEKOFYEAR(date)           | 返回一年中的第几周     |\n| DAYOFYEAR(date)                          | 返回日期是一年中的第几天     |\n| DAYOFMONTH(date)                         | 返回日期位于所在月份的第几天   |\n| DAYOFWEEK(date)         | 返回周几，注意：周日是1，周一是2，。。。周六是7 |\n| EXTRACT(type FROM date) | 返回指定日期中特定的部分，type指定返回的值 |\n| TIME_TO_SEC(time)    | 将 time 转化为秒并返回结果值。转化的公式为：`小时*3600+分钟*60+秒` |\n| SEC_TO_TIME(seconds) | 将 seconds 描述转化为包含小时、分钟和秒的时间     |\n| DATE_ADD(datetime, INTERVAL  expr type)，ADDDATE(date,INTERVAL expr type) | 返回与给定日期时间相差INTERVAL时间段的日期时间 |\n| DATE_SUB(date,INTERVAL expr type)，SUBDATE(date,INTERVAL expr type) | 返回与date相差INTERVAL时间间隔的日期           |\n| ADDTIME(time1,time2)         | 返回time1加上time2的时间。当time2为一个数字时，代表的是`秒`，可以为负数 |\n| SUBTIME(time1,time2)         | 返回time1减去time2后的时间。当time2为一个数字时，代表的是`秒`，可以为负数 |\n| DATEDIFF(date1,date2)        | 返回date1 - date2的日期间隔天数        |\n| TIMEDIFF(time1, time2)       | 返回time1 - time2的时间间隔         |\n| FROM_DAYS(N)                 | 返回从0000年1月1日起，N天以后的日期     |\n| TO_DAYS(date)                | 返回日期date距离0000年1月1日的天数     |\n| LAST_DAY(date)               | 返回date所在月份的最后一天的日期       |\n| MAKEDATE(year,n)             | 针对给定年份与所在年份中的天数返回一个日期   |\n| MAKETIME(hour,minute,second) | 将给定的小时、分钟和秒组合成时间并返回       |\n| PERIOD_ADD(time,n)           | 返回time加上n后的时间                 |\n| DATE_FORMAT(date,fmt)             | 按照字符串fmt格式化日期date值      |\n| TIME_FORMAT(time,fmt)             | 按照字符串fmt格式化时间time值      |\n| GET_FORMAT(date_type,format_type) | 返回日期字符串的显示格式            |\n| STR_TO_DATE(str, fmt)             | 按照字符串fmt对str进行解析，解析为一个日期 |\n\nEXTRACT(type FROM date)函数中type的取值与含义：\n![img-018](./Mysql学习笔记/018.png)\n![img-019](./Mysql学习笔记/019.png)\n\nGET_FORMAT函数中date_type和format_type参数取值如下：\n![img-010](./Mysql学习笔记/020.png)\n\n**流程控制函数**\n流程处理函数可以根据不同的条件，执行不同的处理流程，可以在SQL语句中实现不同的条件选择。MySQL中的流程处理函数主要包括IF()、IFNULL()和CASE()函数。\n| 函数                                                         | 用法   |\n| ------------------------------------------------------------ | ----------------------------------------------- |\n| IF(value,value1,value2)                                      | 如果value的值为TRUE，返回value1，否则返回value2 |\n| IFNULL(value1, value2)                                       | 如果value1不为NULL，返回value1，否则返回value2  |\n| CASE WHEN 条件1 THEN 结果1 WHEN 条件2 THEN 结果2 .... [ELSE resultn] END | 相当于Java的if...else if...else...              |\n| CASE  expr WHEN 常量值1 THEN 值1 WHEN 常量值1 THEN 值1 .... [ELSE 值n] END | 相当于Java的switch...case...                    |\n\n```mysql\nSELECT IF(1 > 0,'正确','错误')    \n->正确\n```\n\n```mysql\nSELECT IFNULL(null,'Hello Word')\n->Hello Word\n```\n\n```mysql\nSELECT CASE \n　　WHEN 1 > 0\n　　THEN '1 > 0'\n　　WHEN 2 > 0\n　　THEN '2 > 0'\n　　ELSE '3 > 0'\n　　END\n->1 > 0\n```\n\n```mysql\nSELECT CASE 1 \n　　WHEN 1 THEN '我是1'\n　　WHEN 2 THEN '我是2'\nELSE '你是谁'\n```\n\n```mysql\nSELECT employee_id,salary, CASE WHEN salary>=15000 THEN '高薪' \n\t\t\t\t  WHEN salary>=10000 THEN '潜力股'  \n\t\t\t\t  WHEN salary>=8000 THEN '屌丝' \n\t\t\t\t  ELSE '草根' END  \"描述\"\nFROM employees; \n```\n\n```mysql\nSELECT oid,`status`, CASE `status` WHEN 1 THEN '未付款' \n\t\t\t\t\t\t\t\t   WHEN 2 THEN '已付款' \n\t\t\t\t\t\t\t\t   WHEN 3 THEN '已发货'  \n\t\t\t\t\t\t\t\t   WHEN 4 THEN '确认收货'  \n\t\t\t\t\t\t\t\t   ELSE '无效订单' END \nFROM t_order;\n```\n\n```mysql\nmysql> SELECT CASE WHEN 1 > 0 THEN 'yes' WHEN 1 <= 0 THEN 'no' ELSE 'unknown' END;\n+---------------------------------------------------------------------+\n| CASE WHEN 1 > 0 THEN 'yes' WHEN 1 <= 0 THEN 'no' ELSE 'unknown' END |\n+---------------------------------------------------------------------+\n| yes                                                                  |\n+---------------------------------------------------------------------+\n1 row in set (0.00 sec)\n\nmysql> SELECT CASE WHEN 1 < 0 THEN 'yes' WHEN 1 = 0 THEN 'no' ELSE 'unknown' END;  \n+--------------------------------------------------------------------+\n| CASE WHEN 1 < 0 THEN 'yes' WHEN 1 = 0 THEN 'no' ELSE 'unknown' END |\n+--------------------------------------------------------------------+\n| unknown                                                             |\n+--------------------------------------------------------------------+\n1 row in set (0.00 sec)\n```\n\n```mysql\nmysql> SELECT CASE 1 WHEN 0 THEN 0 WHEN 1 THEN 1 ELSE -1 END;\n+------------------------------------------------+\n| CASE 1 WHEN 0 THEN 0 WHEN 1 THEN 1 ELSE -1 END |\n+------------------------------------------------+\n|                                               1 |\n+------------------------------------------------+\n1 row in set (0.00 sec)\n\nmysql> SELECT CASE -1 WHEN 0 THEN 0 WHEN 1 THEN 1 ELSE -1 END;\n+-------------------------------------------------+\n| CASE -1 WHEN 0 THEN 0 WHEN 1 THEN 1 ELSE -1 END |\n+-------------------------------------------------+\n|                                               -1 |\n+-------------------------------------------------+\n1 row in set (0.00 sec)\n```\n\n```mysql\nSELECT employee_id,12 * salary * (1 + IFNULL(commission_pct,0))\nFROM employees;\n```\n\n```mysql\nSELECT last_name, job_id, salary,\n       CASE job_id WHEN 'IT_PROG'  THEN  1.10*salary\n                   WHEN 'ST_CLERK' THEN  1.15*salary\n                   WHEN 'SA_REP'   THEN  1.20*salary\n       \t\t\t   ELSE      salary END     \"REVISED_SALARY\"\nFROM   employees;\n```\n\n**加密、解密函数**\n加密与解密函数主要用于对数据库中的数据进行加密和解密处理，以防止数据被他人窃取。这些函数在保证数据库安全时非常有用。\n\n| 函数                        | 用法                                                         |\n| --------------------------- | ------------------------------------------------------------ |\n| PASSWORD(str)               | 返回字符串str的加密版本，41位长的字符串。加密结果`不可逆`，常用于用户的密码加密 |\n| MD5(str)                    | 返回字符串str的md5加密后的值，也是一种加密方式。若参数为NULL，则会返回NULL |\n| SHA(str)                    | 从原明文密码str计算并返回加密后的密码字符串，当参数为NULL时，返回NULL。`SHA加密算法比MD5更加安全`。 |\n| ENCODE(value,password_seed) | 返回使用password_seed作为加密密码加密value                   |\n| DECODE(value,password_seed) | 返回使用password_seed作为加密密码解密value                   |\n\n可以看到，ENCODE(value,password_seed)函数与DECODE(value,password_seed)函数互为反函数。\n\n**Mysql信息函数**\nMySQL中内置了一些可以查询MySQL信息的函数，这些函数主要用于帮助数据库开发或运维人员更好地对数据库进行维护工作。\n\n| 函数                                                  | 用法                                                     |\n| ----------------------------------------------------- | -------------------------------------------------------- |\n| VERSION()                 | 返回当前MySQL的版本号         |\n| CONNECTION_ID()        | 返回当前MySQL服务器的连接数           |\n| DATABASE()，SCHEMA()      | 返回MySQL命令行当前所在的数据库          |\n| USER()，CURRENT_USER()、SYSTEM_USER()，SESSION_USER() | 返回当前连接MySQL的用户名，返回结果格式为“主机名@用户名” |\n| CHARSET(value)         | 返回字符串value自变量的字符集              |\n| COLLATION(value)                    | 返回字符串value的比较规则          |\n\n**其他函数**\nMySQL中有些函数无法对其进行具体的分类，但是这些函数在MySQL的开发和运维过程中也是不容忽视的。\n\n| 函数                           | 用法                                                         |\n| ------------------------------ | ------------------------------------------------------------ |\n| FORMAT(value,n)                | 返回对数字value进行格式化后的结果数据。n表示`四舍五入`后保留到小数点后n位 |\n| CONV(value,from,to)            | 将value的值进行不同进制之间的转换                            |\n| INET_ATON(ipvalue)             | 将以点分隔的IP地址转化为一个数字                             |\n| INET_NTOA(value)               | 将数字形式的IP地址转化为以点分隔的IP地址                     |\n| BENCHMARK(n,expr)              | 将表达式expr重复执行n次。用于测试MySQL处理expr表达式所耗费的时间 |\n| CONVERT(value USING char_code) | 将value所使用的字符编码修改为char_code                       |\n\n### 聚合函数\n聚合函数作用于一组数据，并对一组数据返回一个值。\n\n![img-021](./Mysql学习笔记/021.png)\n\n聚合函数类型：\n- AVG()\n- SUM()\n- MAX()\n- MIN()\n- COUNT()\n\n聚合函数语法：\n\n![img-022](./Mysql学习笔记/022.png)\n\nPS：聚合函数不能嵌套使用！\n\n**AVG和SUM函数**\n对数值类型的数据求**平均值和总和**\n```\nSELECT AVG(salary), MAX(salary), MIN(salary), SUM(salary)\nFROM emloyees\nWHERE job_id LIKE '%REP%';\n```\n\n**MIN和MAX函数**\n可以对任意类型的数据使用，求其**最大值或最小值**\n\n**COUNT函数**\n-  COUNT(*)返回表中记录总数，适用于任意数据类型\n```mysql\nSELECT COUNT(*)\nFROM\t  employees\nWHERE  department_id = 50;\n```\n- COUNT(expr)返回`expr`不为空的记录总数\n```mysql\nSELECT COUNT(commission_pct)\nFROM   employees\nWHERE  department_id = 50;\n```\n\n**QA：用count(*)，count(1)，count(列名)统计记录数量谁好呢***\n- 对于MyISAM引擎的表是没有区别的，这种引擎内部有一计数器在维护着行数\n- Innodb引擎的表用count(*)，count(1)直接读行数，复杂度是O(n)，因为innodb真的要去数一遍。但好于具体的count(列名)\n\n**QA：能不能使用count(列名)替换count(*)**\n不要使用 count(列名)来替代 `count(*)`，`count(*)`是 SQL92 定义的标准统计行数的语法，跟数据库无关，跟 NULL 和非 NULL 无关。\nPS：count(*)会统计值为 NULL 的行，而 count(列名)不会统计此列为 NULL 值的行\n\n## GROUP BY\n![img-023](./Mysql学习笔记/023.png)\n\n可使用GROUP BY将表中的数据分成若干组\n```mysql\nSELECT column, group_function(column)\nFROM table\n[WHERE\tcondition]\n[GROUP BY\tgroup_by_expression]\n[ORDER BY\tcolumn];\n```\n\nPS：\n- SELECT列表中所有未包含在组函数中的列都应该包含在**GROUP BY**子句中\n- 包含在**GROUP BY**子句中的列不必包含在SELECT列表中\n```mysql\nSELECT   department_id, AVG(salary)\nFROM     employees\nGROUP BY department_id ;\n```\n\n可以使用多个列名进行分组：\n```mysql\nSELECT   department_id dept_id, job_id, SUM(salary)\nFROM     employees\nGROUP BY department_id, job_id ;\n```\n\n**使用WITH ROLLUP**\n使用`WITH ROLLUP`关键字后，在所欲查询出的分组记录之后增加一条记录，该记录计算查询出的所有记录的总和，即统计记录数量。\n```mysql\nSELECT department_id,AVG(salary)\nFROM employees\nWHERE department_id > 80\nGROUP BY department_id WITH ROLLUP;\n```\n> PS：\n> 当使用ROLLUP时，不能同时使用ORDER BY子句进行结果排序，即ROLLUP和ORDER BY是互斥的\n\n## HAVING\n![img-024](./Mysql学习笔记/024.png)\n\n**过滤分组：HAVING**\n- 行已经被分组\n- 使用了聚合函数\n- 满足HAVING子句中条件的分组将被显示\n- HAVNG不能单独使用，必须要跟GROUP BY一起使用\n\n![img-025](./Mysql学习笔记/025.png)\n\n```mysql\nSELECT   department_id, MAX(salary)\nFROM     employees\nGROUP BY department_id\nHAVING   MAX(salary)>10000 ;\n```\n\n> PS：\n>\n> 不能再WHERE子句中使用聚合函数\n\n**WHERE和HAVING的对比**\n1. WHERE 可以直接使用表中的字段作为筛选条件，但不能使用分组中的计算函数作为筛选条件；HAVING 必须要与 GROUP BY 配合使用，可以把分组计算的函数和分组字段作为筛选条件。 \n> 这决定了，在需要对数据进行分组统计的时候，HAVING 可以完成 WHERE 不能完成的任务。这是因为，在查询语法结构中，WHERE 在 GROUP BY 之前，所以无法对分组结果进行筛选。HAVING 在 GROUP BY 之后，可以使用分组字段和分组中的计算函数，对分组的结果集进行筛选，这个功能是 WHERE 无法完成的。另外，WHERE排除的记录不再包括在分组中。\n\n2. 如果需要通过连接从关联表中获取需要的数据，WHERE 是先筛选后连接，而 HAVING 是先连接后筛选。\n> 这一点，就决定了在关联查询中，WHERE 比 HAVING 更高效。因为 WHERE 可以先筛选，用一个筛选后的较小数据集和关联表进行连接，这样占用的资源比较少，执行效率也比较高。HAVING 则需要先把结果集准备好，也就是用未被筛选的数据集进行关联，然后对这个大的数据集进行筛选，这样占用的资源就比较多，执行效率也较低。 \n>\n\n小结如下：\n|        | 优点                         | 缺点                          |\n| ------ | ---------------------------- | -------------------------------------- |\n| WHERE  | 先筛选数据再关联，执行效率高 | 不能使用分组中的计算函数进行筛选       |\n| HAVING | 可以使用分组中的计算函数     | 在最后的结果集中进行筛选，执行效率较低 |\n\n开发中的选择：\nWHERE 和 HAVING 不是互相排斥的，可以在一个查询里面同时使用 WHERE 和 HAVING。包含分组统计函数的条件用 HAVING，普通条件用 WHERE。这样既利用了 WHERE 条件的高效快速，又发挥了 HAVING 可以使用包含分组统计函数的查询条件的优点。当数据量特别大的时候，运行效率会有很大的差别。\n\n## SELECT执行过程\n### 查询结构\n```mysql\n#方式1：\nSELECT ...,....,...\nFROM ...,...,....\nWHERE 多表的连接条件\nAND 不包含组函数的过滤条件\nGROUP BY ...,...\nHAVING 包含组函数的过滤条件\nORDER BY ... ASC/DESC\nLIMIT ...,...\n\n#方式2：\nSELECT ...,....,...\nFROM ... JOIN ... \nON 多表的连接条件\nJOIN ...\nON ...\nWHERE 不包含组函数的过滤条件\nAND/OR 不包含组函数的过滤条件\nGROUP BY ...,...\nHAVING 包含组函数的过滤条件\nORDER BY ... ASC/DESC\nLIMIT ...,...\n\n#其中：\n#（1）from：从哪些表中筛选\n#（2）on：关联多表查询时，去除笛卡尔积\n#（3）where：从表中筛选的条件\n#（4）group by：分组依据\n#（5）having：在统计结果中再次筛选\n#（6）order by：排序\n#（7）limit：分页\n```\n\n### 执行顺序\nSELECT查询时的两个顺序\n1. 关键字的顺序不能颠倒\n```mysql\nSELECT ... FROM ... WHERE ... GROUP BY ... HAVING ... ORDER BY ... LIMIT\n```\n\n2. SELECT语句的执行顺序\n```mysql\nFROM -> WHERE -> GROUP BY -> HAVING -> SELECT 的字段 -> DISTINCT -> ORDER BY -> LIMIT\n```\n\n![img-026](./Mysql学习笔记/026.png)\n\nSQL举例：\n```mysql\nSELECT DISTINCT player_id, player_name, count(*) as num # 顺序 5\nFROM player JOIN team ON player.team_id = team.team_id # 顺序 1\nWHERE height > 1.80 # 顺序 2\nGROUP BY player.team_id # 顺序 3\nHAVING num > 2 # 顺序 4\nORDER BY num DESC # 顺序 6\nLIMIT 2 # 顺序 7\n```\n\n> 在SELECT语句执行这些步骤的时候，每一步都会产生一个`虚拟表`，然后将这个`虚拟表`插入下一步中作为输入。这些步骤隐含在SQL的执行过程中，对于我们是不可见的。\n> \n\n### 执行原理\nSELECT 是先执行 FROM 这一步的。在这个阶段，如果是多张表联查，还会经历下面的几个步骤：\n\n1. 首先先通过 CROSS JOIN 求笛卡尔积，相当于得到虚拟表 vt（virtual table）1-1；\n2. 通过 ON 进行筛选，在虚拟表 vt1-1 的基础上进行筛选，得到虚拟表 vt1-2；\n3. 添加外部行。如果我们使用的是左连接、右链接或者全连接，就会涉及到外部行，也就是在虚拟表 vt1-2 的基础上增加外部行，得到虚拟表 vt1-3。\n\n如果我们操作的是两张以上的表，还会重复上面的步骤，直到所有表都被处理完为止。这个过程得到是我们的原始数据。\n\n当我们拿到了查询数据表的原始数据，也就是最终的虚拟表 `vt1`，就可以在此基础上再进行 `WHERE 阶段`。在这个阶段中，会根据 vt1 表的结果进行筛选过滤，得到虚拟表 `vt2`。\n\n然后进入第三步和第四步，也就是 `GROUP 和 HAVING 阶段`。在这个阶段中，实际上是在虚拟表 vt2 的基础上进行分组和分组过滤，得到中间的虚拟表 `vt3` 和 `vt4`。\n\n当我们完成了条件筛选部分之后，就可以筛选表中提取的字段，也就是进入到 `SELECT 和 DISTINCT 阶段`。\n\n首先在 SELECT 阶段会提取想要的字段，然后在 DISTINCT 阶段过滤掉重复的行，分别得到中间的虚拟表 `vt5-1` 和 `vt5-2`。\n\n当我们提取了想要的字段数据之后，就可以按照指定的字段进行排序，也就是 `ORDER BY 阶段`，得到虚拟表 `vt6`。\n\n最后在 vt6 的基础上，取出指定行的记录，也就是 `LIMIT 阶段`，得到最终的结果，对应的是虚拟表 `vt7`。\n\n当然我们在写 SELECT 语句的时候，不一定存在所有的关键字，相应的阶段就会省略。\n\n同时因为 SQL 是一门类似英语的结构化查询语言，所以我们在写 SELECT 语句的时候，还要注意相应的关键字顺序，**所谓底层运行的原理，就是我们刚才讲到的执行顺序。**\n\n## 子查询\n即查询语句的嵌套。\n\n### 基本使用与分类\n基本语法：\n\n![img-027](./Mysql学习笔记/027.png)\n\n- 子查询在主查询之前执行完成\n- 子查询的结果被主查询使用\n> PS： \n> 子查询要包含在括号内\n> 将子查询放在比较条件的右侧\n> 单行操作符对应单行子查询，多行操作符对应多行子查询\n> \n\n**子查询分类**\n- 分类一：\n\t- 单行子查询\n\t- 多行子查询\n- 分类二：\n\t- 相关（关联）子查询\n\t- 不相关（非关联）子查询\n\n### 单行子查询\n单行比较操作符\n| 操作符 | 含义                     |\n| ------ | ------------------------ |\n| =      | equal to                 |\n| >      | greater than             |\n| >=     | greater than or equal to |\n| <      | less than                |\n| <=     | less than or equal to    |\n| <>     | not equal to             |\n\n![img-028](./Mysql学习笔记/028.png)\n\n```mysql\nSELECT last_name, job_id, salary\nFROM   employees\nWHERE  job_id =  \n                (SELECT job_id\n                 FROM   employees\n                 WHERE  employee_id = 141)\nAND    salary >\n                (SELECT salary\n                 FROM   employees\n                 WHERE  employee_id = 143);\n```\n\n```mysql\nSELECT last_name, job_id, salary\nFROM   employees\nWHERE  salary = \n                (SELECT MIN(salary)\n                 FROM   employees);\n```\n\n```mysql\n#写法一\nSELECT  employee_id, manager_id, department_id\nFROM    employees\nWHERE   manager_id IN\n\t\t  (SELECT  manager_id\n                   FROM    employees\n                   WHERE   employee_id IN (174,141))\nAND     department_id IN \n\t\t  (SELECT  department_id\n                   FROM    employees\n                   WHERE   employee_id IN (174,141))\nAND\temployee_id NOT IN(174,141);\n\n#写法二\nSELECT\temployee_id, manager_id, department_id\nFROM\temployees\nWHERE  (manager_id, department_id) IN\n                      (SELECT manager_id, department_id\n                       FROM   employees\n                       WHERE  employee_id IN (141,174))\nAND\temployee_id NOT IN (141,174);\n```\n\n**HAVING中子查询**\n- 首先执行子查询\n- 向主查询中的HAVING子句返回结果\n\nEG：查询最低工资大于50号部门最低工资的部门id和其最低工资\n```mysql\nSELECT   department_id, MIN(salary)\nFROM     employees\nGROUP BY department_id\nHAVING   MIN(salary) >\n                       (SELECT MIN(salary)\n                        FROM   employees\n                        WHERE  department_id = 50);\n```\n\n**CASE中子查询**\n在CASE表达式中使用`单列`子查询\n\nEG：显式员工的employee_id,last_name和location。其中，若员工department_id与location_id为1800的department_id相同，则location为’Canada’，其余则为’USA’\n```mysql\nSELECT employee_id, last_name,\n       (CASE department_id\n        WHEN\n             (SELECT department_id FROM departments\n\t      WHERE location_id = 1800)           \n        THEN 'Canada' ELSE 'USA' END) location\nFROM   employees;\n```\n\n**子查询空值问题**\n```mysql\nSELECT last_name, job_id\nFROM   employees\nWHERE  job_id =\n                (SELECT job_id\n                 FROM   employees\n                 WHERE  last_name = 'Haas');\n```\n\n子查询结果为空值时，此时子查询不返回任何行\n\n**非法使用子查询**\n```mysql\nSELECT employee_id, last_name\nFROM   employees\nWHERE  salary =\n                (SELECT   MIN(salary)\n                 FROM     employees\n                 GROUP BY department_id);\n```\n\n错误原因：子查询类型为多行子查询却使用单行比较符`=`\n\n### 多行子查询\n- 也称集合比较子查询\n- 子查询返回多行\n- 使用多行比较操作符\n\n多行比较操作符\n| 操作符 | 含义                                                         |\n| ------ | ---------------------------------------------------------- |\n| IN     | 等于列表中的**任意一个**                                     |\n| ANY    | 需要和单行比较操作符一起使用，和子查询返回的**某一个**值比较 |\n| ALL    | 需要和单行比较操作符一起使用，和子查询返回的**所有**值比较   |\n| SOME   | 实际上是ANY的别名，作用相同，一般常使用ANY                   |\n\n> 体会 ANY 和 ALL 的区别\n> \n\nEG：返回其它job_id中比job_id为‘IT_PROG’部门任一工资低的员工的员工号、姓名、job_id 以及salary\n\n![img-029](./Mysql学习笔记/029.png)\n\nEG：返回其它job_id中比job_id为‘IT_PROG’部门所有工资都低的员工的员工号、姓名、job_id以及salary\n\n![img-030](./Mysql学习笔记/030.png)\n\nEG：查询平均工资最低的部门id\n```mysql\n#方式1：\nSELECT department_id\nFROM employees\nGROUP BY department_id\nHAVING AVG(salary) = (\n\t\t\tSELECT MIN(avg_sal)\n\t\t\tFROM (\n\t\t\t\tSELECT AVG(salary) avg_sal\n\t\t\t\tFROM employees\n\t\t\t\tGROUP BY department_id\n\t\t\t\t) dept_avg_sal\n\t\t\t)\n\t\t\t\n#方式2：\nSELECT department_id\nFROM employees\nGROUP BY department_id\nHAVING AVG(salary) <= ALL (\n\t\t\t\tSELECT AVG(salary) avg_sal\n\t\t\t\tFROM employees\n\t\t\t\tGROUP BY department_id\n)\n```\n\n**空值问题**\n```mysql\nSELECT last_name\nFROM employees\nWHERE employee_id NOT IN (\n\t\t\tSELECT manager_id\n\t\t\tFROM employees\n\t\t\t);\n```\n同单行子查询，查询为空时不返回任何行\n\n### 相关子查询\n如果子查询的执行依赖于外部查询，通常情况下都是因为子查询中的表用到了外部的表，并进行了条件关联，因此每执行一次外部查询，子查询都要重新计算一次，这样的子查询就称之为`关联子查询`\n\n相关子查询按照一行接一行的顺序执行，主查询的每一行都执行一次子查询\n\n![img-031](./Mysql学习笔记/031.png)\n\n![img-032](./Mysql学习笔记/032.png)\n\n> 子查询中使用主查询中的列\n> \n\nEG：查询员工中工资大于本部门平均工资的员工的last_name,salary和其department_id\n方式一：相关子查询\n\n![img-033](./Mysql学习笔记/033.png)\n\n方式二：在FROM中使用子查询\n```mysql\nSELECT last_name,salary,e1.department_id\nFROM employees e1,(SELECT department_id,AVG(salary) dept_avg_sal FROM employees GROUP BY department_id) e2\nWHERE e1.`department_id` = e2.department_id\nAND e2.dept_avg_sal < e1.`salary`;\n```\n\n> FROM型的子查询：子查询是作为FROM的一部分，子查询要用（）引起来，并且要给这个子查询取别名，把它当成一个`临时的虚拟的表`使用\n> \n\n**在ORDER BY中使用子查询**\nEG：查询员工的id,salary,按照department_name 排序\n```mysql\nSELECT employee_id,salary\nFROM employees e\nORDER BY (\n\t  SELECT department_name\n\t  FROM departments d\n\t  WHERE e.`department_id` = d.`department_id`\n\t);\n```\n\nEG：若employees表中employee_id与job_history表中employee_id相同的数目不小于2，输出这些相同id的员工的employee_id,last_name和其job_id\n```mysql\nSELECT e.employee_id, last_name,e.job_id\nFROM   employees e \nWHERE  2 <= (SELECT COUNT(*)\n             FROM   job_history \n             WHERE  employee_id = e.employee_id);\n```\n\n**EXISTS 与NOT EXISTS关键字**\n- 关联子查询通常也会和 EXISTS操作符一起来使用，用来检查在子查询中是否存在满足条件的行\n- 如果子查询中不存在满足条件的行：\n\t- 条件返回 FALSE\n\t- 继续在子查询中查找\n- 如果在子查询中存在满足条件的行：\n\t- 不在子查询中继续查找\n\t- 条件返回 TRUE\n- NOT EXISTS关键字表示不存在某种条件，则返回TRUE，否则返回FALSE\n\nEG：查询公司管理者的employee_id，last_name，job_id，department_id信息\n方式一：\n```mysql\nSELECT employee_id, last_name, job_id, department_id\nFROM   employees e1\nWHERE  EXISTS ( SELECT *\n                 FROM   employees e2\n                 WHERE  e2.manager_id = \n                        e1.employee_id);\n```\n\n方式二：自连接\n```mysql\nSELECT DISTINCT e1.employee_id, e1.last_name, e1.job_id, e1.department_id\nFROM   employees e1 JOIN employees e2\nWHERE e1.employee_id = e2.manager_id;\n```\n\n方式三：\n```mysql\nSELECT employee_id,last_name,job_id,department_id\nFROM employees\nWHERE employee_id IN (\n\t\t     SELECT DISTINCT manager_id\n\t\t     FROM employees\n\t\t     \n\t\t     );\n```\n\nEG：查询departments表中，不存在于employees表中的部门的department_id和department_name\n```mysql\nSELECT department_id, department_name\nFROM departments d\nWHERE NOT EXISTS (SELECT 'X'\n                  FROM   employees\n                  WHERE  department_id = d.department_id);\n```\n\n**相关更新**\n```sql\nUPDATE table1 alias1\nSET    column = (SELECT expression\n                 FROM   table2 alias2\n                 WHERE  alias1.column = alias2.column);\n```\n\n使用相关子查询依据一个表中的数据更新另一个表的数据。\n\nEG：在employees中增加一个department_name字段，数据为员工对应的部门名称\n\n```mysql\n# 1）\nALTER TABLE employees\nADD(department_name VARCHAR2(14));\n\n# 2）\nUPDATE employees e\nSET department_name =  (SELECT department_name \n\t                       FROM   departments d\n\t                       WHERE  e.department_id = d.department_id);\n```\n\n**相关删除**\n```sql\n DELETE FROM table1 alias1\n WHERE column operator (SELECT expression\n                        FROM   table2 alias2\n                        WHERE  alias1.column = alias2.column);\n```\n\n使用相关子查询依据一个表中的数据删除另一个表的数据。\n\nEG：删除表employees中，其与emp_history表皆有的数据\n\n```sql\nDELETE FROM employees e\nWHERE employee_id in  \n           (SELECT employee_id\n            FROM   emp_history \n            WHERE  employee_id = e.employee_id);\n```\n\n**思考题**\n\nQA：谁的工资比Abel的高？\n```mysql\n#方式1：自连接\nSELECT e2.last_name,e2.salary\nFROM employees e1,employees e2\nWHERE e1.last_name = 'Abel'\nAND e1.`salary` < e2.`salary`\n\n#方式2：子查询\nSELECT last_name,salary\nFROM employees\nWHERE salary > (\n\t\tSELECT salary\n\t\tFROM employees\n\t\tWHERE last_name = 'Abel'\n\t\t);\n```\n\nQA：以上两种方式有好坏之分吗？\n自连接方式好\n\n题目中可以使用子查询，也可以使用自连接。一般情况建议你使用自连接，因为在许多 DBMS 的处理过程中，对于自连接的处理速度要比子查询快得多\n\n可以这样理解：子查询实际上是通过未知表进行查询后的条件判断，而自连接是通过已知的自身数据表进行条件判断，因此在大部分 DBMS 中都对自连接处理进行了优化\n\n# 表创建与管理\n## 标识符命名规则\n- 数据库名、表名不得超过30个字符，变量名限制为29个\n- 必须只能包含 A–Z, a–z, 0–9, `_`共63个字符\n- 数据库名、表名、字段名等对象名中间不要包含空格\n- 同一个MySQL软件中，数据库不能同名；同一个库中，表不能重名；同一个表中，字段不能重名\n- 必须保证你的字段没有和保留字、数据库系统或常用方法冲突。如果坚持使用，请在SQL语句中使用（着重号）引起来\n- 保持字段名和类型的一致性：在命名字段并为其指定数据类型的时候一定要保证一致性，假如数据类型在一个表里是整数，那在另一个表里可就别变成字符型了\n\n## 数据类型\n| 类型             | 类型举例                                                     |\n| ---------------- | ------------------------------------------------------------ |\n| 整数类型         | TINYINT、SMALLINT、MEDIUMINT、**INT(或INTEGER)**、BIGINT     |\n| 浮点类型         | FLOAT、DOUBLE                                      |\n| 定点数类型       | **DECIMAL**                          |\n| 位类型           | BIT                                         |\n| 日期时间类型     | YEAR、TIME、**DATE**、DATETIME、TIMESTAMP         |\n| 文本字符串类型   | CHAR、**VARCHAR**、TINYTEXT、TEXT、MEDIUMTEXT、LONGTEXT      |\n| 枚举类型         | ENUM                                    |\n| 集合类型         | SET                                         |\n| 二进制字符串类型 | BINARY、VARBINARY、TINYBLOB、BLOB、MEDIUMBLOB、LONGBLOB|\n| JSON类型         | JSON对象、JSON数组                                |\n| 空间数据类型     | 单值：GEOMETRY、POINT、LINESTRING、POLYGON；<br/>集合：MULTIPOINT、MULTILINESTRING、MULTIPOLYGON、GEOMETRYCOLLECTION |\n\n常用几种数据类型：\n| 数据类型      | 描述                                                         |\n| ------------- | ------------------------------------------------------------ |\n| INT           | 从-2^31到2^31-1的整型数据。存储大小为 4个字节          |\n| CHAR(size)    | 定长字符数据。若未指定，默认为1个字符，最大长度255           |\n| VARCHAR(size) | 可变长字符数据，根据字符串实际长度保存，**必须指定长度**     |\n| FLOAT(M,D)    | 单精度，占用4个字节，M=整数位+小数位，D=小数位。 D<=M<=255,0<=D<=30，默认M+D<=6 |\n| DOUBLE(M,D)   | 双精度，占用8个字节，D<=M<=255,0<=D<=30，默认M+D<=15     |\n| DECIMAL(M,D)  | 高精度小数，占用M+2个字节，D<=M<=65，0<=D<=30，最大取值范围与DOUBLE相同。 |\n| DATE          | 日期型数据，格式'YYYY-MM-DD'                         |\n| BLOB          | 二进制形式的长文本数据，最大可达4G                      |\n| TEXT          | 长文本数据，最大可达4G      |\n\n## 创建数据库\n- 方式1：创建数据库\n```mysql\nCREATE DATABASE 数据库名; \n```\n\n- 方式2：创建数据库并指定字符集\n```mysql\nCREATE DATABASE 数据库名 CHARACTER SET 字符集;\n```\n\n- 方式3：判断数据库是否已经存在，不存在则创建数据库（`推荐`）\n```mysql\nCREATE DATABASE IF NOT EXISTS 数据库名; \n```\n\n如果MySQL中已经存在相关的数据库，则忽略创建语句，不再创建数据库。\n> 注意：DATABASE 不能改名。一些可视化工具可以改名，它是建新库，把所有表复制到新库，再删旧库完成的。\n> \n\n## 使用数据库\n- 查看当前所有的数据库\n```mysql\nSHOW DATABASES; #有一个S，代表多个数据库\n```\n\n- 查看当前正在使用的数据库\n```mysql\nSELECT DATABASE();  #使用的一个 mysql 中的全局函数\n```\n\n- 查看指定库下所有的表\n```mysql\nSHOW TABLES FROM 数据库名;\n```\n\n- 查看数据库的创建信息\n```mysql\nSHOW CREATE DATABASE 数据库名;\n或者：\nSHOW CREATE DATABASE 数据库名\\G\n```\n\n- 使用/切换数据库\n```mysql\nUSE 数据库名;\n```\n\n> 注意：要操作表格和数据之前必须先说明是对哪个数据库进行操作，否则就要对所有对象加上“数据库名.”\n> \n\n## 修改数据库\n- 更改数据库字符集\n```mysql\nALTER DATABASE 数据库名 CHARACTER SET 字符集;  #比如：gbk、utf8等\n```\n\n## 删除数据库\n- 方式1：删除指定的数据库\n```mysql\nDROP DATABASE 数据库名;\n```\n\n- 方式2：删除指定的数据库（`推荐`）\n```mysql\nDROP DATABASE IF EXISTS 数据库名;\n```\n\n## 创建表\n### 方式一\n\n**必须具备：**\n- CREATE TABLE权限\n- 存储空间\n\n**语法格式：**\n```mysql\nCREATE TABLE [IF NOT EXISTS] 表名(\n\t字段1, 数据类型 [约束条件] [默认值],\n\t字段2, 数据类型 [约束条件] [默认值],\n\t字段3, 数据类型 [约束条件] [默认值],\n\t……\n\t[表约束条件]\n);\n```\n\n> 加上了IF NOT EXISTS关键字，则表示：如果当前数据库中不存在要创建的数据表，则创建数据表；如果当前数据库中已经存在要创建的数据表，则忽略建表语句，不再创建数据表。\n> \n\n**必须指定：**\n- 表名\n- 字段名，数据类型及长度\n\n**可选条件：**\n- 约束条件\n- 默认值\n\nEG-1：\n```mysql\n-- 创建表\nCREATE TABLE emp (\n  -- int类型\n  emp_id INT,\n  -- 最多保存20个中英文字符\n  emp_name VARCHAR(20),\n  -- 总位数不超过15位\n  salary DOUBLE,\n  -- 日期类型\n  birthday DATE\n);\n```\n\n> MySQL在执行建表语句时，将id字段的类型设置为int(11)，这里的11实际上是int类型指定的显示宽度，默认的显示宽度为11。也可以在创建数据表的时候指定数据的显示宽度。\n> \n\nEG-2：\n```mysql\nCREATE TABLE dept(\n    -- int类型，自增\n\tdeptno INT(2) AUTO_INCREMENT,\n\tdname VARCHAR(14),\n\tloc VARCHAR(13),\n    -- 主键\n    PRIMARY KEY (deptno)\n);\n```\n\n> 在MySQL 8.x版本中，不再推荐为INT类型指定显示长度，并在未来的版本中可能去掉这样的语法。\n> \n\n### 方式二\n- 使用 AS subquery 选项，**将创建表和插入数据结合起来**\n- 指定的列和子查询中的列要一一对应\n- 通过列名和默认值定义列\n\n```mysql\nCREATE TABLE emp1 AS SELECT * FROM employees;\n\nCREATE TABLE emp2 AS SELECT * FROM employees WHERE 1=2; -- 创建的emp2是空表\n```\n\n```mysql\nCREATE TABLE dept80\nAS \nSELECT  employee_id, last_name, salary*12 ANNSAL, hire_date\nFROM    employees\nWHERE   department_id = 80;\n```\n\n## 查看表结构\n在MySQL中创建好数据表之后，可以查看数据表的结构。MySQL支持使用`DESCRIBE/DESC`语句查看数据表结构，也支持使用`SHOW CREATE TABLE`语句查看数据表结构。\n\n语法格式如下：\n```mysql\nSHOW CREATE TABLE 表名\\G\n```\n\n使用SHOW CREATE TABLE语句不仅可以查看表创建时的详细语句，还可以查看存储引擎和字符编码。\n\n## 修改表\n修改表指的是修改数据库中已经存在的数据表的结构。\n\n**使用 ALTER TABLE 语句可以实现：**\n- 向已有的表中添加列\n- 修改现有表中的列\n- 删除现有表中的列\n- 重命名现有表中的列\n\n### 追加列\n语法格式：\n```mysql\nALTER TABLE 表名 ADD 【COLUMN】 字段名 字段类型 【FIRST|AFTER 字段名】;\n```\n\nEG：\n```mysql\nALTER TABLE dept80 \nADD job_id varchar(15);\n```\n\n## 修改列\n- 可以修改列的数据类型，长度、默认值和位置\n\n- 修改字段数据类型、长度、默认值、位置的语法格式如下：\n\n```mysql\nALTER TABLE 表名 MODIFY 【COLUMN】 字段名1 字段类型 【DEFAULT 默认值】【FIRST|AFTER 字段名2】;\n```\n\n- 举例：\n\n```mysql\nALTER TABLE\tdept80\nMODIFY last_name VARCHAR(30);\n```\n\n```mysql\nALTER TABLE\tdept80\nMODIFY salary double(9,2) default 1000;\n```\n\n> 对默认值的修改只影响今后对表的修改\n> 此外，还可以通过此种方式修改列的约束。这里暂先不讲。\n> \n\n## 重命名列\n使用 CHANGE old_column  new_column  dataType子句重命名列。语法格式如下：\n\n```mysql\nALTER TABLE 表名 CHANGE 【column】 列名 新列名 新数据类型;\n```\n\n举例：\n\n```mysql\nALTER TABLE  dept80\nCHANGE department_name dept_name varchar(15); \n```\n\n## 删除列\n删除表中某个字段的语法格式如下：\n\n```mysql\nALTER TABLE 表名 DROP 【COLUMN】字段名\n```\n\n举例：\n```mysql\nALTER TABLE  dept80\nDROP COLUMN  job_id; \n```\n\n## 重命名表\n- 方式一：使用RENAME\n```mysql\nRENAME TABLE emp\nTO myemp;\n```\n\n- 方式二：\n```mysql\nALTER table dept\nRENAME [TO] detail_dept;  -- [TO]可以省略\n```\n\n- 必须是对象的拥有者\n\n## 删除表\n- 在MySQL中，当一张数据表`没有与其他任何数据表形成关联关系`时，可以将当前数据表直接删除。\n- 数据和结构都被删除\n- 所有正在运行的相关事务被提交\n- 所有相关索引被删除\n\n语法格式：\n```mysql\nDROP TABLE [IF EXISTS] 数据表1 [, 数据表2, …, 数据表n];\n```\n\n`IF EXISTS`的含义为：如果当前数据库中存在相应的数据表，则删除数据表；如果当前数据库中不存在相应的数据表，则忽略删除语句，不再执行删除数据表的操作。\n\nEG：\n```mysql\nDROP TABLE dept80;\n```\n\n> DROP TABLE 语句不能回滚\n> \n\n## 清空表\n- TRUNCATE TABLE语句：\n  - 删除表中所有的数据\n  - 释放表的存储空间\n\nEG：\n```mysql\nTRUNCATE TABLE detail_dept;\n```\n\n- TRUNCATE语句**不能回滚**，而使用 DELETE 语句删除数据，可以回滚\n- 对比：\n\n```mysql\nSET autocommit = FALSE;\n  \nDELETE FROM emp2; \n#TRUNCATE TABLE emp2;\n  \nSELECT * FROM emp2;\n  \nROLLBACK;\n  \nSELECT * FROM emp2;\n```\n\n> 阿里开发规范：\n>\n> 【参考】TRUNCATE TABLE 比 DELETE 速度快，且使用的系统和事务日志资源少，但 TRUNCATE 无事务且不触发 TRIGGER，有可能造成事故，故不建议在开发代码中使用此语句。 \n>\n> 说明：TRUNCATE TABLE 在功能上与不带 WHERE 子句的 DELETE 语句相同。\n> \n\n## 拓展 \n**阿里规范《Java开发手册》规范**\n- 【`强制`】表名、字段名必须使用小写字母或数字，禁止出现数字开头，禁止两个下划线中间只出现数字。数据库字段名的修改代价很大，因为无法进行预发布，所以字段名称需要慎重考虑。\n  - 正例：aliyun_admin，rdc_config，level3_name \n  - 反例：AliyunAdmin，rdcConfig，level_3_name\n\n- 【`强制`】禁用保留字，如 desc、range、match、delayed 等，请参考 MySQL 官方保留字。\n\n- 【`强制`】表必备三字段：id, gmt_create, gmt_modified。 \n\n  - 说明：其中 id 必为主键，类型为BIGINT UNSIGNED、单表时自增、步长为 1。gmt_create, gmt_modified 的类型均为 DATETIME 类型，前者现在时表示主动式创建，后者过去分词表示被动式更新\n\n- 【`推荐`】表的命名最好是遵循 “业务名称_表的作用”。 \n  - 正例：alipay_task 、 force_project、 trade_config\n\n- 【`推荐`】库名与应用名称尽量一致。\n\n- 【参考】合适的字符存储长度，不但节约数据库表空间、节约索引存储，更重要的是提升检索速度。 \n  - 正例：无符号值可以避免误存负数，且扩大了表示范围。\n\n**如何理解清空表、删除表等操作需谨慎？**\n`表删除`操作将把表的定义和表中的数据一起删除，并且MySQL在执行删除操作时，不会有任何的确认信息提示，因此执行删除操时应当慎重。在删除表前，最好对表中的数据进行`备份`，这样当操作失误时可以对数据进行恢复，以免造成无法挽回的后果。\n\n同样的，在使用 `ALTER TABLE` 进行表的基本修改操作时，在执行操作过程之前，也应该确保对数据进行完整的`备份`，因为数据库的改变是`无法撤销`的，如果添加了一个不需要的字段，可以将其删除；相同的，如果删除了一个需要的列，该列下面的所有数据都将会丢失。\n\n**MySQL8新特性—DDL的原子化**\n在MySQL 8.0版本中，InnoDB表的DDL支持事务完整性，即`DDL操作要么成功要么回滚`。DDL操作回滚日志写入到data dictionary数据字典表mysql.innodb_ddl_log（该表是隐藏的表，通过show tables无法看到）中，用于回滚操作。通过设置参数，可将DDL操作日志打印输出到MySQL错误日志中。\n\n分别在MySQL 5.7版本和MySQL 8.0版本中创建数据库和数据表，结果如下：\n```mysql\nCREATE DATABASE mytest;\n\nUSE mytest;\n\nCREATE TABLE book1(\nbook_id INT ,\nbook_name VARCHAR(255)\n);\n\nSHOW TABLES;\n```\n\n（1）在MySQL 5.7版本中，测试步骤如下：\n删除数据表book1和数据表book2，结果如下：\n```mysql\nmysql> DROP TABLE book1,book2;\nERROR 1051 (42S02): Unknown table 'mytest.book2'\n```\n\n再次查询数据库中的数据表名称，结果如下：\n```mysql\nmysql> SHOW TABLES;\nEmpty set (0.00 sec)\n```\n\n从结果可以看出，虽然删除操作时报错了，但是仍然删除了数据表book1。\n\n（2）在MySQL 8.0版本中，测试步骤如下：\n删除数据表book1和数据表book2，结果如下：\n```mysql\nmysql> DROP TABLE book1,book2;\nERROR 1051 (42S02): Unknown table 'mytest.book2'\n```\n\n再次查询数据库中的数据表名称，结果如下：\n```mysql\nmysql> show tables;\n+------------------+\n| Tables_in_mytest |\n+------------------+\n| book1            |\n+------------------+\n1 row in set (0.00 sec)\n```\n\n从结果可以看出，数据表book1并没有被删除。\n\n# 表之增删改\n\n# 数据类型\n\n# 约束","categories":["mysql"]},{"title":"SpringBoot-注解","url":"/2021/11/15/springboot-zhu-jie/","content":"### @Configuration\n注释类，向SpringBoot表示该类为一个配置类。该注解有一个属性proxyBeanMethods，默认为true，表示该类被SpringBoot所代理，可以理解为该被SpringBoot托管。\n@Configuration配置类本身也是一个组件，组件ID为类名（首字母小写）。\n\n### @Bean\n用来注释方法，要和 “能将类作为组件添加到容器中” 的注解组合使用，例如@Configuration和@Conpoment。表示向IOC容器中添加一个组件，组件ID默认为方法名，组件实例为方法的返回值。\n当@Configuration的 proxyBeanMethods=true 时，当使用类对象调用注解了@Bean的方法时，SpringBoot会去容器中寻找该组件，返回该组件的引用，而不是重新构造一个对象实例。多次从获取时，仍然引用的是容器中组件实例，即该方法的返回值保持单实例。\n当@Configuration的proxyBeanMethods=false时，表示配置类不会由SpringBoot所代理，使用类对象调用注解@Bean方法时，SpringBoot不会去容器中寻找组件，而是直接创建一个实例，每次调用都会创建不同的实例。\n\n```java\n@Configuration(\"haha\")\npublic class test {\n    @Bean\n    public User user(){\n        return new User();\n    }\n}\n\n@SpringBootApplication\npublic class DemoApplication {\n\n    public static void main(String[] args) {\n        ConfigurableApplicationContext app = SpringApplication.run(DemoApplication.class, args);\n        System.out.println(app.containsBean(\"haha\"));\n        System.out.println(app.containsBean(\"user\"));\n    }\n}\n```\n输出结果为：{% asset_img 01.png 输出结果 %}\n\n#### 组件依赖：\n小结：注解@Bean和@Configuration表示在SpringBoot启动时，像容器中添加一个组件。但是如果proxyBeanMethods=true，表示该类被SpringBoot代理。 \n注意：如果使用普通方式，通过构造方法创建是实例时，和注解@Configuration、@Bean没有任何关系。\n\n### @Import\n注释类。表示向容器中添加组件。\n使用方式：@Import(\"***class\", \"***.class\")，组件名为全类名\n\n### @Component\n\n标注在类上，表示将该类作为一个组件添加到Spring容器中。\n\n### @ConfigurationProperties\n@ConfigurationProperties注解可以和@Component搭配（同一类中），也可以和@EnableConfigurationProperties搭配（不同类中）。\n@ConfigurationProperties将类的属性和配置文件中的属性进行绑定。如果该类只有@ConfigurationProperties注解而没有@Component注解，那么配置绑定功能是无法实现的，因为该类没有被作为组件添加到Spring容器中（不能享受Spring容器带来的强大功能），此时可以在其他类中使用@EnableConfigurationProperties注解，将类添加到容器中，开启配置绑定功能。\n代码示例：\n\n```java\npackage org.springframework.boot.autoconfigure.web;\n@ConfigurationProperties(\"spring.web\")\npublic class WebProperties {\n\n\tpublic static class Resources {\n        //和配置文件application.properties中的 spring.web.resources.static-locations 进行绑定\n\t\tprivate String[] staticLocations = CLASSPATH_RESOURCE_LOCATIONS;\n\t}\n}\n```\n\n### @EnableConfigurationProperties\n对只有@ConfigurationProperties注解而没有@Component注解的配置类，使用@EnableConfigurationProperties将配置类添加到容器中。\n代码示例：\n\n```java\npackage org.springframework.boot.autoconfigure.web.servlet;\n@Configuration(proxyBeanMethods = false)\n@ConditionalOnWebApplication(type = Type.SERVLET)\n@ConditionalOnClass({ Servlet.class, DispatcherServlet.class, WebMvcConfigurer.class })\n@ConditionalOnMissingBean(WebMvcConfigurationSupport.class)\n@AutoConfigureOrder(Ordered.HIGHEST_PRECEDENCE + 10)\n@AutoConfigureAfter({ DispatcherServletAutoConfiguration.class, TaskExecutionAutoConfiguration.class,\n\t\tValidationAutoConfiguration.class })\npublic class WebMvcAutoConfiguration {\n\n\t@Configuration(proxyBeanMethods = false)\n\t@Import(EnableWebMvcConfiguration.class)\n\t@EnableConfigurationProperties({ WebMvcProperties.class,\n\t\t\torg.springframework.boot.autoconfigure.web.ResourceProperties.class, WebProperties.class })\n\t@Order(0)\n\tpublic static class WebMvcAutoConfigurationAdapter implements WebMvcConfigurer, ServletContextAware {\n\t\n\t}\n}\n\n\npackage org.springframework.boot.autoconfigure.web.servlet;\n@ConfigurationProperties(prefix = \"spring.mvc\")\npublic class WebMvcProperties {\n\n}\n```\n\n### 参数自动封装\n表单的字段会被自动封装到参数对象中。表单name属性的值要和对象的属性名一致，否则会封装失败，造成对象的属性值为null的情况。\n代码示例：\n\n```java\n@GetMapping(\"/form_createManager\")\n    public String createManager(Manager manager){\n        if(managerService.isExitsByManagerName(manager.getName())){\n            return \"redirect:/createManager.html\";\n        }else {\n            managerService.add(manager);\n            return \"redirect:/listManager.html\";\n        }\n    }\n```\n```html\n<form action=\"/form_createManager\">\n    <input type=\"text\" placeholder=\"姓名\" name=\"name\">\n    <input type=\"text\" placeholder=\"手机\" name=\"phone\">\n    <input type=\"email\" placeholder=\"邮箱\" name=\"email\">\n    <input type=\"submit\" value=\"提交\">\n</form>\n```","tags":["注解"],"categories":["SpringBoot"]},{"title":"前端杂记","url":"/2021/10/30/qian-duan-za-ji/","content":"# HTML\n#### textarea\ntextarea标签：\n```\n\tcols:字符列数\n\trows:字符行数\n\treadonly:值true/false 是否设为只读\n```\n去除首行缩进：将首尾标签放在同一行\n```\n\t<textarea>hello</textarea>\n```\n去除下拉斜线：添加属性 resize: none\n```\n\t<textarea style=\"resize: none;\">hello</textarea>\n```\n去除滚动条：添加属性 overflow: hidden\n```\n\t<textarea style=\"overflow: hidden;\">hello</textarea>\n```\n去除边框：添加属性border: none\n```\n\t<textarea style=\"border: none;\">hello</textarea>\n```\n去除点击文本时的边框：添加属性 outline: none\n```\n\t<textarea style=\"outline: none;\">hello</textarea\n```\n显示高度自适应：\n```\n\t<textarea  autoHeight=\"true\" readonly=\"readonly\" style=\"resize: \t\tnone; border: none; overflow: hidden; outline: \t\n\tnone;\">qwerrtyuiopasdfghjklzxcnm1234567890qwertyuiopasdfghjklzxcvbnm\n\t</textarea>\n```\n```js\n$(function(){\n        $.fn.autoHeight = function(){    \n            function autoHeight(elem){\n                elem.style.height = 'auto';\n                elem.scrollTop = 0; //防抖动\n                elem.style.height = elem.scrollHeight + 'px';\n            }\n            this.each(function(){\n                autoHeight(this);\n                $(this).on('keyup', function(){\n                    autoHeight(this);\n                });\n            });     \n}                \n   $('textarea[autoHeight]').autoHeight();    \n})\n```\ntextarea自适应小问题：实际textarea的宽度比文字行数多了一行\n\n```\n<!--单个媒体对象 start-->\n<div class=\"media\">\n<div class=\"media-left\">\n<a href=\"#\">\n<img class=\"media-object\" src=\"../images/72534562.jpg\" alt=\"头像\" width=\"64px\" height=\"64px\">\n<h5 style=\"margin: 0px;text-align: center;\">用户名</h5>\n</a>\n</div>\n<div class=\"media-body\">\n<h4 class=\"media-heading\">Media heading</h4>\n<textarea cols=\"50\" rows=\"3\" style=\"resize: none; border: none; overflow: hidden; outline: none;\" readonly=\"true\">Cras sit amet nibh libero, in gravida nulla. Nulla vel metus scelerisque ante sollicitudin commodo.</textarea>\n</div>\n</div>\n<!--单个媒体对象 end-->\n```\n\n# thymeleaf\n### 动态包含页面\n```js\n<script>\n    $(\"#head\").load(\"public/head.html\");\n</script>\n```\n### IDEA创建SpringBoot项目\n#### 重定向\n重定向的默认访问路径是Resource/templates,想要访问Resource/static下的静态资源返回字符串要明确添加redirect，例如 return \"redirect:html/hello.html\"\n\n### bootstrap&thymeleaf\n二者不兼容：bootstrap静态页面经由thymeleaf动态打开后静态页面样式消失\n\n### 动态创建列表\n代码示例：\n```\n<table>\n    <thead>\n    <tr>\n        <th>管理者名称</th>\n        <th>手机</th>\n    </tr>\n    </thead>\n    <tbody>\n    <tr th:each=\"manager : ${manager_list}\">\n        <td th:text=\"${manager.getName()}\"></td>\n        <td th:text=\"${manager.phone}\"></td>\n    </tr>\n    </tbody>\n</table>\n```\n1. 向request中放入一个名manager_list的List类型对象。\n\t向Request、Model、ModelAndView中放入数据，都是一样的效果，因为三者最终都将数据放入了同一个地方（雷神SpringBoot2中有讲）\n2. 使用Thymeleaf取数据，显示在列表中。\n\t${manager_list}:取出request中key为manager_list的对象\n\t${manager.getName()}和${manager.phone}两种方法都可以获取对象manager的属性\n\n### Thymeleaf常见错误\n1. 路径拼写错误。\n\t使用了Thymeleaf模板，默认使用了@Controller类的字符串返回类型会被当作转发请求，且返回的字符串不需要带后缀\".html'，因为Thymeleaf会默认去寻找html文件。如果想使用重定向，需要使用：return \"redirect:请求路径\"。\n2. thymeleaf获取request、session中的参数错误。\n\t使用thymeleaf表达式 ${...} 获取数据时，一定要确保在到达该页面前一定已经向对应的request、session中放入了要取的数据，否则也会造成错误。\n\t使用 ${对象.属性} 或 ${对象.方法} 获取数据时，一定确保属性名和方法名和Java类中的保持一致，即使少了一个字母也会报错\n\n###  background-image: url() 拼接\n\n设置背景\n```html\n<div th:style=\"'background:url(' + @{/<path-to-image>} + ');'\"></div>\n```\n根据属性值改变背景\n```html\n<div class=\"media-object resource-card-image\"  th:style=\"'background:url(' + @{(${collect.webLogo}=='' ? 'img/favicon.png' : ${collect.webLogo})} + ')'\" ></div>\n```\n\n### 行内写法（表达式内联）\n语法：\n```\n<p>Hello, [[${session.user.name}]]!</p>\n```\n禁用内联：\n```\n<p th:inline=\"none\">A double array looks like this: [[1, 2, 3], [4, 5]]!</p>\n```","tags":["bootstrap","thymeleaf"],"categories":["SpringBoot","html"]},{"title":"my-first-blog","url":"/2021/10/17/my-first-blog/","content":"\nHexo + GitHub 搭建个人博客\n===\n环境准备\n---\n\tnpm、git\n使用命令（均在git bash下执行）\n---\n安装Hexo博客框架\n```\n\tnpm install hexo-cli -g\n```\n初始化项目文件夹\n```\n\thexo init 文件夹名称（后面不跟文件名称时，需要自己创建文件，并在切换到对应文件路径下执行该命令\n```\n安装npm依赖。执行上条命令时，会提示dependencies 下载失败。按照提示运行命令。\n```\n\tnpm install\n\t有时使用npm下载不成，可以使用cnpm install，多运行几次就好了（亲试）\n```\n本地预览博客是否搭建成功。执行以下两条命令。\n```\n\thexo g\t#编译静态文件\n\thexo s\t#本地预览\n```\n访问 http://localhost:4000/ 。出现以下页面表示本地搭建成功。\n\n![img](https://gitee.com/lsc180/images/raw/master/img/20201105103838.png)\n\n上线到Github\n---\n准备工作：获取SSH密钥\n\t查看本地有无SSH密钥\n\t```\n\tcd ~/.ssh\n\t```\n\t如果没有则生成密钥。\n\t```\n\tssh-keygen -t rsa -C \"你的邮箱\"\t\t#会提示你设置密钥文件名称，和密码，两者都可以为空，直接回车\n\t```\n\t再次查看密钥文件，查询结果出现***.ssh文件表示成功，同样会显示密钥路径。\nGithub设置SSH密钥\n\t在setting中选中SSH and GPG keys，点击New SSH key，密钥名称任取，密钥内容使用记事本打开生成的密钥文件，复制过去，就ok了。\n安装Github部署插件\n\t```\n\tnpm install hexo-deployer-git --save\n\t```\nGithub创建新库 username.github.io。修改项目目录下的配置文件。如下所示。\n\t```\n\tdeploy:\n  \t\ttype: git\n  \t\trepo: git@github.com:up-bear/up-bear.github.io.git\n \t\t branch: master\n\t```\n部署命令\n\t```\n\thexo d\n\t每次修改博客后，需要使用以下命令重新部署\n\thexo clean\n\thexo g\n\thexo d\n\t```\n访问博客网址username.github.io。\n\n{% meting \"523845661\" \"netease\" \"playlist\" \"theme:#FF4081\" \"mode:circulation\" \"mutex:true\" \"listmaxheight:340px\" \"preload:auto\" %}","categories":["blog"]}]